# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Flower Labs GmbH
# This file is distributed under the same license as the Flower package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
msgid ""
msgstr ""
"Project-Id-Version: Flower main\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-23 18:31+0100\n"
"PO-Revision-Date: 2024-02-10 11:56+0000\n"
"Last-Translator: Yan Gao <y.gaogy@gmail.com>\n"
"Language-Team: Chinese (Simplified) <https://hosted.weblate.org/projects/"
"flower-docs/framework/zh_Hans/>\n"
"Language: zh_Hans\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Weblate 5.4-dev\n"
"Generated-By: Babel 2.13.1\n"

#: ../../source/contributor-explanation-architecture.rst:2
msgid "Flower Architecture"
msgstr "Flower的架构"

#: ../../source/contributor-explanation-architecture.rst:5
msgid "Edge Client Engine"
msgstr "边缘客户端引擎"

#: ../../source/contributor-explanation-architecture.rst:7
msgid ""
"`Flower <https://flower.dev>`_ core framework architecture with Edge Client "
"Engine"
msgstr "具有边缘客户端引擎的`Flower <https://flower.dev>`核心架构"

#: ../../source/contributor-explanation-architecture.rst:13
msgid "Virtual Client Engine"
msgstr "虚拟客户端引擎"

#: ../../source/contributor-explanation-architecture.rst:15
msgid ""
"`Flower <https://flower.dev>`_ core framework architecture with Virtual "
"Client Engine"
msgstr "具有虚拟客户端引擎的`Flower <https://flower.dev>`核心架构"

#: ../../source/contributor-explanation-architecture.rst:21
msgid "Virtual Client Engine and Edge Client Engine in the same workload"
msgstr "可同步进行的虚拟客户端引擎和边缘客户端引擎"

#: ../../source/contributor-explanation-architecture.rst:23
msgid ""
"`Flower <https://flower.dev>`_ core framework architecture with both Virtual "
"Client Engine and Edge Client Engine"
msgstr ""
"具有虚拟客户端引擎和边缘客户端引擎的`Flower <https://flower.dev>`核心架构"

#: ../../source/contributor-how-create-new-messages.rst:2
msgid "Creating New Messages"
msgstr "创建新信息"

#: ../../source/contributor-how-create-new-messages.rst:4
msgid ""
"This is a simple guide for creating a new type of message between the server "
"and clients in Flower."
msgstr "这是一个如何用Flower在服务器和客户端之间创建新类型的信息的简要指导。"

#: ../../source/contributor-how-create-new-messages.rst:6
msgid ""
"Let's suppose we have the following example functions in :code:`server.py` "
"and :code:`numpy_client.py`..."
msgstr ""
"假设我们在脚本code:`server.py`和code:`numpy_client.py`中有以下的示例函数..."

#: ../../source/contributor-how-create-new-messages.rst:8
msgid "Server's side:"
msgstr "在服务器端："

#: ../../source/contributor-how-create-new-messages.rst:17
msgid "Client's side:"
msgstr "在客户端："

#: ../../source/contributor-how-create-new-messages.rst:26
msgid ""
"Let's now see what we need to implement in order to get this simple function "
"between the server and client to work!"
msgstr ""
"现在让我们来看看，为了让服务器和客户端之间的这个简单的函数正常工作，我们需要"
"实现哪些功能！"

#: ../../source/contributor-how-create-new-messages.rst:30
msgid "Message Types for Protocol Buffers"
msgstr "协议缓冲区的信息类型"

#: ../../source/contributor-how-create-new-messages.rst:32
msgid ""
"The first thing we need to do is to define a message type for the RPC system "
"in :code:`transport.proto`. Note that we have to do it for both the request "
"and response messages. For more details on the syntax of proto3, please see "
"the  `official documentation <https://developers.google.com/protocol-buffers/"
"docs/proto3>`_."
msgstr ""
"我们需要做的第一件事是在脚本code:`transport.proto`中定义 RPC 系统的消息类型。"
"请注意，我们必须对请求信息和响应信息都这样做。有关 proto3 语法的更多详情，请"
"参阅官方文档 <https://developers.google.com/protocol-buffers/docs/proto3>`_。"

#: ../../source/contributor-how-create-new-messages.rst:35
msgid "Within the :code:`ServerMessage` block:"
msgstr "在 :code:`ServerMessage` 代码块中："

#: ../../source/contributor-how-create-new-messages.rst:52
msgid "Within the ClientMessage block:"
msgstr "在 ClientMessage 代码块中："

#: ../../source/contributor-how-create-new-messages.rst:70
msgid ""
"Make sure to also add a field of the newly created message type in :code:"
"`oneof msg`."
msgstr "确保在 :code:`oneof msg` 中也添加一个新创建的消息类型字段。"

#: ../../source/contributor-how-create-new-messages.rst:72
msgid "Once that is done, we will compile the file with:"
msgstr "完成后，我们将使用："

#: ../../source/contributor-how-create-new-messages.rst:78
msgid "If it compiles succesfully, you should see the following message:"
msgstr "如果编译成功，你应该会看到以下信息："

#: ../../source/contributor-how-create-new-messages.rst:87
msgid "Serialization and Deserialization Functions"
msgstr "序列化和反序列化函数"

#: ../../source/contributor-how-create-new-messages.rst:89
msgid ""
"Our next step is to add functions to serialize and deserialize Python "
"datatypes to or from our defined RPC message types. You should add these "
"functions in :code:`serde.py`."
msgstr ""
"下一步是添加函数，以便将 Python 数据类型序列化和反序列化为我们定义的 RPC 消息"
"类型或从我们定义的 RPC 消息类型反序列化和反序列化 Python 数据类型。您应该在 :"
"code:`serde.py` 中添加这些函数。"

#: ../../source/contributor-how-create-new-messages.rst:91
msgid "The four functions:"
msgstr "四种函数："

#: ../../source/contributor-how-create-new-messages.rst:112
msgid "Sending the Message from the Server"
msgstr "从服务器发送信息"

#: ../../source/contributor-how-create-new-messages.rst:114
msgid ""
"Now write the request function in your Client Proxy class (e.g., :code:"
"`grpc_client_proxy.py`) using the serde functions you just created:"
msgstr ""
"现在，在客户端代理类（例如 :code:`grpc_client_proxy.py`）中使用刚才创建的 "
"serde 函数编写请求函数："

#: ../../source/contributor-how-create-new-messages.rst:128
msgid "Receiving the Message by the Client"
msgstr "由客户端接收信息"

#: ../../source/contributor-how-create-new-messages.rst:130
msgid ""
"Last step! Modify the code in :code:`message_handler.py` to check the field "
"of your message and call the :code:`example_response` function. Remember to "
"use the serde functions!"
msgstr ""
"最后一步 修改 :code:`message_handler.py` 中的代码，检查信息的字段并调用 :"
"code:`example_response` 函数。记住使用 serde 函数！"

#: ../../source/contributor-how-create-new-messages.rst:132
msgid "Within the handle function:"
msgstr "在句柄函数内："

#: ../../source/contributor-how-create-new-messages.rst:139
msgid "And add a new function:"
msgstr "并增加一个新函数："

#: ../../source/contributor-how-create-new-messages.rst:149
msgid "Hopefully, when you run your program you will get the intended result!"
msgstr "希望您在运行程序时能得到预期的结果！"

#: ../../source/contributor-how-to-contribute-translations.rst:2
msgid "Contribute translations"
msgstr "贡献译文"

#: ../../source/contributor-how-to-contribute-translations.rst:4
msgid ""
"Since `Flower 1.5 <https://flower.dev/docs/framework/ref-changelog."
"html#v1-5-0-2023-08-31>`_ we have introduced translations to our doc pages, "
"but, as you might have noticed, the translations are often imperfect. If you "
"speak languages other than English, you might be able to help us in our "
"effort to make Federated Learning accessible to as many people as possible "
"by contributing to those translations! This might also be a great "
"opportunity for those wanting to become open source contributors with little "
"prerequistes."
msgstr ""
"从 `Flower 1.5 <https://flower.dev/docs/framework/ref-changelog."
"html#v1-5-0-2023-08-31>`_ 开始，我们在文档页面中引入了翻译，但正如你可能已经"
"注意到的，这些翻译往往并不完美。如果您会说英语以外的语言，也许您可以帮助我们"
"翻译这些文档，让更多的人了解 Federated Learning！对于那些想成为开源贡献者的人"
"来说，这也是一个很好的机会。"

#: ../../source/contributor-how-to-contribute-translations.rst:13
msgid ""
"Our translation project is publicly available over on `Weblate <https://"
"hosted.weblate.org/projects/flower-docs/framework/>`_, this where most of "
"the work will happen."
msgstr ""
"我们的翻译项目已在 \"Weblate <https://hosted.weblate.org/projects/flower-"
"docs/framework/>`_\"上公开，大部分工作都将在这里进行。"

#: ../../source/contributor-how-to-contribute-translations.rst:18
msgid "Contribute to existing languages"
msgstr "为现有语言作出贡献"

#: ../../source/contributor-how-to-contribute-translations.rst:23
msgid ""
"The first thing you will need to do in order to contribute is to create a "
"free Weblate account on this `page <https://hosted.weblate.org/accounts/"
"register/>`_. More information about profile settings can be found `here "
"<https://docs.weblate.org/en/latest/user/profile.html>`_."
msgstr ""
"您需要做的第一件事就是在本`网页<https://hosted.weblate.org/accounts/register/"
">`_上创建一个免费的Weblate帐户。有关个人资料设置的更多信息，请参阅`这里 "
"<https://docs.weblate.org/en/latest/user/profile.html>`_。"

#: ../../source/contributor-how-to-contribute-translations.rst:29
msgid ""
"Once you are signed in to Weblate, you can navigate to the `Flower Framework "
"project <https://hosted.weblate.org/projects/flower-docs/framework/>`_. "
"Here, you should see the different existing languages that can be found on "
"the website."
msgstr ""
"登录到Weblate后，您可以导航到 \"Flower Framework \"项目<https://hosted."
"weblate.org/projects/flower-docs/framework/>`_。在这里，您可以看到网站上现有"
"的各种语言。"

#: ../../source/contributor-how-to-contribute-translations.rst:34
msgid ""
"Once you have selected the language you want to contribute to, you should "
"see a similar interface to this:"
msgstr "选择您要贡献的语言后，您应该会看到与此类似的界面："

#: ../../source/contributor-how-to-contribute-translations.rst:39
msgid ""
"The most straight forward option here is to click on the ``Translate`` "
"button on the top right (in the ``Translation status`` section). This will "
"automatically bring you to the translation interface for untranslated "
"strings."
msgstr ""
"最简单的方法是点击右上角（\"翻译状态 \"部分）的 \"翻译 \"按钮。这将自动带您进"
"入未翻译字符串的翻译界面。"

#: ../../source/contributor-how-to-contribute-translations.rst:43
msgid "This is what the interface looks like:"
msgstr "这就是界面的样子："

#: ../../source/contributor-how-to-contribute-translations.rst:47
msgid ""
"You input your translation in the textbox at the top and then, once you are "
"happy with it, you either press ``Save and continue`` (to save the "
"translation and go to the next untranslated string), ``Save and stay`` (to "
"save the translation and stay on the same page), ``Suggest`` (to add your "
"translation to suggestions for other users to view), or ``Skip`` (to go to "
"the next untranslated string without saving anything)."
msgstr ""
"您可以在顶部的文本框中输入翻译内容，满意后按 \"保存并继续\"（保存翻译内容并转"
"到下一个未翻译的字符串）、\"保存并停留\"（保存翻译内容并停留在同一页"
"面）、\"建议\"（将您的翻译添加到建议中供其他用户查看）或 \"跳过\"（转到下一个"
"未翻译的字符串而不保存任何内容）。"

#: ../../source/contributor-how-to-contribute-translations.rst:54
msgid ""
"In order to help with the translations, you can see on the bottom the "
"``Nearby strings``, the ``Comments`` (from other contributors), the "
"``Automatic suggestions`` (from machine translation engines), the "
"translations in ``Other languages``, and the ``History`` of translations for "
"this string."
msgstr ""
"为了帮助翻译，您可以在底部看到 \"邻近字符串\"、\"评论\"（来自其他贡献"
"者）、\"自动建议\"（来自机器翻译引擎）、\"其他语言 \"中的翻译以及该字符串的 "
"\"历史翻译\"。"

#: ../../source/contributor-how-to-contribute-translations.rst:59
msgid ""
"On the right, under the ``String information`` section, you can also click "
"the link under ``Source string location`` in order to view the source of the "
"doc file containing the string."
msgstr ""
"在右侧的 \"字符串信息 \"部分，您还可以单击 \"源字符串位置 \"下的链接，以查看"
"包含字符串的 doc 文件的源文件。"

#: ../../source/contributor-how-to-contribute-translations.rst:63
msgid ""
"For more information about translating using Weblate, you can check out this "
"`in-depth guide <https://docs.weblate.org/en/latest/user/translating.html>`_."
msgstr ""
"有关使用 Weblate 进行翻译的更多信息，您可以查看本 \"深入指南 <https://docs."
"weblate.org/en/latest/user/translating.html>`_\"。"

#: ../../source/contributor-how-to-contribute-translations.rst:67
msgid "Add new languages"
msgstr "添加新语言"

#: ../../source/contributor-how-to-contribute-translations.rst:69
msgid ""
"If you want to add a new language, you will first have to contact us, either "
"on `Slack <https://flower.dev/join-slack>`_, or by opening an issue on our "
"`GitHub repo <https://github.com/adap/flower>`_."
msgstr ""
"如果您想添加新语言，请先联系我们，可以在 `Slack <https://flower.dev/join-"
"slack>`_ 上联系，也可以在我们的 `GitHub repo <https://github.com/adap/"
"flower>`_ 上提交问题。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:2
msgid "Develop in VSCode Dev Containers"
msgstr "使用 VSCode Dev Containers 进行开发"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:4
msgid ""
"When working on the Flower framework we want to ensure that all contributors "
"use the same developer environment to format code or run tests. For this "
"purpose we are using the VSCode Remote Containers extension. What is it? "
"Read the following quote:"
msgstr ""
"在开发 Flower 框架时，我们希望确保所有贡献者使用相同的开发环境来格式化代码或"
"运行测试。为此，我们使用了 VSCode 远程容器扩展。这是什么？请阅读下面这段话："

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:7
msgid ""
"The Visual Studio Code Remote - Containers extension lets you use a Docker "
"container as a fully-featured development environment. It allows you to open "
"any folder inside (or mounted into) a container and take advantage of Visual "
"Studio Code's full feature set. A :code:`devcontainer.json` file in your "
"project tells VS Code how to access (or create) a development container with "
"a well-defined tool and runtime stack. This container can be used to run an "
"application or to separate tools, libraries, or runtimes needed for working "
"with a codebase."
msgstr ""
"Visual Studio Code Remote - Containers扩展可让你将Docker容器用作功能齐全的开"
"发环境。它允许你打开容器内（或挂载到容器内）的任何文件夹，并利用 Visual "
"Studio Code 的全部功能集。项目中的 :code:`devcontainer.json` 文件会告诉 VS "
"Code 如何访问（或创建）一个带有定义明确的工具和运行时栈的开发容器。该容器可用"
"于运行应用程序，也可用于分离处理代码库所需的工具、库或运行时。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:9
msgid ""
"Workspace files are mounted from the local file system or copied or cloned "
"into the container. Extensions are installed and run inside the container, "
"where they have full access to the tools, platform, and file system. This "
"means that you can seamlessly switch your entire development environment "
"just by connecting to a different container."
msgstr ""
"工作区文件从本地文件系统加载，或复制或克隆到容器中。扩展在容器内安装和运行，"
"在容器内它们可以完全访问工具、平台和文件系统。这意味着，只需连接到不同的容"
"器，就能无缝切换整个开发环境。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:11
msgid ""
"Source: `Official VSCode documentation <https://code.visualstudio.com/docs/"
"remote/containers>`_"
msgstr ""
"来源：`VSCode 官方文档 <https://code.visualstudio.com/docs/remote/"
"containers>`_"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:15
msgid "Getting started"
msgstr "开始"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:17
msgid ""
"Configuring and setting up the :code:`Dockerfile` as well the configuration "
"for the devcontainer can be a bit more involved. The good thing is you want "
"have to do it. Usually it should be enough to install Docker on your system "
"and ensure its available on your command line. Additionally, install the "
"`VSCode Containers Extension <vscode:extension/ms-vscode-remote.remote-"
"containers>`_."
msgstr ""
"配置和设置 :code:`Dockerfile` 以及 devcontainer 的配置可能比较复杂。好在你想"
"做就得做。通常只需在系统中安装 Docker 并确保其在命令行中可用即可。此外，请安"
"装 `VSCode Containers Extension <vscode:extension/ms-vscode-remote.remote-"
"containers>`_。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:19
msgid ""
"Now you should be good to go. When starting VSCode, it will ask you to run "
"in the container environment and - if you confirm - automatically build the "
"container and use it. To manually instruct VSCode to use the devcontainer, "
"you can, after installing the extension, click the green area in the bottom "
"left corner of your VSCode window and select the option *(Re)Open Folder in "
"Container*."
msgstr ""
"现在你应该可以开始了。启动 VSCode 时，它会要求你在容器环境中运行，如果你确"
"认，它会自动构建容器并使用它。要手动指示 VSCode 使用 devcontainer，可以在安装"
"扩展后，点击 VSCode 窗口左下角的绿色区域，然后选择 \"*（重新）在容器中打开文"
"件夹*\"选项。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:21
msgid ""
"In some cases your setup might be more involved. For those cases consult the "
"following sources:"
msgstr "在某些情况下，您的设置可能更复杂。有关这些情况，请参考以下资料："

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:23
msgid ""
"`Developing inside a Container <https://code.visualstudio.com/docs/remote/"
"containers#_system-requirements>`_"
msgstr ""
"在容器内开发 <https://code.visualstudio.com/docs/remote/containers#_system-"
"requirements>`_"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:24
msgid ""
"`Remote development in Containers <https://code.visualstudio.com/docs/remote/"
"containers-tutorial>`_"
msgstr ""
"容器中的远程开发 <https://code.visualstudio.com/docs/remote/containers-"
"tutorial>`_"

#: ../../source/contributor-how-to-install-development-versions.rst:2
msgid "Install development versions"
msgstr "安装开发版本"

#: ../../source/contributor-how-to-install-development-versions.rst:5
msgid "Install development versions of Flower"
msgstr "安装 Flower 的开发版本"

#: ../../source/contributor-how-to-install-development-versions.rst:8
msgid "Using Poetry (recommended)"
msgstr "使用诗歌（推荐）"

#: ../../source/contributor-how-to-install-development-versions.rst:10
msgid ""
"Install a ``flwr`` pre-release from PyPI: update the ``flwr`` dependency in "
"``pyproject.toml`` and then reinstall (don't forget to delete ``poetry."
"lock`` (``rm poetry.lock``) before running ``poetry install``)."
msgstr ""
"安装来自 PyPI 的 ``flwr`` 预发布版本：更新 ``pyproject.toml`` 中的 ``flwr`` "
"依赖关系，然后重新安装（运行 ``poetry install` 前，别忘了删除 ``poetry.lock` "
"(``rm poetry.lock`))。"

#: ../../source/contributor-how-to-install-development-versions.rst:12
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` (without "
"extras)"
msgstr ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` （不含额外内"
"容）"

#: ../../source/contributor-how-to-install-development-versions.rst:13
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (包含额外内容)"

#: ../../source/contributor-how-to-install-development-versions.rst:15
msgid ""
"Install ``flwr`` from a local copy of the Flower source code via ``pyproject."
"toml``:"
msgstr "通过 ``pyproject.toml`` 从 Flower 源代码的本地副本安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:17
msgid "``flwr = { path = \"../../\", develop = true }`` (without extras)"
msgstr "``flwr = { path = \"../../\", develop = true }`` （不含额外内容）"

#: ../../source/contributor-how-to-install-development-versions.rst:18
msgid ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] }`` "
"(with extras)"
msgstr ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] }`` "
"(包含额外内容)"

#: ../../source/contributor-how-to-install-development-versions.rst:20
msgid "Install ``flwr`` from a local wheel file via ``pyproject.toml``:"
msgstr "通过 ``pyproject.toml`` 从本地轮子文件安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:22
msgid ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\" }`` (without "
"extras)"
msgstr ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\" }``（无额外内"
"容）"

#: ../../source/contributor-how-to-install-development-versions.rst:23
msgid ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (包含额外内容)"

#: ../../source/contributor-how-to-install-development-versions.rst:25
msgid ""
"Please refer to the Poetry documentation for further details: `Poetry "
"Dependency Specification <https://python-poetry.org/docs/dependency-"
"specification/>`_"
msgstr ""
"有关详细信息，请参阅 Poetry 文档： 诗歌依赖性规范 <https://python-poetry.org/"
"docs/dependency-specification/>`_"

#: ../../source/contributor-how-to-install-development-versions.rst:28
msgid "Using pip (recommended on Colab)"
msgstr "使用 pip（建议在 Colab 上使用）"

#: ../../source/contributor-how-to-install-development-versions.rst:30
msgid "Install a ``flwr`` pre-release from PyPI:"
msgstr "从 PyPI 安装 ``flwr`` 预发行版："

#: ../../source/contributor-how-to-install-development-versions.rst:32
msgid "``pip install -U --pre flwr`` (without extras)"
msgstr "`pip install -U -pre flwr``（不含额外功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:33
msgid "``pip install -U --pre flwr[simulation]`` (with extras)"
msgstr "`pip install -U -pre flwr[simulation]``（包含额外功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:35
msgid ""
"Python packages can be installed from git repositories. Use one of the "
"following commands to install the Flower directly from GitHub."
msgstr ""
"Python 软件包可以从 git 仓库安装。使用以下命令之一直接从 GitHub 安装 Flower。"

#: ../../source/contributor-how-to-install-development-versions.rst:37
msgid "Install ``flwr`` from the default GitHub branch (``main``):"
msgstr "从 GitHub 的默认分支 (``main`) 安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:39
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git`` (without extras)"
msgstr ""
"`pip install flwr@git+https://github.com/adap/flower.git`` （不含额外功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:40
msgid ""
"``pip install flwr[simulation]@git+https://github.com/adap/flower.git`` "
"(with extras)"
msgstr ""
"`pip install flwr[simulation]@git+https://github.com/adap/flower.git``（带附"
"加功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:42
msgid "Install ``flwr`` from a specific GitHub branch (``branch-name``):"
msgstr "从特定的 GitHub 分支 (`分支名`) 安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:44
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git@branch-name`` "
"(without extras)"
msgstr ""
"`pip install flwr@git+https://github.com/adap/flower.git@branch-name`` （不含"
"附加功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:45
msgid ""
"``pip install flwr[simulation]@git+https://github.com/adap/flower.git@branch-"
"name`` (with extras)"
msgstr ""
"`pip安装flwr[模拟]@git+https://github.com/adap/flower.git@分支名``（带附加功"
"能）"

#: ../../source/contributor-how-to-install-development-versions.rst:49
msgid "Open Jupyter Notebooks on Google Colab"
msgstr "在谷歌 Colab 上打开 Jupyter 笔记本"

#: ../../source/contributor-how-to-install-development-versions.rst:51
msgid ""
"Open the notebook ``doc/source/tutorial-get-started-with-flower-pytorch."
"ipynb``:"
msgstr ""
"打开笔记本 ``doc/source/tutorial-get-started-with-flower-pytorch.ipynb``："

#: ../../source/contributor-how-to-install-development-versions.rst:53
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source/"
"tutorial-get-started-with-flower-pytorch.ipynb"
msgstr ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source/"
"tutorial-get-started-with-flower-pytorch.ipynb"

#: ../../source/contributor-how-to-install-development-versions.rst:55
msgid ""
"Open a development version of the same notebook from branch `branch-name` by "
"changing ``main`` to ``branch-name`` (right after ``blob``):"
msgstr ""
"将 ``main`` 改为 ``branch-name``（紧跟在 ``blob``之后），从分支 `branch-"
"name` 打开同一笔记本的开发版本："

#: ../../source/contributor-how-to-install-development-versions.rst:57
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/branch-name/doc/"
"source/tutorial-get-started-with-flower-pytorch.ipynb"
msgstr ""
"https://colab.research.google.com/github/adap/flower/blob/branch-name/doc/"
"source/tutorial-get-started-with-flower-pytorch.ipynb"

#: ../../source/contributor-how-to-install-development-versions.rst:59
msgid "Install a `whl` on Google Colab:"
msgstr "在 Google Colab 上安装 `whl`："

#: ../../source/contributor-how-to-install-development-versions.rst:61
msgid ""
"In the vertical icon grid on the left hand side, select ``Files`` > ``Upload "
"to session storage``"
msgstr "在左侧的垂直图标网格中，选择 \"文件\">\"上传到会话存储\""

#: ../../source/contributor-how-to-install-development-versions.rst:62
msgid "Upload the whl (e.g., ``flwr-1.7.0-py3-none-any.whl``)"
msgstr "更新 whl (e.g., ``flwr-1.7.0-py3-none-any.whl``)"

#: ../../source/contributor-how-to-install-development-versions.rst:63
msgid ""
"Change ``!pip install -q 'flwr[simulation]' torch torchvision matplotlib`` "
"to ``!pip install -q 'flwr-1.7.0-py3-none-any.whl[simulation]' torch "
"torchvision matplotlib``"
msgstr ""
"把``!pip install -q 'flwr[simulation]' torch torchvision matplotlib``变为``"
"!pip install -q 'flwr-1.7.0-py3-none-any.whl[simulation]' torch torchvision "
"matplotlib``"

#: ../../source/contributor-how-to-release-flower.rst:2
msgid "Release Flower"
msgstr "发布 Flower"

#: ../../source/contributor-how-to-release-flower.rst:4
msgid ""
"This document describes the current release process. It may or may not "
"change in the future."
msgstr "本文件描述了当前的发布流程。今后可能会有变化，也可能不会有变化。"

#: ../../source/contributor-how-to-release-flower.rst:7
msgid "Before the release"
msgstr "发布前"

#: ../../source/contributor-how-to-release-flower.rst:9
msgid ""
"Update the changelog (``changelog.md``) with all relevant changes that "
"happened after the last release. If the last release was tagged ``v1.2.0``, "
"you can use the following URL to see all commits that got merged into "
"``main`` since then:"
msgstr ""
"更新更新日志 (``changelog.md``)，加入上次发布后发生的所有相关变更。如果上次发"
"布的版本被标记为 ``v1.2.0``，则可以使用以下 URL 查看此后合并到 ``main`` 的所"
"有提交："

#: ../../source/contributor-how-to-release-flower.rst:11
msgid ""
"`GitHub: Compare v1.2.0...main <https://github.com/adap/flower/compare/"
"v1.2.0...main>`_"
msgstr ""
"`GitHub: Compare v1.2.0...main <https://github.com/adap/flower/compare/"
"v1.2.0...main>`_"

#: ../../source/contributor-how-to-release-flower.rst:13
msgid ""
"Thank the authors who contributed since the last release. This can be done "
"by running the ``./dev/add-shortlog.sh`` convenience script (it can be ran "
"multiple times and will update the names in the list if new contributors "
"were added in the meantime)."
msgstr ""
"感谢自上次发布以来做出贡献的作者。可以通过运行 ``./dev/add-shortlog.sh`` 方便"
"脚本来完成（可以多次运行，如果在此期间有新的贡献者加入，则会更新列表中的名"
"字）。"

#: ../../source/contributor-how-to-release-flower.rst:16
msgid "During the release"
msgstr "在发布期间"

#: ../../source/contributor-how-to-release-flower.rst:18
msgid ""
"The version number of a release is stated in ``pyproject.toml``. To release "
"a new version of Flower, the following things need to happen (in that order):"
msgstr ""
"版本号在 ``pyproject.toml`` 中说明。要发布 Flower 的新版本，需要完成以下工作"
"（按顺序排列）："

#: ../../source/contributor-how-to-release-flower.rst:20
msgid ""
"Update the ``changelog.md`` section header ``Unreleased`` to contain the "
"version number and date for the release you are building. Create a pull "
"request with the change."
msgstr ""
"更新 ``changelog.md`` 部分的标题 ``Unreleased`` 以包含你正在构建的版本的版本"
"号和日期。创建一个包含更改的拉取请求。"

#: ../../source/contributor-how-to-release-flower.rst:21
msgid ""
"Tag the release commit with the version number as soon as the PR is merged: "
"``git tag v0.12.3``, then ``git push --tags``. This will create a draft "
"release on GitHub containing the correct artifacts and the relevant part of "
"the changelog."
msgstr ""
"在 PR 合并后立即用版本号标记发布提交：``git tag v0.12.3``，然后``git push --"
"tags``。这将在 GitHub 上创建一个包含正确工件和更新日志相关部分的发布草案。"

#: ../../source/contributor-how-to-release-flower.rst:22
msgid ""
"Check the draft release on GitHub, and if everything is good, publish it."
msgstr "检查 GitHub 上的发布稿，如果一切正常，就发布它。"

#: ../../source/contributor-how-to-release-flower.rst:25
msgid "After the release"
msgstr "发布后"

#: ../../source/contributor-how-to-release-flower.rst:27
msgid "Create a pull request which contains the following changes:"
msgstr "创建包含以下更改的拉取请求："

#: ../../source/contributor-how-to-release-flower.rst:29
msgid "Increase the minor version in ``pyproject.toml`` by one."
msgstr "将 ``pyproject.toml`` 中的次要版本增加一个。"

#: ../../source/contributor-how-to-release-flower.rst:30
msgid "Update all files which contain the current version number if necessary."
msgstr "如有必要，更新包含当前版本号的所有文件。"

#: ../../source/contributor-how-to-release-flower.rst:31
msgid "Add a new ``Unreleased`` section in ``changelog.md``."
msgstr "在 ``changelog.md`` 中添加新的 ``Unreleased`` 部分。"

#: ../../source/contributor-how-to-release-flower.rst:33
msgid ""
"Merge the pull request on the same day (i.e., before a new nighly release "
"gets published to PyPI)."
msgstr "在同一天合并拉取请求（即在新版本发布到 PyPI 之前）。"

#: ../../source/contributor-how-to-release-flower.rst:36
msgid "Publishing a pre-release"
msgstr "发布预发布版本"

#: ../../source/contributor-how-to-release-flower.rst:39
msgid "Pre-release naming"
msgstr "释放前命名"

#: ../../source/contributor-how-to-release-flower.rst:41
msgid ""
"PyPI supports pre-releases (alpha, beta, release candiate). Pre-releases "
"MUST use one of the following naming patterns:"
msgstr ""
"PyPI 支持预发布版本（alpha、beta、release candiate）。预发布版本必须使用以下"
"命名模式之一："

#: ../../source/contributor-how-to-release-flower.rst:43
msgid "Alpha: ``MAJOR.MINOR.PATCHaN``"
msgstr "阿尔法 ``MAJOR.MINOR.PATCHaN``"

#: ../../source/contributor-how-to-release-flower.rst:44
msgid "Beta: ``MAJOR.MINOR.PATCHbN``"
msgstr "贝塔： ``MAJOR.MINOR.PATCHbN``"

#: ../../source/contributor-how-to-release-flower.rst:45
msgid "Release candiate (RC): ``MAJOR.MINOR.PATCHrcN``"
msgstr "版本代号 (RC)： ``MAJOR.MINOR.PATCHrcN``"

#: ../../source/contributor-how-to-release-flower.rst:47
msgid "Examples include:"
msgstr "例子包括："

#: ../../source/contributor-how-to-release-flower.rst:49
msgid "``1.0.0a0``"
msgstr "``1.0.0a0``"

#: ../../source/contributor-how-to-release-flower.rst:50
msgid "``1.0.0b0``"
msgstr "``1.0.0b0``"

#: ../../source/contributor-how-to-release-flower.rst:51
msgid "``1.0.0rc0``"
msgstr "``1.0.0rc0``"

#: ../../source/contributor-how-to-release-flower.rst:52
msgid "``1.0.0rc1``"
msgstr "``1.0.0rc1``"

#: ../../source/contributor-how-to-release-flower.rst:54
msgid ""
"This is in line with PEP-440 and the recommendations from the Python "
"Packaging Authority (PyPA):"
msgstr "这符合 PEP-440 和 Python 包装管理局 (PyPA) 的建议："

#: ../../source/contributor-how-to-release-flower.rst:57
msgid "`PEP-440 <https://peps.python.org/pep-0440/>`_"
msgstr "`PEP-440 <https://peps.python.org/pep-0440/>`_"

#: ../../source/contributor-how-to-release-flower.rst:58
msgid ""
"`PyPA Choosing a versioning scheme <https://packaging.python.org/en/latest/"
"guides/distributing-packages-using-setuptools/#choosing-a-versioning-"
"scheme>`_"
msgstr ""
"`PyPA 选择版本控制方案 <https://packaging.python.org/en/latest/guides/"
"distributing-packages-using-setuptools/#choosing-a-versioning-scheme>`_"

#: ../../source/contributor-how-to-release-flower.rst:60
msgid ""
"Note that the approach defined by PyPA is not compatible with SemVer 2.0.0 "
"spec, for details consult the `Semantic Versioning Specification <https://"
"semver.org/spec/v2.0.0.html#spec-item-11>`_ (specifically item 11 on "
"precedence)."
msgstr ""
"请注意，PyPA 所定义的方法与 SemVer 2.0.0 规范不兼容，详情请查阅《语义版本规"
"范》<https://semver.org/spec/v2.0.0.html#spec-item-11>`_（特别是关于优先级的"
"第 11 项）。"

#: ../../source/contributor-how-to-release-flower.rst:63
msgid "Pre-release classification"
msgstr "发布前分类"

#: ../../source/contributor-how-to-release-flower.rst:65
msgid ""
"Should the next pre-release be called alpha, beta, or release candidate?"
msgstr "下一个预发布版应该叫阿尔法版、贝塔版还是候选发布版？"

#: ../../source/contributor-how-to-release-flower.rst:67
msgid ""
"RC: feature complete, no known issues (apart from issues that are classified "
"as \"won't fix\" for the next stable release) - if no issues surface this "
"will become the next stable release"
msgstr ""
"RC：功能完整，无已知问题（除了下一个稳定版中被列为 \"不会修复 \"的问题）--如"
"果没有问题出现，这将成为下一个稳定版"

#: ../../source/contributor-how-to-release-flower.rst:68
msgid "Beta: feature complete, allowed to have known issues"
msgstr "贝塔版：功能完整，允许存在已知问题"

#: ../../source/contributor-how-to-release-flower.rst:69
msgid "Alpha: not feature complete, allowed to have known issues"
msgstr "阿尔法版：功能不完整，允许存在已知问题"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:2
msgid "Set up a virtual env"
msgstr "建立虚拟环境"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:4
msgid ""
"It is recommended to run your Python setup within a virtual environment. "
"This guide shows three different examples how to create a virtual "
"environment with pyenv virtualenv, poetry, or Anaconda. You can follow the "
"instructions or choose your preferred setup."
msgstr ""
"建议在虚拟环境中运行 Python 设置。本指南展示了如何使用 pyenv virtualenv、"
"poes 或 Anaconda 创建虚拟环境的三个不同示例。您可以按照说明或选择您喜欢的设"
"置。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:9
msgid "Python Version"
msgstr "Python 版本"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:11
#: ../../source/how-to-install-flower.rst:8
msgid ""
"Flower requires at least `Python 3.8 <https://docs.python.org/3.8/>`_, but "
"`Python 3.10 <https://docs.python.org/3.10/>`_ or above is recommended."
msgstr ""
"Flower 至少需要 `Python 3.8 <https://docs.python.org/3.8/>`_，但建议使用 "
"`Python 3.10 <https://docs.python.org/3.10/>`_或更高版本。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:14
msgid "Virutualenv with Pyenv/Virtualenv"
msgstr "Virutualenv 和 Pyenv/Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:16
msgid ""
"One of the recommended virtual environment is `pyenv <https://github.com/"
"pyenv/pyenv>`_/`virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_. "
"Please see `Flower examples <https://github.com/adap/flower/tree/main/"
"examples/>`_ for details."
msgstr ""
"其中一个推荐的虚拟环境是 `pyenv <https://github.com/pyenv/pyenv>`_/"
"`virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_。详情请参见 "
"`Flower 示例 <https://github.com/adap/flower/tree/main/examples/>`_。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:18
msgid ""
"Once Pyenv is set up, you can use it to install `Python Version 3.10 "
"<https://docs.python.org/3.10/>`_ or above:"
msgstr ""
"一旦设置好 Pyenv，就可以用它来安装 `Python 3.10 <https://docs.python."
"org/3.10/>`_ 或更高版本："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:24
msgid "Create the virtualenv with:"
msgstr "创建虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:31
msgid "Activate the virtualenv by running the following command:"
msgstr "运行以下命令激活 virtualenv："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:39
msgid "Virtualenv with Poetry"
msgstr "有诗意的 Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:41
msgid ""
"The Flower examples are based on `Poetry <https://python-poetry.org/docs/>`_ "
"to manage dependencies. After installing Poetry you simply create a virtual "
"environment with:"
msgstr ""
"Flower 示例基于 `Poetry <https://python-poetry.org/docs/>`_ 来管理依赖关系。"
"安装 Poetry 后，只需创建一个虚拟环境即可："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:47
msgid ""
"If you open a new terminal you can activate the previously created virtual "
"environment with the following command:"
msgstr "如果打开一个新终端，可以使用以下命令激活之前创建的虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:55
msgid "Virtualenv with Anaconda"
msgstr "使用 Anaconda 的 Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:57
msgid ""
"If you prefer to use Anaconda for your virtual environment then install and "
"setup the `conda <https://docs.conda.io/projects/conda/en/latest/user-guide/"
"install/index.html>`_  package. After setting it up you can create a virtual "
"environment with:"
msgstr ""
"如果你更喜欢在虚拟环境中使用 Anaconda，那么请安装并设置 `conda <https://docs."
"conda.io/projects/conda/en/latest/user-guide/install/index.html>`_ 软件包。设"
"置完成后，您就可以使用以下工具创建虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:63
msgid "and activate the virtual environment with:"
msgstr "并激活虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:71
msgid "And then?"
msgstr "然后呢？"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:73
msgid ""
"As soon as you created your virtual environment you clone one of the `Flower "
"examples <https://github.com/adap/flower/tree/main/examples/>`_."
msgstr ""
"创建虚拟环境后，您可以克隆一个 `Flower 示例 <https://github.com/adap/flower/"
"tree/main/examples/>`_。"

#: ../../source/contributor-how-to-write-documentation.rst:2
msgid "Write documentation"
msgstr "编写文件"

#: ../../source/contributor-how-to-write-documentation.rst:6
msgid "Project layout"
msgstr "项目布局"

#: ../../source/contributor-how-to-write-documentation.rst:8
msgid ""
"The Flower documentation lives in the ``doc`` directory. The Sphinx-based "
"documentation system supports both reStructuredText (``.rst`` files) and "
"Markdown (``.md`` files)."
msgstr ""
"Flower 文档位于 ``doc`` 目录中。基于 Sphinx 的文档系统支持 reStructuredText"
"（``.rst`` 文件）和 Markdown（``.md`` 文件）。"

#: ../../source/contributor-how-to-write-documentation.rst:10
#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:119
msgid ""
"Note that, in order to build the documentation locally (with ``poetry run "
"make html``, like described below), `Pandoc <https://pandoc.org/installing."
"html>_` needs to be installed on the system."
msgstr ""
"请注意，要在本地构建文档（使用 ``poetry run make html``，如下所述），系统上必"
"须安装 ``Pandoc <https://pandoc.org/installing.html>_`。"

#: ../../source/contributor-how-to-write-documentation.rst:14
msgid "Edit an existing page"
msgstr "编辑现有页面"

#: ../../source/contributor-how-to-write-documentation.rst:16
msgid "Edit an existing ``.rst`` (or ``.md``) file under ``doc/source/``"
msgstr "编辑 ``doc/source/`` 下现有的 ``.rst`` (或 ``.md``) 文件"

#: ../../source/contributor-how-to-write-documentation.rst:17
#: ../../source/contributor-how-to-write-documentation.rst:27
msgid "Compile the docs: ``cd doc``, then ``poetry run make html``"
msgstr "编译文档： cd doc``，然后 ``poetry run make html``"

#: ../../source/contributor-how-to-write-documentation.rst:18
#: ../../source/contributor-how-to-write-documentation.rst:28
msgid "Open ``doc/build/html/index.html`` in the browser to check the result"
msgstr "在浏览器中打开 ``doc/build/html/index.html`` 查看结果"

#: ../../source/contributor-how-to-write-documentation.rst:22
msgid "Create a new page"
msgstr "创建新页面"

#: ../../source/contributor-how-to-write-documentation.rst:24
msgid "Add new ``.rst`` file under ``doc/source/``"
msgstr "在 ``doc/source/`` 下添加新的 ``.rst`` 文件"

#: ../../source/contributor-how-to-write-documentation.rst:25
msgid "Add content to the new ``.rst`` file"
msgstr "为新的 ``.rst`` 文件添加内容"

#: ../../source/contributor-how-to-write-documentation.rst:26
msgid "Link to the new rst from ``index.rst``"
msgstr "从 ``index.rst`` 链接到新的 rst"

#: ../../source/contributor-ref-good-first-contributions.rst:2
msgid "Good first contributions"
msgstr "良好的首批捐款"

#: ../../source/contributor-ref-good-first-contributions.rst:4
msgid ""
"We welcome contributions to Flower! However, it is not always easy to know "
"where to start. We therefore put together a few recommendations on where to "
"start to increase your chances of getting your PR accepted into the Flower "
"codebase."
msgstr ""
"我们欢迎为《鲜花》投稿！然而，要知道从哪里开始并非易事。因此，我们提出了一些"
"建议，告诉您从哪里开始，以增加您的 PR 被 Flower 代码库接受的机会。"

#: ../../source/contributor-ref-good-first-contributions.rst:11
msgid "Where to start"
msgstr "从哪里开始"

#: ../../source/contributor-ref-good-first-contributions.rst:13
msgid ""
"Until the Flower core library matures it will be easier to get PR's accepted "
"if they only touch non-core areas of the codebase. Good candidates to get "
"started are:"
msgstr ""
"在 Flower 核心库成熟之前，如果 PR 只涉及代码库中的非核心区域，则会更容易被接"
"受。可以从以下方面入手："

#: ../../source/contributor-ref-good-first-contributions.rst:17
msgid "Documentation: What's missing? What could be expressed more clearly?"
msgstr "文件： 缺少什么？哪些内容可以表达得更清楚？"

#: ../../source/contributor-ref-good-first-contributions.rst:18
msgid "Baselines: See below."
msgstr "基线： 见下文。"

#: ../../source/contributor-ref-good-first-contributions.rst:19
msgid "Examples: See below."
msgstr "举例说明： 见下文。"

#: ../../source/contributor-ref-good-first-contributions.rst:23
msgid "Request for Flower Baselines"
msgstr "Flower 基线申请"

#: ../../source/contributor-ref-good-first-contributions.rst:25
msgid ""
"If you are not familiar with Flower Baselines, you should probably check-out "
"our `contributing guide for baselines <https://flower.dev/docs/contributing-"
"baselines.html>`_."
msgstr ""
"如果您对 Flower Baselines 还不熟悉，也许应该看看我们的 \"基线贡献指南 "
"<https://flower.dev/docs/contributing-baselines.html>`_\"。"

#: ../../source/contributor-ref-good-first-contributions.rst:27
msgid ""
"You should then check out the open `issues <https://github.com/adap/flower/"
"issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_ for baseline "
"requests. If you find a baseline that you'd like to work on and that has no "
"assignes, feel free to assign it to yourself and start working on it!"
msgstr ""
"然后，您应该查看开放的 `issues <https://github.com/adap/flower/issues?"
"q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_ 基线请求。如果您发现了自"
"己想做的基线，而它还没有被分配，请随时把它分配给自己，然后开始工作！"

#: ../../source/contributor-ref-good-first-contributions.rst:31
msgid ""
"Otherwise, if you don't find a baseline you'd like to work on, be sure to "
"open a new issue with the baseline request template!"
msgstr ""
"否则，如果您没有找到想要处理的基线，请务必使用基线请求模板打开一个新问题！"

#: ../../source/contributor-ref-good-first-contributions.rst:34
msgid "Request for examples"
msgstr "要求提供范例"

#: ../../source/contributor-ref-good-first-contributions.rst:36
msgid ""
"We wish we had more time to write usage examples because we believe they "
"help users to get started with building what they want to build. Here are a "
"few ideas where we'd be happy to accept a PR:"
msgstr ""
"我们希望有更多的时间来撰写使用示例，因为我们相信这些示例可以帮助用户开始构建"
"他们想要构建的东西。以下是我们乐意接受 PR 的几个想法："

#: ../../source/contributor-ref-good-first-contributions.rst:40
msgid "Llama 2 fine-tuning, with Hugging Face Transformers and PyTorch"
msgstr "微调 \"拉玛 2\"，使用 \"抱脸变形金刚 \"和 PyTorch"

#: ../../source/contributor-ref-good-first-contributions.rst:41
msgid "XGBoost"
msgstr "XGBoost"

#: ../../source/contributor-ref-good-first-contributions.rst:42
msgid "Android ONNX on-device training"
msgstr "安卓 ONNX 设备上培训"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:2
msgid "Secure Aggregation Protocols"
msgstr "安全聚合协议"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:4
msgid ""
"Include SecAgg, SecAgg+, and LightSecAgg protocol. The LightSecAgg protocol "
"has not been implemented yet, so its diagram and abstraction may not be "
"accurate in practice. The SecAgg protocol can be considered as a special "
"case of the SecAgg+ protocol."
msgstr ""
"包括 SecAgg、SecAgg+ 和 LightSecAgg 协议。LightSecAgg 协议尚未实施，因此其图"
"表和抽象在实践中可能并不准确。SecAgg 协议可视为 SecAgg+ 协议的特例。"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:8
msgid "The :code:`SecAgg+` abstraction"
msgstr "代码：`SecAgg+` 抽象"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:10
#: ../../source/contributor-ref-secure-aggregation-protocols.rst:161
msgid ""
"In this implementation, each client will be assigned with a unique index "
"(int) for secure aggregation, and thus many python dictionaries used have "
"keys of int type rather than ClientProxy type."
msgstr ""
"在此实现中，将为每个客户端分配一个唯一索引（int），以确保聚合的安全性，因此使"
"用的许多 python 字典的键都是 int 类型，而不是 ClientProxy 类型。"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:65
#: ../../source/contributor-ref-secure-aggregation-protocols.rst:198
msgid ""
"The Flower server will execute and process received results in the following "
"order:"
msgstr "Flower 服务器将按以下顺序执行和处理收到的结果："

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:159
msgid "The :code:`LightSecAgg` abstraction"
msgstr "代码：`LightSecAgg` 抽象"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:271
msgid "Types"
msgstr "类型"

#: ../../source/contributor-tutorial-contribute-on-github.rst:2
msgid "Contribute on GitHub"
msgstr "在 GitHub 上投稿"

#: ../../source/contributor-tutorial-contribute-on-github.rst:4
msgid ""
"This guide is for people who want to get involved with Flower, but who are "
"not used to contributing to GitHub projects."
msgstr "本指南适用于想参与 Flower，但不习惯为 GitHub 项目贡献的人。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:6
msgid ""
"If you're familiar with how contributing on GitHub works, you can directly "
"checkout our `getting started guide for contributors <https://flower.dev/"
"docs/getting-started-for-contributors.html>`_ and examples of `good first "
"contributions <https://flower.dev/docs/good-first-contributions.html>`_."
msgstr ""
"如果您熟悉如何在 GitHub 上贡献，可以直接查看我们的 \"贡献者入门指南\" "
"<https://flower.dev/docs/getting-started-for-contributors.html>`_ 和 \"优秀的"
"首次贡献示例\" <https://flower.dev/docs/good-first-contributions.html>`_。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:12
msgid "Setting up the repository"
msgstr "建立资源库"

#: ../../source/contributor-tutorial-contribute-on-github.rst:23
msgid "**Create a GitHub account and setup Git**"
msgstr "**创建 GitHub 账户并设置 Git**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:15
msgid ""
"Git is a distributed version control tool. This allows for an entire "
"codebase's history to be stored and every developer's machine. It is a "
"software that will need to be installed on your local machine, you can "
"follow this `guide <https://docs.github.com/en/get-started/quickstart/set-up-"
"git>`_ to set it up."
msgstr ""
"Git 是一种分布式版本控制工具。它可以将整个代码库的历史记录保存在每个开发人员"
"的机器上。您需要在本地计算机上安装该软件，可以按照本指南 <https://docs."
"github.com/en/get-started/quickstart/set-up-git>`_ 进行设置。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:18
msgid ""
"GitHub, itself, is a code hosting platform for version control and "
"collaboration. It allows for everyone to collaborate and work from anywhere "
"on remote repositories."
msgstr ""
"GitHub 本身是一个用于版本控制和协作的代码托管平台。它允许每个人在任何地方对远"
"程仓库进行协作和工作。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:20
msgid ""
"If you haven't already, you will need to create an account on `GitHub "
"<https://github.com/signup>`_."
msgstr ""
"如果还没有，您需要在 `GitHub <https://github.com/signup>`_ 上创建一个账户。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:22
msgid ""
"The idea behind the generic Git and GitHub workflow boils down to this: you "
"download code from a remote repository on GitHub, make changes locally and "
"keep track of them using Git and then you upload your new history back to "
"GitHub."
msgstr ""
"通用的 Git 和 GitHub 工作流程背后的理念可以归结为：从 GitHub 上的远程仓库下载"
"代码，在本地进行修改并使用 Git 进行跟踪，然后将新的历史记录上传回 GitHub。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:34
msgid "**Forking the Flower repository**"
msgstr "**叉花仓库**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:26
msgid ""
"A fork is a personal copy of a GitHub repository. To create one for Flower, "
"you must navigate to https://github.com/adap/flower (while connected to your "
"GitHub account) and click the ``Fork`` button situated on the top right of "
"the page."
msgstr ""
"fork 是 GitHub 仓库的个人副本。要为 Flower 创建一个 fork，您必须导航到 "
"https://github.com/adap/flower（同时连接到您的 GitHub 账户），然后点击页面右"
"上方的 ``Fork`` 按钮。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:31
msgid ""
"You can change the name if you want, but this is not necessary as this "
"version of Flower will be yours and will sit inside your own account (i.e., "
"in your own list of repositories). Once created, you should see on the top "
"left corner that you are looking at your own version of Flower."
msgstr ""
"您可以更改名称，但没有必要，因为这个版本的 Flower 将是您自己的，并位于您自己"
"的账户中（即，在您自己的版本库列表中）。创建完成后，您会在左上角看到自己的 "
"Flower 版本。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:49
msgid "**Cloning your forked repository**"
msgstr "**克隆你的分叉仓库**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:37
msgid ""
"The next step is to download the forked repository on your machine to be "
"able to make changes to it. On your forked repository page, you should first "
"click on the ``Code`` button on the right, this will give you the ability to "
"copy the HTTPS link of the repository."
msgstr ""
"下一步是在你的机器上下载分叉版本库，以便对其进行修改。在分叉版本库页面上，首"
"先点击右侧的 \"代码 \"按钮，这样就能复制版本库的 HTTPS 链接。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:43
msgid ""
"Once you copied the \\<URL\\>, you can open a terminal on your machine, "
"navigate to the place you want to download the repository to and type:"
msgstr ""
"一旦复制了 （<URL\\>），你就可以在你的机器上打开一个终端，导航到你想下载软件"
"源的地方，然后键入："

#: ../../source/contributor-tutorial-contribute-on-github.rst:49
msgid ""
"This will create a `flower/` (or the name of your fork if you renamed it) "
"folder in the current working directory."
msgstr ""
"这将在当前工作目录下创建一个 `flower/`（如果重命名了，则使用 fork 的名称）文"
"件夹。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:68
msgid "**Add origin**"
msgstr "**添加原产地**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:52
msgid "You can then go into the repository folder:"
msgstr "然后，您就可以进入存储库文件夹："

#: ../../source/contributor-tutorial-contribute-on-github.rst:58
msgid ""
"And here we will need to add an origin to our repository. The origin is the "
"\\<URL\\> of the remote fork repository. To obtain it, we can do as "
"previously mentioned by going to our fork repository on our GitHub account "
"and copying the link."
msgstr ""
"在这里，我们需要为我们的版本库添加一个 origin。origin 是远程 fork 仓库的 "
"\\<URL/>。要获得它，我们可以像前面提到的那样，访问 GitHub 账户上的分叉仓库并"
"复制链接。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:63
msgid ""
"Once the \\<URL\\> is copied, we can type the following command in our "
"terminal:"
msgstr "一旦复制了 \\<URL\\> ，我们就可以在终端中键入以下命令："

#: ../../source/contributor-tutorial-contribute-on-github.rst:92
msgid "**Add upstream**"
msgstr "**增加上游**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:71
msgid ""
"Now we will add an upstream address to our repository. Still in the same "
"directroy, we must run the following command:"
msgstr ""
"现在，我们要为版本库添加一个上游地址。还是在同一目录下，我们必须运行以下命"
"令："

#: ../../source/contributor-tutorial-contribute-on-github.rst:78
msgid ""
"The following diagram visually explains what we did in the previous steps:"
msgstr "下图直观地解释了我们在前面步骤中的操作："

#: ../../source/contributor-tutorial-contribute-on-github.rst:82
msgid ""
"The upstream is the GitHub remote address of the parent repository (in this "
"case Flower), i.e. the one we eventually want to contribute to and therefore "
"need an up-to-date history of. The origin is just the GitHub remote address "
"of the forked repository we created, i.e. the copy (fork) in our own account."
msgstr ""
"上游是父版本库（这里是 Flower）的 GitHub 远程地址，即我们最终要贡献的版本库，"
"因此需要最新的历史记录。origin 只是我们创建的分叉仓库的 GitHub 远程地址，即我"
"们自己账户中的副本（分叉）。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:86
msgid ""
"To make sure our local version of the fork is up-to-date with the latest "
"changes from the Flower repository, we can execute the following command:"
msgstr ""
"为了确保本地版本的分叉程序与 Flower 代码库的最新更改保持一致，我们可以执行以"
"下命令："

#: ../../source/contributor-tutorial-contribute-on-github.rst:95
msgid "Setting up the coding environment"
msgstr "设置编码环境"

#: ../../source/contributor-tutorial-contribute-on-github.rst:97
msgid ""
"This can be achieved by following this `getting started guide for "
"contributors`_ (note that you won't need to clone the repository). Once you "
"are able to write code and test it, you can finally start making changes!"
msgstr ""
"您可以按照这份 \"贡献者入门指南\"__（注意，您不需要克隆版本库）来实现这一点。"
"一旦您能够编写代码并进行测试，您就可以开始修改了！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:102
msgid "Making changes"
msgstr "做出改变"

#: ../../source/contributor-tutorial-contribute-on-github.rst:104
msgid ""
"Before making any changes make sure you are up-to-date with your repository:"
msgstr "在进行任何更改之前，请确保您的版本库是最新的："

#: ../../source/contributor-tutorial-contribute-on-github.rst:110
msgid "And with Flower's repository:"
msgstr "还有Flower的存储库："

#: ../../source/contributor-tutorial-contribute-on-github.rst:124
msgid "**Create a new branch**"
msgstr "**创建一个新分支**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:117
msgid ""
"To make the history cleaner and easier to work with, it is good practice to "
"create a new branch for each feature/project that needs to be implemented."
msgstr ""
"为了使历史记录更简洁、更易于操作，为每个需要实现的功能/项目创建一个新分支是个"
"不错的做法。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:120
msgid ""
"To do so, just run the following command inside the repository's directory:"
msgstr "为此，只需在版本库目录下运行以下命令即可："

#: ../../source/contributor-tutorial-contribute-on-github.rst:127
msgid "**Make changes**"
msgstr "**进行修改**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:127
msgid ""
"Write great code and create wonderful changes using your favorite editor!"
msgstr "使用您最喜欢的编辑器编写优秀的代码并创建精彩的更改！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:140
msgid "**Test and format your code**"
msgstr "**测试并格式化您的代码**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:130
msgid ""
"Don't forget to test and format your code! Otherwise your code won't be able "
"to be merged into the Flower repository. This is done so the codebase stays "
"consistent and easy to understand."
msgstr ""
"不要忘记测试和格式化您的代码！否则您的代码将无法并入 Flower 代码库。这样做是"
"为了使代码库保持一致并易于理解。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:133
msgid "To do so, we have written a few scripts that you can execute:"
msgstr "为此，我们编写了一些脚本供您执行："

#: ../../source/contributor-tutorial-contribute-on-github.rst:152
msgid "**Stage changes**"
msgstr "**舞台变化**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:143
msgid ""
"Before creating a commit that will update your history, you must specify to "
"Git which files it needs to take into account."
msgstr "在创建更新历史记录的提交之前，必须向 Git 说明需要考虑哪些文件。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:145
msgid "This can be done with:"
msgstr "这可以通过："

#: ../../source/contributor-tutorial-contribute-on-github.rst:151
msgid ""
"To check which files have been modified compared to the last version (last "
"commit) and to see which files are staged for commit, you can use the :code:"
"`git status` command."
msgstr ""
"要查看与上一版本（上次提交）相比哪些文件已被修改，以及哪些文件处于提交阶段，"
"可以使用 :code:`git status` 命令。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:162
msgid "**Commit changes**"
msgstr "**提交更改**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:155
msgid ""
"Once you have added all the files you wanted to commit using :code:`git "
"add`, you can finally create your commit using this command:"
msgstr ""
"使用 :code:`git add` 添加完所有要提交的文件后，就可以使用此命令创建提交了："

#: ../../source/contributor-tutorial-contribute-on-github.rst:161
msgid ""
"The \\<commit_message\\> is there to explain to others what the commit does. "
"It should be written in an imperative style and be concise. An example would "
"be :code:`git commit -m \"Add images to README\"`."
msgstr ""
"<commit_message\\> 用于向他人解释提交的作用。它应该以命令式风格书写，并且简明"
"扼要。例如 :code:`git commit -m \"Add images to README\"`。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:173
msgid "**Push the changes to the fork**"
msgstr "**将更改推送到分叉**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:165
msgid ""
"Once we have committed our changes, we have effectively updated our local "
"history, but GitHub has no way of knowing this unless we push our changes to "
"our origin's remote address:"
msgstr ""
"一旦提交了修改，我们就有效地更新了本地历史记录，但除非我们将修改推送到原点的"
"远程地址，否则 GitHub 无法得知："

#: ../../source/contributor-tutorial-contribute-on-github.rst:172
msgid ""
"Once this is done, you will see on the GitHub that your forked repo was "
"updated with the changes you have made."
msgstr ""
"完成此操作后，您将在 GitHub 上看到您的分叉仓库已根据您所做的更改进行了更新。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:176
msgid "Creating and merging a pull request (PR)"
msgstr "创建和合并拉取请求 (PR)"

#: ../../source/contributor-tutorial-contribute-on-github.rst:203
msgid "**Create the PR**"
msgstr "**创建 PR**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:179
msgid ""
"Once you have pushed changes, on the GitHub webpage of your repository you "
"should see the following message:"
msgstr "推送更改后，在仓库的 GitHub 网页上应该会看到以下信息："

#: ../../source/contributor-tutorial-contribute-on-github.rst:183
msgid "Otherwise you can always find this option in the `Branches` page."
msgstr "否则，您可以在 \"分支 \"页面找到该选项。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:185
msgid ""
"Once you click the `Compare & pull request` button, you should see something "
"similar to this:"
msgstr "点击 \"比较和拉取请求 \"按钮后，您应该会看到类似下面的内容："

#: ../../source/contributor-tutorial-contribute-on-github.rst:189
msgid ""
"At the top you have an explanation of which branch will be merged where:"
msgstr "在顶部，你可以看到关于哪个分支将被合并的说明："

#: ../../source/contributor-tutorial-contribute-on-github.rst:193
msgid ""
"In this example you can see that the request is to merge the branch ``doc-"
"fixes`` from my forked repository to branch ``main`` from the Flower "
"repository."
msgstr ""
"在这个例子中，你可以看到请求将我分叉的版本库中的分支 ``doc-fixes`` 合并到 "
"Flower 版本库中的分支 ``main``。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:195
msgid ""
"The input box in the middle is there for you to describe what your PR does "
"and to link it to existing issues. We have placed comments (that won't be "
"rendered once the PR is opened) to guide you through the process."
msgstr ""
"中间的输入框供您描述 PR 的作用，并将其与现有问题联系起来。我们在此放置了注释"
"（一旦 PR 打开，注释将不会显示），以指导您完成整个过程。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:198
msgid ""
"At the bottom you will find the button to open the PR. This will notify "
"reviewers that a new PR has been opened and that they should look over it to "
"merge or to request changes."
msgstr ""
"在底部，您可以找到打开 PR 的按钮。这将通知审核人员新的 PR 已经打开，他们应该"
"查看该 PR 以进行合并或要求修改。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:201
msgid ""
"If your PR is not yet ready for review, and you don't want to notify anyone, "
"you have the option to create a draft pull request:"
msgstr ""
"如果您的 PR 尚未准备好接受审核，而且您不想通知任何人，您可以选择创建一个草案"
"拉取请求："

#: ../../source/contributor-tutorial-contribute-on-github.rst:206
msgid "**Making new changes**"
msgstr "**作出新的改变**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:206
msgid ""
"Once the PR has been opened (as draft or not), you can still push new "
"commits to it the same way we did before, by making changes to the branch "
"associated with the PR."
msgstr ""
"一旦 PR 被打开（无论是否作为草案），你仍然可以像以前一样，通过修改与 PR 关联"
"的分支来推送新的提交。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:228
msgid "**Review the PR**"
msgstr "**审查 PR**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:209
msgid ""
"Once the PR has been opened or once the draft PR has been marked as ready, a "
"review from code owners will be automatically requested:"
msgstr "一旦 PR 被打开或 PR 草案被标记为就绪，就会自动要求代码所有者进行审核："

#: ../../source/contributor-tutorial-contribute-on-github.rst:213
msgid ""
"Code owners will then look into the code, ask questions, request changes or "
"validate the PR."
msgstr "然后，代码所有者会查看代码、提出问题、要求修改或验证 PR。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:215
msgid "Merging will be blocked if there are ongoing requested changes."
msgstr "如果有正在进行的更改请求，合并将被阻止。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:219
msgid ""
"To resolve them, just push the necessary changes to the branch associated "
"with the PR:"
msgstr "要解决这些问题，只需将必要的更改推送到与 PR 关联的分支即可："

#: ../../source/contributor-tutorial-contribute-on-github.rst:223
msgid "And resolve the conversation:"
msgstr "并解决对话："

#: ../../source/contributor-tutorial-contribute-on-github.rst:227
msgid ""
"Once all the conversations have been resolved, you can re-request a review."
msgstr "一旦所有对话都得到解决，您就可以重新申请审核。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:248
msgid "**Once the PR is merged**"
msgstr "**一旦 PR 被合并**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:231
msgid ""
"If all the automatic tests have passed and reviewers have no more changes to "
"request, they can approve the PR and merge it."
msgstr ""
"如果所有自动测试都已通过，且审核员不再需要修改，他们就可以批准 PR 并将其合"
"并。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:235
msgid ""
"Once it is merged, you can delete the branch on GitHub (a button should "
"appear to do so) and also delete it locally by doing:"
msgstr ""
"合并后，您可以在 GitHub 上删除该分支（会出现一个删除按钮），也可以在本地删除"
"该分支："

#: ../../source/contributor-tutorial-contribute-on-github.rst:242
msgid "Then you should update your forked repository by doing:"
msgstr "然后，你应该更新你的分叉仓库："

#: ../../source/contributor-tutorial-contribute-on-github.rst:251
msgid "Example of first contribution"
msgstr "首次捐款实例"

#: ../../source/contributor-tutorial-contribute-on-github.rst:254
msgid "Problem"
msgstr "问题"

#: ../../source/contributor-tutorial-contribute-on-github.rst:256
msgid ""
"For our documentation, we’ve started to use the `Diàtaxis framework <https://"
"diataxis.fr/>`_."
msgstr ""
"对于我们的文档，我们已经开始使用 \"Diàtaxis 框架 <https://diataxis.fr/>`_\"。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:258
msgid ""
"Our “How to” guides should have titles that continue the sencence “How to "
"…”, for example, “How to upgrade to Flower 1.0”."
msgstr ""
"我们的 \"如何 \"指南的标题应延续 \"如何...... \"的句式，例如 \"如何升级到 "
"Flower 1.0\"。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:260
msgid ""
"Most of our guides do not follow this new format yet, and changing their "
"title is (unfortunately) more involved than one might think."
msgstr ""
"我们的大多数指南还没有采用这种新格式，而更改其标题（不幸的是）比人们想象的要"
"复杂得多。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:262
msgid ""
"This issue is about changing the title of a doc from present continious to "
"present simple."
msgstr "这个问题是关于将文档标题从现在进行时改为现在进行时。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:264
msgid ""
"Let's take the example of “Saving Progress” which we changed to “Save "
"Progress”. Does this pass our check?"
msgstr ""
"以 \"保存进度 \"为例，我们将其改为 \"保存进度\"。这是否通过了我们的检查？"

#: ../../source/contributor-tutorial-contribute-on-github.rst:266
msgid "Before: ”How to saving progress” ❌"
msgstr "之前： \"如何保存进度\" ❌"

#: ../../source/contributor-tutorial-contribute-on-github.rst:268
msgid "After: ”How to save progress” ✅"
msgstr "之后： \"如何保存进度\"✅"

#: ../../source/contributor-tutorial-contribute-on-github.rst:271
msgid "Solution"
msgstr "解决方案"

#: ../../source/contributor-tutorial-contribute-on-github.rst:273
msgid ""
"This is a tiny change, but it’ll allow us to test your end-to-end setup. "
"After cloning and setting up the Flower repo, here’s what you should do:"
msgstr ""
"这只是一个很小的改动，但可以让我们测试你的端到端设置。克隆并设置好 Flower "
"repo 后，你应该这样做："

#: ../../source/contributor-tutorial-contribute-on-github.rst:275
msgid "Find the source file in `doc/source`"
msgstr "在 `doc/source` 中查找源文件"

#: ../../source/contributor-tutorial-contribute-on-github.rst:276
msgid ""
"Make the change in the `.rst` file (beware, the dashes under the title "
"should be the same length as the title itself)"
msgstr "在 `.rst` 文件中进行修改（注意，标题下的破折号应与标题本身的长度相同）"

#: ../../source/contributor-tutorial-contribute-on-github.rst:277
msgid ""
"Build the docs and check the result: `<https://flower.dev/docs/writing-"
"documentation.html#edit-an-existing-page>`_"
msgstr ""
"构建文档并检查结果： `<https://flower.dev/docs/writing-documentation."
"html#edit-an-existing-page>`_"

#: ../../source/contributor-tutorial-contribute-on-github.rst:280
msgid "Rename file"
msgstr "重命名文件"

#: ../../source/contributor-tutorial-contribute-on-github.rst:282
msgid ""
"You might have noticed that the file name still reflects the old wording. If "
"we just change the file, then we break all existing links to it - it is "
"**very important** to avoid that, breaking links can harm our search engine "
"ranking."
msgstr ""
"您可能已经注意到，文件名仍然反映了旧的措辞。如果我们只是更改文件，那么就会破"
"坏与该文件的所有现有链接--避免这种情况是***重要的，破坏链接会损害我们的搜索引"
"擎排名。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:285
msgid "Here’s how to change the file name:"
msgstr "下面是更改文件名的方法："

#: ../../source/contributor-tutorial-contribute-on-github.rst:287
msgid "Change the file name to `save-progress.rst`"
msgstr "将文件名改为`save-progress.rst`"

#: ../../source/contributor-tutorial-contribute-on-github.rst:288
msgid "Add a redirect rule to `doc/source/conf.py`"
msgstr "在 `doc/source/conf.py` 中添加重定向规则"

#: ../../source/contributor-tutorial-contribute-on-github.rst:290
msgid ""
"This will cause a redirect from `saving-progress.html` to `save-progress."
"html`, old links will continue to work."
msgstr ""
"这将导致从 `saving-progress.html` 重定向到 `save-progress.html`，旧链接将继续"
"工作。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:293
msgid "Apply changes in the index file"
msgstr "应用索引文件中的更改"

#: ../../source/contributor-tutorial-contribute-on-github.rst:295
msgid ""
"For the lateral navigation bar to work properly, it is very important to "
"update the `index.rst` file as well. This is where we define the whole "
"arborescence of the navbar."
msgstr ""
"要使横向导航栏正常工作，更新 `index.rst` 文件也非常重要。我们就是在这里定义整"
"个导航栏的结构。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:298
msgid "Find and modify the file name in `index.rst`"
msgstr "查找并修改 `index.rst` 中的文件名"

#: ../../source/contributor-tutorial-contribute-on-github.rst:301
msgid "Open PR"
msgstr "开放式 PR"

#: ../../source/contributor-tutorial-contribute-on-github.rst:303
msgid ""
"Commit the changes (commit messages are always imperative: “Do something”, "
"in this case “Change …”)"
msgstr "提交更改（提交信息总是命令式的：\"做某事\"，这里是 \"更改......\"）"

#: ../../source/contributor-tutorial-contribute-on-github.rst:304
msgid "Push the changes to your fork"
msgstr "将更改推送到分叉"

#: ../../source/contributor-tutorial-contribute-on-github.rst:305
msgid "Open a PR (as shown above)"
msgstr "打开 PR（如上图所示）"

#: ../../source/contributor-tutorial-contribute-on-github.rst:306
msgid "Wait for it to be approved!"
msgstr "等待审批！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:307
msgid "Congrats! 🥳 You're now officially a Flower contributor!"
msgstr "祝贺你 🥳 您现在正式成为 \"Flower \"贡献者！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:311
msgid "How to write a good PR title"
msgstr "如何撰写好的公关标题"

#: ../../source/contributor-tutorial-contribute-on-github.rst:313
msgid ""
"A well-crafted PR title helps team members quickly understand the purpose "
"and scope of the changes being proposed. Here's a guide to help you write a "
"good GitHub PR title:"
msgstr ""
"一个精心撰写的公关标题能帮助团队成员迅速了解所提修改的目的和范围。以下指南可"
"帮助您撰写一个好的 GitHub PR 标题："

#: ../../source/contributor-tutorial-contribute-on-github.rst:315
msgid ""
"1. Be Clear and Concise: Provide a clear summary of the changes in a concise "
"manner. 1. Use Actionable Verbs: Start with verbs like \"Add,\" \"Update,\" "
"or \"Fix\" to indicate the purpose. 1. Include Relevant Information: Mention "
"the affected feature or module for context. 1. Keep it Short: Avoid lengthy "
"titles for easy readability. 1. Use Proper Capitalization and Punctuation: "
"Follow grammar rules for clarity."
msgstr ""
"1. 简明扼要： 以简明扼要的方式清楚地概述变化。1. 使用可操作的动词： 使用 \"添"
"加\"、\"更新 \"或 \"修复 \"等动词来表明目的。1. 包含相关信息： 提及受影响的功"
"能或模块以了解上下文。1. 简短：避免冗长的标题，以方便阅读。1. 使用正确的大小"
"写和标点符号： 遵守语法规则，以确保清晰。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:321
msgid ""
"Let's start with a few examples for titles that should be avoided because "
"they do not provide meaningful information:"
msgstr "让我们先举例说明几个应该避免使用的标题，因为它们不能提供有意义的信息："

#: ../../source/contributor-tutorial-contribute-on-github.rst:323
msgid "Implement Algorithm"
msgstr "执行算法"

#: ../../source/contributor-tutorial-contribute-on-github.rst:324
msgid "Database"
msgstr "数据库"

#: ../../source/contributor-tutorial-contribute-on-github.rst:325
msgid "Add my_new_file.py to codebase"
msgstr "在代码库中添加 my_new_file.py"

#: ../../source/contributor-tutorial-contribute-on-github.rst:326
msgid "Improve code in module"
msgstr "改进模块中的代码"

#: ../../source/contributor-tutorial-contribute-on-github.rst:327
msgid "Change SomeModule"
msgstr "更改 SomeModule"

#: ../../source/contributor-tutorial-contribute-on-github.rst:329
msgid ""
"Here are a few positive examples which provide helpful information without "
"repeating how they do it, as that is already visible in the \"Files "
"changed\" section of the PR:"
msgstr ""
"这里有几个正面的例子，提供了有用的信息，但没有重复他们是如何做的，因为在 PR "
"的 \"已更改文件 \"部分已经可以看到："

#: ../../source/contributor-tutorial-contribute-on-github.rst:331
msgid "Update docs banner to mention Flower Summit 2023"
msgstr "更新文件横幅，提及 2023 年 Flower 峰会"

#: ../../source/contributor-tutorial-contribute-on-github.rst:332
msgid "Remove unnecessary XGBoost dependency"
msgstr "移除不必要的 XGBoost 依赖性"

#: ../../source/contributor-tutorial-contribute-on-github.rst:333
msgid "Remove redundant attributes in strategies subclassing FedAvg"
msgstr "删除 FedAvg 子类化策略中的多余属性"

#: ../../source/contributor-tutorial-contribute-on-github.rst:334
msgid "Add CI job to deploy the staging system when the `main` branch changes"
msgstr "添加 CI 作业，以便在 \"主 \"分支发生变化时部署暂存系统"

#: ../../source/contributor-tutorial-contribute-on-github.rst:335
msgid ""
"Add new amazing library which will be used to improve the simulation engine"
msgstr "添加新的惊人库，用于改进模拟引擎"

#: ../../source/contributor-tutorial-contribute-on-github.rst:339
#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:548
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:946
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:747
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:713
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:367
msgid "Next steps"
msgstr "接下来的步骤"

#: ../../source/contributor-tutorial-contribute-on-github.rst:341
msgid ""
"Once you have made your first PR, and want to contribute more, be sure to "
"check out the following :"
msgstr "一旦您完成了第一份 PR，并希望做出更多贡献，请务必查看以下内容："

#: ../../source/contributor-tutorial-contribute-on-github.rst:343
msgid ""
"`Good first contributions <https://flower.dev/docs/framework/contributor-ref-"
"good-first-contributions.html>`_, where you should particularly look into "
"the :code:`baselines` contributions."
msgstr ""
"好的第一批贡献 <https://flower.dev/docs/framework/contributor-ref-good-first-"
"contributions.html>`_，在这里你应该特别看看 :code:`baselines` 的贡献。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:2
msgid "Get started as a contributor"
msgstr "成为贡献者"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:5
msgid "Prerequisites"
msgstr "先决条件"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:7
msgid "`Python 3.7 <https://docs.python.org/3.7/>`_ or above"
msgstr "Python 3.7 <https://docs.python.org/3.7/>`_ 或更高版本"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:8
msgid "`Poetry 1.3 <https://python-poetry.org/>`_ or above"
msgstr "`Poetry 1.3 <https://python-poetry.org/>`_ 或更高版本"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:9
msgid "(Optional) `pyenv <https://github.com/pyenv/pyenv>`_"
msgstr "(可选） `pyenv <https://github.com/pyenv/pyenv>`_"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:10
msgid ""
"(Optional) `pyenv-virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_"
msgstr ""
"(可选） `pyenv-virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:12
msgid ""
"Flower uses :code:`pyproject.toml` to manage dependencies and configure "
"development tools (the ones which support it). Poetry is a build tool which "
"supports `PEP 517 <https://www.python.org/dev/peps/pep-0517/>`_."
msgstr ""
"Flower 使用 :code:`pyproject.toml` 来管理依赖关系和配置开发工具（支持它的）。"
"Poetry 是一种支持 `PEP 517 <https://www.python.org/dev/peps/pep-0517/>`_ 的构"
"建工具。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:18
msgid "Developer Machine Setup"
msgstr "开发者机器设置"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:20
msgid ""
"First, clone the `Flower repository <https://github.com/adap/flower>`_ from "
"GitHub::"
msgstr ""
"首先，从 GitHub 克隆 \"Flower 存储库 <https://github.com/adap/flower>`_\"："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:26
msgid ""
"Second, create a virtual environment (and activate it). If you chose to use :"
"code:`pyenv` (with the :code:`pyenv-virtualenv` plugin) and already have it "
"installed , you can use the following convenience script (by default it will "
"use :code:`Python 3.8.17`, but you can change it by providing a specific :"
"code:`<version>`)::"
msgstr ""
"其次，创建虚拟环境（并激活它）。如果您选择使用 :code:`pyenv`（使用 :code:"
"`pyenv-virtualenv`插件），并且已经安装了该插件，则可以使用下面的便捷脚本（默"
"认情况下使用 :code:`Python3.8.17`，但您可以通过提供特定的 :code:`<版本>`来更"
"改）：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:33
msgid ""
"If you don't have :code:`pyenv` installed, you can use the following script "
"that will install pyenv, set it up and create the virtual environment (with :"
"code:`Python 3.8.17` by default)::"
msgstr ""
"如果没有安装 :code:`pyenv`，可以使用以下脚本安装 pyenv、设置并创建虚拟环境"
"（默认使用 :code:`Python3.8.17）：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:39
msgid ""
"Third, install the Flower package in development mode (think :code:`pip "
"install -e`) along with all necessary dependencies::"
msgstr ""
"第三，在开发模式下安装 Flower 软件包（想想 :code:`pip install -e`）以及所有必"
"要的依赖项：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:46
msgid "Convenience Scripts"
msgstr "便捷脚本"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:48
msgid ""
"The Flower repository contains a number of convenience scripts to make "
"recurring development tasks easier and less error-prone. See the :code:`/"
"dev` subdirectory for a full list. The following scripts are amonst the most "
"important ones:"
msgstr ""
"Flower 软件仓库包含大量便捷脚本，可使重复性开发任务更轻松、更不易出错。完整列"
"表请参见 :code:`/dev` 子目录。以下是最重要的脚本："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:54
msgid "Create/Delete Virtual Environment"
msgstr "创建/删除虚拟环境"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:62
msgid "Compile ProtoBuf Definitions"
msgstr "编译 ProtoBuf 定义"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:69
msgid "Auto-Format Code"
msgstr "自动格式化代码"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:76
msgid "Run Linters and Tests"
msgstr "运行分类器和测试"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:83
msgid "Run Github Actions (CI) locally"
msgstr "在本地运行 Github 操作 (CI)"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:85
msgid ""
"Developers could run the full set of Github Actions workflows under their "
"local environment by using `Act <https://github.com/nektos/act>_`. Please "
"refer to the installation instructions under the linked repository and run "
"the next command under Flower main cloned repository folder::"
msgstr ""
"开发人员可以使用 `Act <https://github.com/nektos/act>_` 在本地环境下运行全套 "
"Github Actions 工作流程。请参考链接仓库下的安装说明，并在 Flower 主克隆仓库文"
"件夹下运行下一条命令：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:92
msgid ""
"The Flower default workflow would run by setting up the required Docker "
"machines underneath."
msgstr "Flower 默认工作流程将通过在下面设置所需的 Docker 机器来运行。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:97
msgid "Build Release"
msgstr "版本发布"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:99
msgid ""
"Flower uses Poetry to build releases. The necessary command is wrapped in a "
"simple script::"
msgstr "Flower 使用 Poetry 创建发布版本。必要的命令封装在一个简单的脚本中：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:104
msgid ""
"The resulting :code:`.whl` and :code:`.tar.gz` releases will be stored in "
"the :code:`/dist` subdirectory."
msgstr ""
"生成的 :code:`.whl` 和 :code:`.tar.gz` 版本将存储在 :code:`/dist` 子目录中。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:109
msgid "Build Documentation"
msgstr "构建文档"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:111
msgid ""
"Flower's documentation uses `Sphinx <https://www.sphinx-doc.org/>`_. There's "
"no convenience script to re-build the documentation yet, but it's pretty "
"easy::"
msgstr ""
"Flower 的文档使用 `Sphinx <https://www.sphinx-doc.org/>`_。目前还没有很方便的"
"脚本来重新构建文档，不过这很容易：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:117
msgid "This will generate HTML documentation in ``doc/build/html``."
msgstr "这将在 ``doc/build/html`` 中生成 HTML 文档。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:2
msgid "Example: FedBN in PyTorch - From Centralized To Federated"
msgstr "示例： PyTorch 中的 FedBN - 从集中式到联邦式"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:4
msgid ""
"This tutorial will show you how to use Flower to build a federated version "
"of an existing machine learning workload with `FedBN <https://github.com/med-"
"air/FedBN>`_, a federated training strategy designed for non-iid data. We "
"are using PyTorch to train a Convolutional Neural Network(with Batch "
"Normalization layers) on the CIFAR-10 dataset. When applying FedBN, only few "
"changes needed compared to `Example: PyTorch - From Centralized To Federated "
"<https://flower.dev/docs/examples/pytorch-from-centralized-to-federated."
"html>`_."
msgstr ""
"本教程将向您展示如何使用 Flower 为现有的机器学习框架构建一个联邦学习的版本，"
"并使用 \"FedBN <https://github.com/med-air/FedBN>`_\"（一种针对非 iid 数据设"
"计的联邦训练策略）。我们使用 PyTorch 在 CIFAR-10 数据集上训练一个卷积神经网络"
"（带有Batch Normalization层）。在应用 FedBN 时，只需对 `示例: PyTorch - 从集"
"中式到联邦式 <https://flower.dev/docs/examples/pytorch-from-centralized-to-"
"federated.html>`_ 做少量改动。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:9
#: ../../source/example-pytorch-from-centralized-to-federated.rst:10
msgid "Centralized Training"
msgstr "集中式训练"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:10
msgid ""
"All files are revised based on `Example: PyTorch - From Centralized To "
"Federated <https://flower.dev/docs/examples/pytorch-from-centralized-to-"
"federated.html>`_. The only thing to do is modifying the file called :code:"
"`cifar.py`, revised part is shown below:"
msgstr ""
"所有文件均根据 `示例： PyTorch -从集中式到联邦式 <https://flower.dev/docs/"
"examples/pytorch-from-centralized-to-federated.html>`_。唯一要做的就是修改名"
"为 :code:`cifar.py` 的文件，修改部分如下所示："

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:13
msgid ""
"The model architecture defined in class Net() is added with Batch "
"Normalization layers accordingly."
msgstr "类 Net() 中定义的模型架构会相应添加Batch Normalization层。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:41
#: ../../source/example-pytorch-from-centralized-to-federated.rst:157
msgid "You can now run your machine learning workload:"
msgstr "现在，您可以运行您的机器学习工作了："

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:47
msgid ""
"So far this should all look fairly familiar if you've used PyTorch before. "
"Let's take the next step and use what we've built to create a federated "
"learning system within FedBN, the sytstem consists of one server and two "
"clients."
msgstr ""
"到目前为止，如果您以前使用过 PyTorch，这一切看起来应该相当熟悉。让我们进行下"
"一步，使用我们所构建的内容在 FedBN 中创建一个联邦学习系统，该系统由一个服务器"
"和两个客户端组成。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:51
#: ../../source/example-pytorch-from-centralized-to-federated.rst:167
msgid "Federated Training"
msgstr "联邦培训"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:53
msgid ""
"If you have read `Example: PyTorch - From Centralized To Federated <https://"
"flower.dev/docs/examples/pytorch-from-centralized-to-federated.html>`_, the "
"following parts are easy to follow, onyl :code:`get_parameters` and :code:"
"`set_parameters` function in :code:`client.py` needed to revise. If not, "
"please read the `Example: PyTorch - From Centralized To Federated <https://"
"flower.dev/docs/examples/pytorch-from-centralized-to-federated.html>`_. "
"first."
msgstr ""
"如果你读过 `示例： PyTorch - 从集中式到联邦式 <https://flower.dev/docs/"
"examples/pytorch-from-centralized-to-federated.html>`_，下面的部分就很容易理"
"解了，只需要修改 :code:`get_parameters` 和 :code:`set_parameters` 中的 :code:"
"`client.py` 函数。如果没有，请阅读 `示例： PyTorch - 从集中式到联邦式 "
"<https://flower.dev/docs/examples/pytorch-from-centralized-to-federated."
"html>`_。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:56
msgid ""
"Our example consists of one *server* and two *clients*. In FedBN, :code:"
"`server.py` keeps unchanged, we can start the server directly."
msgstr ""
"我们的示例包括一个*服务器*和两个*客户端*。在 FedBN 中，:code:`server.py` 保持"
"不变，我们可以直接启动服务器。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:62
msgid ""
"Finally, we will revise our *client* logic by changing :code:"
"`get_parameters` and :code:`set_parameters` in :code:`client.py`, we will "
"exclude batch normalization parameters from model parameter list when "
"sending to or receiving from the server."
msgstr ""
"最后，我们将修改 *client* 的逻辑，修改 :code:`client.py` 中的 :code:"
"`get_parameters` 和 :code:`set_parameters`，在向服务器发送或从服务器接收时，"
"我们将从模型参数列表中排除batch normalization层的参数。"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:85
msgid "Now, you can now open two additional terminal windows and run"
msgstr "现在，您可以打开另外两个终端窗口并运行程序"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:91
msgid ""
"in each window (make sure that the server is still running before you do so) "
"and see your (previously centralized) PyTorch project run federated learning "
"with FedBN strategy across two clients. Congratulations!"
msgstr ""
"确保服务器仍在运行后，然后您就能看到您的 PyTorch 项目（之前是集中式的）通过 "
"FedBN 策略在两个客户端上运行联合学习。祝贺！"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:94
#: ../../source/example-jax-from-centralized-to-federated.rst:277
#: ../../source/example-mxnet-walk-through.rst:356
#: ../../source/example-pytorch-from-centralized-to-federated.rst:310
#: ../../source/tutorial-quickstart-jax.rst:283
msgid "Next Steps"
msgstr "下一步工作"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:96
msgid ""
"The full source code for this example can be found `here <https://github.com/"
"adap/flower/blob/main/examples/pytorch-from-centralized-to-federated>`_. Our "
"example is of course somewhat over-simplified because both clients load the "
"exact same dataset, which isn't realistic. You're now prepared to explore "
"this topic further. How about using different subsets of CIFAR-10 on each "
"client? How about adding more clients?"
msgstr ""
"本示例的完整源代码可在 <https://github.com/adap/flower/blob/main/examples/"
"pytorch-from-centralized-to-federated>`_ 找到。当然，我们的示例有些过于简单，"
"因为两个客户端都加载了完全相同的数据集，这并不真实。让我们准备好进一步探讨这"
"一主题。如在每个客户端使用不同的 CIFAR-10 子集，或者增加客户端的数量。"

#: ../../source/example-jax-from-centralized-to-federated.rst:2
msgid "Example: JAX - Run JAX Federated"
msgstr "示例： JAX - 运行联邦式 JAX"

#: ../../source/example-jax-from-centralized-to-federated.rst:4
#: ../../source/tutorial-quickstart-jax.rst:10
msgid ""
"This tutorial will show you how to use Flower to build a federated version "
"of an existing JAX workload. We are using JAX to train a linear regression "
"model on a scikit-learn dataset. We will structure the example similar to "
"our `PyTorch - From Centralized To Federated <https://github.com/adap/flower/"
"blob/main/examples/pytorch-from-centralized-to-federated>`_ walkthrough. "
"First, we build a centralized training approach based on the `Linear "
"Regression with JAX <https://coax.readthedocs.io/en/latest/examples/"
"linear_regression/jax.html>`_ tutorial`. Then, we build upon the centralized "
"training code to run the training in a federated fashion."
msgstr ""
"本教程将向您展示如何使用 Flower 构建现有 JAX 的联邦学习版本。我们将使用 JAX "
"在 scikit-learn 数据集上训练线性回归模型。我们将采用与 `PyTorch - 从集中式到"
"联邦式 <https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_ 教程中类似的示例结构。首先，我们根据 `JAX 的线性"
"回归 <https://coax.readthedocs.io/en/latest/examples/linear_regression/jax."
"html>`_ 教程构建集中式训练方法。然后，我们在集中式训练代码的基础上以联邦方式"
"运行训练。"

#: ../../source/example-jax-from-centralized-to-federated.rst:10
#: ../../source/tutorial-quickstart-jax.rst:16
msgid ""
"Before we start building our JAX example, we need install the packages :code:"
"`jax`, :code:`jaxlib`, :code:`scikit-learn`, and :code:`flwr`:"
msgstr ""
"在开始构建 JAX 示例之前，我们需要安装软件包 :code:`jax`、:code:`jaxlib`、:"
"code:`scikit-learn` 和 :code:`flwr`："

#: ../../source/example-jax-from-centralized-to-federated.rst:18
#: ../../source/tutorial-quickstart-jax.rst:24
msgid "Linear Regression with JAX"
msgstr "使用 JAX 进行线性回归"

#: ../../source/example-jax-from-centralized-to-federated.rst:20
#: ../../source/tutorial-quickstart-jax.rst:26
msgid ""
"We begin with a brief description of the centralized training code based on "
"a :code:`Linear Regression` model. If you want a more in-depth explanation "
"of what's going on then have a look at the official `JAX documentation "
"<https://jax.readthedocs.io/>`_."
msgstr ""
"首先，我们将简要介绍基于 :code:`Linear Regression` 模型的集中式训练代码。如果"
"您想获得更深入的解释，请参阅官方的 `JAX 文档 <https://jax.readthedocs.io/"
">`_。"

#: ../../source/example-jax-from-centralized-to-federated.rst:23
#: ../../source/tutorial-quickstart-jax.rst:29
msgid ""
"Let's create a new file called :code:`jax_training.py` with all the "
"components required for a traditional (centralized) linear regression "
"training. First, the JAX packages :code:`jax` and :code:`jaxlib` need to be "
"imported. In addition, we need to import :code:`sklearn` since we use :code:"
"`make_regression` for the dataset and :code:`train_test_split` to split the "
"dataset into a training and test set. You can see that we do not yet import "
"the :code:`flwr` package for federated learning. This will be done later."
msgstr ""
"让我们创建一个名为 :code:`jax_training.py` 的新文件，其中包含传统（集中式）线"
"性回归训练所需的所有组件。首先，需要导入 JAX 包 :code:`jax` 和 :code:"
"`jaxlib`。此外，我们还需要导入 :code:`sklearn`，因为我们使用 :code:"
"`make_regression` 创建数据集，并使用 :code:`train_test_split` 将数据集拆分成"
"训练集和测试集。您可以看到，我们还没有导入用于联邦学习的 :code:`flwr` 软件"
"包，这将在稍后完成。"

#: ../../source/example-jax-from-centralized-to-federated.rst:37
#: ../../source/tutorial-quickstart-jax.rst:43
msgid ""
"The :code:`load_data()` function loads the mentioned training and test sets."
msgstr ":code:`load_data()` 函数会加载上述训练集和测试集。"

#: ../../source/example-jax-from-centralized-to-federated.rst:47
#: ../../source/tutorial-quickstart-jax.rst:53
msgid ""
"The model architecture (a very simple :code:`Linear Regression` model) is "
"defined in :code:`load_model()`."
msgstr ""
"模型结构（一个非常简单的 :code:`Linear Regression` 线性回归模型）在 :code:"
"`load_model()` 中定义。"

#: ../../source/example-jax-from-centralized-to-federated.rst:59
#: ../../source/tutorial-quickstart-jax.rst:65
msgid ""
"We now need to define the training (function :code:`train()`), which loops "
"over the training set and measures the loss (function :code:`loss_fn()`) for "
"each batch of training examples. The loss function is separate since JAX "
"takes derivatives with a :code:`grad()` function (defined in the :code:"
"`main()` function and called in :code:`train()`)."
msgstr ""
"现在，我们需要定义训练函数（ :code:`train()`）。它循环遍历训练集，并计算每批"
"训练数据的损失值（函数 :code:`loss_fn()`）。由于 JAX 使用 :code:`grad()` 函数"
"提取导数（在 :code:`main()` 函数中定义，并在 :code:`train()` 中调用），因此损"
"失函数是独立的。"

#: ../../source/example-jax-from-centralized-to-federated.rst:77
#: ../../source/tutorial-quickstart-jax.rst:83
msgid ""
"The evaluation of the model is defined in the function :code:`evaluation()`. "
"The function takes all test examples and measures the loss of the linear "
"regression model."
msgstr ""
"模型的评估在函数 :code:`evaluation()` 中定义。该函数获取所有测试数据，并计算"
"线性回归模型的损失值。"

#: ../../source/example-jax-from-centralized-to-federated.rst:88
#: ../../source/tutorial-quickstart-jax.rst:94
msgid ""
"Having defined the data loading, model architecture, training, and "
"evaluation we can put everything together and train our model using JAX. As "
"already mentioned, the :code:`jax.grad()` function is defined in :code:"
"`main()` and passed to :code:`train()`."
msgstr ""
"在定义了数据加载、模型架构、训练和评估之后，我们就可以把这些放在一起，使用 "
"JAX 训练我们的模型了。如前所述，:code:`jax.grad()` 函数在 :code:`main()` 中定"
"义，并传递给 :code:`train()`。"

#: ../../source/example-jax-from-centralized-to-federated.rst:105
#: ../../source/tutorial-quickstart-jax.rst:111
msgid "You can now run your (centralized) JAX linear regression workload:"
msgstr "现在您可以运行（集中式）JAX 线性回归工作了："

#: ../../source/example-jax-from-centralized-to-federated.rst:111
#: ../../source/tutorial-quickstart-jax.rst:117
msgid ""
"So far this should all look fairly familiar if you've used JAX before. Let's "
"take the next step and use what we've built to create a simple federated "
"learning system consisting of one server and two clients."
msgstr ""
"到目前为止，如果你以前使用过 JAX，就会对这一切感到很熟悉。下一步，让我们利用"
"已构建的代码创建一个简单的联邦学习系统（一个服务器和两个客户端）。"

#: ../../source/example-jax-from-centralized-to-federated.rst:115
#: ../../source/tutorial-quickstart-jax.rst:121
msgid "JAX meets Flower"
msgstr "JAX 结合 Flower"

#: ../../source/example-jax-from-centralized-to-federated.rst:117
#: ../../source/tutorial-quickstart-jax.rst:123
msgid ""
"The concept of federating an existing workload is always the same and easy "
"to understand. We have to start a *server* and then use the code in :code:"
"`jax_training.py` for the *clients* that are connected to the *server*. The "
"*server* sends model parameters to the clients. The *clients* run the "
"training and update the parameters. The updated parameters are sent back to "
"the *server*, which averages all received parameter updates. This describes "
"one round of the federated learning process, and we repeat this for multiple "
"rounds."
msgstr ""
"把现有工作联邦化的概念始终是相同的，也很容易理解。我们要启动一个*服务器*，然"
"后对连接到*服务器*的*客户端*运行 :code:`jax_training.py`中的代码。*服务器*向"
"客户端发送模型参数，*客户端*运行训练并更新参数。更新后的参数被发回*服务器*，"
"然后服务器对所有收到的参数进行平均聚合。以上的描述构成了一轮联邦学习，我们将"
"重复进行多轮学习。"

#: ../../source/example-jax-from-centralized-to-federated.rst:123
#: ../../source/example-mxnet-walk-through.rst:204
#: ../../source/example-pytorch-from-centralized-to-federated.rst:181
#: ../../source/tutorial-quickstart-jax.rst:129
msgid ""
"Our example consists of one *server* and two *clients*. Let's set up :code:"
"`server.py` first. The *server* needs to import the Flower package :code:"
"`flwr`. Next, we use the :code:`start_server` function to start a server and "
"tell it to perform three rounds of federated learning."
msgstr ""
"我们的示例包括一个*服务器*和两个*客户端*。让我们先设置 :code:`server.py`。*服"
"务器*需要导入 Flower 软件包 :code:`flwr`。接下来，我们使用 :code:"
"`start_server` 函数启动服务器，并让它执行三轮联邦学习。"

#: ../../source/example-jax-from-centralized-to-federated.rst:133
#: ../../source/example-mxnet-walk-through.rst:214
#: ../../source/example-pytorch-from-centralized-to-federated.rst:191
#: ../../source/tutorial-quickstart-jax.rst:139
msgid "We can already start the *server*:"
msgstr "我们已经可以启动*服务器*了："

#: ../../source/example-jax-from-centralized-to-federated.rst:139
#: ../../source/tutorial-quickstart-jax.rst:145
msgid ""
"Finally, we will define our *client* logic in :code:`client.py` and build "
"upon the previously defined JAX training in :code:`jax_training.py`. Our "
"*client* needs to import :code:`flwr`, but also :code:`jax` and :code:"
"`jaxlib` to update the parameters on our JAX model:"
msgstr ""
"最后，我们将在 :code:`client.py` 中定义我们的 *client* 逻辑，并以之前在 :"
"code:`jax_training.py` 中定义的 JAX 训练为基础。我们的 *client* 需要导入 :"
"code:`flwr`，还需要导入 :code:`jax` 和 :code:`jaxlib` 以更新 JAX 模型的参数："

#: ../../source/example-jax-from-centralized-to-federated.rst:154
#: ../../source/tutorial-quickstart-jax.rst:160
msgid ""
"Implementing a Flower *client* basically means implementing a subclass of "
"either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. Our "
"implementation will be based on :code:`flwr.client.NumPyClient` and we'll "
"call it :code:`FlowerClient`. :code:`NumPyClient` is slightly easier to "
"implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like JAX) because it avoids some of the boilerplate that "
"would otherwise be necessary. :code:`FlowerClient` needs to implement four "
"methods, two methods for getting/setting model parameters, one method for "
"training the model, and one method for testing the model:"
msgstr ""
"实现一个 Flower *client*基本上意味着去实现一个 :code:`flwr.client.Client` "
"或 :code:`flwr.client.NumPyClient` 的子类。我们的代码实现将基于 :code:`flwr."
"client.NumPyClient`，并将其命名为 :code:`FlowerClient`。如果使用具有良好 "
"NumPy 互操作性的框架（如 JAX），:code:`NumPyClient` 比 :code:`Client`更容易实"
"现，因为它避免了一些不必要的操作。:code:`FlowerClient` 需要实现四个方法，两个"
"用于获取/设置模型参数，一个用于训练模型，一个用于测试模型："

#: ../../source/example-jax-from-centralized-to-federated.rst:161
#: ../../source/example-mxnet-walk-through.rst:242
#: ../../source/tutorial-quickstart-jax.rst:167
msgid ":code:`set_parameters (optional)`"
msgstr ":code:`set_parameters (可选)`"

#: ../../source/example-jax-from-centralized-to-federated.rst:160
#: ../../source/example-mxnet-walk-through.rst:241
#: ../../source/example-pytorch-from-centralized-to-federated.rst:219
#: ../../source/tutorial-quickstart-jax.rst:166
msgid ""
"set the model parameters on the local model that are received from the server"
msgstr "在本地模型上设置从服务器接收的模型参数"

#: ../../source/example-jax-from-centralized-to-federated.rst:161
#: ../../source/tutorial-quickstart-jax.rst:167
msgid "transform parameters to NumPy :code:`ndarray`'s"
msgstr "将参数转换为 NumPy :code:`ndarray`格式"

#: ../../source/example-jax-from-centralized-to-federated.rst:162
#: ../../source/example-mxnet-walk-through.rst:243
#: ../../source/example-pytorch-from-centralized-to-federated.rst:220
#: ../../source/tutorial-quickstart-jax.rst:168
msgid ""
"loop over the list of model parameters received as NumPy :code:`ndarray`'s "
"(think list of neural network layers)"
msgstr ""
"循环遍历以 NumPy :code:`ndarray` 形式接收的模型参数列表（可以看作神经网络的列"
"表）"

#: ../../source/example-jax-from-centralized-to-federated.rst:163
#: ../../source/example-mxnet-walk-through.rst:244
#: ../../source/example-pytorch-from-centralized-to-federated.rst:221
#: ../../source/tutorial-quickstart-jax.rst:169
#: ../../source/tutorial-quickstart-mxnet.rst:169
#: ../../source/tutorial-quickstart-pytorch.rst:155
#: ../../source/tutorial-quickstart-scikitlearn.rst:108
msgid ":code:`get_parameters`"
msgstr ":code:`get_parameters`"

#: ../../source/example-jax-from-centralized-to-federated.rst:164
#: ../../source/example-mxnet-walk-through.rst:245
#: ../../source/example-pytorch-from-centralized-to-federated.rst:222
#: ../../source/tutorial-quickstart-jax.rst:170
msgid ""
"get the model parameters and return them as a list of NumPy :code:"
"`ndarray`'s (which is what :code:`flwr.client.NumPyClient` expects)"
msgstr ""
"获取模型参数，并以 NumPy :code:`ndarray`的列表形式返回（这正是 :code:`flwr."
"client.NumPyClient`所匹配的格式）"

#: ../../source/example-jax-from-centralized-to-federated.rst:167
#: ../../source/example-mxnet-walk-through.rst:248
#: ../../source/example-pytorch-from-centralized-to-federated.rst:225
#: ../../source/tutorial-quickstart-jax.rst:173
#: ../../source/tutorial-quickstart-mxnet.rst:175
#: ../../source/tutorial-quickstart-pytorch.rst:161
#: ../../source/tutorial-quickstart-scikitlearn.rst:115
msgid ":code:`fit`"
msgstr ":code:`fit`"

#: ../../source/example-jax-from-centralized-to-federated.rst:166
#: ../../source/example-jax-from-centralized-to-federated.rst:170
#: ../../source/example-mxnet-walk-through.rst:247
#: ../../source/example-mxnet-walk-through.rst:251
#: ../../source/example-pytorch-from-centralized-to-federated.rst:224
#: ../../source/example-pytorch-from-centralized-to-federated.rst:228
#: ../../source/tutorial-quickstart-jax.rst:172
#: ../../source/tutorial-quickstart-jax.rst:176
msgid ""
"update the parameters of the local model with the parameters received from "
"the server"
msgstr "用从服务器接收到的参数更新本地模型的参数"

#: ../../source/example-jax-from-centralized-to-federated.rst:167
#: ../../source/example-mxnet-walk-through.rst:248
#: ../../source/example-pytorch-from-centralized-to-federated.rst:225
#: ../../source/tutorial-quickstart-jax.rst:173
msgid "train the model on the local training set"
msgstr "在本地训练集上训练模型"

#: ../../source/example-jax-from-centralized-to-federated.rst:168
#: ../../source/tutorial-quickstart-jax.rst:174
msgid "get the updated local model parameters and return them to the server"
msgstr "获取更新后的本地模型参数并返回服务器"

#: ../../source/example-jax-from-centralized-to-federated.rst:172
#: ../../source/example-mxnet-walk-through.rst:253
#: ../../source/example-pytorch-from-centralized-to-federated.rst:230
#: ../../source/tutorial-quickstart-jax.rst:178
#: ../../source/tutorial-quickstart-mxnet.rst:178
#: ../../source/tutorial-quickstart-pytorch.rst:164
#: ../../source/tutorial-quickstart-scikitlearn.rst:118
msgid ":code:`evaluate`"
msgstr ":code:`evaluate`"

#: ../../source/example-jax-from-centralized-to-federated.rst:171
#: ../../source/example-mxnet-walk-through.rst:252
#: ../../source/example-pytorch-from-centralized-to-federated.rst:229
#: ../../source/tutorial-quickstart-jax.rst:177
msgid "evaluate the updated model on the local test set"
msgstr "在本地测试集上评估更新后的模型"

#: ../../source/example-jax-from-centralized-to-federated.rst:172
#: ../../source/tutorial-quickstart-jax.rst:178
msgid "return the local loss to the server"
msgstr "向服务器返回本地损失值"

#: ../../source/example-jax-from-centralized-to-federated.rst:174
#: ../../source/tutorial-quickstart-jax.rst:180
msgid ""
"The challenging part is to transform the JAX model parameters from :code:"
"`DeviceArray` to :code:`NumPy ndarray` to make them compatible with "
"`NumPyClient`."
msgstr ""
"具有挑战性的部分是将 JAX 模型参数从 :code:`DeviceArray` 转换为 :code:`NumPy "
"ndarray`，使其与 `NumPyClient` 兼容。"

#: ../../source/example-jax-from-centralized-to-federated.rst:176
#: ../../source/tutorial-quickstart-jax.rst:182
msgid ""
"The two :code:`NumPyClient` methods :code:`fit` and :code:`evaluate` make "
"use of the functions :code:`train()` and :code:`evaluate()` previously "
"defined in :code:`jax_training.py`. So what we really do here is we tell "
"Flower through our :code:`NumPyClient` subclass which of our already defined "
"functions to call for training and evaluation. We included type annotations "
"to give you a better understanding of the data types that get passed around."
msgstr ""
"这两个 :code:`NumPyClient` 方法 :code:`fit` 和 :code:`evaluate` 使用了之前"
"在 :code:`jax_training.py` 中定义的函数 :code:`train()` 和 :code:"
"`evaluate()`。因此，我们在这里要做的就是通过 :code:`NumPyClient` 子类告知 "
"Flower 在训练和评估时要调用哪些已定义的函数。我们加入了类型注解，以便让您更好"
"地理解传递的数据类型。"

#: ../../source/example-jax-from-centralized-to-federated.rst:245
#: ../../source/tutorial-quickstart-jax.rst:251
msgid "Having defined the federation process, we can run it."
msgstr "定义了联邦进程后，我们就可以运行它了。"

#: ../../source/example-jax-from-centralized-to-federated.rst:268
#: ../../source/example-mxnet-walk-through.rst:347
#: ../../source/example-pytorch-from-centralized-to-federated.rst:301
#: ../../source/tutorial-quickstart-jax.rst:274
msgid "And that's it. You can now open two additional terminal windows and run"
msgstr "就是这样，现在你可以打开另外两个终端窗口，然后运行"

#: ../../source/example-jax-from-centralized-to-federated.rst:274
#: ../../source/tutorial-quickstart-jax.rst:280
msgid ""
"in each window (make sure that the server is still running before you do so) "
"and see your JAX project run federated learning across two clients. "
"Congratulations!"
msgstr ""
"确保服务器仍在运行，然后在每个客户端窗口就能看到你的 JAX 项目在两个客户端上运"
"行联邦学习了。祝贺!"

#: ../../source/example-jax-from-centralized-to-federated.rst:279
#: ../../source/tutorial-quickstart-jax.rst:285
msgid ""
"The source code of this example was improved over time and can be found "
"here: `Quickstart JAX <https://github.com/adap/flower/blob/main/examples/"
"quickstart-jax>`_. Our example is somewhat over-simplified because both "
"clients load the same dataset."
msgstr ""
"此示例的源代码经过长期改进，可在此处找到： `Quickstart JAX <https://github."
"com/adap/flower/blob/main/examples/quickstart-jax>`_。我们的示例有些过于简"
"单，因为两个客户端都加载了相同的数据集。"

#: ../../source/example-jax-from-centralized-to-federated.rst:282
#: ../../source/tutorial-quickstart-jax.rst:288
msgid ""
"You're now prepared to explore this topic further. How about using a more "
"sophisticated model or using a different dataset? How about adding more "
"clients?"
msgstr ""
"现在，您已准备好进行更深一步探索了。例如使用更复杂的模型或使用不同的数据集会"
"如何？增加更多客户端会如何？"

#: ../../source/example-mxnet-walk-through.rst:2
msgid "Example: MXNet - Run MXNet Federated"
msgstr "示例： MXNet - 运行联邦式 MXNet"

#: ../../source/example-mxnet-walk-through.rst:4
msgid ""
"This tutorial will show you how to use Flower to build a federated version "
"of an existing MXNet workload. We are using MXNet to train a Sequential "
"model on the MNIST dataset. We will structure the example similar to our "
"`PyTorch - From Centralized To Federated <https://github.com/adap/flower/"
"blob/main/examples/pytorch-from-centralized-to-federated>`_ walkthrough. "
"MXNet and PyTorch are very similar and a very good comparison between MXNet "
"and PyTorch is given `here <https://mxnet.apache.org/versions/1.7.0/api/"
"python/docs/tutorials/getting-started/to-mxnet/pytorch.html>`_. First, we "
"build a centralized training approach based on the `Handwritten Digit "
"Recognition <https://mxnet.apache.org/versions/1.7.0/api/python/docs/"
"tutorials/packages/gluon/image/mnist.html>`_ tutorial. Then, we build upon "
"the centralized training code to run the training in a federated fashion."
msgstr ""
"本教程将向您展示如何使用 Flower 构建现有 MXNet 的联学习版本。我们将使用 "
"MXNet 在 MNIST 数据集上训练一个序列模型。另外，我们将采用与我们的 `PyTorch - "
"从集中式到联邦式 <https://github.com/adap/flower/blob/main/examples/pytorch-"
"from-centralized-to-federated>`_ 教程类似的示例结构。MXNet 和 PyTorch 非常相"
"似，参考 `此处 <https://mxnet.apache.org/versions/1.7.0/api/python/docs/"
"tutorials/getting-started/to-mxnet/pytorch.html>`_对 MXNet 和 PyTorch 进行了"
"详细的比较。首先，我们根据 `手写数字识别 <https://mxnet.apache.org/"
"versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html>` 教"
"程 建立了集中式训练方法。然后，我们在集中式训练代码的基础上，以联邦方式运行训"
"练。"

#: ../../source/example-mxnet-walk-through.rst:10
msgid ""
"Before we start setting up our MXNet example, we install the :code:`mxnet` "
"and :code:`flwr` packages:"
msgstr ""
"在开始设置 MXNet 示例之前，我们先安装 :code:`mxnet` 和 :code:`flwr` 软件包："

#: ../../source/example-mxnet-walk-through.rst:19
msgid "MNIST Training with MXNet"
msgstr "使用 MXNet 进行 MNIST 训练"

#: ../../source/example-mxnet-walk-through.rst:21
msgid ""
"We begin with a brief description of the centralized training code based on "
"a :code:`Sequential` model. If you want a more in-depth explanation of "
"what's going on then have a look at the official `MXNet tutorial <https://"
"mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/>`_."
msgstr ""
"首先，我们将简要介绍基于 :code:`Sequential` 模型的集中式训练代码。如果您想获"
"得更深入的解释，请参阅官方的 `MXNet教程 <https://mxnet.apache.org/"
"versions/1.7.0/api/python/docs/tutorials/>`_。"

#: ../../source/example-mxnet-walk-through.rst:24
msgid ""
"Let's create a new file called:code:`mxnet_mnist.py` with all the components "
"required for a traditional (centralized) MNIST training. First, the MXNet "
"package :code:`mxnet` needs to be imported. You can see that we do not yet "
"import the :code:`flwr` package for federated learning. This will be done "
"later."
msgstr ""
"让我们创建一个名为:code:`mxnet_mnist.py`的新文件，其中包含传统（集中式）"
"MNIST 训练所需的所有组件。首先，需要导入 MXNet 包 :code:`mxnet`。您可以看到，"
"我们尚未导入用于联合学习的 :code:`flwr` 包，这将在稍后完成。"

#: ../../source/example-mxnet-walk-through.rst:42
msgid ""
"The :code:`load_data()` function loads the MNIST training and test sets."
msgstr ":code:`load_data()` 函数加载 MNIST 训练集和测试集。"

#: ../../source/example-mxnet-walk-through.rst:57
msgid ""
"As already mentioned, we will use the MNIST dataset for this machine "
"learning workload. The model architecture (a very simple :code:`Sequential` "
"model) is defined in :code:`model()`."
msgstr ""
"如前所述，我们将使用 MNIST 数据集进行机器学习。模型架构（一个非常简单的 :"
"code:`Sequential` 模型）在 :code:`model()` 中定义。"

#: ../../source/example-mxnet-walk-through.rst:70
msgid ""
"We now need to define the training (function :code:`train()`) which loops "
"over the training set and measures the loss for each batch of training "
"examples."
msgstr "现在，我们需要定义训练函数（ "
":code:`train()`），该函数在训练集上循环训练，并计算每批训练示例的损失值。"

#: ../../source/example-mxnet-walk-through.rst:123
msgid ""
"The evaluation of the model is defined in function :code:`test()`. The "
"function loops over all test samples and measures the loss and accuracy of "
"the model based on the test dataset."
msgstr "模型的评估在函数 :code:`test()` 中定义。该函数循环遍历所有测试样本，并根据测"
"试数据集计算模型的损失值和准确度。"

#: ../../source/example-mxnet-walk-through.rst:158
msgid ""
"Having defined the data loading, model architecture, training, and "
"evaluation we can put everything together and train our model on MNIST. Note "
"that the GPU/CPU device for the training and testing is defined within the :"
"code:`ctx` (context)."
msgstr ""
"在定义了数据加载、模型架构、训练和评估之后，我们就可以把所有放在一起，在 "
"MNIST 上训练我们的模型了。请注意，用于训练和测试的 GPU/CPU 设备是在 "
":code:`ctx`中定义的。"

#: ../../source/example-mxnet-walk-through.rst:184
msgid "You can now run your (centralized) MXNet machine learning workload:"
msgstr "现在，您可以运行（集中式）MXNet 机器学习工作："

#: ../../source/example-mxnet-walk-through.rst:190
msgid ""
"So far this should all look fairly familiar if you've used MXNet (or even "
"PyTorch) before. Let's take the next step and use what we've built to create "
"a simple federated learning system consisting of one server and two clients."
msgstr ""
"到目前为止，如果你以前使用过 MXNet（甚至 PyTorch），这一切看起来应该相当熟悉"
"。下一步，让我们利用已构建的内容创建一个简单联邦学习系统（由一个服务器和两个"
"客户端组成）。"

#: ../../source/example-mxnet-walk-through.rst:194
msgid "MXNet meets Flower"
msgstr "MXNet 结合 Flower"

#: ../../source/example-mxnet-walk-through.rst:196
msgid ""
"So far, it was not easily possible to use MXNet workloads for federated "
"learning because federated learning is not supported in MXNet. Since Flower "
"is fully agnostic towards the underlying machine learning framework, it can "
"be used to federated arbitrary machine learning workloads. This section will "
"show you how Flower can be used to federate our centralized MXNet workload."
msgstr ""
"由于 MXNet 目前不支持联邦学习，因此无法轻松地直接将 MXNet 用于联邦学习之中。"
"Flower 与底层机器学习框架完全无关，因此它可用于任意联邦式机器学习工作。"
"本节将向你展示如何使用 Flower 将我们的集中式 MXNet 改为联邦式训练。"

#: ../../source/example-mxnet-walk-through.rst:198
msgid ""
"The concept to federate an existing workload is always the same and easy to "
"understand. We have to start a *server* and then use the code in :code:"
"`mxnet_mnist.py` for the *clients* that are connected to the *server*. The "
"*server* sends model parameters to the clients. The *clients* run the "
"training and update the parameters. The updated parameters are sent back to "
"the *server* which averages all received parameter updates. This describes "
"one round of the federated learning process and we repeat this for multiple "
"rounds."
msgstr ""
"将现有模型框架联邦化的概念始终是相同的，也很容易理解。我们必须启动一个*服务器"
"*，然后对连接到*服务器*的*客户端*使用 :code:`mxnet_mnist.py`中的代码。*服务器"
"*向客户端发送模型参数，然后*客户端*运行训练并更新参数。更新后的参数被发回*服"
"务器*，然后会对所有收到的参数更新进行平均聚合。以上描述的是一轮联邦学习过程，"
"我们将重复进行多轮学习。"

#: ../../source/example-mxnet-walk-through.rst:220
msgid ""
"Finally, we will define our *client* logic in :code:`client.py` and build "
"upon the previously defined MXNet training in :code:`mxnet_mnist.py`. Our "
"*client* needs to import :code:`flwr`, but also :code:`mxnet` to update the "
"parameters on our MXNet model:"
msgstr ""
"最后，我们将在 :code:`client.py` 中定义我们的 *client* 逻辑，并以之前在 :"
"code:`mxnet_mnist.py` 中定义的 MXNet 训练为基础。我们的 *client* 不仅需要导"
"入 :code:`flwr`，还需要导入 :code:`mxnet`，以更新 MXNet 模型的参数："

#: ../../source/example-mxnet-walk-through.rst:235
msgid ""
"Implementing a Flower *client* basically means implementing a subclass of "
"either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. Our "
"implementation will be based on :code:`flwr.client.NumPyClient` and we'll "
"call it :code:`MNISTClient`. :code:`NumPyClient` is slighly easier to "
"implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like PyTorch or MXNet) because it avoids some of the "
"boilerplate that would otherwise be necessary. :code:`MNISTClient` needs to "
"implement four methods, two methods for getting/setting model parameters, "
"one method for training the model, and one method for testing the model:"
msgstr ""
"实现 Flower *client*基本上意味着要实现 :code:`flwr.client.Client` 或 "
":code:`flwr.client.NumPyClient` 的子类。我们的代码实现将基于 :code:`flwr."
"client.NumPyClient`，并将其命名为 :code:`MNISTClient`。如果使用具有良好 "
"NumPy 互操作性的框架（如 PyTorch 或 MXNet），:code:`NumPyClient` 比 "
":code:`Client`更容易实现，因为它避免了一些不必要的操作。:code:`MNISTClient` "
"需要实现四个方法，两个用于获取/设置模型参数，一个用于训练模型，一个用于测试模"
"型："

#: ../../source/example-mxnet-walk-through.rst:242
msgid "transform MXNet :code:`NDArray`'s to NumPy :code:`ndarray`'s"
msgstr "将 MXNet :code:`NDArray` 转换为 NumPy :code:`ndarray`"

#: ../../source/example-mxnet-walk-through.rst:249
#: ../../source/example-pytorch-from-centralized-to-federated.rst:226
msgid "get the updated local model weights and return them to the server"
msgstr "获取更新后的本地模型参数并发送回服务器"

#: ../../source/example-mxnet-walk-through.rst:253
#: ../../source/example-pytorch-from-centralized-to-federated.rst:230
msgid "return the local loss and accuracy to the server"
msgstr "向服务器返回本地损失值和精确度"

#: ../../source/example-mxnet-walk-through.rst:255
msgid ""
"The challenging part is to transform the MXNet parameters from :code:"
"`NDArray` to :code:`NumPy Arrays` to make it readable for Flower."
msgstr ""
"具有挑战性的部分是将 MXNet 参数从 :code:`NDArray` 转换为 :code:`NumPy "
"Arrays` 以便 Flower 可以读取。"

#: ../../source/example-mxnet-walk-through.rst:257
msgid ""
"The two :code:`NumPyClient` methods :code:`fit` and :code:`evaluate` make "
"use of the functions :code:`train()` and :code:`test()` previously defined "
"in :code:`mxnet_mnist.py`. So what we really do here is we tell Flower "
"through our :code:`NumPyClient` subclass which of our already defined "
"functions to call for training and evaluation. We included type annotations "
"to give you a better understanding of the data types that get passed around."
msgstr ""
"这两个 :code:`NumPyClient` 方法 :code:`fit` 和 :code:`evaluate` 使用了之前在 "
":code:`mxnet_mnist.py` 中定义的函数 :code:`train()` 和 :code:`test()`。因此，"
"我们要做的就是通过 :code:`NumPyClient` 子类告知 Flower 在训练和评估时要调用哪"
"些已定义的函数。我们加入了类型注解，以便让您更好地理解传递的数据类型。"

#: ../../source/example-mxnet-walk-through.rst:319
msgid ""
"Having defined data loading, model architecture, training, and evaluation we "
"can put everything together and train our :code:`Sequential` model on MNIST."
msgstr ""
"在定义了数据加载、模型架构、训练和评估之后，我们就可以将所有内容整合在一起，"
"在 MNIST 上训练我们的 :code:`Sequential` 模型。"

#: ../../source/example-mxnet-walk-through.rst:353
msgid ""
"in each window (make sure that the server is still running before you do so) "
"and see your MXNet project run federated learning across two clients. "
"Congratulations!"
msgstr "确保服务器仍在运行后，然后就能在每个窗口中看到 MXNet "
"项目在两个客户端上运行联邦学习了。祝贺!"

#: ../../source/example-mxnet-walk-through.rst:358
msgid ""
"The full source code for this example: `MXNet: From Centralized To Federated "
"(Code) <https://github.com/adap/flower/blob/main/examples/mxnet-from-"
"centralized-to-federated>`_. Our example is of course somewhat over-"
"simplified because both clients load the exact same dataset, which isn't "
"realistic. You're now prepared to explore this topic further. How about "
"using a CNN or using a different dataset? How about adding more clients?"
msgstr ""
"此示例的完整源代码在：\"MXNet： From Centralized To Federated (Code) "
"<https://github.com/adap/flower/blob/main/examples/mxnet-from-centralized-to-"
"federated>`_。当然，我们的示例有些过于简单，因为两个客户端都加载了完全相同的"
"数据集，这并不真实。现在您已经准备好进一步探讨了。使用 CNN "
"或使用不同的数据集会如何？添加更多客户端会如何？"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:2
msgid "Example: PyTorch - From Centralized To Federated"
msgstr "实例： PyTorch - 从集中式到联邦式"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:4
msgid ""
"This tutorial will show you how to use Flower to build a federated version "
"of an existing machine learning workload. We are using PyTorch to train a "
"Convolutional Neural Network on the CIFAR-10 dataset. First, we introduce "
"this machine learning task with a centralized training approach based on the "
"`Deep Learning with PyTorch <https://pytorch.org/tutorials/beginner/blitz/"
"cifar10_tutorial.html>`_ tutorial. Then, we build upon the centralized "
"training code to run the training in a federated fashion."
msgstr ""
"本教程将向您展示如何使用 Flower 构建现有机器学习工作的联邦版本。我们使用 "
"PyTorch 在 CIFAR-10 数据集上训练一个卷积神经网络。首先，我们基于 \"Deep "
"Learning with PyTorch <https://pytorch.org/tutorials/beginner/blitz/"
"cifar10_tutorial.html>`_\"教程，采用集中式训练方法介绍了这项机器学习任务。然"
"后，我们在集中式训练代码的基础上以联邦方式运行训练。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:12
msgid ""
"We begin with a brief description of the centralized CNN training code. If "
"you want a more in-depth explanation of what's going on then have a look at "
"the official `PyTorch tutorial <https://pytorch.org/tutorials/beginner/blitz/"
"cifar10_tutorial.html>`_."
msgstr ""
"我们首先简要介绍一下集中式 CNN 训练代码。如果您想获得更深入的解释，请参阅 "
"PyTorch 官方教程`PyTorch tutorial <https://pytorch.org/tutorials/beginner/"
"blitz/cifar10_tutorial.html>`_。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:15
msgid ""
"Let's create a new file called :code:`cifar.py` with all the components "
"required for a traditional (centralized) training on CIFAR-10. First, all "
"required packages (such as :code:`torch` and :code:`torchvision`) need to be "
"imported. You can see that we do not import any package for federated "
"learning. You can keep all these imports as they are even when we add the "
"federated learning components at a later point."
msgstr ""
"让我们创建一个名为 :code:`cifar.py` 的新文件，其中包含 CIFAR-10 "
"传统（集中）培训所需的所有组件。首先，需要导入所有必需的软件包（如 "
":code:`torch` 和 :code:`torchvision`）。您可以看到，我们没有导入任何用于联邦"
"学习的软件包。即使在以后添加联邦学习组件时，也可以保留所有这些导入。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:32
msgid ""
"As already mentioned we will use the CIFAR-10 dataset for this machine "
"learning workload. The model architecture (a very simple Convolutional "
"Neural Network) is defined in :code:`class Net()`."
msgstr ""
"如前所述，我们将使用 CIFAR-10 数据集进行机器学习。模型架构（一个非常简单的卷"
"积神经网络）在 :code:`class Net()` 中定义。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:56
msgid ""
"The :code:`load_data()` function loads the CIFAR-10 training and test sets. "
"The :code:`transform` normalized the data after loading."
msgstr ""
":code:`load_data()` 函数加载 CIFAR-10 训练集和测试集。加载数据后，:code:"
"`transform`函数对数据进行了归一化处理。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:74
msgid ""
"We now need to define the training (function :code:`train()`) which loops "
"over the training set, measures the loss, backpropagates it, and then takes "
"one optimizer step for each batch of training examples."
msgstr ""
"现在，我们需要定义训练函数（:code:`train()`），该函数在训练集上循环训练，计算"
"损失值并反向传播，然后为每批训练数据在优化器上执行一个优化步骤。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:76
msgid ""
"The evaluation of the model is defined in the function :code:`test()`. The "
"function loops over all test samples and measures the loss of the model "
"based on the test dataset."
msgstr "模型的评估在函数 :code:`test()` "
"中定义。该函数循环遍历所有测试样本，并计算测试数据集的模型损失值。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:136
msgid ""
"Having defined the data loading, model architecture, training, and "
"evaluation we can put everything together and train our CNN on CIFAR-10."
msgstr "在确定了数据加载、模型架构、训练和评估之后，我们就可以将所有整合在一起，在 "
"CIFAR-10 上训练我们的 CNN。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:163
msgid ""
"So far, this should all look fairly familiar if you've used PyTorch before. "
"Let's take the next step and use what we've built to create a simple "
"federated learning system consisting of one server and two clients."
msgstr ""
"到目前为止，如果你以前用过 PyTorch，这一切看起来应该相当熟悉。让我们进行下一"
"步，利用我们所构建的内容创建一个简单联邦学习系统（由一个服务器和两个客户端组"
"成）。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:169
msgid ""
"The simple machine learning project discussed in the previous section trains "
"the model on a single dataset (CIFAR-10), we call this centralized learning. "
"This concept of centralized learning, as shown in the previous section, is "
"probably known to most of you, and many of you have used it previously. "
"Normally, if you'd want to run machine learning workloads in a federated "
"fashion, then you'd have to change most of your code and set everything up "
"from scratch. This can be a considerable effort."
msgstr ""
"上一节讨论的简单机器学习项目在单一数据集（CIFAR-10）上训练模型，我们称之为集"
"中学习。如上一节所示，集中学习的概念可能为大多数人所熟知，而且很多人以前都使"
"用过。通常情况下，如果要以联邦方式运行机器学习工作，就必须更改大部分代码，并"
"从头开始设置一切。这可能是一个相当大的工作量。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:173
msgid ""
"However, with Flower you can evolve your pre-existing code into a federated "
"learning setup without the need for a major rewrite."
msgstr "不过，有了 "
"Flower，您可以轻松地将已有的代码转变成联邦学习的模式，无需进行大量重写。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:175
msgid ""
"The concept is easy to understand. We have to start a *server* and then use "
"the code in :code:`cifar.py` for the *clients* that are connected to the "
"*server*. The *server* sends model parameters to the clients. The *clients* "
"run the training and update the paramters. The updated parameters are sent "
"back to the *server* which averages all received parameter updates. This "
"describes one round of the federated learning process and we repeat this for "
"multiple rounds."
msgstr ""
"这个概念很容易理解。我们必须启动一个*服务器*，然后对连接到*服务器*的*客户端*"
"使用 :code:`cifar.py`中的代码。*服务器*向客户端发送模型参数，*客户端*运行训练"
"并更新参数。更新后的参数被发回*服务器*，然后会对所有收到的参数更新进行平均聚"
"合。以上描述的是一轮联邦学习过程，我们将重复进行多轮学习。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:197
msgid ""
"Finally, we will define our *client* logic in :code:`client.py` and build "
"upon the previously defined centralized training in :code:`cifar.py`. Our "
"*client* needs to import :code:`flwr`, but also :code:`torch` to update the "
"paramters on our PyTorch model:"
msgstr ""
"最后，我们将在 :code:`client.py` 中定义我们的 *client* 逻辑，并以之前在 :"
"code:`cifar.py` 中定义的集中式训练为基础。我们的 *client* 不仅需要导入 :code:"
"`flwr`，还需要导入 :code:`torch`，以更新 PyTorch 模型的参数："

#: ../../source/example-pytorch-from-centralized-to-federated.rst:213
msgid ""
"Implementing a Flower *client* basically means implementing a subclass of "
"either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. Our "
"implementation will be based on :code:`flwr.client.NumPyClient` and we'll "
"call it :code:`CifarClient`. :code:`NumPyClient` is slighly easier to "
"implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like PyTorch or TensorFlow/Keras) because it avoids some "
"of the boilerplate that would otherwise be necessary. :code:`CifarClient` "
"needs to implement four methods, two methods for getting/setting model "
"parameters, one method for training the model, and one method for testing "
"the model:"
msgstr ""
"实现 Flower *client*基本上意味着实现 :code:`flwr.client.Client` 或 "
":code:`flwr.client.NumPyClient` 的子类。我们的代码实现将基于 :code:`flwr."
"client.NumPyClient`，并将其命名为 :code:`CifarClient`。如果使用具有良好 "
"NumPy 互操作性的框架（如 PyTorch 或 TensorFlow/Keras），:code:`NumPyClient`"
"的实现比 "
":code:`Client`略微容易一些，因为它避免了一些不必要的操作。:code:`CifarClient`"
" 需要实现四个方法，两个用于获取/设置模型参数，一个用于训练模型，一个用于测试"
"模型："

#: ../../source/example-pytorch-from-centralized-to-federated.rst:219
msgid ":code:`set_parameters`"
msgstr ":code:`set_parameters`"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:232
msgid ""
"The two :code:`NumPyClient` methods :code:`fit` and :code:`evaluate` make "
"use of the functions :code:`train()` and :code:`test()` previously defined "
"in :code:`cifar.py`. So what we really do here is we tell Flower through "
"our :code:`NumPyClient` subclass which of our already defined functions to "
"call for training and evaluation. We included type annotations to give you a "
"better understanding of the data types that get passed around."
msgstr ""
"这两个 :code:`NumPyClient` 中的方法 :code:`fit` 和 :code:`evaluate` "
"使用了之前在 :code:`cifar.py` 中定义的函数 :code:`train()` 和 "
":code:`test()`。因此，我们在这里要做的就是通过 :code:`NumPyClient` 子类告知 "
"Flower 在训练和评估时要调用哪些已定义的函数。我们加入了类型注解，以便让你更好"
"地理解传递的数据类型。"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:280
msgid ""
"All that's left to do it to define a function that loads both model and "
"data, creates a :code:`CifarClient`, and starts this client. You load your "
"data and model by using :code:`cifar.py`. Start :code:`CifarClient` with the "
"function :code:`fl.client.start_client()` by pointing it at the same IP "
"adress we used in :code:`server.py`:"
msgstr ""
"剩下的就是定义模型和数据加载函数了。创建一个:code:`CifarClient`类，并运行这个"
"客服端。您将通过:code:`cifar.py`加载数据和模型。另外，通过:code:`fl.client.st"
"art_client()`函数来运行客户端:code:`CifarClient`，需要保证IP地址和:code:`serv"
"er.py`中所使用的一致："

#: ../../source/example-pytorch-from-centralized-to-federated.rst:307
msgid ""
"in each window (make sure that the server is running before you do so) and "
"see your (previously centralized) PyTorch project run federated learning "
"across two clients. Congratulations!"
msgstr "确保服务器正在运行后，您就能看到您的 PyTorch "
"项目（之前是集中式的）在两个客户端上运行联邦学习了。祝贺！"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:312
msgid ""
"The full source code for this example: `PyTorch: From Centralized To "
"Federated (Code) <https://github.com/adap/flower/blob/main/examples/pytorch-"
"from-centralized-to-federated>`_. Our example is, of course, somewhat over-"
"simplified because both clients load the exact same dataset, which isn't "
"realistic. You're now prepared to explore this topic further. How about "
"using different subsets of CIFAR-10 on each client? How about adding more "
"clients?"
msgstr ""
"本示例的完整源代码为：`PyTorch： 从集中式到联合式 <https://github.com/adap/"
"flower/blob/main/examples/pytorch-from-centralized-to-federated>`_。当然，我"
"们的示例有些过于简单，因为两个客户端都加载了完全相同的数据集，这并不真实。现"
"在，您已经准备好进一步探讨这一主题了。比如在每个客户端使用不同的 CIFAR-10 "
"子集会如何？增加更多客户端会如何？"

#: ../../source/example-walkthrough-pytorch-mnist.rst:2
msgid "Example: Walk-Through PyTorch & MNIST"
msgstr "实例： PyTorch 和 MNIST 的演练"

#: ../../source/example-walkthrough-pytorch-mnist.rst:4
msgid ""
"In this tutorial we will learn, how to train a Convolutional Neural Network "
"on MNIST using Flower and PyTorch."
msgstr ""
"在本教程中，我们将学习如何使用 Flower 和 PyTorch 在 MNIST 上训练卷积神经网"
"络。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:6
#: ../../source/tutorial-quickstart-mxnet.rst:14
#: ../../source/tutorial-quickstart-pytorch.rst:17
#: ../../source/tutorial-quickstart-scikitlearn.rst:14
msgid ""
"Our example consists of one *server* and two *clients* all having the same "
"model."
msgstr "我们的例子包括一个*服务器*和两个*客户端*，它们都有相同的模型。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:8
#: ../../source/tutorial-quickstart-pytorch.rst:19
msgid ""
"*Clients* are responsible for generating individual weight-updates for the "
"model based on their local datasets. These updates are then sent to the "
"*server* which will aggregate them to produce a better model. Finally, the "
"*server* sends this improved version of the model back to each *client*. A "
"complete cycle of weight updates is called a *round*."
msgstr ""
"*客户端*负责在其本地数据集上更新模型参数。然后，这些参数会被发送到*服务器*，"
"由*服务器*聚合后生成一个更好的模型。最后，*服务器*将改进后的模型发送回每个*客"
"户端*。一个完整的模型参数更新周期称为一*轮*。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:12
#: ../../source/tutorial-quickstart-pytorch.rst:23
msgid ""
"Now that we have a rough idea of what is going on, let's get started. We "
"first need to install Flower. You can do this by running :"
msgstr "现在，我们已经有了一个大致的概念了，那就让我们开始吧。首先，我们需要安装 "
"Flower。可以通过运行 ："

#: ../../source/example-walkthrough-pytorch-mnist.rst:18
msgid ""
"Since we want to use PyTorch to solve a computer vision task, let's go ahead "
"an install PyTorch and the **torchvision** library:"
msgstr "我们想用 PyTorch 来做计算机视觉任务，需要先安装 PyTorch 和 **torchvision** "
"库："

#: ../../source/example-walkthrough-pytorch-mnist.rst:26
msgid "Ready... Set... Train!"
msgstr "准备...设置...训练!"

#: ../../source/example-walkthrough-pytorch-mnist.rst:28
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training procedure "
"and network architecture are based on PyTorch's `Basic MNIST Example "
"<https://github.com/pytorch/examples/tree/master/mnist>`_. This will allow "
"you see how easy it is to wrap your code with Flower and begin training in a "
"federated way. We provide you with two helper scripts, namely *run-server."
"sh*, and *run-clients.sh*. Don't be afraid to look inside, they are simple "
"enough =)."
msgstr ""
"现在我们已经安装了所有的依赖包，让我们用两个客户端和一个服务器来运行一个简单"
"的分布式训练。我们的训练过程和网络架构基于 PyTorch 的 `Basic MNIST Example "
"<https://github.com/pytorch/examples/tree/master/mnist>`_。您会发现用 Flower "
"来封装您的代码并进行联邦学习训练是多么容易。我们为您提供了两个辅助脚本，即 "
"*run-server.sh* 和 *run-clients.sh*。别害怕，它们很简单 =)。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:31
msgid ""
"Go ahead and launch on a terminal the *run-server.sh* script first as "
"follows:"
msgstr "首先在终端上启动 *run-server.sh* 脚本，如下所示："

#: ../../source/example-walkthrough-pytorch-mnist.rst:38
msgid "Now that the server is up and running, go ahead and launch the clients."
msgstr "现在服务器已经启动并运行，请继续启动客户端。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:45
msgid ""
"Et voilà! You should be seeing the training procedure and, after a few "
"iterations, the test accuracy for each client."
msgstr "然后就可以了！您应该能看到训练过程，以及经过几次反复后，每个客户端的测试准确"
"率。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:66
msgid "Now, let's see what is really happening inside."
msgstr "现在，让我们看看里面到底发生了什么。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:69
#: ../../source/tutorial-quickstart-ios.rst:129
#: ../../source/tutorial-quickstart-mxnet.rst:224
#: ../../source/tutorial-quickstart-pytorch.rst:203
#: ../../source/tutorial-quickstart-scikitlearn.rst:157
#: ../../source/tutorial-quickstart-tensorflow.rst:98
#: ../../source/tutorial-quickstart-xgboost.rst:306
msgid "Flower Server"
msgstr "Flower 服务器"

#: ../../source/example-walkthrough-pytorch-mnist.rst:71
msgid ""
"Inside the server helper script *run-server.sh* you will find the following "
"code that basically runs the :code:`server.py`"
msgstr ""
"在服务器辅助脚本 *run-server.sh* 中，你可以找到以下代码，这些代码基本上都是运"
"行 :code:`server.py` 的代码"

#: ../../source/example-walkthrough-pytorch-mnist.rst:78
msgid ""
"We can go a bit deeper and see that :code:`server.py` simply launches a "
"server that will coordinate three rounds of training. Flower Servers are "
"very customizable, but for simple workloads, we can start a server using "
"the :ref:`start_server <flwr-server-start_server-apiref>` function and leave "
"all the configuration possibilities at their default values, as seen below."
msgstr ""
"我们可以再深入一点，:code:`server.py` "
"只是启动了一个服务器，该服务器将协调三轮训练。Flower "
"服务器是非常容易修改的，但对于简单的工作，我们可以使用 :ref:`start_server "
"<flwr-server-start_server-"
"apiref>`函数启动服务器，并将所有可能的配置保留为默认值，如下所示。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:89
#: ../../source/tutorial-quickstart-ios.rst:34
#: ../../source/tutorial-quickstart-mxnet.rst:34
#: ../../source/tutorial-quickstart-pytorch.rst:37
#: ../../source/tutorial-quickstart-scikitlearn.rst:40
#: ../../source/tutorial-quickstart-tensorflow.rst:29
#: ../../source/tutorial-quickstart-xgboost.rst:52
msgid "Flower Client"
msgstr "Flower 客户端"

#: ../../source/example-walkthrough-pytorch-mnist.rst:91
msgid ""
"Next, let's take a look at the *run-clients.sh* file. You will see that it "
"contains the main loop that starts a set of *clients*."
msgstr "接下来，让我们看看 *run-clients.sh* 文件。您会看到它包含了用来启动多个 "
"*客户端* 的代码。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:100
msgid ""
"**cid**: is the client ID. It is an integer that uniquely identifies client "
"identifier."
msgstr "**cid**：是客户 ID。它是一个整数，可唯一标识客户标识符。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:101
msgid "**sever_address**: String that identifies IP and port of the server."
msgstr "**sever_address**： 标识服务器 IP 和端口的字符串。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:102
msgid ""
"**nb_clients**: This defines the number of clients being created. This piece "
"of information is not required by the client, but it helps us partition the "
"original MNIST dataset to make sure that every client is working on unique "
"subsets of both *training* and *test* sets."
msgstr ""
"**nb_clients**： 这定义了正在创建的客户端数量。客户端并不需要这一信息，"
"但它有助于我们对原始 MNIST 数据集进行划分，以确保每个客户端都在 *training* "
"和 *test* 数据集上有独立的数据。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:104
msgid ""
"Again, we can go deeper and look inside :code:`flwr_example/quickstart-"
"pytorch/client.py`. After going through the argument parsing code at the "
"beginning of our :code:`main` function, you will find a call to :code:`mnist."
"load_data`. This function is responsible for partitioning the original MNIST "
"datasets (*training* and *test*) and returning a :code:`torch.utils.data."
"DataLoader` s for each of them. We then instantiate a :code:"
"`PytorchMNISTClient` object with our client ID, our DataLoaders, the number "
"of epochs in each round, and which device we want to use for training (CPU "
"or GPU)."
msgstr ""
"我们可以深入看一下 :code:`flwr_example/quickstart-pytorch/client.py`。查看 "
":code:`main` 函数开头的参数解析代码后，你会发现一个对 :code:`mnist.load_data`"
" 的调用。该函数负责分割原始 MNIST 数据集（*training* 和 *test*），"
"并为每个数据集返回一个 :code:`torch.utils.data.DataLoader` 。然后，"
"我们实例化一个 :code:`PytorchMNISTClient` 对象，其中包含我们的客户端 ID、 "
"DataLoader、每一轮中的遍历数，以及我们希望用于训练的设备（CPU 或 GPU）。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:119
msgid ""
"The :code:`PytorchMNISTClient` object when finally passed to :code:`fl."
"client.start_client` along with the server's address as the training process "
"begins."
msgstr ""
"当训练过程开始时，:code:`PytorchMNISTClient` 对象会连同服务器地址一起传递给 "
":code:`fl.client.start_client`。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:123
msgid "A Closer Look"
msgstr "仔细看一下"

#: ../../source/example-walkthrough-pytorch-mnist.rst:125
msgid ""
"Now, let's look closely into the :code:`PytorchMNISTClient` inside :code:"
"`flwr_example.quickstart-pytorch.mnist` and see what it is doing:"
msgstr ""
"现在，让我们仔细研究一下 :code:`flwr_example.quickstart-pytorch.mnist` 中的 :"
"code:`PytorchMNISTClient`，看看它在做什么："

#: ../../source/example-walkthrough-pytorch-mnist.rst:226
msgid ""
"The first thing to notice is that :code:`PytorchMNISTClient` instantiates a "
"CNN model inside its constructor"
msgstr ""
"首先要注意的是 :code:`PytorchMNISTClient` 在其构造函数中实例化了一个 CNN 模型"

#: ../../source/example-walkthrough-pytorch-mnist.rst:244
msgid ""
"The code for the CNN is available under :code:`quickstart-pytorch.mnist` and "
"it is reproduced below. It is the same network found in `Basic MNIST Example "
"<https://github.com/pytorch/examples/tree/master/mnist>`_."
msgstr ""
"CNN 的代码可在 :code:`quickstart-pytorch.mnist` 下找到，现复制如下。它与 `"
"Basic MNIST Example <https://github.com/pytorch/examples/tree/master/"
"mnist>`_中的网络相同。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:290
msgid ""
"The second thing to notice is that :code:`PytorchMNISTClient` class inherits "
"from the :code:`fl.client.Client`, and hence it must implement the following "
"methods:"
msgstr ""
"第二件要注意的事是 :code:`PytorchMNISTClient` 类继承自 :code:`fl.client."
"Client`，因此它必须实现以下方法："

#: ../../source/example-walkthrough-pytorch-mnist.rst:315
msgid ""
"When comparing the abstract class to its derived class :code:"
"`PytorchMNISTClient` you will notice that :code:`fit` calls a :code:`train` "
"function and that :code:`evaluate` calls a :code:`test`: function."
msgstr ""
"将抽象类与其派生类 :code:`PytorchMNISTClient` 进行比较时，您会发现 :code:"
"`fit` 调用了一个 :code:`train` 函数，而 :code:`evaluate` 则调用了一个 :code:"
"`test`: 函数。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:317
msgid ""
"These functions can both be found inside the same :code:`quickstart-pytorch."
"mnist` module:"
msgstr "这些函数都可以在同一个 :code:`quickstart-pytorch.mnist` 模块中找到："

#: ../../source/example-walkthrough-pytorch-mnist.rst:437
msgid ""
"Observe that these functions encapsulate regular training and test loops and "
"provide :code:`fit` and :code:`evaluate` with final statistics for each "
"round. You could substitute them with your custom train and test loops and "
"change the network architecture, and the entire example would still work "
"flawlessly. As a matter of fact, why not try and modify the code to an "
"example of your liking?"
msgstr ""
"请注意，这些函数封装了常规的训练和测试循环，并为 :code:`fit` 和 :code:"
"`evaluate` 提供了每轮的最终统计数据。您可以用自定义的训练和测试循环来替代它"
"们，并改变网络结构，整个示例仍然可以完美运行。事实上，为什么不按照自己的喜好"
"修改代码呢？"

#: ../../source/example-walkthrough-pytorch-mnist.rst:444
msgid "Give It a Try"
msgstr "试试看"

#: ../../source/example-walkthrough-pytorch-mnist.rst:445
msgid ""
"Looking through the quickstart code description above will have given a good "
"understanding of how *clients* and *servers* work in Flower, how to run a "
"simple experiment, and the internals of a client wrapper. Here are a few "
"things you could try on your own and get more experience with Flower:"
msgstr ""
"通过上面的快速入门代码描述，你将对 Flower 中*客户端*和*服务器*的工作方式、如"
"何运行一个简单的实验以及客户端封装器的内部结构有一个很好的了解。您可以自己尝"
"试以下内容，以获得更多使用 Flower 的经验："

#: ../../source/example-walkthrough-pytorch-mnist.rst:448
msgid ""
"Try and change :code:`PytorchMNISTClient` so it can accept different "
"architectures."
msgstr "尝试修改 :code:`PytorchMNISTClient`，使其可以接受不同的架构。"

#: ../../source/example-walkthrough-pytorch-mnist.rst:449
msgid ""
"Modify the :code:`train` function so that it accepts different optimizers"
msgstr "修改 :code:`train` 函数，使其接受不同的优化器"

#: ../../source/example-walkthrough-pytorch-mnist.rst:450
msgid ""
"Modify the :code:`test` function so that it proves not only the top-1 "
"(regular accuracy) but also the top-5 accuracy?"
msgstr "修改 :code:`test` 函数，使其不仅能输出前 1 名（常规精确度），还能证明前 5 "
"名的精确度？"

#: ../../source/example-walkthrough-pytorch-mnist.rst:451
msgid ""
"Go larger! Try to adapt the code to larger images and datasets. Why not try "
"training on ImageNet with a ResNet-50?"
msgstr "让我们尝试让代码适应更大的图像和数据集。为什么不尝试使用 ResNet-50 在 "
"ImageNet 上进行训练呢？"

#: ../../source/example-walkthrough-pytorch-mnist.rst:453
msgid "You are ready now. Enjoy learning in a federated way!"
msgstr "您现在已经准备就绪。尽情享受联邦学习的乐趣吧！"

#: ../../source/explanation-differential-privacy.rst:2
msgid "Differential privacy"
msgstr "差别隐私"

#: ../../source/explanation-differential-privacy.rst:4
msgid ""
"Flower provides differential privacy (DP) wrapper classes for the easy "
"integration of the central DP guarantees provided by DP-FedAvg into training "
"pipelines defined in any of the various ML frameworks that Flower is "
"compatible with."
msgstr ""
"Flower 提供了差分隐私 (DP) 封装类，可将 DP-FedAvg 提供的核心 DP 轻松集成到 "
"Flower 兼容的各种 ML 框架中定义的训练模式中。"

#: ../../source/explanation-differential-privacy.rst:7
msgid ""
"Please note that these components are still experimental, the correct "
"configuration of DP for a specific task is still an unsolved problem."
msgstr ""
"请注意，这些组件仍处于试验阶段，如何为特定任务正确配置 DP 仍是一个尚未解决的"
"问题。"

#: ../../source/explanation-differential-privacy.rst:10
msgid ""
"The name DP-FedAvg is misleading since it can be applied on top of any FL "
"algorithm that conforms to the general structure prescribed by the FedOpt "
"family of algorithms."
msgstr ""
"DP-FedAvg 这个名称容易引起误解，因为它可以应用于任何符合 FedOpt 系列算法规定"
"的一般结构的 FL 算法之上。"

#: ../../source/explanation-differential-privacy.rst:13
msgid "DP-FedAvg"
msgstr "DP-FedAvg"

#: ../../source/explanation-differential-privacy.rst:15
msgid ""
"DP-FedAvg, originally proposed by McMahan et al. [mcmahan]_ and extended by "
"Andrew et al. [andrew]_, is essentially FedAvg with the following "
"modifications."
msgstr "DP-FedAvg 最初由McMahan等人提出，并由Andrew等人加以扩展。"

#: ../../source/explanation-differential-privacy.rst:17
msgid ""
"**Clipping** : The influence of each client's update is bounded by clipping "
"it. This is achieved by enforcing a cap on the L2 norm of the update, "
"scaling it down if needed."
msgstr "**裁剪** ： 裁剪会影响到每个客户端的模型参数。具体做法是对参数的 L2 "
"准则设置上限，必要时将其缩减。"

#: ../../source/explanation-differential-privacy.rst:18
msgid ""
"**Noising** :  Gaussian noise, calibrated to the clipping threshold, is "
"added to the average computed at the server."
msgstr "**噪声** ： "
"在服务器计算出的平均值中加入高斯噪声，该噪声根据剪切阈值进行校准。"

#: ../../source/explanation-differential-privacy.rst:20
msgid ""
"The distribution of the update norm has been shown to vary from task-to-task "
"and to evolve as training progresses. Therefore, we use an adaptive approach "
"[andrew]_ that continuously adjusts the clipping threshold to track a "
"prespecified quantile of the update norm distribution."
msgstr ""
"事实证明，参数更新准则的分布会随着任务的不同而变化，并随着训练的进展而演变。"
"因此，我们采用了一种自适应方法，该方法会不断调整剪切阈值，以跟踪参数更新准则"
"分布的预设量化值。"

#: ../../source/explanation-differential-privacy.rst:23
msgid "Simplifying Assumptions"
msgstr "简化假设"

#: ../../source/explanation-differential-privacy.rst:25
msgid ""
"We make (and attempt to enforce) a number of assumptions that must be "
"satisfied to ensure that the training process actually realises the :math:"
"`(\\epsilon, \\delta)` guarantees the user has in mind when configuring the "
"setup."
msgstr ""
"我们提出（并试图执行）了一系列必须满足的假设，"
"以确保训练过程真正实现用户在配置设置时所定的 :math:`(\\epsilon,\\delta)` 。"

#: ../../source/explanation-differential-privacy.rst:27
msgid ""
"**Fixed-size subsampling** :Fixed-size subsamples of the clients must be "
"taken at each round, as opposed to variable-sized Poisson subsamples."
msgstr "** 固定大小的子样本** "
":与可变大小的泊松分布子样本相比，每轮必须抽取固定大小的客户端子样本。"

#: ../../source/explanation-differential-privacy.rst:28
msgid ""
"**Unweighted averaging** : The contributions from all the clients must "
"weighted equally in the aggregate to eliminate the requirement for the "
"server to know in advance the sum of the weights of all clients available "
"for selection."
msgstr "**非加权平均**： "
"所有客户端的贡献必须加权相等，这样服务器就不需要事先知道所有客户的权重总和。"

#: ../../source/explanation-differential-privacy.rst:29
msgid ""
"**No client failures** : The set of available clients must stay constant "
"across all rounds of training. In other words, clients cannot drop out or "
"fail."
msgstr "**没有失败的客户端** ： "
"在各轮训练中，可用客户端的数量必须保持不变。换句话说，客户端不能退出或失败。"

#: ../../source/explanation-differential-privacy.rst:31
msgid ""
"The first two are useful for eliminating a multitude of complications "
"associated with calibrating the noise to the clipping threshold while the "
"third one is required to comply with the assumptions of the privacy analysis."
msgstr ""
"前两种方法有助于消除将噪声校准为削波阈值所带来的诸多复杂问题，而第三种方法则"
"需要符合隐私分析的假设。"

#: ../../source/explanation-differential-privacy.rst:34
msgid ""
"These restrictions are in line with constraints imposed by Andrew et al. "
"[andrew]_."
msgstr "这些限制与 Andrew 等人所施加的限制一致。"

#: ../../source/explanation-differential-privacy.rst:37
msgid "Customizable Responsibility for Noise injection"
msgstr "可定制的噪声注入"

#: ../../source/explanation-differential-privacy.rst:38
msgid ""
"In contrast to other implementations where the addition of noise is "
"performed at the server, you can configure the site of noise injection to "
"better match your threat model. We provide users with the flexibility to set "
"up the training such that each client independently adds a small amount of "
"noise to the clipped update, with the result that simply aggregating the "
"noisy updates is equivalent to the explicit addition of noise to the non-"
"noisy aggregate at the server."
msgstr ""
"与其他在服务器上添加噪声的实现方法不同，您可以配置噪声注入的位置，以便更好地"
"匹配您的威胁模型。我们为用户提供了设置训练的灵活性，使每个客户端都能独立地为"
"剪切参数更新添加少量噪声，这样，只需聚合噪声更新，就相当于在服务器上为非噪声"
"聚合添加噪声了。"

#: ../../source/explanation-differential-privacy.rst:41
msgid ""
"To be precise, if we let :math:`m` be the number of clients sampled each "
"round and :math:`\\sigma_\\Delta` be the scale of the total Gaussian noise "
"that needs to be added to the sum of the model updates, we can use simple "
"maths to show that this is equivalent to each client adding noise with "
"scale :math:`\\sigma_\\Delta/\\sqrt{m}`."
msgstr ""
"准确地说，我们假设每轮采样的客户端数量为:math:`m`，:math:`\\sigma_\\Delta` 为"
"需要添加到模型更新总和中的总高斯噪声的规模，我们就可以用简单的数学方法证明了"
"，这相当于每个客户端都添加了规模为 :math:`\\sigma_\\Delta/\\sqrt{m}` 的噪声。"

#: ../../source/explanation-differential-privacy.rst:44
msgid "Wrapper-based approach"
msgstr "基于封装的方法"

#: ../../source/explanation-differential-privacy.rst:46
msgid ""
"Introducing DP to an existing workload can be thought of as adding an extra "
"layer of security around it. This inspired us to provide the additional "
"server and client-side logic needed to make the training process "
"differentially private as wrappers for instances of the :code:`Strategy` "
"and :code:`NumPyClient` abstract classes respectively. This wrapper-based "
"approach has the advantage of being easily composable with other wrappers "
"that someone might contribute to the Flower library in the future, e.g., for "
"secure aggregation. Using Inheritance instead can be tedious because that "
"would require the creation of new sub- classes every time a new class "
"implementing :code:`Strategy` or :code:`NumPyClient` is defined."
msgstr ""
"在现有工作负载中引入 DP 可以被认为是在其周围增加了一层额外的安全性。受此启发"
"，我们提供了额外的服务器端和客户端逻辑，分别作为 :code:`Strategy` 和 "
":code:`NumPyClient` 抽象类实例的封装器，使训练过程具有不同的隐私性。"
"这种基于封装器的方法的优点是可以很容易地与将来有人贡献给 Flower "
"的其他封装器（例如用于安全聚合的封装器）进行组合。使用继承可能会比较繁琐，"
"因为每次定义实现 :code:`Strategy` 或 :code:`NumPyClient` "
"的新类时，都需要创建新的子类。"

#: ../../source/explanation-differential-privacy.rst:49
msgid "Server-side logic"
msgstr "服务器端逻辑"

#: ../../source/explanation-differential-privacy.rst:51
msgid ""
"The first version of our solution was to define a decorator whose "
"constructor accepted, among other things, a boolean valued variable "
"indicating whether adaptive clipping was to be enabled or not. We quickly "
"realized that this would clutter its :code:`__init__()` function with "
"variables corresponding to hyperparameters of adaptive clipping that would "
"remain unused when it was disabled. A cleaner implementation could be "
"achieved by splitting the functionality into two decorators, :code:"
"`DPFedAvgFixed` and :code:`DPFedAvgAdaptive`, with the latter sub- classing "
"the former. The constructors for both classes accept a boolean parameter :"
"code:`server_side_noising`, which, as the name suggests, determines where "
"noising is to be performed."
msgstr ""
"我们的第一版解决方案是定义一个装饰器，其构造函数接受一个布尔值变量，表示是否"
"启用自适应剪裁。我们很快意识到，这样会使其 :code:`__init__()` 函数中与自适应"
"裁剪超参数相对应的变量变得杂乱无章，而这些变量在自适应裁剪被禁用时将保持未使"
"用状态。要实现更简洁的功能，可以将该功能拆分为两个装饰器，即 "
":code:`DPFedAvgFixed` 和 :code:`DPFedAvgAdaptive`，后者是前者的子类。"
"这两个类的构造函数都接受一个布尔参数 "
":code:`server_side_noising`，顾名思义，它决定了在哪里加噪声。"

#: ../../source/explanation-differential-privacy.rst:54
msgid "DPFedAvgFixed"
msgstr "DPFedAvgFixed"

#: ../../source/explanation-differential-privacy.rst:56
msgid ""
"The server-side capabilities required for the original version of DP-FedAvg, "
"i.e., the one which performed fixed clipping, can be completely captured "
"with the help of wrapper logic for just the following two methods of the :"
"code:`Strategy` abstract class."
msgstr ""
"只需对 :code:`Strategy` 抽象类的以下两个方法进行封装，就能完全捕获 DP-FedAvg "
"原始版本（即执行固定剪裁的版本）所需的服务器端功能。"

#: ../../source/explanation-differential-privacy.rst:58
msgid ""
":code:`configure_fit()` : The config dictionary being sent by the wrapped :"
"code:`Strategy` to each client needs to be augmented with an additional "
"value equal to the clipping threshold (keyed under :code:"
"`dpfedavg_clip_norm`) and, if :code:`server_side_noising=true`, another one "
"equal to the scale of the Gaussian noise that needs to be added at the "
"client (keyed under :code:`dpfedavg_noise_stddev`). This entails *post*-"
"processing of the results returned by the wrappee's implementation of :code:"
"`configure_fit()`."
msgstr ""
":code:`configure_fit()` ：由封装的 :code:`Strategy` "
"发送到每个客户端的配置字典需要使用等于裁剪阈值的附加值（在 "
":code:`dpfedavg_clip_norm` 下键入）进行扩充。并且，如果 "
"server_side_noising=true，则另一个值等于需要在客户端添加的高斯噪声的大小（在 "
"dpfedavg_noise_stddev 下键入）。这需要对封装后的configure_fit() "
"所返回的结果进行后处理。"

#: ../../source/explanation-differential-privacy.rst:59
msgid ""
":code:`aggregate_fit()`: We check whether any of the sampled clients dropped "
"out or failed to upload an update before the round timed out. In that case, "
"we need to abort the current round, discarding any successful updates that "
"were received, and move on to the next one. On the other hand, if all "
"clients responded successfully, we must force the averaging of the updates "
"to happen in an unweighted manner by intercepting the :code:`parameters` "
"field of :code:`FitRes` for each received update and setting it to 1. "
"Furthermore, if :code:`server_side_noising=true`, each update is perturbed "
"with an amount of noise equal to what it would have been subjected to had "
"client-side noising being enabled.  This entails *pre*-processing of the "
"arguments to this method before passing them on to the wrappee's "
"implementation of :code:`aggregate_fit()`."
msgstr ""
":code:`aggregate_fit()`： 我们会检查是否有任何客户端在本轮超时前退出或未能上"
"传参数更新。在这种情况下，我们需要中止当前一轮，丢弃已收到的所有参数更新，然"
"后继续下一轮。另一方面，如果所有客户端都成功响应，我们就必须通过拦截 "
":code:`FitRes` 的 :code:`parameters` 字段并将其设置为 "
"1，强制以不加权的方式平均更新。此外，如果 :code:`server_side_noising=true`，"
"每次更新都会受到一定量的噪声扰动，其扰动量相当于启用客户端噪声时的扰动量。 "
"这就需要在将本方法的参数传递给封装的 :code:`aggregate_fit()` "
"之前，对参数进行*预*处理。"

#: ../../source/explanation-differential-privacy.rst:62
msgid ""
"We can't directly change the aggregation function of the wrapped strategy to "
"force it to add noise to the aggregate, hence we simulate client-side "
"noising to implement server-side noising."
msgstr ""
"我们无法直接改变封装策略的聚合函数，迫使它在聚合中添加噪声，因此我们模拟客户"
"端噪声来实现服务器端噪声。"

#: ../../source/explanation-differential-privacy.rst:64
msgid ""
"These changes have been put together into a class called :code:"
"`DPFedAvgFixed`, whose constructor accepts the strategy being decorated, the "
"clipping threshold and the number of clients sampled every round as "
"compulsory arguments. The user is expected to specify the clipping threshold "
"since the order of magnitude of the update norms is highly dependent on the "
"model being trained and providing a default value would be misleading. The "
"number of clients sampled at every round is required to calculate the amount "
"of noise that must be added to each individual update, either by the server "
"or the clients."
msgstr ""
"这些变化被整合到一个名为 :code:`DPFedAvgFixed` 的类中，其构造函数接受被装饰的"
"策略、剪切阈值和每轮采样的客户数作为必选参数。用户需要指定剪切阈值，因为参数"
"更新规范的数量级在很大程度上取决于正在训练的模型，提供默认值会产生误导。每轮"
"采样的客户端数量是计算服务器或客户在每次参数更新时添加的噪音量所必需的。"

#: ../../source/explanation-differential-privacy.rst:67
msgid "DPFedAvgAdaptive"
msgstr "DPFedAvgAdaptive"

#: ../../source/explanation-differential-privacy.rst:69
msgid ""
"The additional functionality required to facilitate adaptive clipping has "
"been provided in :code:`DPFedAvgAdaptive`, a subclass of :code:"
"`DPFedAvgFixed`. It overrides the above-mentioned methods to do the "
"following."
msgstr ""
"自适应剪裁所需的附加功能在 :code:`DPFedAvgAdaptive` 中提供，其是 "
":code:`DPFedAvgFixed` 的子类。它重写了上述方法，以实现以下功能。"

#: ../../source/explanation-differential-privacy.rst:71
msgid ""
":code:`configure_fit()` : It intercepts the config dict returned by :code:"
"`super.configure_fit()` to add the key-value pair :code:"
"`dpfedavg_adaptive_clip_enabled:True` to it, which the client interprets as "
"an instruction to include an indicator bit (1 if update norm <= clipping "
"threshold, 0 otherwise) in the results returned by it."
msgstr ""
":code:`configure_fit()`：它截取由 :code:`super.configure_fit()` 返回的 "
"config 字典，并在其中添加键-值对 :code:`dpfedavg_adaptive_clip_enabled:True\""
"，客户端将其解释为在返回结果中包含一个指示位（如果参数更新范式 <= 剪裁阈值，"
"则为 1，否则为 0）的指令。"

#: ../../source/explanation-differential-privacy.rst:73
msgid ""
":code:`aggregate_fit()` : It follows a call to :code:`super.aggregate_fit()` "
"with one to :code:`__update_clip_norm__()`, a procedure which adjusts the "
"clipping threshold on the basis of the indicator bits received from the "
"sampled clients."
msgstr ""
":code:`aggregate_fit()`：在调用:code:`super.aggregate_fit()`后，再调用:code:`"
"__update_clip_norm__()`，该过程根据从采样客户端接收到的指示位调整裁剪阈值。"

#: ../../source/explanation-differential-privacy.rst:77
msgid "Client-side logic"
msgstr "客户端逻辑"

#: ../../source/explanation-differential-privacy.rst:79
msgid ""
"The client-side capabilities required can be completely captured through "
"wrapper logic for just the :code:`fit()` method of the :code:`NumPyClient` "
"abstract class. To be precise, we need to *post-process* the update computed "
"by the wrapped client to clip it, if necessary, to the threshold value "
"supplied by the server as part of the config dictionary. In addition to "
"this, it may need to perform some extra work if either (or both) of the "
"following keys are also present in the dict."
msgstr ""
"客户端所需的功能完全可以通过 :code:`NumPyClient` 抽象类的 :code:`fit()` 方法"
"的封装逻辑来实现。准确地说，我们需要对封装客户端计算的参数更新进行处理，以便"
"在必要时将其剪切到服务器作为配置字典的一部分提供的阈值。除此之外，如果配置字"
"典中还存在以下任一（或两个）键，客户端可能还需要执行一些额外的工作。"

#: ../../source/explanation-differential-privacy.rst:81
msgid ""
":code:`dpfedavg_noise_stddev` : Generate and add the specified amount of "
"noise to the clipped update."
msgstr "code:`dpfedavg_noise_stddev`：生成并在剪切参数更新中添加指定数量的噪声。"

#: ../../source/explanation-differential-privacy.rst:82
msgid ""
":code:`dpfedavg_adaptive_clip_enabled` : Augment the metrics dict in the :"
"code:`FitRes` object being returned to the server with an indicator bit, "
"calculated as described earlier."
msgstr ""
":code:`dpfedavg_adaptive_clip_enabled`：在返回给服务器的 :code:`FitRes` "
"对象中的度量值字典中增加一个指标位，计算方法如前所述。"

#: ../../source/explanation-differential-privacy.rst:86
msgid "Performing the :math:`(\\epsilon, \\delta)` analysis"
msgstr "进行 :math:`(epsilon, \\delta)` 分析"

#: ../../source/explanation-differential-privacy.rst:88
msgid ""
"Assume you have trained for :math:`n` rounds with sampling fraction :math:"
"`q` and noise multiplier :math:`z`. In order to calculate the :math:"
"`\\epsilon` value this would result in for a particular :math:`\\delta`, the "
"following script may be used."
msgstr ""
"假设您已经训练了 :math:`n` 轮，采样比例为 :math:`q`，噪声乘数为 :math:`z`。"
"为了计算特定 :math:`\\delta` 的 :math:`epsilon` 值，可以使用下面的脚本。"

#: ../../source/explanation-differential-privacy.rst:98
msgid ""
"McMahan, H. Brendan, et al. \"Learning differentially private recurrent "
"language models.\" arXiv preprint arXiv:1710.06963 (2017)."
msgstr ""
"McMahan, H. Brendan等. \"Learning differentially private recurrent language "
"models.\" arXiv preprint arXiv:1710.06963 (2017)."

#: ../../source/explanation-differential-privacy.rst:100
msgid ""
"Andrew, Galen, et al. \"Differentially private learning with adaptive "
"clipping.\" Advances in Neural Information Processing Systems 34 (2021): "
"17455-17466."
msgstr ""
"Andrew, Galen等. \"Differentially private learning with adaptive clipping.\" "
"Advances in Neural Information Processing Systems 34 (2021): 17455-17466."

#: ../../source/explanation-federated-evaluation.rst:2
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:292
msgid "Federated evaluation"
msgstr "联邦学习评估"

#: ../../source/explanation-federated-evaluation.rst:4
msgid ""
"There are two main approaches to evaluating models in federated learning "
"systems: centralized (or server-side) evaluation and federated (or client-"
"side) evaluation."
msgstr "评估联合学习系统中的模型主要有两种方法：集中（或服务器端）评估和联邦（或客户"
"端）评估。"

#: ../../source/explanation-federated-evaluation.rst:8
msgid "Centralized Evaluation"
msgstr "集中评估"

#: ../../source/explanation-federated-evaluation.rst:11
msgid "Built-In Strategies"
msgstr "内置策略"

#: ../../source/explanation-federated-evaluation.rst:13
msgid ""
"All built-in strategies support centralized evaluation by providing an "
"evaluation function during initialization. An evaluation function is any "
"function that can take the current global model parameters as input and "
"return evaluation results:"
msgstr ""
"所有内置策略都通过在初始化过程中提供一个评估函数来支持集中评估。评估函数是任"
"何可以将当前全局模型参数作为输入并返回评估结果的函数："

#: ../../source/explanation-federated-evaluation.rst:58
msgid "Custom Strategies"
msgstr "定制策略"

#: ../../source/explanation-federated-evaluation.rst:60
msgid ""
"The :code:`Strategy` abstraction provides a method called :code:`evaluate` "
"that can directly be used to evaluate the current global model parameters. "
"The current server implementation calls :code:`evaluate` after parameter "
"aggregation and before federated evaluation (see next paragraph)."
msgstr ""
":code:`Strategy` 抽象提供了一个名为 :code:`evaluate` "
"的方法，可直接用于评估当前的全局模型参数。"
"服务器会在参数聚合后和联邦评估前调用 :code:`evaluate`（见下段）。"

#: ../../source/explanation-federated-evaluation.rst:65
msgid "Federated Evaluation"
msgstr "联邦评估"

#: ../../source/explanation-federated-evaluation.rst:68
msgid "Implementing Federated Evaluation"
msgstr "实现联邦评估"

#: ../../source/explanation-federated-evaluation.rst:70
msgid ""
"Client-side evaluation happens in the :code:`Client.evaluate` method and can "
"be configured from the server side."
msgstr ""
"客户端评估在 :code:`Client.evaluate` 方法中进行，并可从服务器端进行配置。"

#: ../../source/explanation-federated-evaluation.rst:101
msgid "Configuring Federated Evaluation"
msgstr "配置联邦评估"

#: ../../source/explanation-federated-evaluation.rst:103
msgid ""
"Federated evaluation can be configured from the server side. Built-in "
"strategies support the following arguments:"
msgstr "联邦评估可从服务器端进行配置。内置策略支持以下参数："

#: ../../source/explanation-federated-evaluation.rst:105
msgid ""
":code:`fraction_evaluate`: a :code:`float` defining the fraction of clients "
"that will be selected for evaluation. If :code:`fraction_evaluate` is set "
"to :code:`0.1` and :code:`100` clients are connected to the server, then :"
"code:`10` will be randomly selected for evaluation. If :code:"
"`fraction_evaluate` is set to :code:`0.0`, federated evaluation will be "
"disabled."
msgstr ""
":code:`fraction_evaluate`： "
":code:`float`，定义了被选中进行评估的客户端的比例。如果 "
":code:`fraction_evaluate` 设置为 :code:`0.1`，并且 :code:`100` "
"个客户端连接到服务器，那么 :code:`10` 个客户端将被随机选中进行评估。如果 "
":code:`fraction_evaluate` 设置为 :code:`0.0`，联邦评估将被禁用。"

#: ../../source/explanation-federated-evaluation.rst:106
msgid ""
":code:`min_evaluate_clients`: an :code:`int`: the minimum number of clients "
"to be selected for evaluation. If :code:`fraction_evaluate` is set to :code:"
"`0.1`, :code:`min_evaluate_clients` is set to 20, and :code:`100` clients "
"are connected to the server, then :code:`20` clients will be selected for "
"evaluation."
msgstr ""
":code:`min_evaluate_clients`：一个 :code:`int`，需要评估的客户的最小数量。"
"如果 :code:`fraction_evaluate` 设置为 :code:`0."
"1`，:code:`min_evaluate_clients` 设置为 20，并且有 :code:`100` "
"个客户端已连接到服务器，那么 :code:`20` 个客户端将被选中进行评估。"

#: ../../source/explanation-federated-evaluation.rst:107
msgid ""
":code:`min_available_clients`: an :code:`int` that defines the minimum "
"number of clients which need to be connected to the server before a round of "
"federated evaluation can start. If fewer than :code:`min_available_clients` "
"are connected to the server, the server will wait until more clients are "
"connected before it continues to sample clients for evaluation."
msgstr ""
":code:`min_available_clients`： "
":code:`int`，定义了在一轮联邦评估开始之前，需要连接到服务器的最小客户端数量。"
"如果连接到服务器的客户端数量少于 :code:`min_available_clients`，服务器将等待"
"更多客户端连接后，才继续采样客户端进行评估。"

#: ../../source/explanation-federated-evaluation.rst:108
msgid ""
":code:`on_evaluate_config_fn`: a function that returns a configuration "
"dictionary which will be sent to the selected clients. The function will be "
"called during each round and provides a convenient way to customize client-"
"side evaluation from the server side, for example, to configure the number "
"of validation steps performed."
msgstr ""
"code:`on_evaluate_config_fn`：返回配置字典的函数，该字典将发送给选定的客户"
"端。该函数将在每一轮中被调用，并提供了一种方便的方法来从服务器端自定义客户端"
"评估，例如，配置执行的验证步骤数。"

#: ../../source/explanation-federated-evaluation.rst:135
msgid "Evaluating Local Model Updates During Training"
msgstr "评估训练期间的本地模型更新"

#: ../../source/explanation-federated-evaluation.rst:137
msgid ""
"Model parameters can also be evaluated during training. :code:`Client.fit` "
"can return arbitrary evaluation results as a dictionary:"
msgstr ""
"模型参数也可在训练过程中进行评估。 :code:`Client.fit`可以字典形式返回任意评估"
"结果："

#: ../../source/explanation-federated-evaluation.rst:177
msgid "Full Code Example"
msgstr "完整代码示例"

#: ../../source/explanation-federated-evaluation.rst:179
msgid ""
"For a full code example that uses both centralized and federated evaluation, "
"see the *Advanced TensorFlow Example* (the same approach can be applied to "
"workloads implemented in any other framework): https://github.com/adap/"
"flower/tree/main/examples/advanced-tensorflow"
msgstr ""
"有关同时使用集中评估和联邦评估的完整代码示例，请参阅 *Advanced TensorFlow "
"Example*（同样的方法也可应用于任何其他框架中）： https://github.com/adap/"
"flower/tree/main/examples/advanced-tensorflow"

#: ../../source/fed/0000-20200102-fed-template.md:10
msgid "FED Template"
msgstr "FED 模板"

#: ../../source/fed/0000-20200102-fed-template.md:12
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:12
msgid "Table of Contents"
msgstr "目录"

#: ../../source/fed/0000-20200102-fed-template.md:14
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:14
msgid "[Table of Contents](#table-of-contents)"
msgstr "[目录]（#table-of-contents）"

#: ../../source/fed/0000-20200102-fed-template.md:15
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:15
msgid "[Summary](#summary)"
msgstr "[总结](#summary)"

#: ../../source/fed/0000-20200102-fed-template.md:16
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:16
msgid "[Motivation](#motivation)"
msgstr "[动机](#motivation)"

#: ../../source/fed/0000-20200102-fed-template.md:17
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:17
msgid "[Goals](#goals)"
msgstr "[目标](#goals)"

#: ../../source/fed/0000-20200102-fed-template.md:18
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:18
msgid "[Non-Goals](#non-goals)"
msgstr "[非目标](#non-goals)"

#: ../../source/fed/0000-20200102-fed-template.md:19
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:19
msgid "[Proposal](#proposal)"
msgstr "[计划](#proposal)"

#: ../../source/fed/0000-20200102-fed-template.md:20
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:23
msgid "[Drawbacks](#drawbacks)"
msgstr "[缺点](#drawbacks)"

#: ../../source/fed/0000-20200102-fed-template.md:21
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:24
msgid "[Alternatives Considered](#alternatives-considered)"
msgstr "[备选方案](#alternatives-considered)"

#: ../../source/fed/0000-20200102-fed-template.md:22
msgid "[Appendix](#appendix)"
msgstr "[附录](#appendix)"

#: ../../source/fed/0000-20200102-fed-template.md:24
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:28
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:76
msgid "Summary"
msgstr "总结"

#: ../../source/fed/0000-20200102-fed-template.md:26
msgid "\\[TODO - sentence 1: summary of the problem\\]"
msgstr "\\[TODO - 句子 1: 问题概括\\]"

#: ../../source/fed/0000-20200102-fed-template.md:28
msgid "\\[TODO - sentence 2: summary of the solution\\]"
msgstr "\\[TODO - 句子 2: 解决方案概括\\]"

#: ../../source/fed/0000-20200102-fed-template.md:30
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:47
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:77
msgid "Motivation"
msgstr "动机"

#: ../../source/fed/0000-20200102-fed-template.md:32
#: ../../source/fed/0000-20200102-fed-template.md:36
#: ../../source/fed/0000-20200102-fed-template.md:40
#: ../../source/fed/0000-20200102-fed-template.md:44
#: ../../source/fed/0000-20200102-fed-template.md:48
#: ../../source/fed/0000-20200102-fed-template.md:54
#: ../../source/fed/0000-20200102-fed-template.md:58
msgid "\\[TODO\\]"
msgstr "\\[TODO\\]"

#: ../../source/fed/0000-20200102-fed-template.md:34
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:53
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:78
msgid "Goals"
msgstr "目标"

#: ../../source/fed/0000-20200102-fed-template.md:38
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:59
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:79
msgid "Non-Goals"
msgstr "非目标"

#: ../../source/fed/0000-20200102-fed-template.md:42
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:65
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:80
msgid "Proposal"
msgstr "提案"

#: ../../source/fed/0000-20200102-fed-template.md:46
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:85
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:129
msgid "Drawbacks"
msgstr "缺点"

#: ../../source/fed/0000-20200102-fed-template.md:50
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:86
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:135
msgid "Alternatives Considered"
msgstr "备选方案"

#: ../../source/fed/0000-20200102-fed-template.md:52
msgid "\\[Alternative 1\\]"
msgstr "\\[备选 1\\]"

#: ../../source/fed/0000-20200102-fed-template.md:56
msgid "\\[Alternative 2\\]"
msgstr "\\[备选 2\\]"

#: ../../source/fed/0000-20200102-fed-template.md:60
msgid "Appendix"
msgstr "附录"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:10
msgid "Flower Enhancement Doc"
msgstr "Flower 改善文档"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:20
msgid "[Enhancement Doc Template](#enhancement-doc-template)"
msgstr "[增强文档模版](#enhancement-doc-template)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:21
msgid "[Metadata](#metadata)"
msgstr "[描述数据](#metadata)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:22
msgid "[Workflow](#workflow)"
msgstr "[工作流程](#workflow)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:25
msgid "[GitHub Issues](#github-issues)"
msgstr "[GitHub 问题](#github-issues)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:26
msgid "[Google Docs](#google-docs)"
msgstr "[谷歌文档](#google-docs)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:30
msgid "A Flower Enhancement is a standardized development process to"
msgstr "改善 Flower 功能是一个标准化的开发流程，目的是"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:32
msgid "provide a common structure for proposing larger changes"
msgstr "为提出更大规模的改动提供一个共同的结构"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:33
msgid "ensure that the motivation for a change is clear"
msgstr "确保改动的动机明确"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:34
msgid "persist project information in a version control system"
msgstr "将项目信息保存在版本控制系统中"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:35
msgid "document the motivation for impactful user-facing changes"
msgstr "记录面向用户的具有影响力的改动的动机"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:36
msgid "reserve GitHub issues for tracking work in flight"
msgstr "保留 GitHub 问题，用于跟踪进行中的工作"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:37
msgid ""
"ensure community participants can successfully drive changes to completion "
"across one or more releases while stakeholders are adequately represented "
"throughout the process"
msgstr "确保社区参与者能够成功推动改动，完成一个或多个版本，同时利益相关者在整个过程"
"中得到充分展现"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:39
msgid "Hence, an Enhancement Doc combines aspects of"
msgstr "因此，\"增强文件\"将以下方面结合起来"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:41
msgid "a feature, and effort-tracking document"
msgstr "一个功能和效力跟踪文档"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:42
msgid "a product requirements document"
msgstr "一个产品需要文档"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:43
msgid "a design document"
msgstr "一个设计文档"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:45
msgid ""
"into one file, which is created incrementally in collaboration with the "
"community."
msgstr "该文件是与社区合作逐步创建的。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:49
msgid ""
"For far-fetching changes or features proposed to Flower, an abstraction "
"beyond a single GitHub issue or pull request is required to understand and "
"communicate upcoming changes to the project."
msgstr ""
"对于向 Flower 提出的远期变更或功能，需要一个超越单个 GitHub 问题或拉取请求（"
"pull request）的抽象概念，以了解和沟通项目即将发生的变更。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:51
msgid ""
"The purpose of this process is to reduce the amount of \"tribal knowledge\" "
"in our community. By moving decisions from Slack threads, video calls, and "
"hallway conversations into a well-tracked artifact, this process aims to "
"enhance communication and discoverability."
msgstr ""
"这一流程的目的是减少我们社区中 \"部落知识 \"的数量。通过将决策从 Slack 线程、"
"视频通话和走廊对话转移到一个跟踪良好的工作环境中，该流程旨在加强沟通和可发现"
"性。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:55
msgid ""
"Roughly any larger, user-facing enhancement should follow the Enhancement "
"process. If an enhancement would be described in either written or verbal "
"communication to anyone besides the author or developer, then consider "
"creating an Enhancement Doc."
msgstr "任何较大的、面向用户的增强都应遵循增强流程。如果要以书面或口头形式向作者或开"
"发人员以外的任何人描述增强功能，则应考虑创建改善文档。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:57
msgid ""
"Similarly, any technical effort (refactoring, major architectural change) "
"that will impact a large section of the development community should also be "
"communicated widely. The Enhancement process is suited for this even if it "
"will have zero impact on the typical user or operator."
msgstr ""
"同样，任何会对开发社区的大部分人产生影响的技术工作（重构、重大架构变更）也应"
"广泛传播。即使对典型用户或操作员的影响为零，改进流程也适用于这种情况。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:61
msgid ""
"For small changes and additions, going through the Enhancement process would "
"be time-consuming and unnecessary. This includes, for example, adding new "
"Federated Learning algorithms, as these only add features without changing "
"how Flower works or is used."
msgstr ""
"对于小的改动和添加，通过 \"改善\"程序既耗时又没有必要"
"。例如，这包括添加新的联邦学习算法，因为这只会增加功能，而不会改变 \"Flower "
"\"的工作或使用方式。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:63
msgid ""
"Enhancements are different from feature requests, as they are already "
"providing a laid-out path for implementation and are championed by members "
"of the community."
msgstr ""
"增强功能与功能请求不同，因为它们已经提供了实施路径，并得到了社区成员的支持。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:67
msgid ""
"An Enhancement is captured in a Markdown file that follows a defined "
"template and a workflow to review and store enhancement docs for reference "
"— the Enhancement Doc."
msgstr ""
"增强功能被记录在一个 Markdown 文件中，该文件遵循已定义的模板和工作流程，用于"
"审查和存储增强功能文档（即增强功能文档）以供参考。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:69
msgid "Enhancement Doc Template"
msgstr "增强文档模板"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:71
msgid ""
"Each enhancement doc is provided as a Markdown file having the following "
"structure"
msgstr "每个增强文档都以 Markdown 文件的形式提供，其结构如下"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:73
msgid "Metadata (as [described below](#metadata) in form of a YAML preamble)"
msgstr "描述数据（[如下所述](#metadata) 以 YAML 前言的形式出现）"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:74
msgid "Title (same as in metadata)"
msgstr "标题（与描述数据中的标题相同）"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:75
msgid "Table of Contents (if needed)"
msgstr "目录（如有需要）"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:81
msgid "Notes/Constraints/Caveats (optional)"
msgstr "注意事项/限制/警告（可选）"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:82
msgid "Design Details (optional)"
msgstr "设计细节（可选）"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:83
msgid "Graduation Criteria"
msgstr "毕业标准"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:84
msgid "Upgrade/Downgrade Strategy (if applicable)"
msgstr "升级/降级策略（如适用）"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:88
msgid "As a reference, this document follows the above structure."
msgstr "作为参考，本文件采用上述结构。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:90
msgid "Metadata"
msgstr "描述数据"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:92
msgid ""
"**fed-number** (Required) The `fed-number` of the last Flower Enhancement "
"Doc + 1. With this number, it becomes easy to reference other proposals."
msgstr "**fed-number**（必填）上一个Flower增强文件的 \"fed-number \""
"+1。有了这个编号，就很容易参考其他提案。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:94
msgid "**title** (Required) The title of the proposal in plain language."
msgstr "**标题** （必填）用简明语言写出提案的标题。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:96
msgid ""
"**status** (Required) The current status of the proposal. See [workflow]"
"(#workflow) for the possible states."
msgstr ""
"**status** （必填）提案的当前状态。有关可能的状态，请参阅 [工作流程]"
"(#workflow)。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:98
msgid ""
"**authors** (Required) A list of authors of the proposal. This is simply the "
"GitHub ID."
msgstr "**作者**（必填） 提案的作者列表。这只是 GitHub ID。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:100
msgid ""
"**creation-date** (Required) The date that the proposal was first submitted "
"in a PR."
msgstr "**创建日期**（必填） 建议书在 PR 中首次提交的日期。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:102
msgid ""
"**last-updated** (Optional) The date that the proposal was last changed "
"significantly."
msgstr "**最后更新** （可选）提案最后一次重大修改的日期。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:104
msgid ""
"**see-also** (Optional) A list of other proposals that are relevant to this "
"one."
msgstr "**另见** （可选）与本提案相关的其他提案清单。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:106
msgid "**replaces** (Optional) A list of proposals that this one replaces."
msgstr "**取代**（可选） 这份提案所取代的提案列表。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:108
msgid ""
"**superseded-by** (Optional) A list of proposals that this one supersedes."
msgstr "**被取代者** （可选） 此提案取代的提案列表。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:111
msgid "Workflow"
msgstr "工作流程"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:113
msgid ""
"The idea forming the enhancement should already have been discussed or "
"pitched in the community. As such, it needs a champion, usually the author, "
"who shepherds the enhancement. This person also has to find committers to "
"Flower willing to review the proposal."
msgstr ""
"形成增强功能的想法应该已经在社区中讨论过或提出过。因此，它需要一个支持者（通"
"常是作者）来引导增强。这个人还必须找到愿意审核提案的提交者。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:115
msgid ""
"New enhancements are checked in with a file name in the form of `NNNN-"
"YYYYMMDD-enhancement-title.md`, with `NNNN` being the Flower Enhancement Doc "
"number, to `enhancements`. All enhancements start in `provisional` state as "
"part of a pull request. Discussions are done as part of the pull request "
"review."
msgstr ""
"新的增强功能以 `NNNN-YYYYMMDD-enhancement-title.md` 的文件名签入，其中 `NNNN`"
" 是花朵增强文档的编号，并将其转入 `enhancements`。作为拉取请求（pull "
"request）的一部分，所有增强功能都从 `provisional` "
"状态开始。讨论是作为拉取请求审查的一部分进行的。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:117
msgid ""
"Once an enhancement has been reviewed and approved, its status is changed to "
"`implementable`. The actual implementation is then done in separate pull "
"requests. These pull requests should mention the respective enhancement as "
"part of their description. After the implementation is done, the proposal "
"status is changed to `implemented`."
msgstr ""
"一旦增强功能通过审核和批准，其状态就会变为 `可实施`。实际的实施工作将在单独的"
"拉取请求中完成。这些拉取请求应在其描述中提及相应的增强功能。实施完成后，"
"提案状态将更改为 `已实施`。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:119
msgid ""
"Under certain conditions, other states are possible. An Enhancement has the "
"following states:"
msgstr "在某些条件下，还可能出现其他状态。增强提案具有以下状态："

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:121
msgid ""
"`provisional`: The enhancement has been proposed and is actively being "
"defined. This is the starting state while the proposal is being fleshed out "
"and actively defined and discussed."
msgstr "`暂定`： 已提出改进建议并正在积极定义。这是在提案得到充实、积极定义和讨论时的"
"起始状态。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:122
msgid "`implementable`: The enhancement has been reviewed and approved."
msgstr "`可实施`： 增强功能已审核通过。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:123
msgid ""
"`implemented`: The enhancement has been implemented and is no longer "
"actively changed."
msgstr "`已实施`： 增强功能已实施，不再主动更改。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:124
msgid ""
"`deferred`: The enhancement is proposed but not actively being worked on."
msgstr "`推迟`： 已提出改进建议，但尚未积极开展工作。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:125
msgid ""
"`rejected`: The authors and reviewers have decided that this enhancement is "
"not moving forward."
msgstr "`拒绝`： 作者和审稿人已决定不再推进该增强功能。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:126
msgid "`withdrawn`: The authors have withdrawn the enhancement."
msgstr "`撤回`： 作者已撤回增强功能。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:127
msgid "`replaced`: The enhancement has been replaced by a new enhancement."
msgstr "`已替换`： 增强功能已被新的增强功能取代。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:131
msgid ""
"Adding an additional process to the ones already provided by GitHub (Issues "
"and Pull Requests) adds more complexity and can be a barrier for potential "
"first-time contributors."
msgstr ""
"在 GitHub 已提供的流程（问题和拉取请求）之外再增加一个流程，会增加复杂性，并"
"可能成为潜在首次贡献者的障碍。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:133
msgid ""
"Expanding the proposal template beyond the single-sentence description "
"currently required in the features issue template may be a heavy burden for "
"non-native English speakers."
msgstr ""
"对于英语非母语者来说，将提案模板扩展到目前要求的单句描述之外可能是一个沉重的"
"负担。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:137
msgid "GitHub Issues"
msgstr "GitHub 问题"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:139
msgid ""
"Using GitHub Issues for these kinds of enhancements is doable. One could "
"use, for example, tags, to differentiate and filter them from other issues. "
"The main issue is in discussing and reviewing an enhancement: GitHub issues "
"only have a single thread for comments. Enhancements usually have multiple "
"threads of discussion at the same time for various parts of the doc. "
"Managing these multiple discussions can be confusing when using GitHub "
"Issues."
msgstr ""
"使用 GitHub Issues 进行此类改进是可行的。例如，我们可以使用标签来区分和过滤这"
"些问题。主要的问题在于讨论和审查增强功能： GitHub 问题只有一个评论线程。而增"
"强功能通常会同时有多个讨论线程，针对文档的不同部分。在使用 GitHub 问题时，管"
"理这些多重讨论会很混乱。"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:141
msgid "Google Docs"
msgstr "谷歌文档"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:143
msgid ""
"Google Docs allow for multiple threads of discussions. But as Google Docs "
"are hosted outside the project, their discoverability by the community needs "
"to be taken care of. A list of links to all proposals has to be managed and "
"made available for the community. Compared to shipping proposals as part of "
"Flower's repository, the potential for missing links is much higher."
msgstr ""
"谷歌文档允许多线程讨论。但是，由于谷歌文档是在项目之外托管的，因此需要注意它"
"们是否能被社区发现。我们必须管理所有提案的链接列表，并提供给社区使用。与作为 "
"Flower 资源库一部分的提案相比，丢失链接的可能性要大得多。"

#: ../../source/fed/index.md:1
msgid "FED - Flower Enhancement Doc"
msgstr "FED - Flower 增强文件"

#: ../../source/how-to-aggregate-evaluation-results.rst:2
msgid "Aggregate evaluation results"
msgstr "整合评估结果"

#: ../../source/how-to-aggregate-evaluation-results.rst:4
msgid ""
"The Flower server does not prescribe a way to aggregate evaluation results, "
"but it enables the user to fully customize result aggregation."
msgstr "Flower 服务器没有规定整合评估结果的方法，但用户可以完全自定义如何整合。"

#: ../../source/how-to-aggregate-evaluation-results.rst:8
msgid "Aggregate Custom Evaluation Results"
msgstr "自定义整合评估结果"

#: ../../source/how-to-aggregate-evaluation-results.rst:10
msgid ""
"The same :code:`Strategy`-customization approach can be used to aggregate "
"custom evaluation results coming from individual clients. Clients can return "
"custom metrics to the server by returning a dictionary:"
msgstr ""
"同样的 :code:`Strategy` 定制方法也可用于汇总来自单个客户端的自定义评估结果。"
"客户端可以通过返回字典的方式向服务器返回自定义指标："

#: ../../source/how-to-aggregate-evaluation-results.rst:36
msgid ""
"The server can then use a customized strategy to aggregate the metrics "
"provided in these dictionaries:"
msgstr "然后，服务器可以使用定制的策略来汇总这些字典中提供的指标："

#: ../../source/how-to-configure-clients.rst:2
msgid "Configure clients"
msgstr "配置客户端"

#: ../../source/how-to-configure-clients.rst:4
msgid ""
"Along with model parameters, Flower can send configuration values to "
"clients. Configuration values can be used for various purposes. They are, "
"for example, a popular way to control client-side hyperparameters from the "
"server."
msgstr "除了模型参数，Flower 还可以向客户端发送配置值。配置值有多种用途。它们是一种从"
"服务器控制客户端超参数的常用方法。"

#: ../../source/how-to-configure-clients.rst:7
msgid "Configuration values"
msgstr "配置值"

#: ../../source/how-to-configure-clients.rst:9
msgid ""
"Configuration values are represented as a dictionary with ``str`` keys and "
"values of type ``bool``, ``bytes``, ``double`` (64-bit precision float), "
"``int``, or ``str`` (or equivalent types in different languages). Here is an "
"example of a configuration dictionary in Python:"
msgstr ""
"配置值以字典的形式表示，字典的键为 ``str``，值的类型为 ``bool``、``bytes``、"
"``double``（64 位精度浮点型）、``int``或 ``str`（或不同语言中的等效类型）。下"
"面是一个 Python 配置字典的示例："

#: ../../source/how-to-configure-clients.rst:20
msgid ""
"Flower serializes these configuration dictionaries (or *config dict* for "
"short) to their ProtoBuf representation, transports them to the client using "
"gRPC, and then deserializes them back to Python dictionaries."
msgstr ""
"Flower 将这些配置字典（简称 *config dict*）序列化为 ProtoBuf 表示形式，使用 "
"gRPC 将其传输到客户端，然后再反序列化为 Python 字典。"

#: ../../source/how-to-configure-clients.rst:24
msgid ""
"Currently, there is no support for directly sending collection types (e.g., "
"``Set``, ``List``, ``Map``) as values in configuration dictionaries. There "
"are several workarounds to send collections as values by converting them to "
"one of the supported value types (and converting them back on the client-"
"side)."
msgstr ""
"目前，还不支持在配置字典中直接发送作为值的集合类型（例如，`Set``, `List`, `Ma"
"p``）。有几种变通方法可将集合转换为支持的值类型之一（并在客户端将其转换回），"
"从而将集合作为值发送。"

#: ../../source/how-to-configure-clients.rst:26
msgid ""
"One can, for example, convert a list of floating-point numbers to a JSON "
"string, then send the JSON string using the configuration dictionary, and "
"then convert the JSON string back to a list of floating-point numbers on the "
"client."
msgstr ""
"例如，可以将浮点数列表转换为 JSON 字符串，然后使用配置字典发送 JSON 字符串，"
"再在客户端将 JSON 字符串转换回浮点数列表。"

#: ../../source/how-to-configure-clients.rst:30
msgid "Configuration through built-in strategies"
msgstr "通过内置策略进行配置"

#: ../../source/how-to-configure-clients.rst:32
msgid ""
"The easiest way to send configuration values to clients is to use a built-in "
"strategy like :code:`FedAvg`. Built-in strategies support so-called "
"configuration functions. A configuration function is a function that the "
"built-in strategy calls to get the configuration dictionary for the current "
"round. It then forwards the configuration dictionary to all the clients "
"selected during that round."
msgstr ""
"向客户端发送配置值的最简单方法是使用内置策略，如 :code:`FedAvg`。内置策略支持"
"所谓的配置函数。配置函数是内置策略调用的函数，用于获取当前轮的配置字典。然后"
"，它会将配置字典转发给该轮中选择的所有客户端。"

#: ../../source/how-to-configure-clients.rst:34
msgid ""
"Let's start with a simple example. Imagine we want to send (a) the batch "
"size that the client should use, (b) the current global round of federated "
"learning, and (c) the number of epochs to train on the client-side. Our "
"configuration function could look like this:"
msgstr ""
"让我们从一个简单的例子开始。想象一下，我们想要发送给客户端（a）应该使用的批次"
"大小，（b）当前联邦学习的全局轮次，以及（c）客户端训练的遍历数。我们的配置函"
"数可以是这样的："

#: ../../source/how-to-configure-clients.rst:47
msgid ""
"To make the built-in strategies use this function, we can pass it to "
"``FedAvg`` during initialization using the parameter :code:"
"`on_fit_config_fn`:"
msgstr ""
"为了让内置策略使用这个函数，我们可以在初始化时使用参数 :code:"
"`on_fit_config_fn` 将它传递给 ``FedAvg`` ："

#: ../../source/how-to-configure-clients.rst:56
msgid ""
"One the client side, we receive the configuration dictionary in ``fit``:"
msgstr "在客户端，我们在 ``fit`` 中接收配置字典："

#: ../../source/how-to-configure-clients.rst:67
msgid ""
"There is also an `on_evaluate_config_fn` to configure evaluation, which "
"works the same way. They are separate functions because one might want to "
"send different configuration values to `evaluate` (for example, to use a "
"different batch size)."
msgstr ""
"还有一个 `on_evaluate_config_fn` 用于配置评估，其工作方式相同。它们是不同的函"
"数，因为可能需要向 `evaluate` 发送不同的配置值（例如，使用不同的批量大小）。"

#: ../../source/how-to-configure-clients.rst:69
msgid ""
"The built-in strategies call this function every round (that is, every time "
"`Strategy.configure_fit` or `Strategy.configure_evaluate` runs). Calling "
"`on_evaluate_config_fn` every round allows us to vary/change the config dict "
"over consecutive rounds. If we wanted to implement a hyperparameter "
"schedule, for example, to increase the number of local epochs during later "
"rounds, we could do the following:"
msgstr ""
"内置策略每轮都会调用此函数（即每次运行 `Strategy.configure_fit` 或 `Strategy."
"configure_evaluate` 时）。每轮调用 `on_evaluate_config_fn` 允许我们在连续几轮"
"中改变配置指令。例如，如果我们想实现一个超参数时间表，以增加后几轮的本地遍历"
"次数，我们可以这样做："

#: ../../source/how-to-configure-clients.rst:82
msgid "The :code:`FedAvg` strategy will call this function *every round*."
msgstr "代码:`FedAvg`策略*每轮*都会调用该函数。"

#: ../../source/how-to-configure-clients.rst:85
msgid "Configuring individual clients"
msgstr "配置个别客户端"

#: ../../source/how-to-configure-clients.rst:87
msgid ""
"In some cases, it is necessary to send different configuration values to "
"different clients."
msgstr "在某些情况下，有必要向不同的客户端发送不同的配置值。"

#: ../../source/how-to-configure-clients.rst:89
msgid ""
"This can be achieved by customizing an existing strategy or by `implementing "
"a custom strategy from scratch <https://flower.dev/docs/framework/how-to-"
"implement-strategies.html>`_. Here's a nonsensical example that customizes :"
"code:`FedAvg` by adding a custom ``\"hello\": \"world\"`` configuration key/"
"value pair to the config dict of a *single client* (only the first client in "
"the list, the other clients in this round to not receive this \"special\" "
"config value):"
msgstr ""
"这可以通过定制现有策略或 `从头开始实施一个定制策略 <https://flower.dev/docs/"
"framework/how-to-implement-strategies."
"html>`_来实现。下面是一个无厘头的例子，`FedAvg`通过在*单个客户端*的配置指令（"
"config dict）中添加自定义的``\"hello\"： \"world\"``配置键/"
"值对添加到此的配置 dict 中（仅列表中的第一个客户端，"
"本轮中的其他客户端不会收到此 \"特殊 \"配置值）："

#: ../../source/how-to-configure-logging.rst:2
msgid "Configure logging"
msgstr "配置日志记录"

#: ../../source/how-to-configure-logging.rst:4
msgid ""
"The Flower logger keeps track of all core events that take place in "
"federated learning workloads. It presents information by default following a "
"standard message format:"
msgstr "Flower 日志记录器会跟踪联邦学习工作负载中发生的所有核心事件。它默认按照标准信"
"息格式提供信息："

#: ../../source/how-to-configure-logging.rst:13
msgid ""
"containing relevant information including: log message level (e.g. :code:"
"`INFO`, :code:`DEBUG`), a timestamp, the line where the logging took place "
"from, as well as the log message itself. In this way, the logger would "
"typically display information on your terminal as follows:"
msgstr ""
"相关信息包括：日志信息级别（例如 :code:`INFO`、:code:`DEBUG`）、时间戳、日志"
"记录的行以及日志信息本身。这样，日志记录器通常会在终端上显示如下信息："

#: ../../source/how-to-configure-logging.rst:34
msgid "Saving log to file"
msgstr "将日志保存到文件"

#: ../../source/how-to-configure-logging.rst:36
msgid ""
"By default, the Flower log is outputted to the terminal where you launch "
"your Federated Learning workload from. This applies for both gRPC-based "
"federation (i.e. when you do :code:`fl.server.start_server`) and when using "
"the :code:`VirtualClientEngine` (i.e. when you do :code:`fl.simulation."
"start_simulation`). In some situations you might want to save this log to "
"disk. You can do so by calling the `fl.common.logger.configure() <https://"
"github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_ function. "
"For example:"
msgstr ""
"默认情况下，Flower 日志会输出到启动联邦学习工作负载的终端。这既适用于基于 "
"gRPC 的联邦学习（即执行 :code:`fl.server.start_server` 时），也适用于使用 "
":code:`VirtualClientEngine` 时（即执行 :code:`fl.simulation.start_simulation`"
" 时）。在某些情况下，您可能希望将此日志保存到磁盘。为此，您可以调用 `fl."
"common.logger.configure() <https://github.com/adap/flower/blob/main/src/py/"
"flwr/common/logger.py>`_ 函数。例如："

#: ../../source/how-to-configure-logging.rst:53
msgid ""
"With the above, Flower will record the log you see on your terminal to :code:"
"`log.txt`. This file will be created in the same directory as were you are "
"running the code from. If we inspect we see the log above is also recorded "
"but prefixing with :code:`identifier` each line:"
msgstr ""
"通过上述操作，Flower 会将您在终端上看到的日志记录到 :code:`log.txt`。该文件将"
"创建在运行代码的同一目录下。如果我们检查一下，就会发现上面的日志也被记录了下"
"来，但每一行都以 :code:`identifier` 作为前缀："

#: ../../source/how-to-configure-logging.rst:74
msgid "Log your own messages"
msgstr "记录自己的信息"

#: ../../source/how-to-configure-logging.rst:76
msgid ""
"You might expand the information shown by default with the Flower logger by "
"adding more messages relevant to your application. You can achieve this "
"easily as follows."
msgstr ""
"您可以通过添加更多与应用程序相关的信息来扩展 Flower 日志记录器默认显示的信"
"息。您可以通过以下方法轻松实现这一目标。"

#: ../../source/how-to-configure-logging.rst:102
msgid ""
"In this way your logger will show, in addition to the default messages, the "
"ones introduced by the clients as specified above."
msgstr ""
"这样，除默认信息外，您的日志记录器还将显示由客户引入的信息，如上文所述。"

#: ../../source/how-to-configure-logging.rst:128
msgid "Log to a remote service"
msgstr "登录远程服务"

#: ../../source/how-to-configure-logging.rst:130
msgid ""
"The :code:`fl.common.logger.configure` function, also allows specifying a "
"host to which logs can be pushed (via :code:`POST`) through a native Python :"
"code:`logging.handler.HTTPHandler`. This is a particularly useful feature "
"in :code:`gRPC`-based Federated Learning workloads where otherwise gathering "
"logs from all entities (i.e. the server and the clients) might be "
"cumbersome. Note that in Flower simulation, the server automatically "
"displays all logs. You can still specify a :code:`HTTPHandler` should you "
"whish to backup or analyze the logs somewhere else."
msgstr ""
"此外，:code:`fl.common.logger.configure`函数还允许指定主机，通过本地 Python "
":code:`logging.handler.HTTPHandler`，向该主机推送日志（通过 :code:`POST`）。"
"在基于 :code:`gRPC` 的联邦学习工作负载中，这是一个特别有用的功能，否则从所有"
"实体（即服务器和客户端）收集日志可能会很麻烦。请注意，在 Flower "
"模拟器中，服务器会自动显示所有日志。如果希望在其他地方备份或分析日志，"
"仍可指定 :code:`HTTPHandler`。"

#: ../../source/how-to-enable-ssl-connections.rst:2
msgid "Enable SSL connections"
msgstr "启用 SSL 连接"

#: ../../source/how-to-enable-ssl-connections.rst:4
msgid ""
"This guide describes how to a SSL-enabled secure Flower server can be "
"started and how a Flower client can establish a secure connections to it."
msgstr ""
"本指南介绍如何启动启用 SSL 的安全 Flower 服务器，以及 Flower 客户端如何与其建"
"立安全连接。"

#: ../../source/how-to-enable-ssl-connections.rst:7
msgid ""
"A complete code example demonstrating a secure connection can be found `here "
"<https://github.com/adap/flower/tree/main/examples/advanced-tensorflow>`_."
msgstr ""
"有关安全连接的完整代码示例，请参见 <https://github.com/adap/flower/tree/main/"
"examples/advanced-tensorflow>`_ 。"

#: ../../source/how-to-enable-ssl-connections.rst:10
msgid ""
"The code example comes with a README.md file which will explain how to start "
"it. Although it is already SSL-enabled, it might be less descriptive on how. "
"Stick to this guide for a deeper introduction to the topic."
msgstr ""
"代码示例附带的 README.md 文件将解释如何启动它。虽然它已经启用了 SSL，但对如何"
"启用可能描述较少。请参考本指南，了解更深入的相关介绍。"

#: ../../source/how-to-enable-ssl-connections.rst:16
msgid "Certificates"
msgstr "证书"

#: ../../source/how-to-enable-ssl-connections.rst:18
msgid ""
"Using SSL-enabled connections requires certificates to be passed to the "
"server and client. For the purpose of this guide we are going to generate "
"self-signed certificates. As this can become quite complex we are going to "
"ask you to run the script in :code:`examples/advanced-tensorflow/"
"certificates/generate.sh`"
msgstr ""
"使用支持 SSL 的连接需要向服务器和客户端传递证书。在本指南中，我们将生成自签名"
"证书。由于这可能会变得相当复杂，我们将要求你运行 :code:`examples/advanced-"
"tensorflow/certificates/generate.sh` 中的脚本"

#: ../../source/how-to-enable-ssl-connections.rst:23
msgid "with the following command sequence:"
msgstr "使用以下命令序列："

#: ../../source/how-to-enable-ssl-connections.rst:30
msgid ""
"This will generate the certificates in :code:`examples/advanced-tensorflow/."
"cache/certificates`."
msgstr ""
"这将在 :code:`examples/advanced-tensorflow/.cache/certificates` 中生成证书。"

#: ../../source/how-to-enable-ssl-connections.rst:32
msgid ""
"The approach how the SSL certificates are generated in this example can "
"serve as an inspiration and starting point but should not be taken as "
"complete for production environments. Please refer to other sources "
"regarding the issue of correctly generating certificates for production "
"environments."
msgstr "本示例中生成 SSL 证书的方法可作为启发和起点，但不应被视为生产环境的完整方法。"
"有关在生产环境中正确生成证书的问题，请参考其他资料。"

#: ../../source/how-to-enable-ssl-connections.rst:36
msgid ""
"In case you are a researcher you might be just fine using the self-signed "
"certificates generated using the scripts which are part of this guide."
msgstr "如果你是一名研究人员，使用本指南中的脚本生成的自签名证书就可以了。"

#: ../../source/how-to-enable-ssl-connections.rst:41
msgid "Server"
msgstr "服务器"

#: ../../source/how-to-enable-ssl-connections.rst:43
msgid ""
"We are now going to show how to write a sever which uses the previously "
"generated scripts."
msgstr "现在，我们将展示如何编写一个使用先前生成的脚本的服务器。"

#: ../../source/how-to-enable-ssl-connections.rst:61
msgid ""
"When providing certificates, the server expects a tuple of three "
"certificates. :code:`Path` can be used to easily read the contents of those "
"files into byte strings, which is the data type :code:`start_server` expects."
msgstr ""
"在提供证书时，服务器希望得到由三个证书组成的元组。 :code:`Path` 可用于轻松地"
"将这些文件的内容读取为字节字符串，这就是 :code:`start_server` 期望的数据类"
"型。"

#: ../../source/how-to-enable-ssl-connections.rst:65
#: ../../source/how-to-upgrade-to-flower-1.0.rst:37
#: ../../source/ref-api-flwr.rst:15
msgid "Client"
msgstr "客户端"

#: ../../source/how-to-enable-ssl-connections.rst:67
msgid ""
"We are now going to show how to write a client which uses the previously "
"generated scripts:"
msgstr "现在我们将演示如何编写一个客户端，使用之前生成的脚本："

#: ../../source/how-to-enable-ssl-connections.rst:84
msgid ""
"When setting :code:`root_certificates`, the client expects the PEM-encoded "
"root certificates as a byte string. We are again using :code:`Path` to "
"simplify reading those as byte strings."
msgstr ""
"当设置 :code:`root_certificates` 时，客户端希望 PEM 编码的根证书是字节字符"
"串。我们再次使用 :code:`Path` 来简化以字节字符串形式读取证书的过程。"

#: ../../source/how-to-enable-ssl-connections.rst:89
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:287
msgid "Conclusion"
msgstr "总结"

#: ../../source/how-to-enable-ssl-connections.rst:91
msgid ""
"You should now have learned how to generate self-signed certificates using "
"the given script, start a SSL-enabled server, and have a client establish a "
"secure connection to it."
msgstr ""
"现在，你应该已经学会了如何使用给定的脚本生成自签名证书、启动启用 SSL 的服务器"
"并让客户端与其建立安全连接。"

#: ../../source/how-to-enable-ssl-connections.rst:96
msgid "Additional resources"
msgstr "补充资源"

#: ../../source/how-to-enable-ssl-connections.rst:98
msgid ""
"These additional sources might be relevant if you would like to dive deeper "
"into the topic of certificates:"
msgstr "如果您想更深入地了解证书主题，这些额外的资料来源可能有帮助："

#: ../../source/how-to-enable-ssl-connections.rst:100
msgid "`Let's Encrypt <https://letsencrypt.org/docs/>`_"
msgstr "`让我们加密 <https://letsencrypt.org/docs/>`_"

#: ../../source/how-to-enable-ssl-connections.rst:101
msgid "`certbot <https://certbot.eff.org/>`_"
msgstr "`certbot <https://certbot.eff.org/>`_"

#: ../../source/how-to-implement-strategies.rst:2
msgid "Implement strategies"
msgstr "实施策略"

#: ../../source/how-to-implement-strategies.rst:4
msgid ""
"The strategy abstraction enables implementation of fully custom strategies. "
"A strategy is basically the federated learning algorithm that runs on the "
"server. Strategies decide how to sample clients, how to configure clients "
"for training, how to aggregate updates, and how to evaluate models. Flower "
"provides a few built-in strategies which are based on the same API described "
"below."
msgstr ""
"策略抽象类可以实现完全定制的策略。策略基本上就是在服务器上运行的联邦学习算法"
"。策略决定如何对客户端进行采样、如何配置客户端进行训练、如何聚合参数更新以及"
"如何评估模型。Flower 提供了一些内置策略，这些策略基于下文所述的相同 API。"

#: ../../source/how-to-implement-strategies.rst:11
msgid "The :code:`Strategy` abstraction"
msgstr ":code:`策略 ` 抽象类"

#: ../../source/how-to-implement-strategies.rst:13
msgid ""
"All strategy implementation are derived from the abstract base class :code:"
"`flwr.server.strategy.Strategy`, both built-in implementations and third "
"party implementations. This means that custom strategy implementations have "
"the exact same capabilities at their disposal as built-in ones."
msgstr ""
"所有策略实现均源自抽象基类 :code:`flwr.server.strategy.Strategy`，包括内置实"
"现和第三方实现。这意味着自定义策略实现与内置实现具有完全相同的功能。"

#: ../../source/how-to-implement-strategies.rst:18
msgid ""
"The strategy abstraction defines a few abstract methods that need to be "
"implemented:"
msgstr "策略抽象定义了一些需要实现的抽象方法："

#: ../../source/how-to-implement-strategies.rst:75
msgid ""
"Creating a new strategy means implementing a new :code:`class` (derived from "
"the abstract base class :code:`Strategy`) that implements for the previously "
"shown abstract methods:"
msgstr ""
"创建一个新策略意味着要实现一个新的 :code:`class`（从抽象基类 :code:"
"`Strategy` 派生），该类要实现前面显示的抽象方法："

#: ../../source/how-to-implement-strategies.rst:100
msgid "The Flower server calls these methods in the following order:"
msgstr "Flower 服务器按以下顺序调用这些方法："

#: ../../source/how-to-implement-strategies.rst:177
msgid "The following sections describe each of those methods in more detail."
msgstr "下文将详细介绍每种方法。"

#: ../../source/how-to-implement-strategies.rst:180
msgid "The :code:`initialize_parameters` method"
msgstr ":code:`初始化参数` 方法"

#: ../../source/how-to-implement-strategies.rst:182
msgid ""
":code:`initialize_parameters` is called only once, at the very beginning of "
"an execution. It is responsible for providing the initial global model "
"parameters in a serialized form (i.e., as a :code:`Parameters` object)."
msgstr ""
":code:`initialize_parameters` 只调用一次，即在执行开始时。它负责以序列化形式"
"（即 :code:`Parameters` 对象）提供初始全局模型参数。"

#: ../../source/how-to-implement-strategies.rst:184
msgid ""
"Built-in strategies return user-provided initial parameters. The following "
"example shows how initial parameters can be passed to :code:`FedAvg`:"
msgstr ""
"内置策略会返回用户提供的初始参数。下面的示例展示了如何将初始参数传递给 :code:"
"`FedAvg`："

#: ../../source/how-to-implement-strategies.rst:209
msgid ""
"The Flower server will call :code:`initialize_parameters`, which either "
"returns the parameters that were passed to :code:`initial_parameters`, or :"
"code:`None`. If no parameters are returned from :code:"
"`initialize_parameters` (i.e., :code:`None`), the server will randomly "
"select one client and ask it to provide its parameters. This is a "
"convenience feature and not recommended in practice, but it can be useful "
"for prototyping. In practice, it is recommended to always use server-side "
"parameter initialization."
msgstr ""
"Flower 服务器将调用 :code:`initialize_parameters`，返回传给 "
":code:`initial_parameters` 的参数或 :code:`None`。如果 "
":code:`initialize_parameters` 没有返回任何参数（即 :code:`None`），服务器将随"
"机选择一个客户端并要求其提供参数。这只是一个便捷的功能，在实际应用中并不推荐"
"使用，但在原型开发中可能很有用。在实践中，建议始终使用服务器端参数初始化。"

#: ../../source/how-to-implement-strategies.rst:213
msgid ""
"Server-side parameter initialization is a powerful mechanism. It can be "
"used, for example, to resume training from a previously saved checkpoint. It "
"is also the fundamental capability needed to implement hybrid approaches, "
"for example, to fine-tune a pre-trained model using federated learning."
msgstr ""
"服务器端参数初始化是一种强大的机制。例如，它可以用来从先前保存的检查点恢复训"
"练。它也是实现混合方法所需的基本能力，例如，使用联邦学习对预先训练好的模型进"
"行微调。"

#: ../../source/how-to-implement-strategies.rst:216
msgid "The :code:`configure_fit` method"
msgstr ":code:`configure_fit`方法"

#: ../../source/how-to-implement-strategies.rst:218
msgid ""
":code:`configure_fit` is responsible for configuring the upcoming round of "
"training. What does *configure* mean in this context? Configuring a round "
"means selecting clients and deciding what instructions to send to these "
"clients. The signature of :code:`configure_fit` makes this clear:"
msgstr ""
":code:`configure_fit` 负责配置即将开始的一轮训练。*配置*在这里是什么意思？配"
"置一轮训练意味着选择客户并决定向这些客户发送什么指令。:code:`configure_fit` "
"说明了这一点："

#: ../../source/how-to-implement-strategies.rst:231
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations usually "
"perform the following steps in :code:`configure_fit`:"
msgstr ""
"返回值是一个元组列表，每个元组代表将发送到特定客户端的指令。策略实现通常在 :"
"code:`configure_fit` 中执行以下步骤："

#: ../../source/how-to-implement-strategies.rst:233
#: ../../source/how-to-implement-strategies.rst:280
msgid ""
"Use the :code:`client_manager` to randomly sample all (or a subset of) "
"available clients (each represented as a :code:`ClientProxy` object)"
msgstr ""
"使用 :code:`client_manager` 随机抽样所有（或部分）可用客户端（每个客户端都表"
"示为 :code:`ClientProxy` 对象）"

#: ../../source/how-to-implement-strategies.rst:234
msgid ""
"Pair each :code:`ClientProxy` with the same :code:`FitIns` holding the "
"current global model :code:`parameters` and :code:`config` dict"
msgstr ""
"将每个 :code:`ClientProxy` 与持有当前全局模型 :code:`parameters` 和 :code:"
"`config` dict 的 :code:`FitIns` 配对"

#: ../../source/how-to-implement-strategies.rst:236
msgid ""
"More sophisticated implementations can use :code:`configure_fit` to "
"implement custom client selection logic. A client will only participate in a "
"round if the corresponding :code:`ClientProxy` is included in the the list "
"returned from :code:`configure_fit`."
msgstr ""
"更复杂的实现可以使用 :code:`configure_fit` 来实现自定义的客户端选择逻辑。"
"只有当相应的 :code:`ClientProxy` 包含在 :code:`configure_fit` "
"返回的列表中时，客户端才会参与进来。"

#: ../../source/how-to-implement-strategies.rst:240
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies to "
"train, for example, different models on different clients, or use different "
"hyperparameters on different clients (via the :code:`config` dict)."
msgstr ""
"该返回值的结构为用户提供了很大的灵活性。由于指令是按客户端定义的，因此可以向"
"每个客户端发送不同的指令。这使得自定义策略成为可能，例如在不同的客户端上训练"
"不同的模型，或在不同的客户端上使用不同的超参数（通过 :code:`config` dict）。"

#: ../../source/how-to-implement-strategies.rst:243
msgid "The :code:`aggregate_fit` method"
msgstr ":code:`aggregate_fit` 方法"

#: ../../source/how-to-implement-strategies.rst:245
msgid ""
":code:`aggregate_fit` is responsible for aggregating the results returned by "
"the clients that were selected and asked to train in :code:`configure_fit`."
msgstr ""
":code:`aggregate_fit` 负责汇总在 :code:`configure_fit` 中选择并要求训练的客户"
"端所返回的结果。"

#: ../../source/how-to-implement-strategies.rst:258
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via :code:"
"`configure_fit`). :code:`aggregate_fit` therefore receives a list of :code:"
"`results`, but also a list of :code:`failures`."
msgstr ""
"当然，失败是有可能发生的，因此无法保证服务器会从它发送指令（通过 :code:"
"`configure_fit`）的所有客户端获得结果。因此 :code:`aggregate_fit` 会收到 :"
"code:`results` 的列表，但也会收到 :code:`failures` 的列表。"

#: ../../source/how-to-implement-strategies.rst:260
msgid ""
":code:`aggregate_fit` returns an optional :code:`Parameters` object and a "
"dictionary of aggregated metrics. The :code:`Parameters` return value is "
"optional because :code:`aggregate_fit` might decide that the results "
"provided are not sufficient for aggregation (e.g., too many failures)."
msgstr ""
":code:`aggregate_fit` 返回一个可选的 :code:`Parameters` 对象和一个聚合度量的"
"字典。:code:`Parameters` 返回值是可选的，因为 :code:`aggregate_fit` 可能会认"
"为所提供的结果不足以进行聚合（例如，失败次数过多）。"

#: ../../source/how-to-implement-strategies.rst:263
msgid "The :code:`configure_evaluate` method"
msgstr ":code:`configure_evaluate`方法"

#: ../../source/how-to-implement-strategies.rst:265
msgid ""
":code:`configure_evaluate` is responsible for configuring the upcoming round "
"of evaluation. What does *configure* mean in this context? Configuring a "
"round means selecting clients and deciding what instructions to send to "
"these clients. The signature of :code:`configure_evaluate` makes this clear:"
msgstr ""
":code:`configure_evaluate` 负责配置下一轮评估。*配置*在这里是什么意思？配置一"
"轮评估意味着选择客户端并决定向这些客户端发送什么指令。:code:`configure_evalua"
"te` 说明了这一点："

#: ../../source/how-to-implement-strategies.rst:278
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations usually "
"perform the following steps in :code:`configure_evaluate`:"
msgstr ""
"返回值是一个元组列表，每个元组代表将发送到特定客户端的指令。策略实现通常在 :"
"code:`configure_evaluate` 中执行以下步骤："

#: ../../source/how-to-implement-strategies.rst:281
msgid ""
"Pair each :code:`ClientProxy` with the same :code:`EvaluateIns` holding the "
"current global model :code:`parameters` and :code:`config` dict"
msgstr ""
"将每个 :code:`ClientProxy` 与持有当前全局模型 :code:`parameters` 和 :code:"
"`config` dict 的 :code:`EvaluateIns` 配对"

#: ../../source/how-to-implement-strategies.rst:283
msgid ""
"More sophisticated implementations can use :code:`configure_evaluate` to "
"implement custom client selection logic. A client will only participate in a "
"round if the corresponding :code:`ClientProxy` is included in the the list "
"returned from :code:`configure_evaluate`."
msgstr ""
"更复杂的实现可以使用 :code:`configure_evaluate` "
"来实现自定义的客户端选择逻辑。只有当相应的 :code:`ClientProxy` 包含在 "
":code:`configure_evaluate` 返回的列表中时，客户端才会参与进来。"

#: ../../source/how-to-implement-strategies.rst:287
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies to "
"evaluate, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the :code:`config` dict)."
msgstr ""
"该返回值的结构为用户提供了很大的灵活性。由于指令是按客户端定义的，因此可以向"
"每个客户端发送不同的指令。这使得自定义策略可以在不同客户端上评估不同的模型，"
"或在不同客户端上使用不同的超参数（通过 :code:`config` dict）。"

#: ../../source/how-to-implement-strategies.rst:291
msgid "The :code:`aggregate_evaluate` method"
msgstr ":code:`aggregate_evaluate` 方法"

#: ../../source/how-to-implement-strategies.rst:293
msgid ""
":code:`aggregate_evaluate` is responsible for aggregating the results "
"returned by the clients that were selected and asked to evaluate in :code:"
"`configure_evaluate`."
msgstr ""
":code:`aggregate_evaluate` 负责汇总在 :code:`configure_evaluate` 中选择并要求"
"评估的客户端返回的结果。"

#: ../../source/how-to-implement-strategies.rst:306
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via :code:"
"`configure_evaluate`). :code:`aggregate_evaluate` therefore receives a list "
"of :code:`results`, but also a list of :code:`failures`."
msgstr ""
"当然，失败是有可能发生的，因此无法保证服务器会从它发送指令（通过 :code:"
"`configure_evaluate`）的所有客户端获得结果。因此， :code:"
"`aggregate_evaluate` 会接收 :code:`results` 的列表，但也会接收 :code:"
"`failures` 的列表。"

#: ../../source/how-to-implement-strategies.rst:308
msgid ""
":code:`aggregate_evaluate` returns an optional :code:`float` (loss) and a "
"dictionary of aggregated metrics. The :code:`float` return value is optional "
"because :code:`aggregate_evaluate` might decide that the results provided "
"are not sufficient for aggregation (e.g., too many failures)."
msgstr ""
":code:`aggregate_evaluate` 返回一个可选的 "
":code:`float`（损失值）和一个聚合指标字典。:code:`float` 返回值是可选的，"
"因为 :code:`aggregate_evaluate` "
"可能会认为所提供的结果不足以进行聚合（例如，失败次数过多）。"

#: ../../source/how-to-implement-strategies.rst:311
msgid "The :code:`evaluate` method"
msgstr ":code:`evaluate`方法"

#: ../../source/how-to-implement-strategies.rst:313
msgid ""
":code:`evaluate` is responsible for evaluating model parameters on the "
"server-side. Having :code:`evaluate` in addition to :code:"
"`configure_evaluate`/:code:`aggregate_evaluate` enables strategies to "
"perform both servers-side and client-side (federated) evaluation."
msgstr ""
":code:`evaluate` 负责在服务器端评估模型参数。除了 "
":code:`configure_evaluate`/:code:`aggregate_evaluate` 之外，:code:`evaluate` "
"可以使策略同时执行服务器端和客户端（联邦）评估。"

#: ../../source/how-to-implement-strategies.rst:323
msgid ""
"The return value is again optional because the strategy might not need to "
"implement server-side evaluation or because the user-defined :code:"
"`evaluate` method might not complete successfully (e.g., it might fail to "
"load the server-side evaluation data)."
msgstr ""
"返回值也是可选的，因为策略可能不需要执行服务器端评估，或者因为用户定义的 :"
"code:`evaluate` 方法可能无法成功完成（例如，它可能无法加载服务器端评估数"
"据）。"

#: ../../source/how-to-install-flower.rst:2
msgid "Install Flower"
msgstr "安装Flower"

#: ../../source/how-to-install-flower.rst:6
msgid "Python version"
msgstr "Python 版本"

#: ../../source/how-to-install-flower.rst:12
msgid "Install stable release"
msgstr "安装稳定版"

#: ../../source/how-to-install-flower.rst:14
msgid ""
"Stable releases are available on `PyPI <https://pypi.org/project/flwr/>`_::"
msgstr "稳定版本可在 `PyPI <https://pypi.org/project/flwr/>`_:："

#: ../../source/how-to-install-flower.rst:18
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` should be "
"installed with the ``simulation`` extra::"
msgstr "对于使用虚拟客户端引擎的模拟，`flwr`` 应与`simulation`` 一起安装："

#: ../../source/how-to-install-flower.rst:24
msgid "Verify installation"
msgstr "验证安装"

#: ../../source/how-to-install-flower.rst:26
msgid ""
"The following command can be used to verfiy if Flower was successfully "
"installed. If everything worked, it should print the version of Flower to "
"the command line::"
msgstr ""
"可以使用以下命令来验证 Flower 是否安装成功。如果一切正常，它将在命令行中打印 "
"Flower 的版本：："

#: ../../source/how-to-install-flower.rst:33
msgid "Advanced installation options"
msgstr "高级安装选项"

#: ../../source/how-to-install-flower.rst:36
msgid "Install pre-release"
msgstr "安装预发布版本"

#: ../../source/how-to-install-flower.rst:38
msgid ""
"New (possibly unstable) versions of Flower are sometimes available as pre-"
"release versions (alpha, beta, release candidate) before the stable release "
"happens::"
msgstr ""
"在稳定版发布之前，Flower 的新版本（可能是不稳定版）有时会作为预发布版本"
"（alpha、beta、候选发布版本）提供：："

#: ../../source/how-to-install-flower.rst:42
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` pre-releases "
"should be installed with the ``simulation`` extra::"
msgstr "对于使用虚拟客户端引擎的模拟，`flwr``预发行版应与`simulation``一起安装："

#: ../../source/how-to-install-flower.rst:47
msgid "Install nightly release"
msgstr "安装隔夜版本"

#: ../../source/how-to-install-flower.rst:49
msgid ""
"The latest (potentially unstable) changes in Flower are available as nightly "
"releases::"
msgstr "Flower 中最新（可能不稳定）的更改以隔夜发布的形式提供：："

#: ../../source/how-to-install-flower.rst:53
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr-nightly`` should "
"be installed with the ``simulation`` extra::"
msgstr "对于使用虚拟客户端引擎的模拟，`flwr-nightly`应与`simulation`一起安装："

#: ../../source/how-to-monitor-simulation.rst:2
msgid "Monitor simulation"
msgstr "监控模拟"

#: ../../source/how-to-monitor-simulation.rst:4
msgid ""
"Flower allows you to monitor system resources while running your simulation. "
"Moreover, the Flower simulation engine is powerful and enables you to decide "
"how to allocate resources per client manner and constrain the total usage. "
"Insights from resource consumption can help you make smarter decisions and "
"speed up the execution time."
msgstr ""
"Flower 允许您在运行模拟时监控系统资源。此外，Flower 仿真引擎功能强大，能让您"
"决定如何按客户端方式分配资源并限制总使用量。从资源消耗中获得的观察可以帮助您"
"做出更明智的决策，并加快执行时间。"

#: ../../source/how-to-monitor-simulation.rst:6
msgid ""
"The specific instructions assume you are using macOS and have the `Homebrew "
"<https://brew.sh/>`_ package manager installed."
msgstr ""
"具体说明假定你使用的是 macOS，并且安装了 `Homebrew <https://brew.sh/>`_ 软件"
"包管理器。"

#: ../../source/how-to-monitor-simulation.rst:10
msgid "Downloads"
msgstr "下载"

#: ../../source/how-to-monitor-simulation.rst:16
msgid ""
"`Prometheus <https://prometheus.io/>`_ is used for data collection, while "
"`Grafana <https://grafana.com/>`_ will enable you to visualize the collected "
"data. They are both well integrated with `Ray <https://www.ray.io/>`_ which "
"Flower uses under the hood."
msgstr ""
"`Prometheus <https://prometheus.io/>`_ 用于收集数据，而 `Grafana "
"<https://grafana.com/>`_ 则能让你将收集到的数据可视化。它们都与 Flower "
"在引擎下使用的 `Ray <https://www.ray.io/>`_ 紧密集成。"

#: ../../source/how-to-monitor-simulation.rst:18
msgid ""
"Overwrite the configuration files (depending on your device, it might be "
"installed on a different path)."
msgstr "重写配置文件（根据设备的不同，可能安装在不同的路径上）。"

#: ../../source/how-to-monitor-simulation.rst:20
msgid "If you are on an M1 Mac, it should be:"
msgstr "如果你使用的是 M1 Mac，应该是这样："

#: ../../source/how-to-monitor-simulation.rst:27
msgid "On the previous generation Intel Mac devices, it should be:"
msgstr "在上一代英特尔 Mac 设备上，应该是这样："

#: ../../source/how-to-monitor-simulation.rst:34
msgid ""
"Open the respective configuration files and change them. Depending on your "
"device, use one of the two following commands:"
msgstr "打开相应的配置文件并修改它们。根据设备情况，使用以下两个命令之一："

#: ../../source/how-to-monitor-simulation.rst:44
msgid ""
"and then delete all the text in the file and paste a new Prometheus config "
"you see below. You may adjust the time intervals to your requirements:"
msgstr ""
"然后删除文件中的所有文本，粘贴一个新的 Prometheus 配置文件，如下所示。您可以"
"根据需要调整时间间隔："

#: ../../source/how-to-monitor-simulation.rst:59
msgid ""
"Now after you have edited the Prometheus configuration, do the same with the "
"Grafana configuration files. Open those using one of the following commands "
"as before:"
msgstr ""
"编辑完 Prometheus 配置后，请对 Grafana 配置文件执行同样的操作。与之前一样，使"
"用以下命令之一打开这些文件："

#: ../../source/how-to-monitor-simulation.rst:69
msgid ""
"Your terminal editor should open and allow you to apply the following "
"configuration as before."
msgstr "您的终端编辑器应该会打开，并允许您像之前一样应用以下配置。"

#: ../../source/how-to-monitor-simulation.rst:84
msgid ""
"Congratulations, you just downloaded all the necessary software needed for "
"metrics tracking. Now, let’s start it."
msgstr "恭喜您，您刚刚下载了指标跟踪所需的所有软件。现在，让我们开始吧。"

#: ../../source/how-to-monitor-simulation.rst:88
msgid "Tracking metrics"
msgstr "跟踪指标"

#: ../../source/how-to-monitor-simulation.rst:90
msgid ""
"Before running your Flower simulation, you have to start the monitoring "
"tools you have just installed and configured."
msgstr "在运行 Flower 模拟之前，您必须启动刚刚安装和配置的监控工具。"

#: ../../source/how-to-monitor-simulation.rst:97
msgid ""
"Please include the following argument in your Python code when starting a "
"simulation."
msgstr "开始模拟时，请在 Python 代码中加入以下参数。"

#: ../../source/how-to-monitor-simulation.rst:108
msgid "Now, you are ready to start your workload."
msgstr "现在，您可以开始工作了。"

#: ../../source/how-to-monitor-simulation.rst:110
msgid ""
"Shortly after the simulation starts, you should see the following logs in "
"your terminal:"
msgstr "模拟启动后不久，您就会在终端中看到以下日志："

#: ../../source/how-to-monitor-simulation.rst:117
msgid "You can look at everything at `<http://127.0.0.1:8265>`_ ."
msgstr "您可以在 `<http://127.0.0.1:8265>`_ 查看所有内容。"

#: ../../source/how-to-monitor-simulation.rst:119
msgid ""
"It's a Ray Dashboard. You can navigate to Metrics (on the left panel, the "
"lowest option)."
msgstr ""
"这是一个 Ray Dashboard。您可以导航到 \"度量标准\"（左侧面板，最低选项）。"

#: ../../source/how-to-monitor-simulation.rst:121
msgid ""
"Or alternatively, you can just see them in Grafana by clicking on the right-"
"up corner, “View in Grafana”. Please note that the Ray dashboard is only "
"accessible during the simulation. After the simulation ends, you can only "
"use Grafana to explore the metrics. You can start Grafana by going to "
"``http://localhost:3000/``."
msgstr ""
"或者，您也可以点击右上角的 \"在 Grafana 中查看\"，在 Grafana 中查看它们。请注"
"意，Ray 仪表盘只能在模拟期间访问。模拟结束后，您只能使用 Grafana 浏览指标。您"
"可以访问 ``http://localhost:3000/``启动 Grafana。"

#: ../../source/how-to-monitor-simulation.rst:123
msgid ""
"After you finish the visualization, stop Prometheus and Grafana. This is "
"important as they will otherwise block, for example port :code:`3000` on "
"your machine as long as they are running."
msgstr ""
"完成可视化后，请停止 Prometheus 和 Grafana。这一点很重要，否则只要它们在运"
"行，就会阻塞机器上的端口 :code:`3000`。"

#: ../../source/how-to-monitor-simulation.rst:132
msgid "Resource allocation"
msgstr "资源分配"

#: ../../source/how-to-monitor-simulation.rst:134
msgid ""
"You must understand how the Ray library works to efficiently allocate system "
"resources to simulation clients on your own."
msgstr ""
"您必须了解 Ray 库是如何工作的，才能有效地为自己的仿真客户端分配系统资源。"

#: ../../source/how-to-monitor-simulation.rst:136
msgid ""
"Initially, the simulation (which Ray handles under the hood) starts by "
"default with all the available resources on the system, which it shares "
"among the clients. It doesn't mean it divides it equally among all of them, "
"nor that the model training happens at all of them simultaneously. You will "
"learn more about that in the later part of this blog. You can check the "
"system resources by running the following:"
msgstr ""
"最初，模拟（由 Ray 在引擎下处理）默认使用系统上的所有可用资源启动，并在客户端"
"之间共享。但这并不意味着它会将资源平均分配给所有客户端，也不意味着模型训练会"
"在所有客户端同时进行。您将在本博客的后半部分了解到更多相关信息。您可以运行以"
"下命令检查系统资源："

#: ../../source/how-to-monitor-simulation.rst:143
msgid "In Google Colab, the result you see might be similar to this:"
msgstr "在 Google Colab 中，您看到的结果可能与此类似："

#: ../../source/how-to-monitor-simulation.rst:155
msgid ""
"However, you can overwrite the defaults. When starting a simulation, do the "
"following (you don't need to overwrite all of them):"
msgstr "不过，您可以覆盖默认值。开始模拟时，请执行以下操作（不必全部覆盖）："

#: ../../source/how-to-monitor-simulation.rst:175
msgid "Let’s also specify the resource for a single client."
msgstr "我们还可以为单个客户指定资源。"

#: ../../source/how-to-monitor-simulation.rst:205
msgid ""
"Now comes the crucial part. Ray will start a new client only when it has all "
"the required resources (such that they run in parallel) when the resources "
"allow."
msgstr ""
"现在到了关键部分。只有在资源允许的情况下，Ray 才会在拥有所有所需资源（如并行"
"运行）时启动新客户端。"

#: ../../source/how-to-monitor-simulation.rst:207
msgid ""
"In the example above, only one client will be run, so your clients won't run "
"concurrently. Setting :code:`client_num_gpus = 0.5` would allow running two "
"clients and therefore enable them to run concurrently. Be careful not to "
"require more resources than available. If you specified :code:"
"`client_num_gpus = 2`, the simulation wouldn't start (even if you had 2 GPUs "
"but decided to set 1 in :code:`ray_init_args`)."
msgstr ""
"在上面的示例中，将只运行一个客户端，因此您的客户端不会并发运行。设置 :code:"
"`client_num_gpus = 0.5` 将允许运行两个客户端，从而使它们能够并发运行。请注"
"意，所需的资源不要超过可用资源。如果您指定 :code:`client_num_gpus = 2`，模拟"
"将无法启动（即使您有 2 个 GPU，但决定在 :code:`ray_init_args` 中设置为 1）。"

#: ../../source/how-to-monitor-simulation.rst:212 ../../source/ref-faq.rst:2
msgid "FAQ"
msgstr "常见问题"

#: ../../source/how-to-monitor-simulation.rst:214
msgid "Q: I don't see any metrics logged."
msgstr "问：我没有看到任何指标记录。"

#: ../../source/how-to-monitor-simulation.rst:216
msgid ""
"A: The timeframe might not be properly set. The setting is in the top right "
"corner (\"Last 30 minutes\" by default). Please change the timeframe to "
"reflect the period when the simulation was running."
msgstr ""
"答：时间范围可能没有正确设置。设置在右上角（默认为 \"最后 30 分钟\"）。请更改"
"时间框架，以反映模拟运行的时间段。"

#: ../../source/how-to-monitor-simulation.rst:218
msgid ""
"Q: I see “Grafana server not detected. Please make sure the Grafana server "
"is running and refresh this page” after going to the Metrics tab in Ray "
"Dashboard."
msgstr ""
"问：我看到 \"未检测到 Grafana 服务器。请确保 Grafana 服务器正在运行并刷新此页"
"面\"。"

#: ../../source/how-to-monitor-simulation.rst:220
msgid ""
"A: You probably don't have Grafana running. Please check the running services"
msgstr "答：您可能没有运行 Grafana。请检查正在运行的服务"

#: ../../source/how-to-monitor-simulation.rst:226
msgid ""
"Q: I see \"This site can't be reached\" when going to "
"`<http://127.0.0.1:8265>`_."
msgstr "问：在访问 `<http://127.0.0.1:8265>`_时，我看到 \"无法访问该网站\"。"

#: ../../source/how-to-monitor-simulation.rst:228
msgid ""
"A: Either the simulation has already finished, or you still need to start "
"Prometheus."
msgstr "答：要么模拟已经完成，要么您还需要启动Prometheus。"

#: ../../source/how-to-monitor-simulation.rst:232
msgid "Resources"
msgstr "资源"

#: ../../source/how-to-monitor-simulation.rst:234
msgid ""
"Ray Dashboard: `<https://docs.ray.io/en/latest/ray-core/ray-dashboard.html>`_"
msgstr "Ray 仪表盘: `<https://docs.ray.io/en/latest/ray-core/ray-dashboard.html>`_"

#: ../../source/how-to-monitor-simulation.rst:236
msgid ""
"Ray Metrics: `<https://docs.ray.io/en/latest/ray-observability/ray-metrics."
"html>`_"
msgstr ""
"Ray 指标: `<https://docs.ray.io/en/latest/ray-observability/ray-metrics."
"html>`_"

#: ../../source/how-to-run-simulations.rst:2
msgid "Run simulations"
msgstr "运行模拟"

#: ../../source/how-to-run-simulations.rst:8
msgid ""
"Simulating Federated Learning workloads is useful for a multitude of use-"
"cases: you might want to run your workload on a large cohort of clients but "
"without having to source, configure and mange a large number of physical "
"devices; you might want to run your FL workloads as fast as possible on the "
"compute systems you have access to without having to go through a complex "
"setup process; you might want to validate your algorithm on different "
"scenarios at varying levels of data and system heterogeneity, client "
"availability, privacy budgets, etc. These are among some of the use-cases "
"where simulating FL workloads makes sense. Flower can accommodate these "
"scenarios by means of its `VirtualClientEngine <contributor-explanation-"
"architecture.html#virtual-client-engine>`_ or VCE."
msgstr ""
"模拟联邦学习工作负载可用于多种案例：您可能希望在大量客户端上运行您的工作负载"
"，但无需采购、配置和管理大量物理设备；"
"您可能希望在您可以访问的计算系统上尽可能快地运行您的 FL 工作负载，而无需经过"
"复杂的设置过程；您可能希望在不同数据和系统异构性、客户端可用性、隐私预算等不"
"同水平的场景中验证您的算法。这些都是模拟 FL 工作负载的一些案例。Flower "
"可以通过其 \"虚拟客户端引擎\"（VirtualClientEngine）<contributor-explanation-"
"architecture.html#virtual-client-engine>_或 VCE 来匹配这些情况。"

#: ../../source/how-to-run-simulations.rst:10
msgid ""
"The :code:`VirtualClientEngine` schedules, launches and manages `virtual` "
"clients. These clients are identical to `non-virtual` clients (i.e. the ones "
"you launch via the command `flwr.client.start_client <ref-api-flwr."
"html#start-client>`_) in the sense that they can be configure by creating a "
"class inheriting, for example, from `flwr.client.NumPyClient <ref-api-flwr."
"html#flwr.client.NumPyClient>`_ and therefore behave in an identical way. In "
"addition to that, clients managed by the :code:`VirtualClientEngine` are:"
msgstr ""
":code:`VirtualClientEngine`用来规划，启动和管理`虚拟`客户端。这些客户端跟`非"
"虚拟`客户端是一样的（即为您通过`flwr.client.start_client <ref-api-flwr.html"
"#start-client>`_启动的客户端），因为它们可以通过创建一个继承自 `"
"flwr.client.NumPyClient <ref-api-flwr.html#flwr.client.NumPyClient>`_ "
"的类进行配置，因此其行为方式相同。另外，由 `VirtualClientEngine` "
"管理的客户端有："

#: ../../source/how-to-run-simulations.rst:12
msgid ""
"resource-aware: this means that each client gets assigned a portion of the "
"compute and memory on your system. You as a user can control this at the "
"beginning of the simulation and allows you to control the degree of "
"parallelism of your Flower FL simulation. The fewer the resources per "
"client, the more clients can run concurrently on the same hardware."
msgstr ""
"资源感知：这意味着每个客户端都会分配到系统中的一部分计算和内存。作为用户，您"
"可以在模拟开始时对其进行控制，从而控制 Flower FL 模拟的并行程度。每个客户端的"
"资源越少，在同一硬件上并发运行的客户端就越多。"

#: ../../source/how-to-run-simulations.rst:13
msgid ""
"self-managed: this means that you as a user do not need to launch clients "
"manually, instead this gets delegated to :code:`VirtualClientEngine`'s "
"internals."
msgstr "自管理：这意味着用户无需手动启动客户端，而是由 :code:`VirtualClientEngine` "
"负责。"

#: ../../source/how-to-run-simulations.rst:14
msgid ""
"ephemeral: this means that a client is only materialized when it is required "
"in the FL process (e.g. to do `fit() <ref-api-flwr.html#flwr.client.Client."
"fit>`_). The object is destroyed afterwards, releasing the resources it was "
"assigned and allowing in this way other clients to participate."
msgstr ""
"即时性：这意味着客户端只有在 FL 进程中需要它时才会被实体化（例如执行 `fit() "
"<ref-api-flwr.html#flwr.client.Client.fit>`_ "
"）。之后该对象将被销毁，释放分配给它的资源，并允许其他客户端以这种方式参与。"

#: ../../source/how-to-run-simulations.rst:16
msgid ""
"The :code:`VirtualClientEngine` implements `virtual` clients using `Ray "
"<https://www.ray.io/>`_, an open-source framework for scalable Python "
"workloads. In particular, Flower's :code:`VirtualClientEngine` makes use of "
"`Actors <https://docs.ray.io/en/latest/ray-core/actors.html>`_ to spawn "
"`virtual` clients and run their workload."
msgstr ""
":code:`VirtualClientEngine`使用`Ray <https://www.ray.io/"
">`_来实现`虚拟`客户端，这是一个用于可扩展 Python 工作负载的开源框架。特别地，"
"Flower 的 :code:`VirtualClientEngine` 使用 `Actors <https://docs.ray.io/en/"
"latest/ray-core/actors.html>`_ 来生成 `virtual` 客户端并运行它们的工作负载。"

#: ../../source/how-to-run-simulations.rst:20
msgid "Launch your Flower simulation"
msgstr "启动 Flower 模拟"

#: ../../source/how-to-run-simulations.rst:22
msgid ""
"Running Flower simulations still require you to define your client class, a "
"strategy, and utility functions to download and load (and potentially "
"partition) your dataset. With that out of the way, launching your simulation "
"is done with `start_simulation <ref-api-flwr.html#flwr.simulation."
"start_simulation>`_ and a minimal example looks as follows:"
msgstr ""
"运行 Flower 模拟器仍然需要定义客户端类、策略以及下载和加载（可能还需要分割）"
"数据集的实用程序。在完成这些工作后，就可以使用 \"start_simulation <ref-api-"
"flwr.html#flwr.simulation.start_simulation>`_\" "
"来启动模拟了，一个最简单的示例如下："

#: ../../source/how-to-run-simulations.rst:44
msgid "VirtualClientEngine resources"
msgstr "虚拟客户端引擎资源"

#: ../../source/how-to-run-simulations.rst:45
msgid ""
"By default the VCE has access to all system resources (i.e. all CPUs, all "
"GPUs, etc) since that is also the default behavior when starting Ray. "
"However, in some settings you might want to limit how many of your system "
"resources are used for simulation. You can do this via the :code:"
"`ray_init_args` input argument to :code:`start_simulation` which the VCE "
"internally passes to Ray's :code:`ray.init` command. For a complete list of "
"settings you can configure check the `ray.init <https://docs.ray.io/en/"
"latest/ray-core/api/doc/ray.init.html#ray-init>`_ documentation. Do not set :"
"code:`ray_init_args` if you want the VCE to use all your system's CPUs and "
"GPUs."
msgstr ""
"默认情况下，VCE 可以访问所有系统资源（即所有 CPU、所有 GPU 等），"
"因为这也是启动 Ray "
"时的默认行为。不过，在某些设置中，您可能希望限制有多少系统资源用于模拟。"
"您可以通过 :code:`ray_init_args` 输入到 :code:`start_simulation` "
"的参数来做到这一点，VCE 会在内部将该参数传递给 Ray 的 :code:`ray.init` "
"命令。有关您可以配置的设置的完整列表，请查看 `ray.init <https://docs.ray.io/"
"en/latest/ray-core/api/doc/ray.init.html#ray-init>`_ 文档。如果希望 VCE "
"使用系统中所有的 CPU 和 GPU，请不要设置 :code:`ray_init_args`。"

#: ../../source/how-to-run-simulations.rst:62
msgid "Assigning client resources"
msgstr "分配客户端资源"

#: ../../source/how-to-run-simulations.rst:63
msgid ""
"By default the :code:`VirtualClientEngine` assigns a single CPU core (and "
"nothing else) to each virtual client. This means that if your system has 10 "
"cores, that many virtual clients can be concurrently running."
msgstr ""
"默认情况下，:code:`VirtualClientEngine` 会为每个虚拟客户端分配一个 CPU 内核"
"（不分配其他任何内核）。这意味着，如果系统有 10 个内核，那么可以同时运行这么"
"多虚拟客户端。"

#: ../../source/how-to-run-simulations.rst:65
msgid ""
"More often than not, you would probably like to adjust the resources your "
"clients get assigned based on the complexity (i.e. compute and memory "
"footprint) of your FL workload. You can do so when starting your simulation "
"by setting the argument `client_resources` to `start_simulation <ref-api-"
"flwr.html#flwr.simulation.start_simulation>`_. Two keys are internally used "
"by Ray to schedule and spawn workloads (in our case Flower clients):"
msgstr ""
"通常情况下，您可能希望根据 FL "
"工作负载的复杂性（即计算和内存占用）来调整分配给客户端的资源。"
"您可以在启动模拟时将参数 `client_resources` 设置为 `start_simulation <ref-"
"api-flwr.html#flwr.simulation.start_simulation>`_ 。Ray "
"内部使用两个键来调度和生成工作负载（在我们的例子中是 Flower 客户端）："

#: ../../source/how-to-run-simulations.rst:67
msgid ":code:`num_cpus` indicates the number of CPU cores a client would get."
msgstr ":code:`num_cpus` 表示客户端将获得的 CPU 内核数量。"

#: ../../source/how-to-run-simulations.rst:68
msgid ""
":code:`num_gpus` indicates the **ratio** of GPU memory a client gets "
"assigned."
msgstr ":code:`num_gpus` 表示分配给客户端的 GPU 内存的**比例**。"

#: ../../source/how-to-run-simulations.rst:70
msgid "Let's see a few examples:"
msgstr "让我们来看几个例子："

#: ../../source/how-to-run-simulations.rst:89
msgid ""
"While the :code:`client_resources` can be used to control the degree of "
"concurrency in your FL simulation, this does not stop you from running "
"dozens, hundreds or even thousands of clients in the same round and having "
"orders of magnitude more `dormant` (i.e. not participating in a round) "
"clients. Let's say you want to have 100 clients per round but your system "
"can only accommodate 8 clients concurrently. The :code:`VirtualClientEngine` "
"will schedule 100 jobs to run (each simulating a client sampled by the "
"strategy) and then will execute them in a resource-aware manner in batches "
"of 8."
msgstr ""
"虽然 :code:`client_resources` 可用来控制 FL 模拟的并发程度，但这并不能阻止您"
"在同一轮模拟中运行几十、几百甚至上千个客户端，并拥有数量级更多的 \"休眠\""
"（即不参与一轮模拟）客户端。比方说，您希望每轮有 100 个客户端，"
"但您的系统只能同时容纳 8 个客户端。:code:`VirtualClientEngine` 将安排运行 "
"100 "
"个工作（每个工作模拟策略采样的一个客户端），然后以资源感知的方式分批执行。"

#: ../../source/how-to-run-simulations.rst:91
msgid ""
"To understand all the intricate details on how resources are used to "
"schedule FL clients and how to define custom resources, please take a look "
"at the `Ray documentation <https://docs.ray.io/en/latest/ray-core/scheduling/"
"resources.html>`_."
msgstr ""
"要了解资源如何用于调度 FL 客户端以及如何定义自定义资源的所有复杂细节，请查看 "
"`Ray 文档 <https://docs.ray.io/en/latest/ray-core/scheduling/resources."
"html>`_。"

#: ../../source/how-to-run-simulations.rst:94
msgid "Simulation examples"
msgstr "模拟示例"

#: ../../source/how-to-run-simulations.rst:96
msgid ""
"A few ready-to-run complete examples for Flower simulation in Tensorflow/"
"Keras and PyTorch are provided in the `Flower repository <https://github.com/"
"adap/flower>`_. You can run them on Google Colab too:"
msgstr ""
"在 Tensorflow/Keras 和 PyTorch 中进行 Flower "
"模拟的几个可随时运行的完整示例已在 `Flower 库 <https://github.com/adap/"
"flower>`_ 中提供。您也可以在 Google Colab 上运行它们："

#: ../../source/how-to-run-simulations.rst:98
msgid ""
"`Tensorflow/Keras Simulation <https://github.com/adap/flower/tree/main/"
"examples/simulation-tensorflow>`_: 100 clients collaboratively train a MLP "
"model on MNIST."
msgstr ""
"Tensorflow/Keras模拟 <https://github.com/adap/flower/tree/main/examples/"
"simulation-tensorflow>`_：100个客户端在MNIST上协作训练一个MLP模型。"

#: ../../source/how-to-run-simulations.rst:99
msgid ""
"`PyTorch Simulation <https://github.com/adap/flower/tree/main/examples/"
"simulation-pytorch>`_: 100 clients collaboratively train a CNN model on "
"MNIST."
msgstr ""
"PyTorch 模拟 <https://github.com/adap/flower/tree/main/examples/simulation-"
"pytorch>`_：100 个客户端在 MNIST 上协作训练一个 CNN 模型。"

#: ../../source/how-to-run-simulations.rst:104
msgid "Multi-node Flower simulations"
msgstr "多节点 Flower 模拟"

#: ../../source/how-to-run-simulations.rst:106
msgid ""
"Flower's :code:`VirtualClientEngine` allows you to run FL simulations across "
"multiple compute nodes. Before starting your multi-node simulation ensure "
"that you:"
msgstr ""
"Flower 的 :code:`VirtualClientEngine` 允许您在多个计算节点上运行 FL "
"模拟。在开始多节点模拟之前，请确保："

#: ../../source/how-to-run-simulations.rst:108
msgid "Have the same Python environment in all nodes."
msgstr "所有节点都有相同的 Python 环境。"

#: ../../source/how-to-run-simulations.rst:109
msgid "Have a copy of your code (e.g. your entire repo) in all nodes."
msgstr "在所有节点上都有一份代码副本（例如整个软件包）。"

#: ../../source/how-to-run-simulations.rst:110
msgid ""
"Have a copy of your dataset in all nodes (more about this in :ref:"
"`simulation considerations <considerations-for-simulations>`)"
msgstr ""
"在所有节点中都有一份数据集副本（更多相关信息请参阅 :ref:`模拟注意事项"
"<considerations-for-simulations>`）"

#: ../../source/how-to-run-simulations.rst:111
msgid ""
"Pass :code:`ray_init_args={\"address\"=\"auto\"}` to `start_simulation <ref-"
"api-flwr.html#flwr.simulation.start_simulation>`_ so the :code:"
"`VirtualClientEngine` attaches to a running Ray instance."
msgstr ""
"将 :code:`ray_init_args={\"address\"=\"auto\"}`传递给 `start_simulation <ref-"
"api-flwr.html#flwr.simulation.start_simulation>`_ ，这样 :code:"
"`VirtualClientEngine`就会连接到正在运行的 Ray 实例。"

#: ../../source/how-to-run-simulations.rst:112
msgid ""
"Start Ray on you head node: on the terminal type :code:`ray start --head`. "
"This command will print a few lines, one of which indicates how to attach "
"other nodes to the head node."
msgstr ""
"在头部节点上启动 Ray：在终端上输入 :code:`raystart--"
"head`。该命令将打印几行输出，其中一行说明如何将其他节点连接到头部节点。"

#: ../../source/how-to-run-simulations.rst:113
msgid ""
"Attach other nodes to the head node: copy the command shown after starting "
"the head and execute it on terminal of a new node: for example :code:`ray "
"start --address='192.168.1.132:6379'`"
msgstr ""
"将其他节点附加到头部节点：复制启动头部后显示的命令，并在新节点的终端上执行："
"例如 :code:`ray start --address='192.168.1.132:6379'`"

#: ../../source/how-to-run-simulations.rst:115
msgid ""
"With all the above done, you can run your code from the head node as you "
"would if the simulation was running on a single node."
msgstr ""
"完成上述所有操作后，您就可以在头部节点上运行代码了，就像在单个节点上运行模拟"
"一样。"

#: ../../source/how-to-run-simulations.rst:117
msgid ""
"Once your simulation is finished, if you'd like to dismantle your cluster "
"you simply need to run the command :code:`ray stop` in each node's terminal "
"(including the head node)."
msgstr ""
"模拟结束后，如果要拆除集群，只需在每个节点（包括头部节点）的终端运行 :code:"
"`ray stop` 命令即可。"

#: ../../source/how-to-run-simulations.rst:120
msgid "Multi-node simulation good-to-know"
msgstr "了解多节点模拟"

#: ../../source/how-to-run-simulations.rst:122
msgid ""
"Here we list a few interesting functionality when running multi-node FL "
"simulations:"
msgstr "在此，我们列举了运行多节点 FL 模拟时的一些有趣功能："

#: ../../source/how-to-run-simulations.rst:124
msgid ""
"User :code:`ray status` to check all nodes connected to your head node as "
"well as the total resources available to the :code:`VirtualClientEngine`."
msgstr ""
"使用 :code:`ray status` 查看连接到头部节点的所有节点，以及 :code:"
"`VirtualClientEngine` 可用的总资源。"

#: ../../source/how-to-run-simulations.rst:126
msgid ""
"When attaching a new node to the head, all its resources (i.e. all CPUs, all "
"GPUs) will be visible by the head node. This means that the :code:"
"`VirtualClientEngine` can schedule as many `virtual` clients as that node "
"can possible run. In some settings you might want to exclude certain "
"resources from the simulation. You can do this by appending `--num-"
"cpus=<NUM_CPUS_FROM_NODE>` and/or `--num-gpus=<NUM_GPUS_FROM_NODE>` in any :"
"code:`ray start` command (including when starting the head)"
msgstr ""
"将新节点附加到头部节点时，头部节点将可见其所有资源（即所有 CPU 和 GPU）。这意"
"味着 :code:`VirtualClientEngine` 可以调度尽可能多的 \"虚拟 \"客户端来运行该节"
"点。在某些设置中，您可能希望将某些资源排除在模拟之外。为此，您可以在任何 :"
"code:`ray start` 命令（包括启动头部时）中添加 `--num-"
"cpus=<NUM_CPUS_FROM_NODE>`和/或 `--num-gpus=<NUM_GPUS_FROM_NODE>`"

#: ../../source/how-to-run-simulations.rst:132
msgid "Considerations for simulations"
msgstr "模拟的注意事项"

#: ../../source/how-to-run-simulations.rst:135
msgid ""
"We are actively working on these fronts so to make it trivial to run any FL "
"workload with Flower simulation."
msgstr "我们正在积极开展这些方面的工作，以便使 FL 工作负载与 Flower "
"模拟的运行变得轻而易举。"

#: ../../source/how-to-run-simulations.rst:138
msgid ""
"The current VCE allows you to run Federated Learning workloads in simulation "
"mode whether you are prototyping simple scenarios on your personal laptop or "
"you want to train a complex FL pipeline across multiple high-performance GPU "
"nodes. While we add more capabilities to the VCE, the points below highlight "
"some of the considerations to keep in mind when designing your FL pipeline "
"with Flower. We also highlight a couple of current limitations in our "
"implementation."
msgstr ""
"当前的 VCE 允许您在模拟模式下运行联邦学习工作负载，无论您是在个人笔记本电脑上"
"建立简单的场景原型，还是要在多个高性能 GPU 节点上训练复杂的 FL情景。"
"虽然我们为 VCE 增加了更多的功能，但以下几点强调了在使用 Flower 设计 FL "
"时需要注意的一些事项。我们还强调了我们的实现中目前存在的一些局限性。"

#: ../../source/how-to-run-simulations.rst:141
msgid "GPU resources"
msgstr "GPU 资源"

#: ../../source/how-to-run-simulations.rst:143
msgid ""
"The VCE assigns a share of GPU memory to a client that specifies the key :"
"code:`num_gpus` in :code:`client_resources`. This being said, Ray (used "
"internally by the VCE) is by default:"
msgstr ""
"VCE 会为指定 :code:`client_resources` 中 :code:`num_gpus` 关键字的客户端分配 "
"GPU 内存份额。也就是说，Ray（VCE 内部使用）是默认的："

#: ../../source/how-to-run-simulations.rst:146
msgid ""
"not aware of the total VRAM available on the GPUs. This means that if you "
"set :code:`num_gpus=0.5` and you have two GPUs in your system with different "
"(e.g. 32GB and 8GB) VRAM amounts, they both would run 2 clients concurrently."
msgstr ""
"不知道 GPU 上可用的总 VRAM。这意味着，如果您设置 :code:`num_gpus=0.5`，而系统"
"中有两个不同（如 32GB 和 8GB）VRAM 的 GPU，它们都将同时运行 2 个客户端。"

#: ../../source/how-to-run-simulations.rst:147
msgid ""
"not aware of other unrelated (i.e. not created by the VCE) workloads are "
"running on the GPU. Two takeaways from this are:"
msgstr ""
"不知道 GPU 上正在运行其他无关（即不是由 VCE 创建）的工作负载。从中可以得到以"
"下两点启示："

#: ../../source/how-to-run-simulations.rst:149
msgid ""
"Your Flower server might need a GPU to evaluate the `global model` after "
"aggregation (by instance when making use of the `evaluate method <how-to-"
"implement-strategies.html#the-evaluate-method>`_)"
msgstr ""
"您的 Flower 服务器可能需要 GPU 来评估聚合后的 \"全局模型\"（例如在使用 \"评估"
"方法\"<how-to-implement-strategies.html#the-evaluate-method>`_时）"

#: ../../source/how-to-run-simulations.rst:150
msgid ""
"If you want to run several independent Flower simulations on the same "
"machine you need to mask-out your GPUs with :code:"
"`CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"` when launching your experiment."
msgstr ""
"如果您想在同一台机器上运行多个独立的 Flower 模拟，则需要在启动实验时使用 "
":code:`CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"` 屏蔽 GPU。"

#: ../../source/how-to-run-simulations.rst:153
msgid ""
"In addition, the GPU resource limits passed to :code:`client_resources` are "
"not `enforced` (i.e. they can be exceeded) which can result in the situation "
"of client using more VRAM than the ratio specified when starting the "
"simulation."
msgstr ""
"此外，传递给 :code:`client_resources` 的 GPU 资源限制并不是 \"强制 \"的（即可"
"以超出），这可能导致客户端使用的 VRAM 超过启动模拟时指定的比例。"

#: ../../source/how-to-run-simulations.rst:156
msgid "TensorFlow with GPUs"
msgstr "使用 GPU 的 TensorFlow"

#: ../../source/how-to-run-simulations.rst:158
msgid ""
"When `using a GPU with TensorFlow <https://www.tensorflow.org/guide/gpu>`_ "
"nearly your entire GPU memory of all your GPUs visible to the process will "
"be mapped. This is done by TensorFlow for optimization purposes. However, in "
"settings such as FL simulations where we want to split the GPU into multiple "
"`virtual` clients, this is not a desirable mechanism. Luckily we can disable "
"this default behavior by `enabling memory growth <https://www.tensorflow.org/"
"guide/gpu#limiting_gpu_memory_growth>`_."
msgstr ""
"在 TensorFlow <https://www.tensorflow.org/guide/gpu>`_ 中使用 GPU 时，"
"几乎所有进程可见的 GPU 内存都将被映射。TensorFlow "
"这样做是出于优化目的。然而，在 FL 模拟等设置中，我们希望将 GPU 分割成多个 "
"\"虚拟 \"客户端，这并不是一个理想的机制。幸运的是，我们可以通过 `"
"启用内存增长 <https://www.tensorflow.org/guide/"
"gpu#limiting_gpu_memory_growth>`_来禁用这一默认行为。"

#: ../../source/how-to-run-simulations.rst:160
msgid ""
"This would need to be done in the main process (which is where the server "
"would run) and in each Actor created by the VCE. By means of :code:"
"`actor_kwargs` we can pass the reserved key `\"on_actor_init_fn\"` in order "
"to specify a function to be executed upon actor initialization. In this "
"case, to enable GPU growth for TF workloads. It would look as follows:"
msgstr ""
"这需要在主进程（也就是服务器运行的地方）和 VCE 创建的每个角色中完成。通过 "
":code:`actor_kwargs`，我们可以传递保留关键字`\"on_actor_init_fn\""
"`，以指定在角色初始化时执行的函数。在本例中，为了使 TF 工作负载的 GPU "
"增长，它看起来如下："

#: ../../source/how-to-run-simulations.rst:179
msgid ""
"This is precisely the mechanism used in `Tensorflow/Keras Simulation "
"<https://github.com/adap/flower/tree/main/examples/simulation-tensorflow>`_ "
"example."
msgstr ""
"这正是 \"Tensorflow/Keras 模拟 <https://github.com/adap/flower/tree/main/"
"examples/simulation-tensorflow>`_\"示例中使用的机制。"

#: ../../source/how-to-run-simulations.rst:183
msgid "Multi-node setups"
msgstr "多节点设置"

#: ../../source/how-to-run-simulations.rst:185
msgid ""
"The VCE does not currently offer a way to control on which node a particular "
"`virtual` client is executed. In other words, if more than a single node "
"have the resources needed by a client to run, then any of those nodes could "
"get the client workload scheduled onto. Later in the FL process (i.e. in a "
"different round) the same client could be executed by a different node. "
"Depending on how your clients access their datasets, this might require "
"either having a copy of all dataset partitions on all nodes or a dataset "
"serving mechanism (e.g. using nfs, a database) to circumvent data "
"duplication."
msgstr ""
"VCE 目前不提供控制特定 \"虚拟 \"客户端在哪个节点上执行的方法。换句话说，如果"
"不止一个节点拥有客户端运行所需的资源，那么这些节点中的任何一个都可能被调度到"
"客户端工作负载上。在 FL 进程的稍后阶段（即在另一轮中），同一客户端可以由不同"
"的节点执行。根据客户访问数据集的方式，这可能需要在所有节点上复制所有数据集分"
"区，或采用数据集服务机制（如使用 nfs 或数据库）来避免数据重复。"

#: ../../source/how-to-run-simulations.rst:187
msgid ""
"By definition virtual clients are `stateless` due to their ephemeral nature. "
"A client state can be implemented as part of the Flower client class but "
"users need to ensure this saved to persistent storage (e.g. a database, "
"disk) and that can be retrieve later by the same client regardless on which "
"node it is running from. This is related to the point above also since, in "
"some way, the client's dataset could be seen as a type of `state`."
msgstr ""
"根据定义，虚拟客户端是 \"无状态 \"的，因为它们具有即时性。客户机状态可以作为 "
"Flower 客户机类的一部分来实现，但用户需要确保将其保存到持久存储（如数据库、磁"
"盘）中，而且无论客户机在哪个节点上运行，都能在以后检索到。这也与上述观点有关"
"，因为在某种程度上，客户端的数据集可以被视为一种 \"状态\"。"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:2
msgid "Save and load model checkpoints"
msgstr "保存和加载模型检查点"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:4
msgid ""
"Flower does not automatically save model updates on the server-side. This "
"how-to guide describes the steps to save (and load) model checkpoints in "
"Flower."
msgstr ""
"Flower 不会在服务器端自动保存模型更新。本指南将介绍在 Flower 中保存（和加载）"
"模型检查点的步骤。"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:8
msgid "Model checkpointing"
msgstr "模型检查点"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:10
msgid ""
"Model updates can be persisted on the server-side by customizing :code:"
"`Strategy` methods. Implementing custom strategies is always an option, but "
"for many cases it may be more convenient to simply customize an existing "
"strategy. The following code example defines a new :code:`SaveModelStrategy` "
"which customized the existing built-in :code:`FedAvg` strategy. In "
"particular, it customizes :code:`aggregate_fit` by calling :code:"
"`aggregate_fit` in the base class (:code:`FedAvg`). It then continues to "
"save returned (aggregated) weights before it returns those aggregated "
"weights to the caller (i.e., the server):"
msgstr ""
"模型更新可通过自定义 :code:`Strategy` 方法在服务器端持久化。实现自定义策略始"
"终是一种选择，但在许多情况下，简单地自定义现有策略可能更方便。"
"下面的代码示例定义了一个新的 :code:`SaveModelStrategy`，它自定义了现有的内置 "
":code:`FedAvg` 策略。特别是，它通过调用基类（:code:`FedAvg`）中的 "
":code:`aggregate_fit` 来定制 :code:`aggregate_fit`。然后继续保存返回的（聚合"
"）参数，然后再将这些聚合参数返回给调用者（即服务器）："

#: ../../source/how-to-save-and-load-model-checkpoints.rst:47
msgid "Save and load PyTorch checkpoints"
msgstr "保存和加载 PyTorch 检查点"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:49
msgid ""
"Similar to the previous example but with a few extra steps, we'll show how "
"to store a PyTorch checkpoint we'll use the ``torch.save`` function. "
"Firstly, ``aggregate_fit`` returns a ``Parameters`` object that has to be "
"transformed into a list of NumPy ``ndarray``'s, then those are transformed "
"into the PyTorch ``state_dict`` following the ``OrderedDict`` class "
"structure."
msgstr ""
"与前面的例子类似，但多了几个步骤，我们将展示如何存储一个 PyTorch 检查点，我们"
"将使用 ``torch.save`` 函数。首先，``aggregate_fit`` 返回一个 ``Parameters`` "
"对象，它必须被转换成一个 NumPy ``ndarray`` 的列表，然后这些对象按照 "
"``OrderedDict`` 类结构被转换成 PyTorch `state_dict` 对象。"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:85
msgid ""
"To load your progress, you simply append the following lines to your code. "
"Note that this will iterate over all saved checkpoints and load the latest "
"one:"
msgstr ""
"要加载进度，只需在代码中添加以下几行。请注意，这将遍历所有已保存的检查点，并"
"加载最新的检查点："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:2
msgid "Upgrade to Flower 1.0"
msgstr "升级至 Flower 1.0"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:4
msgid ""
"Flower 1.0 is here. Along with new features, Flower 1.0 provides a stable "
"foundation for future growth. Compared to Flower 0.19 (and other 0.x series "
"releases), there are a few breaking changes that make it necessary to change "
"the code of existing 0.x-series projects."
msgstr ""
"Flower 1.0 正式发布。除了新功能，Flower 1.0 还为未来的发展奠定了稳定的基础。"
"与 Flower 0.19（以及其他 0.x 系列版本）相比，有一些破坏性改动需要修改现有 0."
"x 系列项目的代码。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:8
msgid "Install update"
msgstr "安装更新"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:10
msgid ""
"Here's how to update an existing installation to Flower 1.0 using either pip "
"or Poetry:"
msgstr "下面介绍如何使用 pip 或 Poetry 将现有安装更新到 Flower 1.0："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:12
msgid "pip: add ``-U`` when installing."
msgstr "pip: 安装时添加 ``-U``."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:14
msgid ""
"``python -m pip install -U flwr`` (when using ``start_server`` and "
"``start_client``)"
msgstr ""
"`python -m pip install -U flwr``（当使用`start_server`和`start_client`时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:15
msgid ""
"``python -m pip install -U flwr[simulation]`` (when using "
"``start_simulation``)"
msgstr ""
"`python -m pip install -U flwr[simulation]``（当使用`start_simulation``时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:17
msgid ""
"Poetry: update the ``flwr`` dependency in ``pyproject.toml`` and then "
"reinstall (don't forget to delete ``poetry.lock`` via ``rm poetry.lock`` "
"before running ``poetry install``)."
msgstr ""
"Poetry：更新 ``pyproject.toml`` 中的 ``flwr`` 依赖包，然后重新安装（运行 ``"
"poetry install`` 前，别忘了通过 ``rm poetry.lock` 删除 ``poetry.lock`）。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:19
msgid ""
"``flwr = \"^1.0.0\"`` (when using ``start_server`` and ``start_client``)"
msgstr "``flwr = \"^1.0.0\"`` （当使用 ``start_server` 和 ``start_client` 时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:20
msgid ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] }`` (when using "
"``start_simulation``)"
msgstr ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] }``（当使用"
"``start_simulation``时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:24
msgid "Required changes"
msgstr "所需变更"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:26
msgid "The following breaking changes require manual updates."
msgstr "以下更改需要手动更新。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:29
msgid "General"
msgstr "一般情况"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:31
msgid ""
"Pass all arguments as keyword arguments (not as positional arguments). "
"Here's an example:"
msgstr "将所有参数作为关键字参数传递（而不是位置参数）。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:33
msgid ""
"Flower 0.19 (positional arguments): ``start_client(\"127.0.0.1:8080\", "
"FlowerClient())``"
msgstr ""
"Flower 0.19 (位置参数)： ``start_client(\"127.0.0.1:8080\", FlowerClient())``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:34
msgid ""
"Flower 1.0 (keyword arguments): "
"``start_client(server_address=\"127.0.0.1:8080\", client=FlowerClient())``"
msgstr ""
"Flower 1.0（关键字参数）： ``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:39
msgid ""
"Subclasses of ``NumPyClient``: change ``def get_parameters(self):``` to "
"``def get_parameters(self, config):``"
msgstr ""
"NumPyClient的子类：将``def get_parameters(self):```改为``def "
"get_parameters(self,config):``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:40
msgid ""
"Subclasses of ``Client``: change ``def get_parameters(self):``` to ``def "
"get_parameters(self, ins: GetParametersIns):``"
msgstr ""
"客户端 \"的子类：将 \"get_parameters(self): \"改为 \"get_parameters(self, "
"ins: GetParametersIns):\""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:43
msgid "Strategies / ``start_server`` / ``start_simulation``"
msgstr "策略 / ``start_server`` / ``start_simulation``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:45
msgid ""
"Pass ``ServerConfig`` (instead of a dictionary) to ``start_server`` and "
"``start_simulation``. Here's an example:"
msgstr ""
"向 ``start_server`` 和 ``start_simulation` 传递 ``ServerConfig``（而不是 "
"dictionary）。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:47
msgid ""
"Flower 0.19: ``start_server(..., config={\"num_rounds\": 3, "
"\"round_timeout\": 600.0}, ...)``"
msgstr ""
"Flower 0.19: ``start_server(..., config={\"num_rounds\": 3, "
"\"round_timeout\": 600.0}, ...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:48
msgid ""
"Flower 1.0: ``start_server(..., config=flwr.server."
"ServerConfig(num_rounds=3, round_timeout=600.0), ...)``"
msgstr ""
"Flower 1.0: ``start_server(..., config=flwr.server.ServerConfig("
"num_rounds=3, round_timeout=600.0), ...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:50
msgid ""
"Replace ``num_rounds=1`` in ``start_simulation`` with the new "
"``config=ServerConfig(...)`` (see previous item)"
msgstr ""
"将`start_simulation``中的`num_rounds=1``替换为新的`config=ServerConfig(...)`"
"（参见前一项）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:51
msgid ""
"Remove ``force_final_distributed_eval`` parameter from calls to "
"``start_server``. Distributed evaluation on all clients can be enabled by "
"configuring the strategy to sample all clients for evaluation after the last "
"round of training."
msgstr ""
"删除调用 ``start_server`` 时的 ``force_final_distributed_eval` 参数。可以通过"
"配置策略，在最后一轮训练后对所有客户端进行抽样评估，从而启用对所有客户端的分"
"布式评估。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:52
msgid "Rename parameter/ndarray conversion functions:"
msgstr "重命名参数/数组转换函数："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:54
msgid "``parameters_to_weights`` --> ``parameters_to_ndarrays``"
msgstr "``parameters_to_weights`` --> ``parameters_to_ndarrays``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:55
msgid "``weights_to_parameters`` --> ``ndarrays_to_parameters``"
msgstr "``weights_to_parameters`` --> ``ndarrays_to_parameters``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:57
msgid ""
"Strategy initialization: if the strategy relies on the default values for "
"``fraction_fit`` and ``fraction_evaluate``, set ``fraction_fit`` and "
"``fraction_evaluate`` manually to ``0.1``. Projects that do not manually "
"create a strategy (by calling ``start_server`` or ``start_simulation`` "
"without passing a strategy instance) should now manually initialize FedAvg "
"with ``fraction_fit`` and ``fraction_evaluate`` set to ``0.1``."
msgstr ""
"策略初始化：如果策略依赖于 ``fraction_fit`` 和 ``fraction_evaluate`` 的默认"
"值，请手动将 ``fraction_fit`` 和 ``fraction_evaluate`` 设置为 ``0.1``。未手动"
"创建策略的项目（调用 ``start_server` 或 ``start_simulation` 时未传递策略实"
"例）现在应手动初始化 FedAvg，并将 `fraction_fit` 和 `fraction_evaluate` 设为 "
"`0.1``。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:58
msgid "Rename built-in strategy parameters (e.g., ``FedAvg``):"
msgstr "重命名内置策略参数（例如，`FedAvg``）："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:60
msgid "``fraction_eval`` --> ``fraction_evaluate``"
msgstr "``fraction_eval`` --> ``fraction_evaluate``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:61
msgid "``min_eval_clients`` --> ``min_evaluate_clients``"
msgstr "``min_eval_clients`` --> ``min_evaluate_clients``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:62
msgid "``eval_fn`` --> ``evaluate_fn``"
msgstr "``eval_fn`` --> ``evaluate_fn``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:64
msgid ""
"Rename ``rnd`` to ``server_round``. This impacts multiple methods and "
"functions, for example, ``configure_fit``, ``aggregate_fit``, "
"``configure_evaluate``, ``aggregate_evaluate``, and ``evaluate_fn``."
msgstr ""
"将 `rnd` 更名为 `server_round`。这会影响多个方法和函数，例如 "
"``configure_fit``、``aggregate_fit``、``configure_evaluate``、"
"`aggregate_evaluate`` 和 ``evaluate_fn``。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:65
msgid "Add ``server_round`` and ``config`` to ``evaluate_fn``:"
msgstr "在 ``evaluate_fn` 中添加 ``server_round` 和 ``config`："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:67
msgid ""
"Flower 0.19: ``def evaluate(parameters: NDArrays) -> Optional[Tuple[float, "
"Dict[str, Scalar]]]:``"
msgstr ""
"Flower 0.19: ``def evaluate(parameters: NDArrays) -> Optional[Tuple[float, "
"Dict[str, Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:68
msgid ""
"Flower 1.0: ``def evaluate(server_round: int, parameters: NDArrays, config: "
"Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 1.0: ``def evaluate(server_round: int, parameters: NDArrays, config: "
"Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:71
msgid "Custom strategies"
msgstr "定制策略"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:73
msgid ""
"The type of parameter ``failures`` has changed from ``List[BaseException]`` "
"to ``List[Union[Tuple[ClientProxy, FitRes], BaseException]]`` (in "
"``aggregate_fit``) and ``List[Union[Tuple[ClientProxy, EvaluateRes], "
"BaseException]]`` (in ``aggregate_evaluate``)"
msgstr ""
"参数``failures``的类型已从``List[BaseException]``变为"
"``List[Union[Tuple[ClientProxy, FitRes], BaseException]]``（在"
"``agregate_fit``中）和``List[Union[Tuple[ClientProxy, EvaluateRes], "
"BaseException]]``（在``agregate_evaluate``中）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:74
msgid ""
"The ``Strategy`` method ``evaluate`` now receives the current round of "
"federated learning/evaluation as the first parameter:"
msgstr "``Strategy``方法 "
"的``evaluate``现在会接收当前一轮联邦学习/评估作为第一个参数："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:76
msgid ""
"Flower 0.19: ``def evaluate(self, parameters: Parameters) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 0.19: ``def evaluate(self, parameters: Parameters) -> Optional[Tuple["
"float, Dict[str, Scalar]]]:```"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:77
msgid ""
"Flower 1.0: ``def evaluate(self, server_round: int, parameters: Parameters) -"
"> Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 1.0: ``def evaluate(self, server_round: int, parameters: Parameters) -"
"> Optional[Tuple[float, Dict[str, Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:80
msgid "Optional improvements"
msgstr "可选的改进措施"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:82
msgid ""
"Along with the necessary changes above, there are a number of potential "
"improvements that just became possible:"
msgstr "除了上述必要的改动之外，还有一些潜在的改进措施："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:84
msgid ""
"Remove \"placeholder\" methods from subclasses of ``Client`` or "
"``NumPyClient``. If you, for example, use server-side evaluation, then empy "
"placeholder implementations of ``evaluate`` are no longer necessary."
msgstr ""
"删除 ``Client`` 或 ``NumPyClient`` 子类中的 \"占位符 \"方法"
"。例如，如果你使用服务器端评估，那么就不再需要``evaluate``的 \"空占位符 "
"\"实现。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:85
msgid ""
"Configure the round timeout via ``start_simulation``: "
"``start_simulation(..., config=flwr.server.ServerConfig(num_rounds=3, "
"round_timeout=600.0), ...)``"
msgstr ""
"通过 ``start_simulation`` 配置循环超时： ``start_simulation(..., config=flwr."
"server.ServerConfig(num_rounds=3, round_timeout=600.0), ...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:89
msgid "Further help"
msgstr "更多帮助"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:91
msgid ""
"Most official `Flower code examples <https://github.com/adap/flower/tree/"
"main/examples>`_ are already updated to Flower 1.0, they can serve as a "
"reference for using the Flower 1.0 API. If there are further questionsm, "
"`join the Flower Slack <https://flower.dev/join-slack/>`_ and use the "
"channgel ``#questions``."
msgstr ""
"大多数官方的 `Flower 代码示例 <https://github.com/adap/flower/tree/main/"
"examples>`_ 已经更新到 Flower 1.0，它们可以作为使用 Flower 1.0 API "
"的参考。如果还有其他问题，请加入 Flower Slack <https://flower.dev/join-slack/"
">`_ 并使用 \"#questions``\"。"

#: ../../source/how-to-use-strategies.rst:2
msgid "Use strategies"
msgstr "使用策略"

#: ../../source/how-to-use-strategies.rst:4
msgid ""
"Flower allows full customization of the learning process through the :code:"
"`Strategy` abstraction. A number of built-in strategies are provided in the "
"core framework."
msgstr "Flower 允许通过 :code:`Strategy` "
"抽象类对学习过程进行完全定制。核心框架中提供了许多内置策略。"

#: ../../source/how-to-use-strategies.rst:6
msgid ""
"There are three ways to customize the way Flower orchestrates the learning "
"process on the server side:"
msgstr "有三种方法可以自定义 Flower 在服务器端协调学习过程的方式："

#: ../../source/how-to-use-strategies.rst:8
msgid "Use an existing strategy, for example, :code:`FedAvg`"
msgstr "使用现有策略，例如 :code:`FedAvg`"

#: ../../source/how-to-use-strategies.rst:9
#: ../../source/how-to-use-strategies.rst:40
msgid "Customize an existing strategy with callback functions"
msgstr "使用回调函数定制现有策略"

#: ../../source/how-to-use-strategies.rst:10
#: ../../source/how-to-use-strategies.rst:87
msgid "Implement a novel strategy"
msgstr "实施新策略"

#: ../../source/how-to-use-strategies.rst:14
msgid "Use an existing strategy"
msgstr "使用现有策略"

#: ../../source/how-to-use-strategies.rst:16
msgid ""
"Flower comes with a number of popular federated learning strategies built-"
"in. A built-in strategy can be instantiated as follows:"
msgstr "Flower 内置了许多流行的联邦学习策略。内置策略的实例化方法如下："

#: ../../source/how-to-use-strategies.rst:25
msgid ""
"This creates a strategy with all parameters left at their default values and "
"passes it to the :code:`start_server` function. It is usually recommended to "
"adjust a few parameters during instantiation:"
msgstr ""
"这会创建一个所有参数都保持默认值的策略，并将其传递给 :code:`start_server` 函"
"数。通常建议在实例化过程中调整一些参数："

#: ../../source/how-to-use-strategies.rst:42
msgid ""
"Existing strategies provide several ways to customize their behaviour. "
"Callback functions allow strategies to call user-provided code during "
"execution."
msgstr ""
"现有的策略提供了多种自定义行为的方法。回调函数允许策略在执行过程中调用用户提"
"供的代码。"

#: ../../source/how-to-use-strategies.rst:45
msgid "Configuring client fit and client evaluate"
msgstr "配置客户匹配和客户评估"

#: ../../source/how-to-use-strategies.rst:47
msgid ""
"The server can pass new configuration values to the client each round by "
"providing a function to :code:`on_fit_config_fn`. The provided function will "
"be called by the strategy and must return a dictionary of configuration key "
"values pairs that will be sent to the client. It must return a dictionary of "
"arbitraty configuration values  :code:`client.fit` and :code:`client."
"evaluate` functions during each round of federated learning."
msgstr ""
"服务器可以通过向 :code:`on_fit_config_fn` 提供一个函数，在每一轮向客户端传递"
"新的配置值。提供的函数将被策略调用，并且必须返回一个配置键值对的字典，该字典"
"将被发送到客户端。在每一轮联邦学习期间，它必须返回一个任意配置值 dictionary "
":code:`client.fit`和 :code:`client.evaluate`函数。"

#: ../../source/how-to-use-strategies.rst:75
msgid ""
"The :code:`on_fit_config_fn` can be used to pass arbitrary configuration "
"values from server to client, and poetentially change these values each "
"round, for example, to adjust the learning rate. The client will receive the "
"dictionary returned by the :code:`on_fit_config_fn` in its own :code:`client."
"fit()` function."
msgstr ""
":code:`on_fit_config_fn`可用于将任意配置值从服务器传递到客户端，并在每一轮改"
"变这些值，例如，调整学习率。客户端将在自己的 :code:`client.fit()` 函数中接收 "
":code:`on_fit_config_fn` 返回的字典。"

#: ../../source/how-to-use-strategies.rst:78
msgid ""
"Similar to :code:`on_fit_config_fn`, there is also :code:"
"`on_evaluate_config_fn` to customize the configuration sent to :code:`client."
"evaluate()`"
msgstr ""
"与 :code:`on_fit_config_fn` 类似，还有 :code:`on_evaluate_config_fn` 用于定制"
"发送到 :code:`client.evaluate()` 的配置"

#: ../../source/how-to-use-strategies.rst:81
msgid "Configuring server-side evaluation"
msgstr "配置服务器端评估"

#: ../../source/how-to-use-strategies.rst:83
msgid ""
"Server-side evaluation can be enabled by passing an evaluation function to :"
"code:`evaluate_fn`."
msgstr "服务器端评估可通过向 :code:`evaluate_fn` 传递评估函数来启用。"

#: ../../source/how-to-use-strategies.rst:89
msgid ""
"Writing a fully custom strategy is a bit more involved, but it provides the "
"most flexibility. Read the `Implementing Strategies <how-to-implement-"
"strategies.html>`_ guide to learn more."
msgstr ""
"编写完全自定义的策略涉及的内容较多，但灵活性最高。阅读 `实施策略 <how-to-"
"implement-strategies.html>_ 指南，了解更多信息。"

#: ../../source/index.rst:34
msgid "Tutorial"
msgstr "教程"

#: ../../source/index.rst:44
msgid "Quickstart tutorials"
msgstr "快速入门教程"

#: ../../source/index.rst:75 ../../source/index.rst:79
msgid "How-to guides"
msgstr "操作指南"

#: ../../source/index.rst:95
msgid "Legacy example guides"
msgstr "旧版指南范例"

#: ../../source/index.rst:106 ../../source/index.rst:110
msgid "Explanations"
msgstr "说明"

#: ../../source/index.rst:122
msgid "API reference"
msgstr "应用程序接口参考"

#: ../../source/index.rst:129
msgid "Reference docs"
msgstr "参考文档"

#: ../../source/index.rst:145
msgid "Contributor tutorials"
msgstr "贡献者教程"

#: ../../source/index.rst:152
msgid "Contributor how-to guides"
msgstr "投稿指南"

#: ../../source/index.rst:164
msgid "Contributor explanations"
msgstr "贡献者解释"

#: ../../source/index.rst:170
msgid "Contributor references"
msgstr "贡献者参考资料"

#: ../../source/index.rst:-1
msgid ""
"Check out the documentation of the main Flower Framework enabling easy "
"Python development for Federated Learning."
msgstr "查看主 Flower Framework 的文档，轻松实现联邦学习的 Python 开发。"

#: ../../source/index.rst:2
msgid "Flower Framework Documentation"
msgstr "Flower 框架文档"

#: ../../source/index.rst:7
msgid ""
"Welcome to Flower's documentation. `Flower <https://flower.dev>`_ is a "
"friendly federated learning framework."
msgstr "欢迎访问 Flower 文档。`Flower <https://flower.dev>`_ "
"是一个友好的联邦学习框架。"

#: ../../source/index.rst:11
msgid "Join the Flower Community"
msgstr "加入 Flower 社区"

#: ../../source/index.rst:13
msgid ""
"The Flower Community is growing quickly - we're a friendly group of "
"researchers, engineers, students, professionals, academics, and other "
"enthusiasts."
msgstr ""
"Flower 社区发展迅速--我们是一个由研究人员、工程师、学生、专业人士、学者和其他"
"爱好者组成的友好团体。"

#: ../../source/index.rst:15
msgid "Join us on Slack"
msgstr "在 Slack 上加入我们"

#: ../../source/index.rst:23
msgid "Flower Framework"
msgstr "Flower 框架"

#: ../../source/index.rst:25
msgid ""
"The user guide is targeted at researchers and developers who want to use "
"Flower to bring existing machine learning workloads into a federated "
"setting. One of Flower's design goals was to make this simple. Read on to "
"learn more."
msgstr ""
"该用户指南面向希望使用 Flower "
"将现有机器学习工作负载引入联邦环境的研究人员和开发人员。Flower "
"的设计目标之一就是让这一切变得简单。请继续阅读，了解更多信息。"

#: ../../source/index.rst:30
msgid "Tutorials"
msgstr "教程"

#: ../../source/index.rst:32
msgid ""
"A learning-oriented series of federated learning tutorials, the best place "
"to start."
msgstr "以学习为导向的联邦学习教程系列，最好的起点。"

#: ../../source/index.rst:62
msgid ""
"QUICKSTART TUTORIALS: :doc:`PyTorch <tutorial-quickstart-pytorch>` | :doc:"
"`TensorFlow <tutorial-quickstart-tensorflow>` | :doc:`🤗 Transformers "
"<tutorial-quickstart-huggingface>` | :doc:`JAX <tutorial-quickstart-jax>` | :"
"doc:`Pandas <tutorial-quickstart-pandas>` | :doc:`fastai <tutorial-"
"quickstart-fastai>` | :doc:`PyTorch Lightning <tutorial-quickstart-pytorch-"
"lightning>` | :doc:`MXNet <tutorial-quickstart-mxnet>` | :doc:`scikit-learn "
"<tutorial-quickstart-scikitlearn>` | :doc:`XGBoost <tutorial-quickstart-"
"xgboost>` | :doc:`Android <tutorial-quickstart-android>` | :doc:`iOS "
"<tutorial-quickstart-ios>`"
msgstr ""
"快速入门教程: :doc:`PyTorch <tutorial-quickstart-pytorch>` | :doc:`"
"TensorFlow <tutorial-quickstart-tensorflow>` | :doc:`🤗 Transformers "
"<tutorial-quickstart-huggingface>` | :doc:`JAX <tutorial-quickstart-jax>` | "
":doc:`Pandas <tutorial-quickstart-pandas>` | :doc:`fastai <tutorial-"
"quickstart-fastai>` | :doc:`PyTorch Lightning <tutorial-quickstart-pytorch-"
"lightning>` | :doc:`MXNet <tutorial-quickstart-mxnet>` | :doc:`scikit-learn "
"<tutorial-quickstart-scikitlearn>` | :doc:`XGBoost <tutorial-quickstart-"
"xgboost>` | :doc:`Android <tutorial-quickstart-android>` | :doc:`iOS "
"<tutorial-quickstart-ios>`"

#: ../../source/index.rst:64
msgid "We also made video tutorials for PyTorch:"
msgstr "我们还为 PyTorch 制作了视频教程："

#: ../../source/index.rst:69
msgid "And TensorFlow:"
msgstr "还有 TensorFlow："

#: ../../source/index.rst:77
msgid ""
"Problem-oriented how-to guides show step-by-step how to achieve a specific "
"goal."
msgstr "以问题为导向的 \"如何做 \"指南逐步展示如何实现特定目标。"

#: ../../source/index.rst:108
msgid ""
"Understanding-oriented concept guides explain and discuss key topics and "
"underlying ideas behind Flower and collaborative AI."
msgstr "以理解为导向的概念指南解释并讨论了Flower和协作式人工智能背后的关键主题和基本"
"思想。"

#: ../../source/index.rst:118
msgid "References"
msgstr "参考资料"

#: ../../source/index.rst:120
msgid "Information-oriented API reference and other reference material."
msgstr "以信息为导向的 API 参考资料和其他参考资料。"

#: ../../source/index.rst:140
msgid "Contributor docs"
msgstr "贡献者文档"

#: ../../source/index.rst:142
msgid ""
"The Flower community welcomes contributions. The following docs are intended "
"to help along the way."
msgstr "Flower 社区欢迎您的贡献。以下文档旨在为您提供帮助。"

#: ../../source/ref-api-cli.rst:2
msgid "Flower CLI reference"
msgstr "Flower CLI 参考"

#: ../../source/ref-api-cli.rst:7
msgid "flower-superlink"
msgstr "flower-superlink"

#: ../../source/ref-api-cli.rst:17
msgid "flower-driver-api"
msgstr "flower-driver-api"

#: ../../source/ref-api-cli.rst:27
msgid "flower-fleet-api"
msgstr "flower-fleet-api"

#: ../../source/ref-api-flwr.rst:2
msgid "flwr (Python API reference)"
msgstr "flwr（Python API 参考）"

#: ../../source/ref-api-flwr.rst:8
msgid "client"
msgstr "客户端"

#: flwr.client:1 of
msgid "Flower client."
msgstr "Flower 客户端。"

#: flwr.client.client.Client:1 of
msgid "Abstract base class for Flower clients."
msgstr "Flower 客户端的抽象基类。"

#: flwr.client.client.Client.evaluate:1
#: flwr.client.numpy_client.NumPyClient.evaluate:1 of
msgid "Evaluate the provided parameters using the locally held dataset."
msgstr "使用本地数据集评估所提供的参数。"

#: flwr.client.app.start_client flwr.client.app.start_numpy_client
#: flwr.client.client.Client.evaluate flwr.client.client.Client.fit
#: flwr.client.client.Client.get_parameters
#: flwr.client.client.Client.get_properties
#: flwr.client.numpy_client.NumPyClient.evaluate
#: flwr.client.numpy_client.NumPyClient.fit
#: flwr.client.numpy_client.NumPyClient.get_parameters
#: flwr.client.numpy_client.NumPyClient.get_properties
#: flwr.server.app.start_server flwr.server.strategy.bulyan.Bulyan.__init__
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__
#: flwr.server.strategy.fedadam.FedAdam.__init__
#: flwr.server.strategy.fedavg.FedAvg.__init__
#: flwr.server.strategy.fedavgm.FedAvgM.__init__
#: flwr.server.strategy.fedopt.FedOpt.__init__
#: flwr.server.strategy.fedprox.FedProx.__init__
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__
#: flwr.server.strategy.fedyogi.FedYogi.__init__
#: flwr.server.strategy.krum.Krum.__init__
#: flwr.server.strategy.qfedavg.QFedAvg.__init__
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate
#: flwr.server.strategy.strategy.Strategy.aggregate_fit
#: flwr.server.strategy.strategy.Strategy.configure_evaluate
#: flwr.server.strategy.strategy.Strategy.configure_fit
#: flwr.server.strategy.strategy.Strategy.evaluate
#: flwr.server.strategy.strategy.Strategy.initialize_parameters
#: flwr.simulation.app.start_simulation of
msgid "Parameters"
msgstr "参数"

#: flwr.client.client.Client.evaluate:3 of
msgid ""
"The evaluation instructions containing (global) model parameters received "
"from the server and a dictionary of configuration values used to customize "
"the local evaluation process."
msgstr ""
"评估指令包含从服务器接收的（全局）模型参数，以及用于定制本地评估流程的配置值"
"字典。"

#: flwr.client.client.Client.evaluate flwr.client.client.Client.fit
#: flwr.client.client.Client.get_parameters
#: flwr.client.client.Client.get_properties
#: flwr.client.numpy_client.NumPyClient.evaluate
#: flwr.client.numpy_client.NumPyClient.fit
#: flwr.client.numpy_client.NumPyClient.get_parameters
#: flwr.client.numpy_client.NumPyClient.get_properties
#: flwr.server.app.start_server
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate
#: flwr.server.strategy.strategy.Strategy.aggregate_fit
#: flwr.server.strategy.strategy.Strategy.configure_evaluate
#: flwr.server.strategy.strategy.Strategy.configure_fit
#: flwr.server.strategy.strategy.Strategy.evaluate
#: flwr.server.strategy.strategy.Strategy.initialize_parameters
#: flwr.simulation.app.start_simulation of
msgid "Returns"
msgstr "返回"

#: flwr.client.client.Client.evaluate:8 of
msgid ""
"The evaluation result containing the loss on the local dataset and other "
"details such as the number of local data examples used for evaluation."
msgstr "评估结果包含本地数据集上的损失值和其他详细信息，如用于评估的本地数据的数量。"

#: flwr.client.client.Client.evaluate flwr.client.client.Client.fit
#: flwr.client.client.Client.get_parameters
#: flwr.client.client.Client.get_properties
#: flwr.client.numpy_client.NumPyClient.get_parameters
#: flwr.client.numpy_client.NumPyClient.get_properties
#: flwr.server.app.start_server
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate
#: flwr.server.strategy.strategy.Strategy.aggregate_fit
#: flwr.server.strategy.strategy.Strategy.configure_evaluate
#: flwr.server.strategy.strategy.Strategy.configure_fit
#: flwr.server.strategy.strategy.Strategy.evaluate
#: flwr.server.strategy.strategy.Strategy.initialize_parameters
#: flwr.simulation.app.start_simulation of
msgid "Return type"
msgstr "返回类型"

#: flwr.client.client.Client.fit:1 of
msgid "Refine the provided parameters using the locally held dataset."
msgstr "利用本地数据集完善所提供的参数。"

#: flwr.client.client.Client.fit:3 of
msgid ""
"The training instructions containing (global) model parameters received from "
"the server and a dictionary of configuration values used to customize the "
"local training process."
msgstr ""
"训练指令，包含从服务器接收的（全局）模型参数，以及用于定制本地训练过程的配置"
"值字典。"

#: flwr.client.client.Client.fit:8 of
msgid ""
"The training result containing updated parameters and other details such as "
"the number of local training examples used for training."
msgstr "训练结果包含更新的参数和其他详细信息，如用于训练的本地训练示例的数量。"

#: flwr.client.client.Client.get_parameters:1
#: flwr.client.numpy_client.NumPyClient.get_parameters:1 of
msgid "Return the current local model parameters."
msgstr "返回当前本地模型参数。"

#: flwr.client.client.Client.get_parameters:3 of
msgid ""
"The get parameters instructions received from the server containing a "
"dictionary of configuration values."
msgstr "从服务器接收的获取参数指令包含配置值字典。"

#: flwr.client.client.Client.get_parameters:7 of
msgid "The current local model parameters."
msgstr "当前的本地模型参数。"

#: flwr.client.client.Client.get_properties:1 of
msgid "Return set of client's properties."
msgstr "返回客户端的属性集。"

#: flwr.client.client.Client.get_properties:3 of
msgid ""
"The get properties instructions received from the server containing a "
"dictionary of configuration values."
msgstr "从服务器接收的获取属性指令包含配置值字典。"

#: flwr.client.client.Client.get_properties:7 of
msgid "The current client properties."
msgstr "当前客户端属性。"

#: flwr.client.client.Client.to_client:1 of
msgid "Return client (itself)."
msgstr "返回客户端（本身）。"

#: ../../source/ref-api-flwr.rst:24
msgid "start_client"
msgstr "启动客户端"

#: flwr.client.app.start_client:1 of
msgid "Start a Flower client node which connects to a Flower server."
msgstr "启动一个 Flower 客户节点，连接到 Flower 服务器。"

#: flwr.client.app.start_client:3 flwr.client.app.start_numpy_client:3 of
msgid ""
"The IPv4 or IPv6 address of the server. If the Flower server runs on the "
"same machine on port 8080, then `server_address` would be `\"[::]:8080\"`."
msgstr ""
"服务器的 IPv4 或 IPv6 地址：如果 Flower 服务器在同一台机器上运行，端口为 "
"8080，则`server_address`应为`\"[::]:8080\"`。"

#: flwr.client.app.start_client:7 of
msgid "..."
msgstr "..."

#: flwr.client.app.start_client:9 of
msgid "A callable that instantiates a Client. (default: None)"
msgstr "用于实例化客户端的可调用程序。(默认值：无）"

#: flwr.client.app.start_client:11 of
msgid ""
"An implementation of the abstract base class `flwr.client.Client` (default: "
"None)"
msgstr "抽象基类 `flwr.client.Client` 的实现（默认值：无）"

#: flwr.client.app.start_client:14 flwr.client.app.start_numpy_client:9 of
msgid ""
"The maximum length of gRPC messages that can be exchanged with the Flower "
"server. The default should be sufficient for most models. Users who train "
"very large models might need to increase this value. Note that the Flower "
"server needs to be started with the same value (see `flwr.server."
"start_server`), otherwise it will not know about the increased limit and "
"block larger messages."
msgstr ""
"可与 Flower 服务器交换的 gRPC 信息的最大长度：默认值对大多数模型都足够了。训"
"练超大模型的用户可能需要增加该值。请注意，Flower 服务器需要以相同的值启动（"
"请参阅 `flwr.server."
"start_server`），否则它将不知道增加的限制并阻止更大的消息。"

#: flwr.client.app.start_client:21 flwr.client.app.start_numpy_client:16 of
msgid ""
"The PEM-encoded root certificates as a byte string or a path string. If "
"provided, a secure connection using the certificates will be established to "
"an SSL-enabled Flower server."
msgstr ""
"字节字符串或路径字符串形式的 PEM 编码根证书。如果提供，将使用这些证书与启用 "
"SSL 的 Flower 服务器建立安全连接。"

#: flwr.client.app.start_client:25 flwr.client.app.start_numpy_client:20 of
msgid ""
"Configure the transport layer. Allowed values: - 'grpc-bidi': gRPC, "
"bidirectional streaming - 'grpc-rere': gRPC, request-response (experimental) "
"- 'rest': HTTP (experimental)"
msgstr ""
"配置传输层：允许的值包括 - 'grpc-bidi': gRPC，双向流 - 'grpc-rere': "
"gRPC，请求-响应（实验性） - 'rest': HTTP（实验性）"

#: flwr.client.app.start_client:32 flwr.client.app.start_numpy_client:27
#: flwr.server.app.start_server:41 of
msgid "Examples"
msgstr "实例"

#: flwr.client.app.start_client:33 of
msgid "Starting a gRPC client with an insecure server connection:"
msgstr "使用不安全的服务器连接启动 gRPC 客户端："

#: flwr.client.app.start_client:43 flwr.client.app.start_numpy_client:35 of
msgid "Starting an SSL-enabled gRPC client:"
msgstr "启动支持 SSL 的 gRPC 客户端："

#: ../../source/ref-api-flwr.rst:32
msgid "NumPyClient"
msgstr "NumPyClient"

#: flwr.client.numpy_client.NumPyClient:1 of
msgid "Abstract base class for Flower clients using NumPy."
msgstr "使用 NumPy 的 Flower 客户端的抽象基类。"

#: flwr.client.numpy_client.NumPyClient.evaluate:3
#: flwr.client.numpy_client.NumPyClient.fit:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:5
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:8
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:5
#: flwr.server.strategy.strategy.Strategy.configure_fit:5
#: flwr.server.strategy.strategy.Strategy.evaluate:8 of
msgid "The current (global) model parameters."
msgstr "当前（全局）模型参数。"

#: flwr.client.numpy_client.NumPyClient.evaluate:5 of
msgid ""
"Configuration parameters which allow the server to influence evaluation on "
"the client. It can be used to communicate arbitrary values from the server "
"to the client, for example, to influence the number of examples used for "
"evaluation."
msgstr ""
"允许服务器影响客户端评估的配置参数。它可用于将任意值从服务器传送到客户端，例"
"如，影响用于评估的示例数量。"

#: flwr.client.numpy_client.NumPyClient.evaluate:11 of
msgid ""
"* **loss** (*float*) -- The evaluation loss of the model on the local "
"dataset. * **num_examples** (*int*) -- The number of examples used for "
"evaluation. * **metrics** (*Dict[str, Scalar]*) -- A dictionary mapping "
"arbitrary string keys to values of   type bool, bytes, float, int, or str. "
"It can be used to   communicate arbitrary values back to the server."
msgstr ""
"**loss** (*float*) -- 模型在本地数据集上的评估损失值。**num_examples** "
"(*int*) -- 用于评估的示例数量。**metrics** (*Dict[str, Scalar]*) -- "
"将任意字符串键映射到 bool、bytes、float、int 或 str "
"类型值的字典。它可用于将任意值传回服务器。"

#: flwr.client.numpy_client.NumPyClient.evaluate:11 of
msgid ""
"**loss** (*float*) -- The evaluation loss of the model on the local dataset."
msgstr "**loss** (*float*) -- 模型在本地数据集上的评估损失值。"

#: flwr.client.numpy_client.NumPyClient.evaluate:12 of
msgid "**num_examples** (*int*) -- The number of examples used for evaluation."
msgstr "**num_examples** (*int*) -- 用于评估的示例数量。"

#: flwr.client.numpy_client.NumPyClient.evaluate:13
#: flwr.client.numpy_client.NumPyClient.fit:13 of
msgid ""
"**metrics** (*Dict[str, Scalar]*) -- A dictionary mapping arbitrary string "
"keys to values of type bool, bytes, float, int, or str. It can be used to "
"communicate arbitrary values back to the server."
msgstr ""
"**metrics** (*Dict[str, Scalar]*) -- 将任意字符串键映射到 bool、bytes、"
"float、int 或 str 类型值的字典。它可用于将任意值传回服务器。"

#: flwr.client.numpy_client.NumPyClient.evaluate:19 of
msgid ""
"The previous return type format (int, float, float) and the extended format "
"(int, float, float, Dict[str, Scalar]) have been deprecated and removed "
"since Flower 0.19."
msgstr ""
"自 Flower 0.19 起，之前的返回类型格式（int、float、float）和扩展格式（int、"
"float、float、Dict[str, Scalar]）已被弃用和移除。"

#: flwr.client.numpy_client.NumPyClient.fit:1 of
msgid "Train the provided parameters using the locally held dataset."
msgstr "使用本地数据集训练所提供的参数。"

#: flwr.client.numpy_client.NumPyClient.fit:5 of
msgid ""
"Configuration parameters which allow the server to influence training on the "
"client. It can be used to communicate arbitrary values from the server to "
"the client, for example, to set the number of (local) training epochs."
msgstr "允许服务器影响客户端训练的配置参数。它可用于将任意值从服务器传送到客户端，例"
"如设置（本地）训练遍历数。"

#: flwr.client.numpy_client.NumPyClient.fit:11 of
msgid ""
"* **parameters** (*NDArrays*) -- The locally updated model parameters. * "
"**num_examples** (*int*) -- The number of examples used for training. * "
"**metrics** (*Dict[str, Scalar]*) -- A dictionary mapping arbitrary string "
"keys to values of type   bool, bytes, float, int, or str. It can be used to "
"communicate   arbitrary values back to the server."
msgstr ""
"**parameters** (*NDArrays*) -- 本地更新的模型参数。**num_examples** (*int*) "
"-- 用于训练的示例数量。**metrics** (*Dict[str, Scalar]*) -- 将任意字符串键映"
"射到 bool、bytes、float、int 或 str 类型值的字典。它可用于将任意值传回服务"
"器。"

#: flwr.client.numpy_client.NumPyClient.fit:11 of
msgid "**parameters** (*NDArrays*) -- The locally updated model parameters."
msgstr "**parameters** (*NDArrays*) -- 本地更新的模型参数。"

#: flwr.client.numpy_client.NumPyClient.fit:12 of
msgid "**num_examples** (*int*) -- The number of examples used for training."
msgstr "**num_examples** (*int*) -- 用于训练的数据数量。"

#: flwr.client.numpy_client.NumPyClient.get_parameters:3 of
msgid ""
"Configuration parameters requested by the server. This can be used to tell "
"the client which parameters are needed along with some Scalar attributes."
msgstr ""
"服务器请求的配置参数。这可以用来告诉客户端需要哪些参数以及一些标量属性。"

#: flwr.client.numpy_client.NumPyClient.get_parameters:8 of
msgid ""
"**parameters** -- The local model parameters as a list of NumPy ndarrays."
msgstr "**parameters** -- NumPy ndarrays 的本地模型参数列表。"

#: flwr.client.numpy_client.NumPyClient.get_properties:1 of
msgid "Return a client's set of properties."
msgstr "返回客户端的属性集。"

#: flwr.client.numpy_client.NumPyClient.get_properties:3 of
msgid ""
"Configuration parameters requested by the server. This can be used to tell "
"the client which properties are needed along with some Scalar attributes."
msgstr ""
"服务器请求的配置参数。这可以用来告诉客户端需要哪些属性以及一些标量属性。"

#: flwr.client.numpy_client.NumPyClient.get_properties:8 of
msgid ""
"**properties** -- A dictionary mapping arbitrary string keys to values of "
"type bool, bytes, float, int, or str. It can be used to communicate "
"arbitrary property values back to the server."
msgstr ""
"**properties** -- 将任意字符串键映射到 bool、bytes、float、int 或 str 类型值"
"的字典。它可用于将任意属性值传回服务器。"

#: flwr.client.numpy_client.NumPyClient.to_client:1 of
msgid "Convert to object to Client type and return it."
msgstr "将对象转换为客户类型并返回。"

#: ../../source/ref-api-flwr.rst:41
msgid "start_numpy_client"
msgstr "start_numpy_client"

#: flwr.client.app.start_numpy_client:1 of
msgid "Start a Flower NumPyClient which connects to a gRPC server."
msgstr "启动 Flower NumPyClient，连接到 gRPC 服务器。"

#: flwr.client.app.start_numpy_client:7 of
msgid "An implementation of the abstract base class `flwr.client.NumPyClient`."
msgstr "抽象基类 `flwr.client.NumPyClient` 的实现。"

#: flwr.client.app.start_numpy_client:28 of
msgid "Starting a client with an insecure server connection:"
msgstr "使用不安全的服务器连接启动客户端："

#: ../../source/ref-api-flwr.rst:49
msgid "start_simulation"
msgstr "start_simulation"

#: flwr.simulation.app.start_simulation:1 of
msgid "Start a Ray-based Flower simulation server."
msgstr "启动基于 Ray 的Flower模拟服务器。"

#: flwr.simulation.app.start_simulation:3 of
msgid ""
"A function creating client instances. The function must take a single `str` "
"argument called `cid`. It should return a single client instance of type "
"Client. Note that the created client instances are ephemeral and will often "
"be destroyed after a single method invocation. Since client instances are "
"not long-lived, they should not attempt to carry state over method "
"invocations. Any state required by the instance (model, dataset, "
"hyperparameters, ...) should be (re-)created in either the call to "
"`client_fn` or the call to any of the client methods (e.g., load evaluation "
"data in the `evaluate` method itself)."
msgstr ""
"创建客户端实例的函数。该函数必须接受一个名为 `cid` 的 `str` 参数。"
"它应返回一个 Client 类型的客户端实例。请注意，创建的客户端实例是短暂的，通常"
"在调用一个方法后就会被销毁。由于客户机实例不是长期存在的，它们不应试图在方法"
"调用时携带状态数据。实例所需的任何状态数据（模型、数据集、超参数......）"
"都应在调用 `client_fn` 或任何客户端方法（例如，在 `evaluate` "
"方法中加载评估数据）时（重新）创建。"

#: flwr.simulation.app.start_simulation:13 of
msgid ""
"The total number of clients in this simulation. This must be set if "
"`clients_ids` is not set and vice-versa."
msgstr ""
"本次模拟的客户总数。如果未设置 `clients_ids`，则必须设置该参数，反之亦然。"

#: flwr.simulation.app.start_simulation:16 of
msgid ""
"List `client_id`s for each client. This is only required if `num_clients` is "
"not set. Setting both `num_clients` and `clients_ids` with "
"`len(clients_ids)` not equal to `num_clients` generates an error."
msgstr ""
"列出每个客户的 `client_id`。只有在未设置 `num_clients` 时才需要这样做。同时设"
"置`num_clients`和`clients_ids`，且`len(clients_ids)`不等于`num_clients`，会产"
"生错误。"

#: flwr.simulation.app.start_simulation:20 of
msgid ""
"\"num_gpus\": 0.0}` CPU and GPU resources for a single client. Supported "
"keys are `num_cpus` and `num_gpus`. To understand the GPU utilization caused "
"by `num_gpus`, as well as using custom resources, please consult the Ray "
"documentation."
msgstr ""
"\"num_gpus\"： 0.0` 单个客户端的 CPU 和 GPU 资源。支持的键值为 `num_cpus` 和 "
"`num_gpus`。要了解 `num_gpus` 所导致的 GPU 利用率，以及使用自定义资源的情况，"
"请查阅 Ray 文档。"

#: flwr.simulation.app.start_simulation:25 of
msgid ""
"An implementation of the abstract base class `flwr.server.Server`. If no "
"instance is provided, then `start_server` will create one."
msgstr ""
"抽象基类 `flwr.server.Server`的实现。如果没有提供实例，`start_server` 将创建"
"一个。"

#: flwr.server.app.start_server:9 flwr.simulation.app.start_simulation:28 of
msgid ""
"Currently supported values are `num_rounds` (int, default: 1) and "
"`round_timeout` in seconds (float, default: None)."
msgstr ""
"目前支持的值有：`num_rounds`（int，默认值：1）和以秒为单位的`round_timeout`"
"（float，默认值：无）。"

#: flwr.simulation.app.start_simulation:31 of
msgid ""
"An implementation of the abstract base class `flwr.server.Strategy`. If no "
"strategy is provided, then `start_server` will use `flwr.server.strategy."
"FedAvg`."
msgstr ""
"抽象基类 `flwr.server.strategy` 的实现。如果没有提供策略，`start_server` 将使"
"用 `flwr.server.strategy.FedAvg`。"

#: flwr.simulation.app.start_simulation:35 of
msgid ""
"An implementation of the abstract base class `flwr.server.ClientManager`. If "
"no implementation is provided, then `start_simulation` will use `flwr.server."
"client_manager.SimpleClientManager`."
msgstr ""
"抽象基类 `flwr.server.ClientManager` 的实现。如果没有提供实现，"
"`start_simulation` 将使用 `flwr.server.client_manager.SimpleClientManager`。"

#: flwr.simulation.app.start_simulation:39 of
msgid ""
"Optional dictionary containing arguments for the call to `ray.init`. If "
"ray_init_args is None (the default), Ray will be initialized with the "
"following default args:  { \"ignore_reinit_error\": True, "
"\"include_dashboard\": False }  An empty dictionary can be used "
"(ray_init_args={}) to prevent any arguments from being passed to ray.init."
msgstr ""
"可选字典，包含调用 `ray.init` 时的参数。如果 ray_init_args 为 None（默认"
"值），则将使用以下默认参数初始化 Ray： { \"ignore_reinit_error\"： True, "
"\"include_dashboard\"： False }  可以使用空字典（ray_init_args={}）来防止向 "
"ray.init 传递任何参数。"

#: flwr.simulation.app.start_simulation:39 of
msgid ""
"Optional dictionary containing arguments for the call to `ray.init`. If "
"ray_init_args is None (the default), Ray will be initialized with the "
"following default args:"
msgstr ""
"可选字典，包含调用 `ray.init` 时的参数。如果 ray_init_args 为 None（默认"
"值），则将使用以下默认参数初始化 Ray："

#: flwr.simulation.app.start_simulation:43 of
msgid "{ \"ignore_reinit_error\": True, \"include_dashboard\": False }"
msgstr "{ \"ignore_reinit_error\"： True, \"include_dashboard\"： False }"

#: flwr.simulation.app.start_simulation:45 of
msgid ""
"An empty dictionary can be used (ray_init_args={}) to prevent any arguments "
"from being passed to ray.init."
msgstr "可以使用空字典 (ray_init_args={}) 来防止向 ray.init 传递任何参数。"

#: flwr.simulation.app.start_simulation:48 of
msgid ""
"Set to True to prevent `ray.shutdown()` in case `ray.is_initialized()=True`."
msgstr ""
"设为 True 可在 `ray.is_initialized()=True` 情况下阻止 `ray.shutdown()` 。"

#: flwr.simulation.app.start_simulation:50 of
msgid ""
"Optionally specify the type of actor to use. The actor object, which "
"persists throughout the simulation, will be the process in charge of running "
"the clients' jobs (i.e. their `fit()` method)."
msgstr "可选择指定要使用的actor类型。actor对象将在整个模拟过程中持续存在，它将是负责"
"运行客户端作业（即其 `fit()`方法）的进程。"

#: flwr.simulation.app.start_simulation:54 of
msgid ""
"If you want to create your own Actor classes, you might need to pass some "
"input argument. You can use this dictionary for such purpose."
msgstr ""
"如果您想创建自己的 Actor 类，可能需要传递一些输入参数。为此，您可以使用本字"
"典。"

#: flwr.simulation.app.start_simulation:57 of
msgid ""
"(default: \"DEFAULT\") Optional string (\"DEFAULT\" or \"SPREAD\") for the "
"VCE to choose in which node the actor is placed. If you are an advanced user "
"needed more control you can use lower-level scheduling strategies to pin "
"actors to specific compute nodes (e.g. via NodeAffinitySchedulingStrategy). "
"Please note this is an advanced feature. For all details, please refer to "
"the Ray documentation: https://docs.ray.io/en/latest/ray-core/scheduling/"
"index.html"
msgstr ""
"(默认：\"DEFAULT\"）可选字符串（\"DEFAULT \"或 \"SPREAD\"），供 VCE 选择将行"
"为体放置在哪个节点上。如果你是需要更多控制权的高级用户，可以使用低级调度策略"
"将actor固定到特定计算节点（例如，通过 "
"NodeAffinitySchedulingStrategy）。请注意，这是一项高级功能。有关详细信息，"
"请参阅 Ray 文档：https://docs.ray.io/en/latest/ray-core/scheduling/index.html"

#: flwr.simulation.app.start_simulation:66 of
msgid "**hist** -- Object containing metrics from training."
msgstr "**hist** -- 包含训练指标的对象。"

#: ../../source/ref-api-flwr.rst:57
msgid "server"
msgstr "服务器"

#: flwr.server:1 of
msgid "Flower server."
msgstr "Flower 服务器。"

#: ../../source/ref-api-flwr.rst:65
msgid "server.start_server"
msgstr "server.start_server"

#: flwr.server.app.start_server:1 of
msgid "Start a Flower server using the gRPC transport layer."
msgstr "使用 gRPC 传输层启动 Flower 服务器。"

#: flwr.server.app.start_server:3 of
msgid "The IPv4 or IPv6 address of the server. Defaults to `\"[::]:8080\"`."
msgstr "服务器的 IPv4 或 IPv6 地址。默认为 `\"[::]:8080\"。"

#: flwr.server.app.start_server:5 of
msgid ""
"A server implementation, either `flwr.server.Server` or a subclass thereof. "
"If no instance is provided, then `start_server` will create one."
msgstr ""
"服务器实现，可以是 `flwr.server.Server` 或其子类。如果没有提供实例，"
"`start_server` 将创建一个。"

#: flwr.server.app.start_server:12 of
msgid ""
"An implementation of the abstract base class `flwr.server.strategy."
"Strategy`. If no strategy is provided, then `start_server` will use `flwr."
"server.strategy.FedAvg`."
msgstr ""
"抽象基类 `flwr.server.strategy.Strategy` 的实现。如果没有提供策略，"
"`start_server` 将使用 `flwr.server.strategy.FedAvg`。"

#: flwr.server.app.start_server:16 of
msgid ""
"An implementation of the abstract base class `flwr.server.ClientManager`. If "
"no implementation is provided, then `start_server` will use `flwr.server."
"client_manager.SimpleClientManager`."
msgstr ""
"抽象基类 `flwr.server.ClientManager` 的实现。如果没有提供实现，"
"`start_server` 将使用 `flwr.server.client_manager.SimpleClientManager`。"

#: flwr.server.app.start_server:21 of
msgid ""
"The maximum length of gRPC messages that can be exchanged with the Flower "
"clients. The default should be sufficient for most models. Users who train "
"very large models might need to increase this value. Note that the Flower "
"clients need to be started with the same value (see `flwr.client."
"start_client`), otherwise clients will not know about the increased limit "
"and block larger messages."
msgstr ""
"可与 Flower 客户端交换的 gRPC 消息的最大长度：默认值对大多数模型都足够了。训"
"练超大模型的用户可能需要增加该值。请注意，Flower 客户端需要以相同的值启动（"
"请参阅 `flwr.client."
"start_client`），否则客户端将不知道已增加的限制并阻止更大的消息。"

#: flwr.server.app.start_server:28 of
msgid ""
"Tuple containing root certificate, server certificate, and private key to "
"start a secure SSL-enabled server. The tuple is expected to have three bytes "
"elements in the following order:      * CA certificate.     * server "
"certificate.     * server private key."
msgstr ""
"包含根证书、服务器证书和私钥的元组，用于启动启用 SSL "
"的安全服务器。元组应按以下顺序包含三个字节元素： * CA 证书，* 服务器证书， * "
"服务器私钥。"

#: flwr.server.app.start_server:28 of
msgid ""
"Tuple containing root certificate, server certificate, and private key to "
"start a secure SSL-enabled server. The tuple is expected to have three bytes "
"elements in the following order:"
msgstr ""
"包含根证书、服务器证书和私钥的元组，用于启动启用 SSL 的安全服务器。元组应按以"
"下顺序包含三个字节元素："

#: flwr.server.app.start_server:32 of
msgid "CA certificate."
msgstr "CA 证书。"

#: flwr.server.app.start_server:33 of
msgid "server certificate."
msgstr "服务器证书。"

#: flwr.server.app.start_server:34 of
msgid "server private key."
msgstr "服务器私人密钥。"

#: flwr.server.app.start_server:37 of
msgid "**hist** -- Object containing training and evaluation metrics."
msgstr "**hist** -- 包含训练和评估指标的对象。"

#: flwr.server.app.start_server:42 of
msgid "Starting an insecure server:"
msgstr "启动不安全的服务器："

#: flwr.server.app.start_server:46 of
msgid "Starting an SSL-enabled server:"
msgstr "启动支持 SSL 的服务器："

#: ../../source/ref-api-flwr.rst:73
msgid "server.strategy"
msgstr "server.strategy"

#: flwr.server.strategy:1 of
msgid "Contains the strategy abstraction and different implementations."
msgstr "包含策略抽象和不同的实现方法。"

#: ../../source/ref-api-flwr.rst:81
msgid "server.strategy.Strategy"
msgstr "server.strategy.Strategy"

#: flwr.server.strategy.strategy.Strategy:1 of
msgid "Abstract base class for server strategy implementations."
msgstr "服务器策略实现的抽象基类。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1 of
msgid "Aggregate evaluation results."
msgstr "聚合评估结果。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:6
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:3
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:3
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:3
#: flwr.server.strategy.strategy.Strategy.configure_fit:3
#: flwr.server.strategy.strategy.Strategy.evaluate:6 of
msgid "The current round of federated learning."
msgstr "本轮联邦学习。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:5 of
msgid ""
"Successful updates from the previously selected and configured clients. Each "
"pair of `(ClientProxy, FitRes` constitutes a successful update from one of "
"the previously selected clients. Not that not all previously selected "
"clients are necessarily included in this list: a client might drop out and "
"not submit a result. For each client that did not submit an update, there "
"should be an `Exception` in `failures`."
msgstr ""
"从先前选定和配置的客户端进行的成功更新。每一对`(ClientProxy, FitRes)`都是来自"
"先前选定客户端的一次成功更新。但并非所有先前选定的客户机都一定包含在此列表中"
"：客户机可能会退出，不提交结果。对于每个没有提交更新的客户端，`failures`中都"
"应该有一个`Exception`。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:13
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:13 of
msgid ""
"Exceptions that occurred while the server was waiting for client updates."
msgstr "服务器等待客户端更新时发生的异常。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:16 of
msgid ""
"**aggregation_result** -- The aggregated evaluation result. Aggregation "
"typically uses some variant of a weighted average."
msgstr "**aggregation_result** -- 汇总的评估结果。聚合通常使用某种加权平均值。"

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:1 of
msgid "Aggregate training results."
msgstr "汇总训练结果。"

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:5 of
msgid ""
"Successful updates from the previously selected and configured clients. Each "
"pair of `(ClientProxy, FitRes)` constitutes a successful update from one of "
"the previously selected clients. Not that not all previously selected "
"clients are necessarily included in this list: a client might drop out and "
"not submit a result. For each client that did not submit an update, there "
"should be an `Exception` in `failures`."
msgstr ""
"来自先前选定和配置的客户端的成功更新。每一对`(ClientProxy, FitRes)`都构成先前"
"选定的客户端之一的一次成功更新。但并非所有先前选定的客户机都一定包含在此列表"
"中：客户机可能会退出，不提交结果。对于每个没有提交更新的客户端，\"失败 "
"\"中都应该有一个 \"异常\"。"

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:17 of
msgid ""
"**parameters** -- If parameters are returned, then the server will treat "
"these as the new global model parameters (i.e., it will replace the previous "
"parameters with the ones returned from this method). If `None` is returned "
"(e.g., because there were only failures and no viable results) then the "
"server will no update the previous model parameters, the updates received in "
"this round are discarded, and the global model parameters remain the same."
msgstr ""
"**parameters** -- 如果返回参数，那么服务器将把这些参数作为新的全局模型参数"
"（即用本方法返回的参数替换之前的参数）。如果返回 \"无\"（例如，因为只有失败而"
"没有可行的结果），那么服务器将不再更新之前的模型参数，本轮收到的更新将被丢"
"弃，全局模型参数保持不变。"

#: flwr.server.strategy.fedavg.FedAvg.configure_evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.configure_evaluate:1
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:1 of
msgid "Configure the next round of evaluation."
msgstr "配置下一轮评估。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:7
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:10
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:7
#: flwr.server.strategy.strategy.Strategy.configure_fit:7
#: flwr.server.strategy.strategy.Strategy.initialize_parameters:3 of
msgid "The client manager which holds all currently connected clients."
msgstr "客户端管理器，用于管理当前连接的所有客户端。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:10
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:10 of
msgid ""
"**evaluate_configuration** -- A list of tuples. Each tuple in the list "
"identifies a `ClientProxy` and the `EvaluateIns` for this particular "
"`ClientProxy`. If a particular `ClientProxy` is not included in this list, "
"it means that this `ClientProxy` will not participate in the next round of "
"federated evaluation."
msgstr ""
"**evaluate_configuration** -- 一个元组列表。列表中的每个元组都标识了一个`Clie"
"ntProxy`和该特定`ClientProxy`的`EvaluateIns`。如果某个特定的 `ClientProxy` "
"未包含在此列表中，则表示该 `ClientProxy` 将不参与下一轮联合评估。"

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive.configure_fit:1
#: flwr.server.strategy.fedavg.FedAvg.configure_fit:1
#: flwr.server.strategy.fedprox.FedProx.configure_fit:1
#: flwr.server.strategy.qfedavg.QFedAvg.configure_fit:1
#: flwr.server.strategy.strategy.Strategy.configure_fit:1 of
msgid "Configure the next round of training."
msgstr "配置下一轮训练。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:13
#: flwr.server.strategy.strategy.Strategy.configure_fit:10 of
msgid ""
"**fit_configuration** -- A list of tuples. Each tuple in the list identifies "
"a `ClientProxy` and the `FitIns` for this particular `ClientProxy`. If a "
"particular `ClientProxy` is not included in this list, it means that this "
"`ClientProxy` will not participate in the next round of federated learning."
msgstr ""
"**fit_configuration** -- 一个元组列表。列表中的每个元组都标识了一个`ClientPro"
"xy`和该特定`ClientProxy`的`FitIns'。如果某个特定的`ClientProxy`不在此列表中，"
"则表示该`ClientProxy`将不参加下一轮联合学习。"

#: flwr.server.strategy.strategy.Strategy.evaluate:1 of
msgid "Evaluate the current model parameters."
msgstr "评估当前的模型参数。"

#: flwr.server.strategy.strategy.Strategy.evaluate:3 of
msgid ""
"This function can be used to perform centralized (i.e., server-side) "
"evaluation of model parameters."
msgstr "该函数可用于对模型参数进行集中（即服务器端）评估。"

#: flwr.server.strategy.strategy.Strategy.evaluate:11 of
msgid ""
"**evaluation_result** -- The evaluation result, usually a Tuple containing "
"loss and a dictionary containing task-specific metrics (e.g., accuracy)."
msgstr "**evaluation_result** -- 评估结果，通常是一个元组，包含损失值和一个字典，字典"
"中包含特定任务的指标（如准确率）。"

#: flwr.server.strategy.strategy.Strategy.initialize_parameters:1 of
msgid "Initialize the (global) model parameters."
msgstr "初始化（全局）模型参数。"

#: flwr.server.strategy.strategy.Strategy.initialize_parameters:6 of
msgid ""
"**parameters** -- If parameters are returned, then the server will treat "
"these as the initial global model parameters."
msgstr ""
"**parameters** -- 如果返回参数，服务器将把这些参数视为初始全局模型参数。"

#: ../../source/ref-api-flwr.rst:90
msgid "server.strategy.FedAvg"
msgstr "server.strategy.FedAvg"

#: flwr.server.strategy.fedavg.FedAvg:1 of
msgid "Configurable FedAvg strategy implementation."
msgstr "可配置的 FedAvg 策略实施。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:1
#: flwr.server.strategy.fedavg.FedAvg.__init__:1
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:1 of
msgid "Federated Averaging strategy."
msgstr "联邦平均策略。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:3
#: flwr.server.strategy.fedavg.FedAvg.__init__:3
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:3 of
msgid "Implementation based on https://arxiv.org/abs/1602.05629"
msgstr "实施基于 https://arxiv.org/abs/1602.05629"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:5
#: flwr.server.strategy.fedavg.FedAvg.__init__:5
#: flwr.server.strategy.fedprox.FedProx.__init__:37
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:5 of
msgid ""
"Fraction of clients used during training. In case `min_fit_clients` is "
"larger than `fraction_fit * available_clients`, `min_fit_clients` will still "
"be sampled. Defaults to 1.0."
msgstr ""
"训练过程中使用的客户端比例。如果 `min_fit_clients` 大于 `fraction_fit * "
"available_clients`，则仍会对 `min_fit_clients` 进行采样。默认为 1.0。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:9
#: flwr.server.strategy.fedavg.FedAvg.__init__:9
#: flwr.server.strategy.fedprox.FedProx.__init__:41
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:9 of
msgid ""
"Fraction of clients used during validation. In case `min_evaluate_clients` "
"is larger than `fraction_evaluate * available_clients`, "
"`min_evaluate_clients` will still be sampled. Defaults to 1.0."
msgstr ""
"验证过程中使用的客户端的比例。如果 `min_evaluate_clients` 大于 `"
"fraction_evaluate * available_clients`，则仍会对 `min_evaluate_clients` "
"进行采样。默认为 1.0。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:9
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:13
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:9
#: flwr.server.strategy.fedadam.FedAdam.__init__:9
#: flwr.server.strategy.fedavg.FedAvg.__init__:13
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:9
#: flwr.server.strategy.fedopt.FedOpt.__init__:9
#: flwr.server.strategy.fedprox.FedProx.__init__:45
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:7
#: flwr.server.strategy.fedyogi.FedYogi.__init__:9
#: flwr.server.strategy.krum.Krum.__init__:7
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:13 of
msgid "Minimum number of clients used during training. Defaults to 2."
msgstr "训练期间使用的最少客户数。默认为 2。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:11
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:15
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:11
#: flwr.server.strategy.fedadam.FedAdam.__init__:11
#: flwr.server.strategy.fedavg.FedAvg.__init__:15
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:11
#: flwr.server.strategy.fedopt.FedOpt.__init__:11
#: flwr.server.strategy.fedprox.FedProx.__init__:47
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:9
#: flwr.server.strategy.fedyogi.FedYogi.__init__:11
#: flwr.server.strategy.krum.Krum.__init__:9
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:15 of
msgid "Minimum number of clients used during validation. Defaults to 2."
msgstr "验证过程中使用的最少客户端数量。默认为 2。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:13
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:17
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:13
#: flwr.server.strategy.fedadam.FedAdam.__init__:13
#: flwr.server.strategy.fedavg.FedAvg.__init__:17
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:13
#: flwr.server.strategy.fedopt.FedOpt.__init__:13
#: flwr.server.strategy.fedprox.FedProx.__init__:49
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:11
#: flwr.server.strategy.fedyogi.FedYogi.__init__:13
#: flwr.server.strategy.krum.Krum.__init__:11
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:17 of
msgid "Minimum number of total clients in the system. Defaults to 2."
msgstr "系统中客户总数的最小值。默认为 2。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:17
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:19
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:15
#: flwr.server.strategy.fedadam.FedAdam.__init__:15
#: flwr.server.strategy.fedavg.FedAvg.__init__:19
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:15
#: flwr.server.strategy.fedopt.FedOpt.__init__:15
#: flwr.server.strategy.fedprox.FedProx.__init__:51
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:13
#: flwr.server.strategy.fedyogi.FedYogi.__init__:15
#: flwr.server.strategy.krum.Krum.__init__:18
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:19 of
msgid "Optional function used for validation. Defaults to None."
msgstr "用于验证的可选函数。默认为 \"无\"。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:19
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:21
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:17
#: flwr.server.strategy.fedadam.FedAdam.__init__:17
#: flwr.server.strategy.fedavg.FedAvg.__init__:21
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:17
#: flwr.server.strategy.fedopt.FedOpt.__init__:17
#: flwr.server.strategy.fedprox.FedProx.__init__:53
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:15
#: flwr.server.strategy.fedyogi.FedYogi.__init__:17
#: flwr.server.strategy.krum.Krum.__init__:20
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:21 of
msgid "Function used to configure training. Defaults to None."
msgstr "用于配置训练的功能。默认为 \"无\"。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:21
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:23
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:19
#: flwr.server.strategy.fedadam.FedAdam.__init__:19
#: flwr.server.strategy.fedavg.FedAvg.__init__:23
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:19
#: flwr.server.strategy.fedopt.FedOpt.__init__:19
#: flwr.server.strategy.fedprox.FedProx.__init__:55
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:17
#: flwr.server.strategy.fedyogi.FedYogi.__init__:19
#: flwr.server.strategy.krum.Krum.__init__:22
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:23 of
msgid "Function used to configure validation. Defaults to None."
msgstr "用于配置验证的函数。默认为 \"无\"。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:23
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:25
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:25
#: flwr.server.strategy.fedadam.FedAdam.__init__:21
#: flwr.server.strategy.fedavg.FedAvg.__init__:25
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:21
#: flwr.server.strategy.fedopt.FedOpt.__init__:21
#: flwr.server.strategy.fedprox.FedProx.__init__:57
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:19
#: flwr.server.strategy.fedyogi.FedYogi.__init__:21
#: flwr.server.strategy.krum.Krum.__init__:24
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:25 of
msgid "Whether or not accept rounds containing failures. Defaults to True."
msgstr "是否接受包含失败的轮。默认为 True。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:25
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:27
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:27
#: flwr.server.strategy.fedadam.FedAdam.__init__:23
#: flwr.server.strategy.fedavg.FedAvg.__init__:27
#: flwr.server.strategy.fedavgm.FedAvgM.__init__:23
#: flwr.server.strategy.fedopt.FedOpt.__init__:23
#: flwr.server.strategy.fedprox.FedProx.__init__:59
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:21
#: flwr.server.strategy.fedyogi.FedYogi.__init__:23
#: flwr.server.strategy.krum.Krum.__init__:26
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:27 of
msgid "Initial global model parameters."
msgstr "初始全局模型参数。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:29
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.__init__:31
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:21
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:23
#: flwr.server.strategy.fedadam.FedAdam.__init__:25
#: flwr.server.strategy.fedadam.FedAdam.__init__:27
#: flwr.server.strategy.fedavg.FedAvg.__init__:29
#: flwr.server.strategy.fedavg.FedAvg.__init__:31
#: flwr.server.strategy.fedopt.FedOpt.__init__:25
#: flwr.server.strategy.fedopt.FedOpt.__init__:27
#: flwr.server.strategy.fedprox.FedProx.__init__:61
#: flwr.server.strategy.fedprox.FedProx.__init__:63
#: flwr.server.strategy.fedyogi.FedYogi.__init__:25
#: flwr.server.strategy.fedyogi.FedYogi.__init__:27
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:29
#: flwr.server.strategy.qfedavg.QFedAvg.__init__:31 of
msgid "Metrics aggregation function, optional."
msgstr "指标汇总功能，可选。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1 of
msgid "Aggregate evaluation losses using weighted average."
msgstr "采用加权平均法计算评估损失总额。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_fit:1
#: flwr.server.strategy.fedadagrad.FedAdagrad.aggregate_fit:1
#: flwr.server.strategy.fedadam.FedAdam.aggregate_fit:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_fit:1
#: flwr.server.strategy.fedavgm.FedAvgM.aggregate_fit:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.aggregate_fit:1
#: flwr.server.strategy.fedyogi.FedYogi.aggregate_fit:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_fit:1 of
msgid "Aggregate fit results using weighted average."
msgstr "使用加权平均法汇总拟合结果。"

#: flwr.server.strategy.fedavg.FedAvg.evaluate:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.evaluate:1 of
msgid "Evaluate model parameters using an evaluation function."
msgstr "使用评估函数评估模型参数。"

#: flwr.server.strategy.fedavg.FedAvg.initialize_parameters:1
#: flwr.server.strategy.fedavgm.FedAvgM.initialize_parameters:1 of
msgid "Initialize global model parameters."
msgstr "初始化全局模型参数。"

#: flwr.server.strategy.fedavg.FedAvg.num_evaluation_clients:1
#: flwr.server.strategy.qfedavg.QFedAvg.num_evaluation_clients:1 of
msgid "Use a fraction of available clients for evaluation."
msgstr "使用部分可用客户进行评估。"

#: flwr.server.strategy.fedavg.FedAvg.num_fit_clients:1
#: flwr.server.strategy.qfedavg.QFedAvg.num_fit_clients:1 of
msgid "Return the sample size and the required number of available clients."
msgstr "返回样本大小和所需的可用客户数量。"

#: ../../source/ref-api-flwr.rst:101
msgid "server.strategy.FedAvgM"
msgstr "server.strategy.FedAvgM"

#: flwr.server.strategy.fedavgm.FedAvgM:1
#: flwr.server.strategy.fedmedian.FedMedian:1 of
msgid "Configurable FedAvg with Momentum strategy implementation."
msgstr "可配置的 FedAvg 动量策略实施。"

#: flwr.server.strategy.fedavgm.FedAvgM.__init__:1 of
msgid "Federated Averaging with Momentum strategy."
msgstr "联邦平均动量策略。"

#: flwr.server.strategy.fedavgm.FedAvgM.__init__:3 of
msgid "Implementation based on https://arxiv.org/pdf/1909.06335.pdf"
msgstr "实施基于 https://arxiv.org/pdf/1909.06335.pdf"

#: flwr.server.strategy.fedavgm.FedAvgM.__init__:5
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:3
#: flwr.server.strategy.krum.Krum.__init__:3 of
msgid "Fraction of clients used during training. Defaults to 0.1."
msgstr "训练期间使用客户的比例。默认为 0.1。"

#: flwr.server.strategy.fedavgm.FedAvgM.__init__:7
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:5
#: flwr.server.strategy.krum.Krum.__init__:5 of
msgid "Fraction of clients used during validation. Defaults to 0.1."
msgstr "验证过程中使用的客户端比例。默认为 0.1。"

#: flwr.server.strategy.fedavgm.FedAvgM.__init__:25 of
msgid ""
"Server-side learning rate used in server-side optimization. Defaults to 1.0."
msgstr "服务器端优化中使用的服务器端学习率。默认为 1.0。"

#: flwr.server.strategy.fedavgm.FedAvgM.__init__:28 of
msgid "Server-side momentum factor used for FedAvgM. Defaults to 0.0."
msgstr "用于 FedAvgM 的服务器端动量因子。默认为 0.0。"

#: ../../source/ref-api-flwr.rst:112
msgid "server.strategy.FedMedian"
msgstr "server.strategy.FedMedian"

#: flwr.server.strategy.fedmedian.FedMedian.aggregate_fit:1 of
msgid "Aggregate fit results using median."
msgstr "使用中位数汇总拟合结果。"

#: ../../source/ref-api-flwr.rst:122
msgid "server.strategy.QFedAvg"
msgstr "server.strategy.QFedAvg"

#: flwr.server.strategy.qfedavg.QFedAvg:1 of
msgid "Configurable QFedAvg strategy implementation."
msgstr "可配置的 QFedAvg 策略实施。"

#: ../../source/ref-api-flwr.rst:133
msgid "server.strategy.FaultTolerantFedAvg"
msgstr "server.strategy.FaultTolerantFedAvg"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg:1 of
msgid "Configurable fault-tolerant FedAvg strategy implementation."
msgstr "可配置的容错 FedAvg 策略实施。"

#: ../../source/ref-api-flwr.rst:144
msgid "server.strategy.FedOpt"
msgstr "server.strategy.FedOpt"

#: flwr.server.strategy.fedopt.FedOpt:1 of
msgid "Configurable FedAdagrad strategy implementation."
msgstr "可配置的 FedAdagrad 策略实施。"

#: flwr.server.strategy.fedopt.FedOpt.__init__:1 of
msgid "Federated Optim strategy interface."
msgstr "Federated Optim 策略界面。"

#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:3
#: flwr.server.strategy.fedadam.FedAdam.__init__:3
#: flwr.server.strategy.fedopt.FedOpt.__init__:3
#: flwr.server.strategy.fedyogi.FedYogi.__init__:3 of
msgid "Implementation based on https://arxiv.org/abs/2003.00295v5"
msgstr "实施基于 https://arxiv.org/abs/2003.00295v5"

#: flwr.server.strategy.bulyan.Bulyan.__init__:5
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:5
#: flwr.server.strategy.fedadam.FedAdam.__init__:5
#: flwr.server.strategy.fedopt.FedOpt.__init__:5
#: flwr.server.strategy.fedyogi.FedYogi.__init__:5 of
msgid "Fraction of clients used during training. Defaults to 1.0."
msgstr "训练期间使用客户的比例。默认为 1.0。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:7
#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:7
#: flwr.server.strategy.fedadam.FedAdam.__init__:7
#: flwr.server.strategy.fedopt.FedOpt.__init__:7
#: flwr.server.strategy.fedyogi.FedYogi.__init__:7 of
msgid "Fraction of clients used during validation. Defaults to 1.0."
msgstr "验证过程中使用的客户端比例。默认为 1.0。"

#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:29
#: flwr.server.strategy.fedadam.FedAdam.__init__:29
#: flwr.server.strategy.fedopt.FedOpt.__init__:29
#: flwr.server.strategy.fedyogi.FedYogi.__init__:29 of
msgid "Server-side learning rate. Defaults to 1e-1."
msgstr "服务器端学习率。默认为 1e-1。"

#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:31
#: flwr.server.strategy.fedadam.FedAdam.__init__:31
#: flwr.server.strategy.fedopt.FedOpt.__init__:31
#: flwr.server.strategy.fedyogi.FedYogi.__init__:31 of
msgid "Client-side learning rate. Defaults to 1e-1."
msgstr "客户端学习率。默认为 1e-1。"

#: flwr.server.strategy.fedopt.FedOpt.__init__:33 of
msgid "Momentum parameter. Defaults to 0.0."
msgstr "动量参数。默认为 0.0。"

#: flwr.server.strategy.fedopt.FedOpt.__init__:35 of
msgid "Second moment parameter. Defaults to 0.0."
msgstr "第二动量参数。默认为 0.0。"

#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:33
#: flwr.server.strategy.fedadam.FedAdam.__init__:37
#: flwr.server.strategy.fedopt.FedOpt.__init__:37
#: flwr.server.strategy.fedyogi.FedYogi.__init__:37 of
msgid "Controls the algorithm's degree of adaptability. Defaults to 1e-9."
msgstr "控制算法的适应度。默认为 1e-9。"

#: ../../source/ref-api-flwr.rst:155
msgid "server.strategy.FedProx"
msgstr "server.strategy.FedProx"

#: flwr.server.strategy.fedprox.FedProx:1 of
msgid "Configurable FedProx strategy implementation."
msgstr "可配置的 FedProx 策略实施。"

#: flwr.server.strategy.fedprox.FedProx.__init__:1 of
msgid "Federated Optimization strategy."
msgstr "联邦优化策略。"

#: flwr.server.strategy.fedprox.FedProx.__init__:3 of
msgid "Implementation based on https://arxiv.org/abs/1812.06127"
msgstr "实施基于 https://arxiv.org/abs/1812.06127"

#: flwr.server.strategy.fedprox.FedProx.__init__:5 of
msgid ""
"The strategy in itself will not be different than FedAvg, the client needs "
"to be adjusted. A proximal term needs to be added to the loss function "
"during the training:"
msgstr "策略本身与 FedAvg "
"并无不同，客户端需要进行调整。在训练过程中，需要在损失函数中添加一个近端项："

#: flwr.server.strategy.fedprox.FedProx.__init__:9 of
msgid ""
"\\\\frac{\\\\mu}{2} || w - w^t ||^2\n"
"\n"
msgstr ""
"\\\\frac{\\\\mu}{2} || w - w^t ||^2\n"
"\n"

#: flwr.server.strategy.fedprox.FedProx.__init__:12 of
msgid ""
"Where $w^t$ are the global parameters and $w$ are the local weights the "
"function will be optimized with."
msgstr "其中，$w^t$ 是全局参数，$w$ 是优化函数的局部权重。"

#: flwr.server.strategy.fedprox.FedProx.__init__:15 of
msgid "In PyTorch, for example, the loss would go from:"
msgstr "例如，在 PyTorch 中，损失将从："

#: flwr.server.strategy.fedprox.FedProx.__init__:21 of
msgid "To:"
msgstr "致："

#: flwr.server.strategy.fedprox.FedProx.__init__:30 of
msgid ""
"With `global_params` being a copy of the parameters before the training "
"takes place."
msgstr "其中，\"global_params \"是训练前的参数副本。"

#: flwr.server.strategy.fedprox.FedProx.__init__:65 of
msgid ""
"The weight of the proximal term used in the optimization. 0.0 makes this "
"strategy equivalent to FedAvg, and the higher the coefficient, the more "
"regularization will be used (that is, the client parameters will need to be "
"closer to the server parameters during training)."
msgstr ""
"优化中使用的近端项权重。0.0 使该策略等同于 FedAvg，系数越大，使用的正则化就越"
"多（也就是说，在训练过程中，客户端参数需要更接近服务器参数）。"

#: flwr.server.strategy.fedprox.FedProx.configure_fit:3 of
msgid "Sends the proximal factor mu to the clients"
msgstr "向客户发送近端因子mu"

#: ../../source/ref-api-flwr.rst:166
msgid "server.strategy.FedAdagrad"
msgstr "server.strategy.FedAdagrad"

#: flwr.server.strategy.fedadagrad.FedAdagrad:1 of
msgid "FedAdagrad strategy - Adaptive Federated Optimization using Adagrad."
msgstr "FedAdagrad 策略 - 使用 Adagrad 进行自适应联合优化。"

#: flwr.server.strategy.fedadagrad.FedAdagrad:3
#: flwr.server.strategy.fedadam.FedAdam:3
#: flwr.server.strategy.fedyogi.FedYogi:5 of
msgid "Paper: https://arxiv.org/abs/2003.00295"
msgstr "论文： https://arxiv.org/abs/2003.00295"

#: flwr.server.strategy.fedadagrad.FedAdagrad.__init__:1
#: flwr.server.strategy.fedadam.FedAdam.__init__:1 of
msgid "Federated learning strategy using Adagrad on server-side."
msgstr "在服务器端使用 Adagrad 的联邦学习策略。"

#: ../../source/ref-api-flwr.rst:177
msgid "server.strategy.FedAdam"
msgstr "server.strategy.FedAdam"

#: flwr.server.strategy.fedadam.FedAdam:1 of
msgid "FedAdam - Adaptive Federated Optimization using Adam."
msgstr "FedAdam - 使用 Adam 进行自适应联合优化。"

#: flwr.server.strategy.fedadam.FedAdam.__init__:33
#: flwr.server.strategy.fedyogi.FedYogi.__init__:33 of
msgid "Momentum parameter. Defaults to 0.9."
msgstr "动量参数。默认为 0.9。"

#: flwr.server.strategy.fedadam.FedAdam.__init__:35
#: flwr.server.strategy.fedyogi.FedYogi.__init__:35 of
msgid "Second moment parameter. Defaults to 0.99."
msgstr "第二动量参数。默认为 0.99。"

#: ../../source/ref-api-flwr.rst:188
msgid "server.strategy.FedYogi"
msgstr "server.strategy.FedYogi"

#: flwr.server.strategy.fedyogi.FedYogi:1 of
msgid "FedYogi [Reddi et al., 2020] strategy."
msgstr "FedYogi [Reddi 等人，2020] 策略。"

#: flwr.server.strategy.fedyogi.FedYogi:3 of
msgid "Adaptive Federated Optimization using Yogi."
msgstr "使用 Yogi 的自适应联合优化。"

#: flwr.server.strategy.fedyogi.FedYogi.__init__:1 of
msgid "Federated learning strategy using Yogi on server-side."
msgstr "在服务器端使用 Yogi 的联邦学习策略。"

#: ../../source/ref-api-flwr.rst:199
msgid "server.strategy.FedTrimmedAvg"
msgstr "server.strategy.FedTrimmedAvg"

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:1 of
msgid "Federated Averaging with Trimmed Mean [Dong Yin, et al., 2021]."
msgstr "带修剪均值的联邦平均法[Dong Yin 等，2021]。"

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:3 of
msgid "Paper: https://arxiv.org/abs/1803.01498"
msgstr "论文：https://arxiv.org/abs/1803.01498"

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.__init__:23 of
msgid "Fraction to cut off of both tails of the distribution. Defaults to 0.2."
msgstr "截取分布两个尾部的分数。默认为 0.2。"

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.aggregate_fit:1 of
msgid "Aggregate fit results using trimmed average."
msgstr "使用修剪平均值汇总拟合结果。"

#: ../../source/ref-api-flwr.rst:210
msgid "server.strategy.Krum"
msgstr "server.strategy.Krum"

#: flwr.server.strategy.krum.Krum:1 of
msgid "Configurable Krum strategy implementation."
msgstr "可配置的 Krum 策略实施。"

#: flwr.server.strategy.krum.Krum.__init__:1 of
msgid "Krum strategy."
msgstr "Krum 策略。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:15
#: flwr.server.strategy.krum.Krum.__init__:13 of
msgid "Number of malicious clients in the system. Defaults to 0."
msgstr "系统中恶意客户端的数量。默认为 0。"

#: flwr.server.strategy.krum.Krum.__init__:15 of
msgid ""
"Number of clients to keep before averaging (MultiKrum). Defaults to 0, in "
"that case classical Krum is applied."
msgstr ""
"求平均值前保留的客户端数量（MultiKrum）。默认值为 0，在这种情况下会应用经典 "
"Krum。"

#: flwr.server.strategy.krum.Krum.aggregate_fit:1 of
msgid "Aggregate fit results using Krum."
msgstr "使用 Krum 汇总拟合结果。"

#: ../../source/ref-api-flwr.rst:220
msgid "server.strategy.Bulyan"
msgstr "server.strategy.Bulyan"

#: flwr.server.strategy.bulyan.Bulyan:1 of
msgid "Bulyan strategy implementation."
msgstr "Bulyan策略的实施。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:1 of
msgid "Bulyan strategy."
msgstr "Bulyan 策略。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:3 of
msgid "Implementation based on https://arxiv.org/abs/1802.07927."
msgstr "实施基于 https://arxiv.org/abs/1802.07927。"

#: flwr.server.strategy.bulyan.Bulyan.__init__:27 of
msgid ""
"Byzantine resilient aggregation rule that is used as the first step of the "
"Bulyan (e.g., Krum)"
msgstr "Byzantine弹性聚合规则，用作 Bulyan 的第一步（如 Krum）"

#: flwr.server.strategy.bulyan.Bulyan.__init__:29 of
msgid "arguments to the first_aggregation rule"
msgstr "第一聚类规则的参数"

#: flwr.server.strategy.bulyan.Bulyan.aggregate_fit:1 of
msgid "Aggregate fit results using Bulyan."
msgstr "使用 Bulyan 技术汇总拟合结果。"

#: ../../source/ref-api-flwr.rst:231
msgid "server.strategy.FedXgbNnAvg"
msgstr "server.strategy.FedXgbNnAvg"

#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:1 of
msgid "Configurable FedXgbNnAvg strategy implementation."
msgstr "可配置的 FedXgbNAvg 策略实施。"

#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.__init__:1 of
msgid "Federated XGBoost [Ma et al., 2023] strategy."
msgstr "Federated XGBoost [Ma 等人，2023] 策略。"

#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.__init__:3 of
msgid "Implementation based on https://arxiv.org/abs/2304.07537."
msgstr "实施基于 https://arxiv.org/abs/2304.07537。"

#: ../../source/ref-api-flwr.rst:242
msgid "server.strategy.DPFedAvgAdaptive"
msgstr "server.strategy.DPFedAvgAdaptive"

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:1 of
msgid "Wrapper for configuring a Strategy for DP with Adaptive Clipping."
msgstr "用于配置具有自适应剪切功能的 DP 策略的包装器。"

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive.aggregate_fit:1 of
msgid "Aggregate training results as in DPFedAvgFixed and update clip norms."
msgstr "汇总 DPFedAvgFixed 中的训练结果并更新片段标准。"

#: ../../source/ref-api-flwr.rst:253
msgid "server.strategy.DPFedAvgFixed"
msgstr "server.strategy.DPFedAvgFixed"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:1 of
msgid "Wrapper for configuring a Strategy for DP with Fixed Clipping."
msgstr "封装器，用于为具有固定剪切功能的 DP 配置策略。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1 of
msgid "Aggregate evaluation losses using the given strategy."
msgstr "使用给定的策略汇总评估损失。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_fit:1 of
msgid "Aggregate training results using unweighted aggregation."
msgstr "使用非加权汇总法汇总训练结果。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:1 of
msgid "Configure the next round of evaluation using the specified strategy."
msgstr "使用指定策略配置下一轮评估。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:1 of
msgid ""
"Configure the next round of training incorporating Differential Privacy (DP)."
msgstr "配置包含差分隐私 (DP) 的下一轮训练。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:3 of
msgid ""
"Configuration of the next training round includes information related to DP, "
"such as clip norm and noise stddev."
msgstr "下一轮训练的配置包括与 DP 相关的信息，如片段规范和噪声 stddev。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.evaluate:1 of
msgid ""
"Evaluate model parameters using an evaluation function from the strategy."
msgstr "使用策略中的评估函数评估模型参数。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.initialize_parameters:1 of
msgid "Initialize global model parameters using given strategy."
msgstr "使用给定的策略初始化全局模型参数。"

#: ../../source/ref-api-flwr.rst:261
msgid "common"
msgstr "常见"

#: flwr.common:1 of
msgid "Common components shared between server and client."
msgstr "服务器和客户端共享的通用组件。"

#: flwr.common.typing.ClientMessage:1 of
msgid "ClientMessage is a container used to hold one result message."
msgstr "ClientMessage 是用于容纳一条结果信息的容器。"

#: flwr.common.typing.Code:1 of
msgid "Client status codes."
msgstr "客户端状态代码。"

#: flwr.common.typing.DisconnectRes:1 of
msgid "DisconnectRes message from client to server."
msgstr "客户端向服务器发送 DisconnectRes 信息。"

#: flwr.common.typing.EvaluateIns:1 of
msgid "Evaluate instructions for a client."
msgstr "评估客户端的指示。"

#: flwr.common.typing.EvaluateRes:1 of
msgid "Evaluate response from a client."
msgstr "评估客户端的反应。"

#: flwr.common.telemetry.EventType:1 of
msgid "Types of telemetry events."
msgstr "遥测事件类型。"

#: flwr.common.typing.FitIns:1 of
msgid "Fit instructions for a client."
msgstr "为客户提供安装说明。"

#: flwr.common.typing.FitRes:1 of
msgid "Fit response from a client."
msgstr "来自客户端的合适回复。"

#: flwr.common.typing.GetParametersIns:1 of
msgid "Parameters request for a client."
msgstr "客户端的参数请求。"

#: flwr.common.typing.GetParametersRes:1 of
msgid "Response when asked to return parameters."
msgstr "要求返回参数时的响应。"

#: flwr.common.typing.GetPropertiesIns:1 of
msgid "Properties request for a client."
msgstr "客户端的属性请求。"

#: flwr.common.typing.GetPropertiesRes:1 of
msgid "Properties response from a client."
msgstr "来自客户端的属性响应。"

#: flwr.common.typing.Parameters:1 of
msgid "Model parameters."
msgstr "模型参数。"

#: flwr.common.typing.ReconnectIns:1 of
msgid "ReconnectIns message from server to client."
msgstr "服务器发送给客户端的重新连接信息。"

#: flwr.common.typing.ServerMessage:1 of
msgid "ServerMessage is a container used to hold one instruction message."
msgstr "ServerMessage 是用于容纳一条指令信息的容器。"

#: flwr.common.typing.Status:1 of
msgid "Client status."
msgstr "客户端状态。"

#: flwr.common.parameter.bytes_to_ndarray:1 of
msgid "Deserialize NumPy ndarray from bytes."
msgstr "从字节反序列化 NumPy ndarray。"

#: flwr.common.logger.configure:1 of
msgid "Configure logging to file and/or remote log server."
msgstr "配置将日志记录到文件和/或远程日志服务器。"

#: logging.Logger.log:1 of
msgid "Log 'msg % args' with the integer severity 'level'."
msgstr "以整数严重性 \"级别 \"记录 \"msg % args\"。"

#: logging.Logger.log:3 of
msgid ""
"To pass exception information, use the keyword argument exc_info with a true "
"value, e.g."
msgstr "要传递异常信息，请使用带 true 值的关键字参数 exc_info，例如。"

#: logging.Logger.log:6 of
#, python-format
msgid "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"
msgstr "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"

#: flwr.common.parameter.ndarray_to_bytes:1 of
msgid "Serialize NumPy ndarray to bytes."
msgstr "将 NumPy ndarray 序列化为字节。"

#: flwr.common.parameter.ndarrays_to_parameters:1 of
msgid "Convert NumPy ndarrays to parameters object."
msgstr "将 NumPy ndarrays 转换为参数对象。"

#: flwr.common.date.now:1 of
msgid "Construct a datetime from time.time() with time zone set to UTC."
msgstr "从 time.time() 生成日期时间，时区设置为 UTC。"

#: flwr.common.parameter.parameters_to_ndarrays:1 of
msgid "Convert parameters object to NumPy ndarrays."
msgstr "将参数对象转换为 NumPy ndarrays。"

#: ../../source/ref-changelog.md:1
msgid "Changelog"
msgstr "更新日志"

#: ../../source/ref-changelog.md:3
msgid "Unreleased"
msgstr "尚未发布"

#: ../../source/ref-changelog.md:5 ../../source/ref-changelog.md:83
#: ../../source/ref-changelog.md:167 ../../source/ref-changelog.md:231
#: ../../source/ref-changelog.md:289 ../../source/ref-changelog.md:358
#: ../../source/ref-changelog.md:487 ../../source/ref-changelog.md:529
#: ../../source/ref-changelog.md:596 ../../source/ref-changelog.md:662
#: ../../source/ref-changelog.md:707 ../../source/ref-changelog.md:746
#: ../../source/ref-changelog.md:779 ../../source/ref-changelog.md:829
msgid "What's new?"
msgstr "有什么新内容？"

#: ../../source/ref-changelog.md:7
msgid ""
"**Add experimental support for Python 3.12** ([#2565](https://github.com/"
"adap/flower/pull/2565))"
msgstr ""
"** 增加对 Python 3.12 的实验支持** ([#2565](https://github.com/adap/flower/"
"pull/2565))"

#: ../../source/ref-changelog.md:9
msgid ""
"**Support custom** `ClientManager` **in** `start_driver()` ([#2292](https://"
"github.com/adap/flower/pull/2292))"
msgstr ""
"**在***`start_driver()`中支持自定义***`ClientManager([#2292](https://github."
"com/adap/flower/pull/2292))"

#: ../../source/ref-changelog.md:11
msgid ""
"**Update REST API to support create and delete nodes** ([#2283](https://"
"github.com/adap/flower/pull/2283))"
msgstr ""
"**更新 REST API 以支持创建和删除节点** ([#2283](https://github.com/adap/"
"flower/pull/2283))"

#: ../../source/ref-changelog.md:13
msgid ""
"**Update the C++ SDK** ([#2537](https://github/com/adap/flower/pull/2537), "
"[#2528](https://github/com/adap/flower/pull/2528), [#2523](https://github."
"com/adap/flower/pull/2523), [#2522](https://github.com/adap/flower/"
"pull/2522))"
msgstr ""
"** 更新 C++ SDK** ([#2537](https://github/com/adap/flower/pull/2537), [#2528]"
"(https://github/com/adap/flower/pull/2528), [#2523](https://github.com/adap/"
"flower/pull/2523), [#2522](https://github.com/adap/flower/pull/2522))"

#: ../../source/ref-changelog.md:15
msgid "Add gRPC request-response capability to the C++ SDK."
msgstr "为 C++ SDK 添加 gRPC 请求-响应功能。"

#: ../../source/ref-changelog.md:17
msgid ""
"**Fix the incorrect return types of Strategy** ([#2432](https://github.com/"
"adap/flower/pull/2432/files))"
msgstr ""
"**修复策略的错误返回类型** ([#2432](https://github.com/adap/flower/pull/2432/"
"files))"

#: ../../source/ref-changelog.md:19
msgid ""
"The types of the return values in the docstrings in two methods "
"(`aggregate_fit` and `aggregate_evaluate`) now match the hint types in the "
"code."
msgstr ""
"两个方法（\"aggregate_fit \"和 \"aggregate_evaluate\"）的文档说明中的返回值类"
"型现在与代码中的提示类型一致。"

#: ../../source/ref-changelog.md:21
msgid ""
"**Unify client API** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), [#2493](https://github."
"com/adap/flower/pull/2493))"
msgstr ""
"** 统一客户端应用程序接口** ([#2303](https://github.com/adap/flower/"
"pull/2303), [#2390](https://github.com/adap/flower/pull/2390), [#2493]"
"(https://github.com/adap/flower/pull/2493))"

#: ../../source/ref-changelog.md:23
msgid ""
"Using the `client_fn`, Flower clients can interchangeably run as standalone "
"processes (i.e. via `start_client`) or in simulation (i.e. via "
"`start_simulation`) without requiring changes to how the client class is "
"defined and instantiated. Calling `start_numpy_client` is now deprecated."
msgstr ""
"使用 `client_fn`，Flower 客户端可以作为独立进程（即通过 `start_client`）或在"
"模拟中（即通过 `start_simulation`）交替运行，而无需更改客户端类的定义和实例化"
"方式。调用 `start_numpy_client` 现已过时。"

#: ../../source/ref-changelog.md:25
msgid "**Update Flower Baselines**"
msgstr "**更新 Flower Baselines**"

#: ../../source/ref-changelog.md:27
msgid ""
"FedProx ([#2210](https://github.com/adap/flower/pull/2210), [#2286](https://"
"github.com/adap/flower/pull/2286), [#2509](https://github.com/adap/flower/"
"pull/2509))"
msgstr ""
"FedProx ([#2210](https://github.com/adap/flower/pull/2210), "
"[#2286](https://github.com/adap/flower/pull/2286), [#2509](https://github."
"com/adap/flower/pull/2509))"

#: ../../source/ref-changelog.md:29
msgid ""
"Baselines Docs ([#2290](https://github.com/adap/flower/pull/2290), [#2400]"
"(https://github.com/adap/flower/pull/2400))"
msgstr ""
"Baselines文档（[#2290](https://github.com/adap/flower/pull/2290), "
"[#2400](https://github.com/adap/flower/pull/2400)"

#: ../../source/ref-changelog.md:31
msgid ""
"FedMLB ([#2340](https://github.com/adap/flower/pull/2340), [#2507](https://"
"github.com/adap/flower/pull/2507))"
msgstr ""
"FedMLB ([#2340](https://github.com/adap/flower/pull/2340), "
"[#2507](https://github.com/adap/flower/pull/2507))"

#: ../../source/ref-changelog.md:33
msgid ""
"TAMUNA ([#2254](https://github.com/adap/flower/pull/2254), [#2508](https://"
"github.com/adap/flower/pull/2508))"
msgstr ""
"TAMUNA ([#2254](https://github.com/adap/flower/pull/2254), "
"[#2508](https://github.com/adap/flower/pull/2508))"

#: ../../source/ref-changelog.md:35
msgid "FedMeta [#2438](https://github.com/adap/flower/pull/2438)"
msgstr "FedMeta [#2438](https://github.com/adap/flower/pull/2438)"

#: ../../source/ref-changelog.md:37
msgid "FjORD [#2431](https://github.com/adap/flower/pull/2431)"
msgstr "FjORD [#2431](https://github.com/adap/flower/pull/2431)"

#: ../../source/ref-changelog.md:39
msgid "MOON [#2421](https://github.com/adap/flower/pull/2421)"
msgstr "MOON [#2421](https://github.com/adap/flower/pull/2421)"

#: ../../source/ref-changelog.md:41
msgid "DepthFL [#2295](https://github.com/adap/flower/pull/2295)"
msgstr "DepthFL [#2295](https://github.com/adap/flower/pull/2295)"

#: ../../source/ref-changelog.md:43
msgid "FedPer [#2266](https://github.com/adap/flower/pull/2266)"
msgstr "FedPer [#2266](https://github.com/adap/flower/pull/2266)"

#: ../../source/ref-changelog.md:45
msgid "FedWav2vec [#2551](https://github.com/adap/flower/pull/2551)"
msgstr "FedWav2vec [#2551](https://github.com/adap/flower/pull/2551)"

#: ../../source/ref-changelog.md:47
msgid "niid-Bench [#2428](https://github.com/adap/flower/pull/2428)"
msgstr "niid-Bench [#2428](https://github.com/adap/flower/pull/2428)"

#: ../../source/ref-changelog.md:49
msgid ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), [#2615](https://"
"github.com/adap/flower/pull/2615))"
msgstr ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"

#: ../../source/ref-changelog.md:51
msgid ""
"**Update Flower Examples** ([#2384](https://github.com/adap/flower/"
"pull/2384),[#2425](https://github.com/adap/flower/pull/2425), [#2526]"
"(https://github.com/adap/flower/pull/2526))"
msgstr ""
"** 更新 Flower Examples** ([#2384](https://github.com/adap/flower/pull/"
"2384),[#2425](https://github.com/adap/flower/pull/2425), "
"[#2526](https://github.com/adap/flower/pull/2526))"

#: ../../source/ref-changelog.md:53
msgid ""
"**General updates to baselines** ([#2301](https://github.com/adap/flower/"
"pull/2301), [#2305](https://github.com/adap/flower/pull/2305), [#2307]"
"(https://github.com/adap/flower/pull/2307), [#2327](https://github.com/adap/"
"flower/pull/2327), [#2435](https://github.com/adap/flower/pull/2435))"
msgstr ""
"** baselines的普通更新** ([#2301](https://github.com/adap/flower/pull/2301), "
"[#2305](https://github.com/adap/flower/pull/2305), [#2307](https://github."
"com/adap/flower/pull/2307), [#2327](https://github.com/adap/flower/pull/2327)"
", [#2435](https://github.com/adap/flower/pull/2435))"

#: ../../source/ref-changelog.md:55
msgid ""
"**General updates to the simulation engine** ([#2331](https://github.com/"
"adap/flower/pull/2331), [#2447](https://github.com/adap/flower/pull/2447), "
"[#2448](https://github.com/adap/flower/pull/2448))"
msgstr ""
"**模拟引擎的普通更新** ([#2331](https://github.com/adap/flower/pull/2331), "
"[#2447](https://github.com/adap/flower/pull/2447), [#2448](https://github."
"com/adap/flower/pull/2448))"

#: ../../source/ref-changelog.md:57
msgid ""
"**General improvements** ([#2309](https://github.com/adap/flower/pull/2309), "
"[#2310](https://github.com/adap/flower/pull/2310), [2313](https://github.com/"
"adap/flower/pull/2313), [#2316](https://github.com/adap/flower/pull/2316), "
"[2317](https://github.com/adap/flower/pull/2317),[#2349](https://github.com/"
"adap/flower/pull/2349), [#2360](https://github.com/adap/flower/pull/2360), "
"[#2402](https://github.com/adap/flower/pull/2402), [#2446](https://github."
"com/adap/flower/pull/2446) [#2561](https://github.com/adap/flower/pull/2561))"
msgstr ""
"**普通改进**（[#2309](https://github.com/adap/flower/pull/2309), "
"[#2310](https://github.com/adap/flower/pull/2310), [2313](https://github.com/"
"adap/flower/pull/2313), [#2316](https://github.com/adap/flower/pull/2316), "
"[2317](https://github.com/adap/flower/pull/2317),[#2349](https://github.com/"
"adap/flower/pull/2349), [#2360](https://github.com/adap/flower/pull/2360), "
"[#2402](https://github.com/adap/flower/pull/2402), [#2446](https://github."
"com/adap/flower/pull/2446) [#2561](https://github.com/adap/flower/pull/2561))"

#: ../../source/ref-changelog.md:59 ../../source/ref-changelog.md:153
#: ../../source/ref-changelog.md:217 ../../source/ref-changelog.md:271
#: ../../source/ref-changelog.md:338
msgid ""
"Flower received many improvements under the hood, too many to list here."
msgstr "Flower 进行了许多改进，这里就不一一列举了。"

#: ../../source/ref-changelog.md:61
msgid ""
"**Add new** `Bulyan` **strategy** ([#1817](https://github.com/adap/flower/"
"pull/1817), [#1891](https://github.com/adap/flower/pull/1891))"
msgstr ""
"**添加新**\"Bulyan \"**策略**（[#1817](https://github.com/adap/flower/"
"pull/1817), [#1891](https://github.com/adap/flower/pull/1891)"

#: ../../source/ref-changelog.md:63
msgid ""
"The new `Bulyan` strategy implements Bulyan by [El Mhamdi et al., 2018]"
"(https://arxiv.org/abs/1802.07927)"
msgstr ""
"新的 \"Bulyan\"策略通过[El Mhamdi 等人，2018]（https://arxiv.org/"
"abs/1802.07927）实现"

#: ../../source/ref-changelog.md:65 ../../source/ref-changelog.md:155
#: ../../source/ref-changelog.md:219 ../../source/ref-changelog.md:277
#: ../../source/ref-changelog.md:346 ../../source/ref-changelog.md:408
#: ../../source/ref-changelog.md:427 ../../source/ref-changelog.md:583
#: ../../source/ref-changelog.md:654 ../../source/ref-changelog.md:691
#: ../../source/ref-changelog.md:734
msgid "Incompatible changes"
msgstr "不兼容的更改"

#: ../../source/ref-changelog.md:67
msgid ""
"**Remove support for Python 3.7** ([#2280](https://github.com/adap/flower/"
"pull/2280), [#2299](https://github.com/adap/flower/pull/2299), [#2304]"
"(https://github.com/adap/flower/pull/2304), [#2306](https://github.com/adap/"
"flower/pull/2306), [#2355](https://github.com/adap/flower/pull/2355), [#2356]"
"(https://github.com/adap/flower/pull/2356))"
msgstr ""
"**移除对 Python 3.7 的支持** ([#2280](https://github.com/adap/flower/"
"pull/2280), [#2299](https://github.com/adap/flower/pull/2299), [#2304]"
"(https://github.com/adap/flower/pull/2304), [#2306](https://github.com/adap/"
"flower/pull/2306), [#2355](https://github.com/adap/flower/pull/2355), [#2356]"
"(https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:69
msgid ""
"Python 3.7 support was deprecated in Flower 1.5, and this release removes "
"support. Flower now requires Python 3.8."
msgstr ""
"在 Flower 1.5 中，Python 3.7 支持已被弃用，本版本将删除该支持。Flower 现在需"
"要 Python 3.8。"

#: ../../source/ref-changelog.md:71
msgid ""
"**Remove experimental argument** `rest` **from** `start_client` ([#2324]"
"(https://github.com/adap/flower/pull/2324))"
msgstr ""
"**从** `start_client` 中移除** `rest` **实验参数 ([#2324](https://github.com/"
"adap/flower/pull/2324))"

#: ../../source/ref-changelog.md:73
msgid ""
"The (still experimental) argument `rest` was removed from `start_client` and "
"`start_numpy_client`. Use `transport=\"rest\"` to opt into the experimental "
"REST API instead."
msgstr ""
"删除了 `start_client` 和 `start_numpy_client` 中的参数 `rest`（仍属试验性"
"质）。请使用 `transport=\"rest\"` 来选择使用试验性 REST API。"

#: ../../source/ref-changelog.md:75
msgid "v1.5.0 (2023-08-31)"
msgstr "v1.5.0 (2023-08-31)"

#: ../../source/ref-changelog.md:77 ../../source/ref-changelog.md:161
#: ../../source/ref-changelog.md:225 ../../source/ref-changelog.md:283
#: ../../source/ref-changelog.md:352 ../../source/ref-changelog.md:421
msgid "Thanks to our contributors"
msgstr "感谢我们的贡献者"

#: ../../source/ref-changelog.md:79 ../../source/ref-changelog.md:163
#: ../../source/ref-changelog.md:227 ../../source/ref-changelog.md:285
msgid ""
"We would like to give our special thanks to all the contributors who made "
"the new version of Flower possible (in `git shortlog` order):"
msgstr ""
"在此，我们要特别感谢所有为 Flower 的新版本做出贡献的人员（按 `git shortlog` "
"顺序排列）："

#: ../../source/ref-changelog.md:81
msgid ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, `"
"Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner Topal`"
", `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:85
msgid ""
"**Introduce new simulation engine** ([#1969](https://github.com/adap/flower/"
"pull/1969), [#2221](https://github.com/adap/flower/pull/2221), [#2248]"
"(https://github.com/adap/flower/pull/2248))"
msgstr ""
"**引入新的模拟引擎** ([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), [#2248](https://github."
"com/adap/flower/pull/2248))"

#: ../../source/ref-changelog.md:87
msgid ""
"The new simulation engine has been rewritten from the ground up, yet it "
"remains fully backwards compatible. It offers much improved stability and "
"memory handling, especially when working with GPUs. Simulations "
"transparently adapt to different settings to scale simulation in CPU-only, "
"CPU+GPU, multi-GPU, or multi-node multi-GPU environments."
msgstr ""
"新的模拟引擎从头开始重新编写，但仍完全向后兼容。它的稳定性和内存处理能力大大"
"提高，尤其是在使用 GPU 时。仿真可透明地适应不同的设置，以在仅 CPU、CPU+GPU、"
"多 GPU 或多节点多 GPU 环境中扩展模拟。"

#: ../../source/ref-changelog.md:89
msgid ""
"Comprehensive documentation includes a new [how-to run simulations](https://"
"flower.dev/docs/framework/how-to-run-simulations.html) guide, new "
"[simulation-pytorch](https://flower.dev/docs/examples/simulation-pytorch."
"html) and [simulation-tensorflow](https://flower.dev/docs/examples/"
"simulation-tensorflow.html) notebooks, and a new [YouTube tutorial series]"
"(https://www.youtube.com/watch?"
"v=cRebUIGB5RU&list=PLNG4feLHqCWlnj8a_E1A_n5zr2-8pafTB)."
msgstr ""
"综合文档包括新的[how-to run simulations](https://flower.dev/docs/framework/"
"how-to-run-simulations.html) guide, new [simulation-pytorch](https://flower."
"dev/docs/examples/simulation-pytorch.html) and [simulation-"
"tensorflow](https://flower.dev/docs/examples/simulation-tensorflow.html) "
"notebooks, and a new [YouTube tutorial series](https://www.youtube.com/"
"watch?v=cRebUIGB5RU&list=PLNG4feLHqCWlnj8a_E1A_n5zr2-8pafTB)。"

#: ../../source/ref-changelog.md:91
msgid ""
"**Restructure Flower Docs** ([#1824](https://github.com/adap/flower/"
"pull/1824), [#1865](https://github.com/adap/flower/pull/1865), [#1884]"
"(https://github.com/adap/flower/pull/1884), [#1887](https://github.com/adap/"
"flower/pull/1887), [#1919](https://github.com/adap/flower/pull/1919), [#1922]"
"(https://github.com/adap/flower/pull/1922), [#1920](https://github.com/adap/"
"flower/pull/1920), [#1923](https://github.com/adap/flower/pull/1923), [#1924]"
"(https://github.com/adap/flower/pull/1924), [#1962](https://github.com/adap/"
"flower/pull/1962), [#2006](https://github.com/adap/flower/pull/2006), [#2133]"
"(https://github.com/adap/flower/pull/2133), [#2203](https://github.com/adap/"
"flower/pull/2203), [#2215](https://github.com/adap/flower/pull/2215), [#2122]"
"(https://github.com/adap/flower/pull/2122), [#2223](https://github.com/adap/"
"flower/pull/2223), [#2219](https://github.com/adap/flower/pull/2219), [#2232]"
"(https://github.com/adap/flower/pull/2232), [#2233](https://github.com/adap/"
"flower/pull/2233), [#2234](https://github.com/adap/flower/pull/2234), [#2235]"
"(https://github.com/adap/flower/pull/2235), [#2237](https://github.com/adap/"
"flower/pull/2237), [#2238](https://github.com/adap/flower/pull/2238), [#2242]"
"(https://github.com/adap/flower/pull/2242), [#2231](https://github.com/adap/"
"flower/pull/2231), [#2243](https://github.com/adap/flower/pull/2243), [#2227]"
"(https://github.com/adap/flower/pull/2227))"
msgstr ""
"**重构 Flower 文档** ([#1824](https://github.com/adap/flower/pull/1824), "
"[#1865](https://github.com/adap/flower/pull/1865), [#1884](https://github."
"com/adap/flower/pull/1884), [#1887](https://github.com/adap/flower/pull/1887)"
", [#1919](https://github.com/adap/flower/pull/1919), [#1922](https://github."
"com/adap/flower/pull/1922), [#1920](https://github.com/adap/flower/pull/1920)"
", [#1923](https://github.com/adap/flower/pull/1923), [#1924](https://github."
"com/adap/flower/pull/1924), [#1962](https://github.com/adap/flower/pull/1962)"
", [#2006](https://github.com/adap/flower/pull/2006), [#2133](https://github."
"com/adap/flower/pull/2133), [#2203](https://github.com/adap/flower/pull/2203)"
", [#2215](https://github.com/adap/flower/pull/2215), [#2122](https://github."
"com/adap/flower/pull/2122), [#2223](https://github.com/adap/flower/pull/2223)"
", [#2219](https://github.com/adap/flower/pull/2219), [#2232](https://github."
"com/adap/flower/pull/2232), [#2233](https://github.com/adap/flower/pull/2233)"
", [#2234](https://github.com/adap/flower/pull/2234), [#2235](https://github."
"com/adap/flower/pull/2235), [#2237](https://github.com/adap/flower/pull/2237)"
", [#2238](https://github.com/adap/flower/pull/2238), [#2242](https://github."
"com/adap/flower/pull/2242), [#2231](https://github.com/adap/flower/pull/2231)"
", [#2243](https://github.com/adap/flower/pull/2243), [#2227](https://github."
"com/adap/flower/pull/2227))"

#: ../../source/ref-changelog.md:93
msgid ""
"Much effort went into a completely restructured Flower docs experience. The "
"documentation on [flower.dev/docs](flower.dev/docs) is now divided into "
"Flower Framework, Flower Baselines, Flower Android SDK, Flower iOS SDK, and "
"code example projects."
msgstr ""
"Flower 文档体验的全面重构耗费了大量精力。现在，[flower.dev/docs](flower.dev/"
"docs)上的文档分为 Flower Framework、Flower Baselines、Flower Android SDK、"
"Flower iOS SDK 和代码示例项目。"

#: ../../source/ref-changelog.md:95
msgid ""
"**Introduce Flower Swift SDK** ([#1858](https://github.com/adap/flower/"
"pull/1858), [#1897](https://github.com/adap/flower/pull/1897))"
msgstr ""
"**介绍 Flower Swift SDK** ([#1858](https://github.com/adap/flower/pull/1858)"
", [#1897](https://github.com/adap/flower/pull/1897))"

#: ../../source/ref-changelog.md:97
msgid ""
"This is the first preview release of the Flower Swift SDK. Flower support on "
"iOS is improving, and alongside the Swift SDK and code example, there is now "
"also an iOS quickstart tutorial."
msgstr ""
"这是 Flower Swift SDK 的首个预览版。Flower 对 iOS 的支持正在不断改进，除了 "
"Swift SDK 和代码示例外，现在还有 iOS 快速入门教程。"

#: ../../source/ref-changelog.md:99
msgid ""
"**Introduce Flower Android SDK** ([#2131](https://github.com/adap/flower/"
"pull/2131))"
msgstr ""
"**介绍Flower Android SDK** ([#2131](https://github.com/adap/flower/"
"pull/2131))"

#: ../../source/ref-changelog.md:101
msgid ""
"This is the first preview release of the Flower Kotlin SDK. Flower support "
"on Android is improving, and alongside the Kotlin SDK and code example, "
"there is now also an Android quickstart tutorial."
msgstr ""
"这是 Flower Kotlin SDK 的首个预览版。Flower 对 Android 的支持正在不断改进，除"
"了 Kotlin SDK 和代码示例，现在还有 Android 快速入门教程。"

#: ../../source/ref-changelog.md:103
msgid ""
"**Introduce new end-to-end testing infrastructure** ([#1842](https://github."
"com/adap/flower/pull/1842), [#2071](https://github.com/adap/flower/"
"pull/2071), [#2072](https://github.com/adap/flower/pull/2072), [#2068]"
"(https://github.com/adap/flower/pull/2068), [#2067](https://github.com/adap/"
"flower/pull/2067), [#2069](https://github.com/adap/flower/pull/2069), [#2073]"
"(https://github.com/adap/flower/pull/2073), [#2070](https://github.com/adap/"
"flower/pull/2070), [#2074](https://github.com/adap/flower/pull/2074), [#2082]"
"(https://github.com/adap/flower/pull/2082), [#2084](https://github.com/adap/"
"flower/pull/2084), [#2093](https://github.com/adap/flower/pull/2093), [#2109]"
"(https://github.com/adap/flower/pull/2109), [#2095](https://github.com/adap/"
"flower/pull/2095), [#2140](https://github.com/adap/flower/pull/2140), [#2137]"
"(https://github.com/adap/flower/pull/2137), [#2165](https://github.com/adap/"
"flower/pull/2165))"
msgstr ""
"*介绍新的端到端测试** ([#1842](https://github.com/adap/flower/pull/1842), "
"[#2071](https://github.com/adap/flower/pull/2071), [#2072](https://github."
"com/adap/flower/pull/2072), [#2068](https://github.com/adap/flower/pull/2068)"
", [#2067](https://github.com/adap/flower/pull/2067), [#2069](https://github."
"com/adap/flower/pull/2069), [#2073](https://github.com/adap/flower/pull/2073)"
", [#2070](https://github.com/adap/flower/pull/2070), [#2074](https://github."
"com/adap/flower/pull/2074), [#2082](https://github.com/adap/flower/pull/2082)"
", [#2084](https://github.com/adap/flower/pull/2084), [#2093](https://github."
"com/adap/flower/pull/2093), [#2109](https://github.com/adap/flower/pull/2109)"
", [#2095](https://github.com/adap/flower/pull/2095), [#2140](https://github."
"com/adap/flower/pull/2140), [#2137](https://github.com/adap/flower/pull/2137)"
", [#2165](https://github.com/adap/flower/pull/2165))"

#: ../../source/ref-changelog.md:105
msgid ""
"A new testing infrastructure ensures that new changes stay compatible with "
"existing framework integrations or strategies."
msgstr "新的测试设施可确保新的变更与现有的框架集成或策略保持兼容。"

#: ../../source/ref-changelog.md:107
msgid "**Deprecate Python 3.7**"
msgstr "** 过时的 Python 3.7**"

#: ../../source/ref-changelog.md:109
msgid ""
"Since Python 3.7 reached its end of life (EOL) on 2023-06-27, support for "
"Python 3.7 is now deprecated and will be removed in an upcoming release."
msgstr ""
"由于 Python 3.7 已于 2023-06-27 弃用 (EOL)，对 Python 3.7 "
"的支持现已废弃，并将在即将发布的版本中移除。"

#: ../../source/ref-changelog.md:111
msgid ""
"**Add new** `FedTrimmedAvg` **strategy** ([#1769](https://github.com/adap/"
"flower/pull/1769), [#1853](https://github.com/adap/flower/pull/1853))"
msgstr ""
"**添加新的**`FedTrimmedAvg`**策略**（[#1769](https://github.com/adap/flower/"
"pull/1769), [#1853](https://github.com/adap/flower/pull/1853)"

#: ../../source/ref-changelog.md:113
msgid ""
"The new `FedTrimmedAvg` strategy implements Trimmed Mean by [Dong Yin, 2018]"
"(https://arxiv.org/abs/1803.01498)."
msgstr ""
"新的 \"FedTrimmedAvg \"策略实现了[Dong Yin, 2018]（https://arxiv.org/"
"abs/1803.01498）的 \"Trimmed Mean\"。"

#: ../../source/ref-changelog.md:115
msgid ""
"**Introduce start_driver** ([#1697](https://github.com/adap/flower/"
"pull/1697))"
msgstr ""
"**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:117
msgid ""
"In addition to `start_server` and using the raw Driver API, there is a new "
"`start_driver` function that allows for running `start_server` scripts as a "
"Flower driver with only a single-line code change. Check out the `mt-"
"pytorch` code example to see a working example using `start_driver`."
msgstr ""
"除了 `start_server` 和使用原始驱动 API 之外，还有一个新的 `start_driver` 函"
"数，只需修改一行代码，就能将 `start_server` 脚本作为 Flower 驱动程序运行。请"
"查看 `mt-pytorch` 代码示例，了解使用 `start_driver` 的工作示例。"

#: ../../source/ref-changelog.md:119
msgid ""
"**Add parameter aggregation to** `mt-pytorch` **code example** ([#1785]"
"(https://github.com/adap/flower/pull/1785))"
msgstr ""
"为 `mt-pytorch` **代码示例**添加参数聚合 ([#1785](https://github.com/adap/"
"flower/pull/1785))"

#: ../../source/ref-changelog.md:121
msgid ""
"The `mt-pytorch` example shows how to aggregate parameters when writing a "
"driver script. The included `driver.py` and `server.py` have been aligned to "
"demonstrate both the low-level way and the high-level way of building server-"
"side logic."
msgstr ""
"`mt-pytorch`示例展示了如何在编写驱动程序脚本时聚合参数。附带的 `driver.py` "
"和 `server.py` 已经进行了调整，以演示构建服务器端逻辑的低级方法和高级方法。"

#: ../../source/ref-changelog.md:123
msgid ""
"**Migrate experimental REST API to Starlette** ([2171](https://github.com/"
"adap/flower/pull/2171))"
msgstr ""
"**将实验性 REST API 移植到 Starlette** ([2171](https://github.com/adap/"
"flower/pull/2171))"

#: ../../source/ref-changelog.md:125
msgid ""
"The (experimental) REST API used to be implemented in [FastAPI](https://"
"fastapi.tiangolo.com/), but it has now been migrated to use [Starlette]"
"(https://www.starlette.io/) directly."
msgstr ""
"REST API（试验性）曾在 [FastAPI](https://fastapi.tiangolo.com/) 中实现，但现"
"在已迁移到直接使用 [Starlette](https://www.starlette.io/) 。"

#: ../../source/ref-changelog.md:127
msgid ""
"Please note: The REST request-response API is still experimental and will "
"likely change significantly over time."
msgstr ""
"请注意：REST 请求-响应 API 仍处于试验阶段，随着时间的推移可能会发生重大变化。"

#: ../../source/ref-changelog.md:129
msgid ""
"**Introduce experimental gRPC request-response API** ([#1867](https://github."
"com/adap/flower/pull/1867), [#1901](https://github.com/adap/flower/"
"pull/1901))"
msgstr ""
"**引入实验性 gRPC 请求-响应 API** （[#1867](https://github.com/adap/flower/"
"pull/1867), [#1901](https://github.com/adap/flower/pull/1901)"

#: ../../source/ref-changelog.md:131
msgid ""
"In addition to the existing gRPC API (based on bidirectional streaming) and "
"the experimental REST API, there is now a new gRPC API that uses a request-"
"response model to communicate with client nodes."
msgstr ""
"除了现有的 gRPC 应用程序接口（基于双向流）和试验性 REST 应用程序接口外，现在"
"还有一个新的 gRPC 应用程序接口，它使用请求-响应模型与客户端节点通信。"

#: ../../source/ref-changelog.md:133
msgid ""
"Please note: The gRPC request-response API is still experimental and will "
"likely change significantly over time."
msgstr ""
"请注意：gRPC 请求-响应 API 仍处于试验阶段，随着时间的推移可能会发生重大变化。"

#: ../../source/ref-changelog.md:135
msgid ""
"**Replace the experimental** `start_client(rest=True)` **with the new** "
"`start_client(transport=\"rest\")` ([#1880](https://github.com/adap/flower/"
"pull/1880))"
msgstr ""
"**用新的** `start_client(transport=\"rest\")` 替换实验性** "
"`start_client(rest=True)` ([#1880](https://github.com/adap/flower/pull/1880))"

#: ../../source/ref-changelog.md:137
msgid ""
"The (experimental) `start_client` argument `rest` was deprecated in favour "
"of a new argument `transport`. `start_client(transport=\"rest\")` will yield "
"the same behaviour as `start_client(rest=True)` did before. All code should "
"migrate to the new argument `transport`. The deprecated argument `rest` will "
"be removed in a future release."
msgstr ""
"已废弃（试验性的）`start_client`参数`rest`，改用新参数`transport`。"
"`start_client(transport=\"rest\")`将产生与以前的`start_client(rest=True)`相同"
"的行为。所有代码都应迁移到新参数 `transport`。过时的参数 `rest` 将在今后的版"
"本中删除。"

#: ../../source/ref-changelog.md:139
msgid ""
"**Add a new gRPC option** ([#2197](https://github.com/adap/flower/pull/2197))"
msgstr ""
"** 添加一个新的 gRPC 选项**（[#2197](https://github.com/adap/flower/"
"pull/2197)）"

#: ../../source/ref-changelog.md:141
msgid ""
"We now start a gRPC server with the `grpc.keepalive_permit_without_calls` "
"option set to 0 by default. This prevents the clients from sending keepalive "
"pings when there is no outstanding stream."
msgstr ""
"现在我们启动一个 gRPC 服务器，并将 `grpc.keepalive_permit_without_calls` "
"选项默认设置为 0。这将防止客户端在没有未处理数据流时发送 keepalive pings。"

#: ../../source/ref-changelog.md:143
msgid ""
"**Improve example notebooks** ([#2005](https://github.com/adap/flower/"
"pull/2005))"
msgstr "**改进示例笔记** ([#2005](https://github.com/adap/flower/pull/2005))"

#: ../../source/ref-changelog.md:145
msgid "There's a new 30min Federated Learning PyTorch tutorial!"
msgstr "有一个新的 30 分钟的联邦学习 PyTorch 教程！"

#: ../../source/ref-changelog.md:147
msgid ""
"**Example updates** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), [#1981](https://github."
"com/adap/flower/pull/1981), [#1988](https://github.com/adap/flower/"
"pull/1988), [#1984](https://github.com/adap/flower/pull/1984), [#1982]"
"(https://github.com/adap/flower/pull/1982), [#2112](https://github.com/adap/"
"flower/pull/2112), [#2144](https://github.com/adap/flower/pull/2144), [#2174]"
"(https://github.com/adap/flower/pull/2174), [#2225](https://github.com/adap/"
"flower/pull/2225), [#2183](https://github.com/adap/flower/pull/2183))"
msgstr ""
"**更新Example** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), [#1981](https://github."
"com/adap/flower/pull/1981), [#1988](https://github.com/adap/flower/pull/1988)"
", [#1984](https://github.com/adap/flower/pull/1984), [#1982](https://github."
"com/adap/flower/pull/1982), [#2112](https://github.com/adap/flower/pull/2112)"
", [#2144](https://github.com/adap/flower/pull/2144), [#2174](https://github."
"com/adap/flower/pull/2174), [#2225](https://github.com/adap/flower/pull/2225)"
", [#2183](https://github.com/adap/flower/pull/2183))"

#: ../../source/ref-changelog.md:149
msgid ""
"Many examples have received significant updates, including simplified "
"advanced-tensorflow and advanced-pytorch examples, improved macOS "
"compatibility of TensorFlow examples, and code examples for simulation. A "
"major upgrade is that all code examples now have a `requirements.txt` (in "
"addition to `pyproject.toml`)."
msgstr ""
"许多示例都进行了重大更新，包括简化了 advanced-tensorflow 和 advanced-pytorch "
"示例，改进了 TensorFlow 示例的 macOS 兼容性，以及模拟代码示例。"
"一项重大升级是所有代码示例现在都有了 \"requirements.txt\"（除 \"pyproject."
"toml \"外）。"

#: ../../source/ref-changelog.md:151
msgid ""
"**General improvements** ([#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), [#1884](https://github."
"com/adap/flower/pull/1884), [#1837](https://github.com/adap/flower/"
"pull/1837), [#1477](https://github.com/adap/flower/pull/1477), [#2171]"
"(https://github.com/adap/flower/pull/2171))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), [#1884](https://github."
"com/adap/flower/pull/1884), [#1837](https://github.com/adap/flower/pull/1837)"
", [#1477](https://github.com/adap/flower/pull/1477), [#2171](https://github."
"com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:157 ../../source/ref-changelog.md:221
#: ../../source/ref-changelog.md:279 ../../source/ref-changelog.md:348
#: ../../source/ref-changelog.md:410
msgid "None"
msgstr "无"

#: ../../source/ref-changelog.md:159
msgid "v1.4.0 (2023-04-21)"
msgstr "v1.4.0 (2023-04-21)"

#: ../../source/ref-changelog.md:165
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, `Iacob-"
"Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal Sarkhel`, "
"`L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic Lane`, "
"`Nikolaos Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, `Steve "
"Laskaridis`, `Steven Hé (Sīchàng)`, `Taner Topal`"
msgstr ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, `"
"Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, `Iacob-"
"Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal Sarkhel`, `"
"L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic Lane`, `Nikolaos "
"Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, `Steve Laskaridis`, `"
"Steven Hé (Sīchàng)`, `Taner Topal`"

#: ../../source/ref-changelog.md:169
msgid ""
"**Introduce support for XGBoost (**`FedXgbNnAvg` **strategy and example)** "
"([#1694](https://github.com/adap/flower/pull/1694), [#1709](https://github."
"com/adap/flower/pull/1709), [#1715](https://github.com/adap/flower/"
"pull/1715), [#1717](https://github.com/adap/flower/pull/1717), [#1763]"
"(https://github.com/adap/flower/pull/1763), [#1795](https://github.com/adap/"
"flower/pull/1795))"
msgstr ""
"**引入对XGBoost的支持（**`FedXgbNnAvg` **策略和示例）** ([#1694](https://"
"github.com/adap/flower/pull/1694), [#1709](https://github.com/adap/flower/"
"pull/1709), [#1715](https://github.com/adap/flower/pull/1715), [#1717]"
"(https://github.com/adap/flower/pull/1717), [#1763](https://github.com/adap/"
"flower/pull/1763), [#1795](https://github.com/adap/flower/pull/1795))"

#: ../../source/ref-changelog.md:171
msgid ""
"XGBoost is a tree-based ensemble machine learning algorithm that uses "
"gradient boosting to improve model accuracy. We added a new `FedXgbNnAvg` "
"[strategy](https://github.com/adap/flower/tree/main/src/py/flwr/server/"
"strategy/fedxgb_nn_avg.py), and a [code example](https://github.com/adap/"
"flower/tree/main/examples/quickstart_xgboost_horizontal) that demonstrates "
"the usage of this new strategy in an XGBoost project."
msgstr ""
"XGBoost 是一种基于树的集合机器学习算法，它使用梯度提升来提高模型的准确性。我"
"们添加了一个新的 \"FedXgbNnAvg\"[策略](https://github.com/adap/flower/tree/"
"main/src/py/flwr/server/strategy/fedxgb_nn_avg.py)和一个[代码示例](https://"
"github.com/adap/flower/tree/main/examples/quickstart_xgboost_horizontal)，演"
"示如何在 XGBoost 项目中使用这个新策略。"

#: ../../source/ref-changelog.md:173
msgid ""
"**Introduce iOS SDK (preview)** ([#1621](https://github.com/adap/flower/"
"pull/1621), [#1764](https://github.com/adap/flower/pull/1764))"
msgstr ""
"**介绍 iOS SDK（预览版）** ([#1621](https://github.com/adap/flower/"
"pull/1621), [#1764](https://github.com/adap/flower/pull/1764))"

#: ../../source/ref-changelog.md:175
msgid ""
"This is a major update for anyone wanting to implement Federated Learning on "
"iOS mobile devices. We now have a swift iOS SDK present under [src/swift/"
"flwr](https://github.com/adap/flower/tree/main/src/swift/flwr) that will "
"facilitate greatly the app creating process. To showcase its use, the [iOS "
"example](https://github.com/adap/flower/tree/main/examples/ios) has also "
"been updated!"
msgstr ""
"对于想要在 iOS 移动设备上实施联邦学习的人来说，这是一次重大更新。现在，"
"我们在 [src/swift/flwr](https://github.com/adap/flower/tree/main/src/swift/"
"flwr) 下提供了一个迅捷的 iOS "
"SDK，这将大大方便应用程序的创建过程。为了展示其使用情况，我们还更新了 [iOS "
"示例](https://github.com/adap/flower/tree/main/examples/ios)！"

#: ../../source/ref-changelog.md:177
msgid ""
"**Introduce new \"What is Federated Learning?\" tutorial** ([#1657](https://"
"github.com/adap/flower/pull/1657), [#1721](https://github.com/adap/flower/"
"pull/1721))"
msgstr ""
"**引入新的 \"什么是联邦学习？\"教程**（[#1657](https://github.com/adap/"
"flower/pull/1657), [#1721](https://github.com/adap/flower/pull/1721)"

#: ../../source/ref-changelog.md:179
msgid ""
"A new [entry-level tutorial](https://flower.dev/docs/framework/tutorial-what-"
"is-federated-learning.html) in our documentation explains the basics of "
"Fedetated Learning. It enables anyone who's unfamiliar with Federated "
"Learning to start their journey with Flower. Forward it to anyone who's "
"interested in Federated Learning!"
msgstr ""
"我们的文档中新增了一个[入门级教程](https://flower.dev/docs/framework/"
"tutorial-what-is-federated-learning.html)，解释了联邦学习的基础知识。"
"它让任何不熟悉联邦学习的人都能开始 Flower "
"之旅。请转发给对联邦学习感兴趣的人！"

#: ../../source/ref-changelog.md:181
msgid ""
"**Introduce new Flower Baseline: FedProx MNIST** ([#1513](https://github.com/"
"adap/flower/pull/1513), [#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), [#1679](https://github."
"com/adap/flower/pull/1679))"
msgstr ""
"**引入新的 Flower Baseline： FedProx MNIST** （[#1513](https://github.com/"
"adap/flower/pull/1513), [#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), [#1679](https://github."
"com/adap/flower/pull/1679)"

#: ../../source/ref-changelog.md:183
msgid ""
"This new baseline replicates the MNIST+CNN task from the paper [Federated "
"Optimization in Heterogeneous Networks (Li et al., 2018)](https://arxiv.org/"
"abs/1812.06127). It uses the `FedProx` strategy, which aims at making "
"convergence more robust in heterogenous settings."
msgstr ""
"这条新Baseline复现了论文[Federated Optimization in Heterogeneous Networks ("
"Li et al., 2018)](https://arxiv.org/abs/1812.06127)中的 MNIST+CNN 任务。"
"它使用 \"FedProx \"策略，旨在使收敛在异构环境中更加稳健。"

#: ../../source/ref-changelog.md:185
msgid ""
"**Introduce new Flower Baseline: FedAvg FEMNIST** ([#1655](https://github."
"com/adap/flower/pull/1655))"
msgstr ""
"**引入新的 Flower Baseline： FedAvg FEMNIST** ([#1655](https://github.com/"
"adap/flower/pull/1655))"

#: ../../source/ref-changelog.md:187
msgid ""
"This new baseline replicates an experiment evaluating the performance of the "
"FedAvg algorithm on the FEMNIST dataset from the paper [LEAF: A Benchmark "
"for Federated Settings (Caldas et al., 2018)](https://arxiv.org/"
"abs/1812.01097)."
msgstr ""
"这一新Baseline复现了论文[LEAF: A Benchmark for Federated Settings（Caldas "
"等人，2018 年）](https://arxiv.org/abs/1812.01097)中评估 FedAvg 算法在 "
"FEMNIST 数据集上性能的实验。"

#: ../../source/ref-changelog.md:189
msgid ""
"**Introduce (experimental) REST API** ([#1594](https://github.com/adap/"
"flower/pull/1594), [#1690](https://github.com/adap/flower/pull/1690), [#1695]"
"(https://github.com/adap/flower/pull/1695), [#1712](https://github.com/adap/"
"flower/pull/1712), [#1802](https://github.com/adap/flower/pull/1802), [#1770]"
"(https://github.com/adap/flower/pull/1770), [#1733](https://github.com/adap/"
"flower/pull/1733))"
msgstr ""
"**引入（试验性）REST API** ([#1594](https://github.com/adap/flower/"
"pull/1594), [#1690](https://github.com/adap/flower/pull/1690), [#1695]"
"(https://github.com/adap/flower/pull/1695), [#1712](https://github.com/adap/"
"flower/pull/1712), [#1802](https://github.com/adap/flower/pull/1802), [#1770]"
"(https://github.com/adap/flower/pull/1770), [#1733](https://github.com/adap/"
"flower/pull/1733))"

#: ../../source/ref-changelog.md:191
msgid ""
"A new REST API has been introduced as an alternative to the gRPC-based "
"communication stack. In this initial version, the REST API only supports "
"anonymous clients."
msgstr ""
"作为基于 gRPC 的通信栈的替代方案，我们引入了新的 REST API。在初始版本中，"
"REST API 仅支持匿名客户端。"

#: ../../source/ref-changelog.md:193
msgid ""
"Please note: The REST API is still experimental and will likely change "
"significantly over time."
msgstr "请注意：REST API 仍处于试验阶段，随着时间的推移可能会发生重大变化。"

#: ../../source/ref-changelog.md:195
msgid ""
"**Improve the (experimental) Driver API** ([#1663](https://github.com/adap/"
"flower/pull/1663), [#1666](https://github.com/adap/flower/pull/1666), [#1667]"
"(https://github.com/adap/flower/pull/1667), [#1664](https://github.com/adap/"
"flower/pull/1664), [#1675](https://github.com/adap/flower/pull/1675), [#1676]"
"(https://github.com/adap/flower/pull/1676), [#1693](https://github.com/adap/"
"flower/pull/1693), [#1662](https://github.com/adap/flower/pull/1662), [#1794]"
"(https://github.com/adap/flower/pull/1794))"
msgstr ""
"**改进（试验性）驱动程序应用程序接口** ([#1663](https://github.com/adap/"
"flower/pull/1663), [#1666](https://github.com/adap/flower/pull/1666), [#1667]"
"(https://github.com/adap/flower/pull/1667), [#1664](https://github.com/adap/"
"flower/pull/1664), [#1675](https://github.com/adap/flower/pull/1675), [#1676]"
"(https://github.com/adap/flower/pull/1676), [#1693](https://github.com/adap/"
"flower/pull/1693), [#1662](https://github.com/adap/flower/pull/1662), [#1794]"
"(https://github.com/adap/flower/pull/1794))"

#: ../../source/ref-changelog.md:197
msgid ""
"The Driver API is still an experimental feature, but this release introduces "
"some major upgrades. One of the main improvements is the introduction of an "
"SQLite database to store server state on disk (instead of in-memory). "
"Another improvement is that tasks (instructions or results) that have been "
"delivered will now be deleted. This greatly improves the memory efficiency "
"of a long-running Flower server."
msgstr ""
"驱动程序应用程序接口（Driver API）仍是一项试验性功能，但这一版本引入了一些重"
"大升级。主要改进之一是引入了 SQLite 数据库，将服务器状态存储在磁盘上（而不是"
"内存中）。另一项改进是，已交付的任务（指令或结果）现在将被删除。这大大提高了"
"长期运行的 Flower 服务器的内存效率。"

#: ../../source/ref-changelog.md:199
msgid ""
"**Fix spilling issues related to Ray during simulations** ([#1698](https://"
"github.com/adap/flower/pull/1698))"
msgstr ""
"**修复模拟过程中与Ray有关的溢出问题** ([#1698](https://github.com/adap/"
"flower/pull/1698))"

#: ../../source/ref-changelog.md:201
msgid ""
"While running long simulations, `ray` was sometimes spilling huge amounts of "
"data that would make the training unable to continue. This is now fixed! 🎉"
msgstr ""
"在运行长时间模拟时，`ray` 有时会溢出大量数据，导致训练无法继续。现在这个问题"
"已经解决！🎉"

#: ../../source/ref-changelog.md:203
msgid ""
"**Add new example using** `TabNet` **and Flower** ([#1725](https://github."
"com/adap/flower/pull/1725))"
msgstr ""
"** 添加使用** `TabNet` ** 的新示例** ([#1725](https://github.com/adap/flower/"
"pull/1725))"

#: ../../source/ref-changelog.md:205
msgid ""
"TabNet is a powerful and flexible framework for training machine learning "
"models on tabular data. We now have a federated example using Flower: "
"[https://github.com/adap/flower/tree/main/examples/tabnet](https://github."
"com/adap/flower/tree/main/examples/quickstart_tabnet)."
msgstr ""
"TabNet 是一个强大而灵活的框架，用于在表格数据上训练机器学习模型。"
"我们现在有一个使用 Flower 的联邦示例：[https://github.com/adap/flower/tree/"
"main/examples/tabnet](https://github.com/adap/flower/tree/main/examples/"
"quickstart_tabnet)。"

#: ../../source/ref-changelog.md:207
msgid ""
"**Add new how-to guide for monitoring simulations** ([#1649](https://github."
"com/adap/flower/pull/1649))"
msgstr ""
"** 添加新的模拟监控指南** ([#1649](https://github.com/adap/flower/pull/1649))"

#: ../../source/ref-changelog.md:209
msgid ""
"We now have a documentation guide to help users monitor their performance "
"during simulations."
msgstr "我们现在有一份文档指南，可帮助用户在模拟过程中监控其性能。"

#: ../../source/ref-changelog.md:211
msgid ""
"**Add training metrics to** `History` **object during simulations** ([#1696]"
"(https://github.com/adap/flower/pull/1696))"
msgstr ""
"**在模拟过程中为***`历史`***对象添加训练指标*** ([#1696](https://github.com/"
"adap/flower/pull/1696))"

#: ../../source/ref-changelog.md:213
msgid ""
"The `fit_metrics_aggregation_fn` can be used to aggregate training metrics, "
"but previous releases did not save the results in the `History` object. This "
"is now the case!"
msgstr ""
"`fit_metrics_aggregation_fn`可用于汇总训练指标，但以前的版本不会将结果保存在 "
"\"History \"对象中。现在可以了！"

#: ../../source/ref-changelog.md:215
msgid ""
"**General improvements** ([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), [#1647](https://github."
"com/adap/flower/pull/1647), [#1471](https://github.com/adap/flower/"
"pull/1471), [#1648](https://github.com/adap/flower/pull/1648), [#1651]"
"(https://github.com/adap/flower/pull/1651), [#1652](https://github.com/adap/"
"flower/pull/1652), [#1653](https://github.com/adap/flower/pull/1653), [#1659]"
"(https://github.com/adap/flower/pull/1659), [#1665](https://github.com/adap/"
"flower/pull/1665), [#1670](https://github.com/adap/flower/pull/1670), [#1672]"
"(https://github.com/adap/flower/pull/1672), [#1677](https://github.com/adap/"
"flower/pull/1677), [#1684](https://github.com/adap/flower/pull/1684), [#1683]"
"(https://github.com/adap/flower/pull/1683), [#1686](https://github.com/adap/"
"flower/pull/1686), [#1682](https://github.com/adap/flower/pull/1682), [#1685]"
"(https://github.com/adap/flower/pull/1685), [#1692](https://github.com/adap/"
"flower/pull/1692), [#1705](https://github.com/adap/flower/pull/1705), [#1708]"
"(https://github.com/adap/flower/pull/1708), [#1711](https://github.com/adap/"
"flower/pull/1711), [#1713](https://github.com/adap/flower/pull/1713), [#1714]"
"(https://github.com/adap/flower/pull/1714), [#1718](https://github.com/adap/"
"flower/pull/1718), [#1716](https://github.com/adap/flower/pull/1716), [#1723]"
"(https://github.com/adap/flower/pull/1723), [#1735](https://github.com/adap/"
"flower/pull/1735), [#1678](https://github.com/adap/flower/pull/1678), [#1750]"
"(https://github.com/adap/flower/pull/1750), [#1753](https://github.com/adap/"
"flower/pull/1753), [#1736](https://github.com/adap/flower/pull/1736), [#1766]"
"(https://github.com/adap/flower/pull/1766), [#1760](https://github.com/adap/"
"flower/pull/1760), [#1775](https://github.com/adap/flower/pull/1775), [#1776]"
"(https://github.com/adap/flower/pull/1776), [#1777](https://github.com/adap/"
"flower/pull/1777), [#1779](https://github.com/adap/flower/pull/1779), [#1784]"
"(https://github.com/adap/flower/pull/1784), [#1773](https://github.com/adap/"
"flower/pull/1773), [#1755](https://github.com/adap/flower/pull/1755), [#1789]"
"(https://github.com/adap/flower/pull/1789), [#1788](https://github.com/adap/"
"flower/pull/1788), [#1798](https://github.com/adap/flower/pull/1798), [#1799]"
"(https://github.com/adap/flower/pull/1799), [#1739](https://github.com/adap/"
"flower/pull/1739), [#1800](https://github.com/adap/flower/pull/1800), [#1804]"
"(https://github.com/adap/flower/pull/1804), [#1805](https://github.com/adap/"
"flower/pull/1805))"
msgstr ""
"**普通改进** ([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), [#1647](https://github."
"com/adap/flower/pull/1647), [#1471](https://github.com/adap/flower/pull/1471)"
", [#1648](https://github.com/adap/flower/pull/1648), [#1651](https://github."
"com/adap/flower/pull/1651), [#1652](https://github.com/adap/flower/pull/1652)"
", [#1653](https://github.com/adap/flower/pull/1653), [#1659](https://github."
"com/adap/flower/pull/1659), [#1665](https://github.com/adap/flower/pull/1665)"
", [#1670](https://github.com/adap/flower/pull/1670), [#1672](https://github."
"com/adap/flower/pull/1672), [#1677](https://github.com/adap/flower/pull/1677)"
", [#1684](https://github.com/adap/flower/pull/1684), [#1683](https://github."
"com/adap/flower/pull/1683), [#1686](https://github.com/adap/flower/pull/1686)"
", [#1682](https://github.com/adap/flower/pull/1682), [#1685](https://github."
"com/adap/flower/pull/1685), [#1692](https://github.com/adap/flower/pull/1692)"
", [#1705](https://github.com/adap/flower/pull/1705), [#1708](https://github."
"com/adap/flower/pull/1708), [#1711](https://github.com/adap/flower/pull/1711)"
", [#1713](https://github.com/adap/flower/pull/1713), [#1714](https://github."
"com/adap/flower/pull/1714), [#1718](https://github.com/adap/flower/pull/1718)"
", [#1716](https://github.com/adap/flower/pull/1716), [#1723](https://github."
"com/adap/flower/pull/1723), [#1735](https://github.com/adap/flower/pull/1735)"
", [#1678](https://github.com/adap/flower/pull/1678), [#1750](https://github."
"com/adap/flower/pull/1750), [#1753](https://github.com/adap/flower/pull/1753)"
", [#1736](https://github.com/adap/flower/pull/1736), [#1766](https://github."
"com/adap/flower/pull/1766), [#1760](https://github.com/adap/flower/pull/1760)"
", [#1775](https://github.com/adap/flower/pull/1775), [#1776](https://github."
"com/adap/flower/pull/1776), [#1777](https://github.com/adap/flower/pull/1777)"
", [#1779](https://github.com/adap/flower/pull/1779), [#1784](https://github."
"com/adap/flower/pull/1784), [#1773](https://github.com/adap/flower/pull/1773)"
", [#1755](https://github.com/adap/flower/pull/1755), [#1789](https://github."
"com/adap/flower/pull/1789), [#1788](https://github.com/adap/flower/pull/1788)"
", [#1798](https://github.com/adap/flower/pull/1798), [#1799](https://github."
"com/adap/flower/pull/1799), [#1739](https://github.com/adap/flower/pull/1739)"
", [#1800](https://github.com/adap/flower/pull/1800), [#1804](https://github."
"com/adap/flower/pull/1804), [#1805](https://github.com/adap/flower/pull/"
"1805))"

#: ../../source/ref-changelog.md:223
msgid "v1.3.0 (2023-02-06)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:229
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, `Daniel "
"J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"
msgstr ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, `Daniel "
"J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"

#: ../../source/ref-changelog.md:233
msgid ""
"**Add support for** `workload_id` **and** `group_id` **in Driver API** "
"([#1595](https://github.com/adap/flower/pull/1595))"
msgstr ""
"**在驱动程序应用程序接口中添加对** `workload_id` **和** `group_id` **的支持**"
" ([#1595](https://github.com/adap/flower/pull/1595))"

#: ../../source/ref-changelog.md:235
msgid ""
"The (experimental) Driver API now supports a `workload_id` that can be used "
"to identify which workload a task belongs to. It also supports a new "
"`group_id` that can be used, for example, to indicate the current training "
"round. Both the `workload_id` and `group_id` enable client nodes to decide "
"whether they want to handle a task or not."
msgstr ""
"驱动程序 API（试验性）现在支持 `workload_id`，可用于识别任务所属的工作量。"
"它还支持新的 `group_id`，例如，可用于指示当前的训练轮次。通过 `workload_id` "
"和 `group_id` 客户端节点可以决定是否要处理某个任务。"

#: ../../source/ref-changelog.md:237
msgid ""
"**Make Driver API and Fleet API address configurable** ([#1637](https://"
"github.com/adap/flower/pull/1637))"
msgstr ""
"**使Driver API 和Fleet API地址可配置**（[#1637](https://github.com/adap/"
"flower/pull/1637)）"

#: ../../source/ref-changelog.md:239
msgid ""
"The (experimental) long-running Flower server (Driver API and Fleet API) can "
"now configure the server address of both Driver API (via `--driver-api-"
"address`) and Fleet API (via `--fleet-api-address`) when starting:"
msgstr ""
"长期运行的 Flower 服务器（Driver API 和 Fleet API）现在可以在启动时配置 "
"Driver API（通过 `--driver-api-address`）和 Fleet API（通过 `-fleet-api-"
"address`）的服务器地址："

#: ../../source/ref-changelog.md:241
msgid ""
"`flower-superlink --driver-api-address \"0.0.0.0:8081\" --fleet-api-address "
"\"0.0.0.0:8086\"`"
msgstr ""
"`flower-server --driver-api-address \"0.0.0.0:8081\" --fleet-api-address \"0."
"0.0.0:8086\"`"

#: ../../source/ref-changelog.md:243
msgid "Both IPv4 and IPv6 addresses are supported."
msgstr "支持 IPv4 和 IPv6 地址。"

#: ../../source/ref-changelog.md:245
msgid ""
"**Add new example of Federated Learning using fastai and Flower** ([#1598]"
"(https://github.com/adap/flower/pull/1598))"
msgstr ""
"** 添加使用 fastai 和 Flower 进行联邦学习的新示例** ([#1598](https://github."
"com/adap/flower/pull/1598))"

#: ../../source/ref-changelog.md:247
msgid ""
"A new code example (`quickstart_fastai`) demonstrates federated learning "
"with [fastai](https://www.fast.ai/) and Flower. You can find it here: "
"[quickstart_fastai](https://github.com/adap/flower/tree/main/examples/"
"quickstart_fastai)."
msgstr ""
"一个新的代码示例（`quickstart_fastai`）演示了使用 [fastai](https://www.fast."
"ai/) 和 Flower 的联邦学习。您可以在这里找到它： "
"[quickstart_fastai](https://github.com/adap/flower/tree/main/examples/"
"quickstart_fastai)。"

#: ../../source/ref-changelog.md:249
msgid ""
"**Make Android example compatible with** `flwr >= 1.0.0` **and the latest "
"versions of Android** ([#1603](https://github.com/adap/flower/pull/1603))"
msgstr ""
"**使安卓示例兼容** `flwr >= 1.0.0` **和最新版本的安卓** ([#1603](https://"
"github.com/adap/flower/pull/1603))"

#: ../../source/ref-changelog.md:251
msgid ""
"The Android code example has received a substantial update: the project is "
"compatible with Flower 1.0 (and later), the UI received a full refresh, and "
"the project is updated to be compatible with newer Android tooling."
msgstr ""
"Android 代码示例已进行了大幅更新：项目兼容 Flower 1.0（及更高版本），用户界面"
"已全面刷新，项目已更新为兼容较新的 Android 工具。"

#: ../../source/ref-changelog.md:253
msgid ""
"**Add new `FedProx` strategy** ([#1619](https://github.com/adap/flower/"
"pull/1619))"
msgstr "**添加新的`FedProx`策略** （[#1619](https://github.com/adap/flower/pull/"
"1619)）"

#: ../../source/ref-changelog.md:255
msgid ""
"This [strategy](https://github.com/adap/flower/blob/main/src/py/flwr/server/"
"strategy/fedprox.py) is almost identical to [`FedAvg`](https://github.com/"
"adap/flower/blob/main/src/py/flwr/server/strategy/fedavg.py), but helps "
"users replicate what is described in this [paper](https://arxiv.org/"
"abs/1812.06127). It essentially adds a parameter called `proximal_mu` to "
"regularize the local models with respect to the global models."
msgstr ""
"该[策略](https://github.com/adap/flower/blob/main/src/py/flwr/server/"
"strategy/fedprox.py)与[`FedAvg`](https://github.com/adap/flower/blob/main/"
"src/py/flwr/server/strategy/fedavg."
"py)几乎相同，但可以帮助用户复现本[论文](https://arxiv.org/abs/1812."
"06127)中的描述。它的本质是添加一个名为 "
"`proximal_mu`的参数，使局部模型与全局模型正则化。"

#: ../../source/ref-changelog.md:257
msgid ""
"**Add new metrics to telemetry events** ([#1640](https://github.com/adap/"
"flower/pull/1640))"
msgstr ""
"**为遥测事件添加新指标**（[#1640](https://github.com/adap/flower/pull/1640)）"

#: ../../source/ref-changelog.md:259
msgid ""
"An updated event structure allows, for example, the clustering of events "
"within the same workload."
msgstr "例如，更新后的事件结构可以将同一工作负载中的事件集中在一起。"

#: ../../source/ref-changelog.md:261
msgid ""
"**Add new custom strategy tutorial section** [#1623](https://github.com/adap/"
"flower/pull/1623)"
msgstr ""
"**添加新的自定义策略教程部分** [#1623](https://github.com/adap/flower/"
"pull/1623)"

#: ../../source/ref-changelog.md:263
msgid ""
"The Flower tutorial now has a new section that covers implementing a custom "
"strategy from scratch: [Open in Colab](https://colab.research.google.com/"
"github/adap/flower/blob/main/doc/source/tutorial-build-a-strategy-from-"
"scratch-pytorch.ipynb)"
msgstr ""
"Flower 教程新增了一个章节，介绍如何从零开始实施自定义策略： [在 Colab 中打开]"
"(https://colab.research.google.com/github/adap/flower/blob/main/doc/source/"
"tutorial-build-a-strategy-from-scratch-pytorch.ipynb)"

#: ../../source/ref-changelog.md:265
msgid ""
"**Add new custom serialization tutorial section** ([#1622](https://github."
"com/adap/flower/pull/1622))"
msgstr ""
"** 添加新的自定义序列化教程部分** ([#1622](https://github.com/adap/flower/"
"pull/1622))"

#: ../../source/ref-changelog.md:267
msgid ""
"The Flower tutorial now has a new section that covers custom serialization: "
"[Open in Colab](https://colab.research.google.com/github/adap/flower/blob/"
"main/doc/source/tutorial-customize-the-client-pytorch.ipynb)"
msgstr ""
"Flower 教程现在新增了一个章节，介绍自定义序列化： [在 Colab 中打开](https://"
"colab.research.google.com/github/adap/flower/blob/main/doc/source/tutorial-"
"customize-the-client-pytorch.ipynb)"

#: ../../source/ref-changelog.md:269
msgid ""
"**General improvements** ([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), [#1636](https://github."
"com/adap/flower/pull/1636), [#1635](https://github.com/adap/flower/"
"pull/1635), [#1633](https://github.com/adap/flower/pull/1633), [#1632]"
"(https://github.com/adap/flower/pull/1632), [#1631](https://github.com/adap/"
"flower/pull/1631), [#1630](https://github.com/adap/flower/pull/1630), [#1627]"
"(https://github.com/adap/flower/pull/1627), [#1593](https://github.com/adap/"
"flower/pull/1593), [#1616](https://github.com/adap/flower/pull/1616), [#1615]"
"(https://github.com/adap/flower/pull/1615), [#1607](https://github.com/adap/"
"flower/pull/1607), [#1609](https://github.com/adap/flower/pull/1609), [#1608]"
"(https://github.com/adap/flower/pull/1608), [#1603](https://github.com/adap/"
"flower/pull/1603), [#1590](https://github.com/adap/flower/pull/1590), [#1580]"
"(https://github.com/adap/flower/pull/1580), [#1599](https://github.com/adap/"
"flower/pull/1599), [#1600](https://github.com/adap/flower/pull/1600), [#1601]"
"(https://github.com/adap/flower/pull/1601), [#1597](https://github.com/adap/"
"flower/pull/1597), [#1595](https://github.com/adap/flower/pull/1595), [#1591]"
"(https://github.com/adap/flower/pull/1591), [#1588](https://github.com/adap/"
"flower/pull/1588), [#1589](https://github.com/adap/flower/pull/1589), [#1587]"
"(https://github.com/adap/flower/pull/1587), [#1573](https://github.com/adap/"
"flower/pull/1573), [#1581](https://github.com/adap/flower/pull/1581), [#1578]"
"(https://github.com/adap/flower/pull/1578), [#1574](https://github.com/adap/"
"flower/pull/1574), [#1572](https://github.com/adap/flower/pull/1572), [#1586]"
"(https://github.com/adap/flower/pull/1586))"
msgstr ""
"**普通改进** ([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), [#1636](https://github."
"com/adap/flower/pull/1636), [#1635](https://github.com/adap/flower/pull/1635)"
", [#1633](https://github.com/adap/flower/pull/1633), [#1632](https://github."
"com/adap/flower/pull/1632), [#1631](https://github.com/adap/flower/pull/1631)"
", [#1630](https://github.com/adap/flower/pull/1630), [#1627](https://github. "
"com/adap/flower/pull/1627), [#1593](https://github.com/adap/flower/pull/1593)"
", [#1616](https://github.com/adap/flower/pull/1616), [#1615](https://github."
"com/adap/flower/pull/1615), [#1607](https://github.com/adap/flower/pull/1607)"
", [#1609](https://github.com/adap/flower/pull/1609), [#1608](https://github."
"com/adap/flower/pull/1608), [#1603](https://github.com/adap/flower/pull/1603)"
", [#1590](https://github. com/adap/flower/pull/1590), [#1580](https://github."
"com/adap/flower/pull/1580), [#1599](https://github.com/adap/flower/pull/1599)"
", [#1600](https://github.com/adap/flower/pull/1600), [#1601](https://github."
"com/adap/flower/pull/1601), [#1597](https://github.com/adap/flower/pull/1597)"
", [#1595](https://github.com/adap/flower/pull/1595), [#1591](https://github."
"com/adap/flower/pull/1591), [#1588](https://github. com/adap/flower/pull/"
"1588), [#1589](https://github.com/adap/flower/pull/1589), "
"[#1587](https://github.com/adap/flower/pull/1587), [#1573](https://github."
"com/adap/flower/pull/1573), [#1581](https://github.com/adap/flower/pull/1581)"
", [#1578](https://github.com/adap/flower/pull/1578), [#1574](https://github."
"com/adap/flower/pull/1574), [#1572](https://github.com/adap/flower/pull/1572)"
", [#1586](https://github.com/adap/flower/pull/1586))"

#: ../../source/ref-changelog.md:273
msgid ""
"**Updated documentation** ([#1629](https://github.com/adap/flower/"
"pull/1629), [#1628](https://github.com/adap/flower/pull/1628), [#1620]"
"(https://github.com/adap/flower/pull/1620), [#1618](https://github.com/adap/"
"flower/pull/1618), [#1617](https://github.com/adap/flower/pull/1617), [#1613]"
"(https://github.com/adap/flower/pull/1613), [#1614](https://github.com/adap/"
"flower/pull/1614))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), [#1628]"
"(https://github.com/adap/flower/pull/1628), [#1620](https://github.com/adap/"
"flower/pull/1620), [#1618](https://github.com/adap/flower/pull/1618), [#1617]"
"(https://github.com/adap/flower/pull/1617), [#1613](https://github.com/adap/"
"flower/pull/1613), [#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:275 ../../source/ref-changelog.md:342
msgid ""
"As usual, the documentation has improved quite a bit. It is another step in "
"our effort to make the Flower documentation the best documentation of any "
"project. Stay tuned and as always, feel free to provide feedback!"
msgstr ""
"和往常一样，我们的文档有了很大的改进。这是我们努力使 Flower 文档成为所有项目"
"中最好文档的又一步骤。请继续关注，并随时提供反馈意见！"

#: ../../source/ref-changelog.md:281
msgid "v1.2.0 (2023-01-13)"
msgstr "v1.2.0 (2023-01-13)"

#: ../../source/ref-changelog.md:287
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L. "
"Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"
msgstr ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L. "
"Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"

#: ../../source/ref-changelog.md:291
msgid ""
"**Introduce new Flower Baseline: FedAvg MNIST** ([#1497](https://github.com/"
"adap/flower/pull/1497), [#1552](https://github.com/adap/flower/pull/1552))"
msgstr ""
"**引入新的 Flower Baseline： FedAvg MNIST** ([#1497](https://github.com/adap/"
"flower/pull/1497), [#1552](https://github.com/adap/flower/pull/1552))"

#: ../../source/ref-changelog.md:293
msgid ""
"Over the coming weeks, we will be releasing a number of new reference "
"implementations useful especially to FL newcomers. They will typically "
"revisit well known papers from the literature, and be suitable for "
"integration in your own application or for experimentation, in order to "
"deepen your knowledge of FL in general. Today's release is the first in this "
"series. [Read more.](https://flower.dev/blog/2023-01-12-fl-starter-pack-"
"fedavg-mnist-cnn/)"
msgstr ""
"在未来几周内，我们将发布一些新的参考，特别是对 FL 新手有用的方法。它们通常会"
"重温文献中的知名论文，适合集成到您自己的应用程序中或用于实验，以加深您对 FL "
"的总体了解。今天发布的是该系列中的第一篇。[阅读全文](https://flower.dev/blog/"
"2023-01-12-fl-starter-pack-fedavg-mnist-cnn/)"

#: ../../source/ref-changelog.md:295
msgid ""
"**Improve GPU support in simulations** ([#1555](https://github.com/adap/"
"flower/pull/1555))"
msgstr ""
"**改进模拟中的 GPU 支持**（[#1555](https://github.com/adap/flower/"
"pull/1555)）"

#: ../../source/ref-changelog.md:297
msgid ""
"The Ray-based Virtual Client Engine (`start_simulation`) has been updated to "
"improve GPU support. The update includes some of the hard-earned lessons "
"from scaling simulations in GPU cluster environments. New defaults make "
"running GPU-based simulations substantially more robust."
msgstr ""
"基于 Ray 的虚拟客户端引擎 (`start_simulation`)已更新，以改进对 GPU 的支持。"
"此次更新包含了在 GPU 集群环境中扩展模拟的一些经验教训。新的默认设置使基于 "
"GPU 的模拟运行更加稳健。"

#: ../../source/ref-changelog.md:299
msgid ""
"**Improve GPU support in Jupyter Notebook tutorials** ([#1527](https://"
"github.com/adap/flower/pull/1527), [#1558](https://github.com/adap/flower/"
"pull/1558))"
msgstr ""
"**改进 Jupyter Notebook 教程中的 GPU 支持** ([#1527](https://github.com/adap/"
"flower/pull/1527), [#1558](https://github.com/adap/flower/pull/1558))"

#: ../../source/ref-changelog.md:301
msgid ""
"Some users reported that Jupyter Notebooks have not always been easy to use "
"on GPU instances. We listened and made improvements to all of our Jupyter "
"notebooks! Check out the updated notebooks here:"
msgstr ""
"一些用户报告说，在 GPU 实例上使用 Jupyter "
"笔记本并不是很方便。我们听取了他们的意见，并对所有 Jupyter "
"笔记本进行了改进！点击这里查看更新后的笔记本："

#: ../../source/ref-changelog.md:303
msgid ""
"[An Introduction to Federated Learning](https://flower.dev/docs/framework/"
"tutorial-get-started-with-flower-pytorch.html)"
msgstr ""
"[联邦学习简介](https://flower.dev/docs/framework/tutorial-get-started-with-"
"flower-pytorch.html)"

#: ../../source/ref-changelog.md:304
msgid ""
"[Strategies in Federated Learning](https://flower.dev/docs/framework/"
"tutorial-use-a-federated-learning-strategy-pytorch.html)"
msgstr ""
"[联邦学习策略](https://flower.dev/docs/framework/tutorial-use-a-federated-"
"learning-strategy-pytorch.html)"

#: ../../source/ref-changelog.md:305
msgid ""
"[Building a Strategy](https://flower.dev/docs/framework/tutorial-build-a-"
"strategy-from-scratch-pytorch.html)"
msgstr ""
"[制定策略](https://flower.dev/docs/framework/tutorial-build-a-strategy-from-"
"scratch-pytorch.html)"

#: ../../source/ref-changelog.md:306
msgid ""
"[Client and NumPyClient](https://flower.dev/docs/framework/tutorial-"
"customize-the-client-pytorch.html)"
msgstr ""
"[客户端和 NumPyClient](https://flower.dev/docs/framework/tutorial-customize-"
"the-client-pytorch.html)"

#: ../../source/ref-changelog.md:308
msgid ""
"**Introduce optional telemetry** ([#1533](https://github.com/adap/flower/"
"pull/1533), [#1544](https://github.com/adap/flower/pull/1544), [#1584]"
"(https://github.com/adap/flower/pull/1584))"
msgstr ""
"**引入可选遥测**（[#1533](https://github.com/adap/flower/pull/1533), [#1544]"
"(https://github.com/adap/flower/pull/1544), [#1584](https://github.com/adap/"
"flower/pull/1584)"

#: ../../source/ref-changelog.md:310
msgid ""
"After a [request for feedback](https://github.com/adap/flower/issues/1534) "
"from the community, the Flower open-source project introduces optional "
"collection of *anonymous* usage metrics to make well-informed decisions to "
"improve Flower. Doing this enables the Flower team to understand how Flower "
"is used and what challenges users might face."
msgstr ""
"在社区发出[反馈请求](https://github.com/adap/flower/issues/1534)之后，Flower "
"开放源码项目引入了可选的*匿名*使用指标收集，以便在充分知情的情况下做出改进 "
"Flower 的决定。这样做能让 Flower 团队了解 Flower 的使用情况以及用户可能面临的"
"挑战。"

#: ../../source/ref-changelog.md:312
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.** "
"Staying true to this statement, Flower makes it easy to disable telemetry "
"for users who do not want to share anonymous usage metrics. [Read more.]"
"(https://flower.dev/docs/telemetry.html)."
msgstr ""
"**Flower 是一个用于协作式人工智能和数据科学的友好框架。** Flower 遵循这一声"
"明，让不想分享匿名使用指标的用户可以轻松禁用遥测技术。[阅读全文](https://"
"flower.dev/docs/telemetry.html)。"

#: ../../source/ref-changelog.md:314
msgid ""
"**Introduce (experimental) Driver API** ([#1520](https://github.com/adap/"
"flower/pull/1520), [#1525](https://github.com/adap/flower/pull/1525), [#1545]"
"(https://github.com/adap/flower/pull/1545), [#1546](https://github.com/adap/"
"flower/pull/1546), [#1550](https://github.com/adap/flower/pull/1550), [#1551]"
"(https://github.com/adap/flower/pull/1551), [#1567](https://github.com/adap/"
"flower/pull/1567))"
msgstr ""
"**引入（试验性）Driver API** ([#1520](https://github.com/adap/flower/pull/"
"1520), [#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), [#1546](https://github."
"com/adap/flower/pull/1546), [#1550](https://github.com/adap/flower/pull/1550)"
", [#1551](https://github.com/adap/flower/pull/1551), [#1567](https://github."
"com/adap/flower/pull/1567))"

#: ../../source/ref-changelog.md:316
msgid ""
"Flower now has a new (experimental) Driver API which will enable fully "
"programmable, async, and multi-tenant Federated Learning and Federated "
"Analytics applications. Phew, that's a lot! Going forward, the Driver API "
"will be the abstraction that many upcoming features will be built on - and "
"you can start building those things now, too."
msgstr ""
"Flower 现在有了一个新的（试验性的）驱动程序应用程序接口（Driver "
"API），它将支持完全可编程、异步和多租户的联邦学习（Federated "
"Learning）和联邦分析（Federated Analytics）应用程序。展望未来，Driver API "
"将成为许多即将推出的功能的抽象基础，您现在就可以开始构建这些功能。"

#: ../../source/ref-changelog.md:318
msgid ""
"The Driver API also enables a new execution mode in which the server runs "
"indefinitely. Multiple individual workloads can run concurrently and start "
"and stop their execution independent of the server. This is especially "
"useful for users who want to deploy Flower in production."
msgstr ""
"驱动程序应用程序接口还支持一种新的执行模式，在这种模式下，服务器可无限期运"
"行。多个单独的工作负载可以同时运行，并独立于服务器启动和停止执行。这对于希望"
"在生产中部署 Flower 的用户来说尤其有用。"

#: ../../source/ref-changelog.md:320
msgid ""
"To learn more, check out the `mt-pytorch` code example. We look forward to "
"you feedback!"
msgstr "要了解更多信息，请查看 `mt-pytorch` 代码示例。我们期待您的反馈！"

#: ../../source/ref-changelog.md:322
msgid ""
"Please note: *The Driver API is still experimental and will likely change "
"significantly over time.*"
msgstr "请注意：Driver API仍处于试验阶段，随着时间的推移可能会发生重大变化。*"

#: ../../source/ref-changelog.md:324
msgid ""
"**Add new Federated Analytics with Pandas example** ([#1469](https://github."
"com/adap/flower/pull/1469), [#1535](https://github.com/adap/flower/"
"pull/1535))"
msgstr ""
"** 添加新的使用 Pandas 的联邦分析示例**（[#1469](https://github.com/adap/"
"flower/pull/1469), [#1535](https://github.com/adap/flower/pull/1535)"

#: ../../source/ref-changelog.md:326
msgid ""
"A new code example (`quickstart_pandas`) demonstrates federated analytics "
"with Pandas and Flower. You can find it here: [quickstart_pandas](https://"
"github.com/adap/flower/tree/main/examples/quickstart_pandas)."
msgstr ""
"新代码示例（`quickstart_pandas`）演示了使用 Pandas 和 Flower "
"进行联邦分析。您可以在此处找到它： [quickstart_pandas](https://github.com/"
"adap/flower/tree/main/examples/quickstart_pandas)。"

#: ../../source/ref-changelog.md:328
msgid ""
"**Add new strategies: Krum and MultiKrum** ([#1481](https://github.com/adap/"
"flower/pull/1481))"
msgstr ""
"**添加新策略： Krum 和 MultiKrum** ([#1481](https://github.com/adap/flower/"
"pull/1481))"

#: ../../source/ref-changelog.md:330
msgid ""
"Edoardo, a computer science student at the Sapienza University of Rome, "
"contributed a new `Krum` strategy that enables users to easily use Krum and "
"MultiKrum in their workloads."
msgstr ""
"罗马萨皮恩扎大学（Sapienza University）计算机科学专业的学生埃多尔多"
"（Edoardo）提出了一种新的 \"Krum \"策略，使用户能够在其工作负载中轻松使用 "
"Krum 和 MultiKrum。"

#: ../../source/ref-changelog.md:332
msgid ""
"**Update C++ example to be compatible with Flower v1.2.0** ([#1495](https://"
"github.com/adap/flower/pull/1495))"
msgstr ""
"** 更新 C++ 示例，与 Flower v1.2.0 兼容** ([#1495](https://github.com/adap/"
"flower/pull/1495))"

#: ../../source/ref-changelog.md:334
msgid ""
"The C++ code example has received a substantial update to make it compatible "
"with the latest version of Flower."
msgstr "为了与最新版本的 Flower 兼容，C++ 示例代码进行了大幅更新。"

#: ../../source/ref-changelog.md:336
msgid ""
"**General improvements** ([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), [#1506](https://github."
"com/adap/flower/pull/1506), [#1514](https://github.com/adap/flower/"
"pull/1514), [#1522](https://github.com/adap/flower/pull/1522), [#1523]"
"(https://github.com/adap/flower/pull/1523), [#1526](https://github.com/adap/"
"flower/pull/1526), [#1528](https://github.com/adap/flower/pull/1528), [#1547]"
"(https://github.com/adap/flower/pull/1547), [#1549](https://github.com/adap/"
"flower/pull/1549), [#1560](https://github.com/adap/flower/pull/1560), [#1564]"
"(https://github.com/adap/flower/pull/1564), [#1566](https://github.com/adap/"
"flower/pull/1566))"
msgstr ""
"**普通改进** ([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), [#1506](https://github."
"com/adap/flower/pull/1506), [#1514](https://github.com/adap/flower/pull/1514)"
", [#1522](https://github.com/adap/flower/pull/1522), [#1523](https://github."
"com/adap/flower/pull/1523), [#1526](https://github. com/adap/flower/pull/"
"1526), [#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), [#1549](https://github."
"com/adap/flower/pull/1549), [#1560](https://github.com/adap/flower/pull/1560)"
", [#1564](https://github.com/adap/flower/pull/1564), [#1566](https://github."
"com/adap/flower/pull/1566))"

#: ../../source/ref-changelog.md:340
msgid ""
"**Updated documentation** ([#1494](https://github.com/adap/flower/"
"pull/1494), [#1496](https://github.com/adap/flower/pull/1496), [#1500]"
"(https://github.com/adap/flower/pull/1500), [#1503](https://github.com/adap/"
"flower/pull/1503), [#1505](https://github.com/adap/flower/pull/1505), [#1524]"
"(https://github.com/adap/flower/pull/1524), [#1518](https://github.com/adap/"
"flower/pull/1518), [#1519](https://github.com/adap/flower/pull/1519), [#1515]"
"(https://github.com/adap/flower/pull/1515))"
msgstr ""
"** 更新文档** ([#1494](https://github.com/adap/flower/pull/1494), [#1496]"
"(https://github.com/adap/flower/pull/1496), [#1500](https://github.com/adap/"
"flower/pull/1500), [#1503](https://github.com/adap/flower/pull/1503), [#1505]"
"(https://github.com/adap/flower/pull/1505), [#1524](https://github.com/adap/"
"flower/pull/1524), [#1518](https://github.com/adap/flower/pull/1518), [#1519]"
"(https://github.com/adap/flower/pull/1519), [#1515](https://github.com/adap/"
"flower/pull/1515))"

#: ../../source/ref-changelog.md:344
msgid ""
"One highlight is the new [first time contributor guide](https://flower.dev/"
"docs/first-time-contributors.html): if you've never contributed on GitHub "
"before, this is the perfect place to start!"
msgstr ""
"其中一个亮点是新的[首次贡献者指南](https://flower.dev/docs/first-time-"
"contributors.html)：如果你以前从未在 GitHub 上做过贡献，这将是一个完美的开"
"始！"

#: ../../source/ref-changelog.md:350
msgid "v1.1.0 (2022-10-31)"
msgstr "v1.1.0 (2022-10-31)"

#: ../../source/ref-changelog.md:354
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made the new version of Flower possible (in `git shortlog` order):"
msgstr ""
"在此，我们向所有促成 Flower 新版本的贡献者致以**特别的谢意（按 \"git "
"shortlog \"顺序排列）："

#: ../../source/ref-changelog.md:356
msgid ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, `danielnugraha`, "
"`edogab33`"
msgstr ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, `danielnugraha`, "
"`edogab33`"

#: ../../source/ref-changelog.md:360
msgid ""
"**Introduce Differential Privacy wrappers (preview)** ([#1357](https://"
"github.com/adap/flower/pull/1357), [#1460](https://github.com/adap/flower/"
"pull/1460))"
msgstr ""
"**引入差分隐私包装器（预览）** ([#1357](https://github.com/adap/flower/"
"pull/1357), [#1460](https://github.com/adap/flower/pull/1460))"

#: ../../source/ref-changelog.md:362
msgid ""
"The first (experimental) preview of pluggable Differential Privacy wrappers "
"enables easy configuration and usage of differential privacy (DP). The "
"pluggable DP wrappers enable framework-agnostic **and** strategy-agnostic "
"usage of both client-side DP and server-side DP. Head over to the Flower "
"docs, a new explainer goes into more detail."
msgstr ""
"可插拔差分隐私封装器的首个（实验性）预览版可轻松配置和使用差分隐私（DP）。可"
"插拔的差分隐私封装器可实现客户端差分隐私和服务器端差分隐私的框架无关**以及**"
"策略无关的使用。请访问 Flower 文档，新的解释器会提供更多细节。"

#: ../../source/ref-changelog.md:364
msgid ""
"**New iOS CoreML code example** ([#1289](https://github.com/adap/flower/"
"pull/1289))"
msgstr ""
"**新的 iOS CoreML 代码示例**（[#1289](https://github.com/adap/flower/"
"pull/1289)）"

#: ../../source/ref-changelog.md:366
msgid ""
"Flower goes iOS! A massive new code example shows how Flower clients can be "
"built for iOS. The code example contains both Flower iOS SDK components that "
"can be used for many tasks, and one task example running on CoreML."
msgstr ""
"Flower 进入 iOS！大量新代码示例展示了如何为 iOS 构建 Flower 客户端。该代码示"
"例包含可用于多种任务的 Flower iOS SDK 组件，以及在 CoreML 上运行的一个任务示"
"例。"

#: ../../source/ref-changelog.md:368
msgid ""
"**New FedMedian strategy** ([#1461](https://github.com/adap/flower/"
"pull/1461))"
msgstr "**新的联邦医疗策略** ([#1461](https://github.com/adap/flower/pull/1461))"

#: ../../source/ref-changelog.md:370
msgid ""
"The new `FedMedian` strategy implements Federated Median (FedMedian) by [Yin "
"et al., 2018](https://arxiv.org/pdf/1803.01498v1.pdf)."
msgstr ""
"新的 \"FedMedian \"战略实现了[Yin 等人，2018]的联邦中值（FedMedian）(https://"
"arxiv.org/pdf/1803.01498v1.pdf)。"

#: ../../source/ref-changelog.md:372
msgid ""
"**Log** `Client` **exceptions in Virtual Client Engine** ([#1493](https://"
"github.com/adap/flower/pull/1493))"
msgstr ""
"**虚拟客户端引擎中的**日志**`客户端`**异常（[#1493](https://github.com/adap/"
"flower/pull/1493)）"

#: ../../source/ref-changelog.md:374
msgid ""
"All `Client` exceptions happening in the VCE are now logged by default and "
"not just exposed to the configured `Strategy` (via the `failures` argument)."
msgstr ""
"VCE 中发生的所有 \"客户端 \"异常现在都会被默认记录下来，而不只是暴露给配置的 "
"`Strategy`（通过 `failures`参数）。"

#: ../../source/ref-changelog.md:376
msgid ""
"**Improve Virtual Client Engine internals** ([#1401](https://github.com/adap/"
"flower/pull/1401), [#1453](https://github.com/adap/flower/pull/1453))"
msgstr ""
"**改进虚拟客户端引擎内部**（[#1401](https://github.com/adap/flower/"
"pull/1401)、[#1453](https://github.com/adap/flower/pull/1453)）"

#: ../../source/ref-changelog.md:378
msgid ""
"Some internals of the Virtual Client Engine have been revamped. The VCE now "
"uses Ray 2.0 under the hood, the value type of the `client_resources` "
"dictionary changed to `float` to allow fractions of resources to be "
"allocated."
msgstr ""
"虚拟客户端引擎的部分内部结构已进行了修改。VCE 现在使用 Ray "
"2.0，\"client_resources \"字典的值类型改为 \"float\"，以允许分配分数资源。"

#: ../../source/ref-changelog.md:380
msgid ""
"**Support optional** `Client`**/**`NumPyClient` **methods in Virtual Client "
"Engine**"
msgstr "**支持虚拟客户端引擎中的可选** `Client`**/**`NumPyClient` **方法**"

#: ../../source/ref-changelog.md:382
msgid ""
"The Virtual Client Engine now has full support for optional `Client` (and "
"`NumPyClient`) methods."
msgstr "虚拟客户端引擎现在完全支持可选的 `Client`（和 `NumPyClient`）方法。"

#: ../../source/ref-changelog.md:384
msgid ""
"**Provide type information to packages using** `flwr` ([#1377](https://"
"github.com/adap/flower/pull/1377))"
msgstr ""
"**使用** `flwr`向软件包提供类型信息 ([#1377](https://github.com/adap/flower/"
"pull/1377))"

#: ../../source/ref-changelog.md:386
msgid ""
"The package `flwr` is now bundled with a `py.typed` file indicating that the "
"package is typed. This enables typing support for projects or packages that "
"use `flwr` by enabling them to improve their code using static type checkers "
"like `mypy`."
msgstr ""
"软件包 `flwr` 现在捆绑了一个 `py.typed` 文件，表明该软件包是类型化的。这样，"
"使用 `flwr` 的项目或软件包就可以使用 `mypy` 等静态类型检查器改进代码，从而获"
"得类型支持。"

#: ../../source/ref-changelog.md:388
msgid ""
"**Updated code example** ([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"
msgstr ""
"** 更新代码示例** ([#1344](https://github.com/adap/flower/pull/1344), [#1347]"
"(https://github.com/adap/flower/pull/1347))"

#: ../../source/ref-changelog.md:390
msgid ""
"The code examples covering scikit-learn and PyTorch Lightning have been "
"updated to work with the latest version of Flower."
msgstr ""
"涵盖 scikit-learn 和 PyTorch Lightning 的代码示例已更新，以便与最新版本的 "
"Flower 配合使用。"

#: ../../source/ref-changelog.md:392
msgid ""
"**Updated documentation** ([#1355](https://github.com/adap/flower/"
"pull/1355), [#1558](https://github.com/adap/flower/pull/1558), [#1379]"
"(https://github.com/adap/flower/pull/1379), [#1380](https://github.com/adap/"
"flower/pull/1380), [#1381](https://github.com/adap/flower/pull/1381), [#1332]"
"(https://github.com/adap/flower/pull/1332), [#1391](https://github.com/adap/"
"flower/pull/1391), [#1403](https://github.com/adap/flower/pull/1403), [#1364]"
"(https://github.com/adap/flower/pull/1364), [#1409](https://github.com/adap/"
"flower/pull/1409), [#1419](https://github.com/adap/flower/pull/1419), [#1444]"
"(https://github.com/adap/flower/pull/1444), [#1448](https://github.com/adap/"
"flower/pull/1448), [#1417](https://github.com/adap/flower/pull/1417), [#1449]"
"(https://github.com/adap/flower/pull/1449), [#1465](https://github.com/adap/"
"flower/pull/1465), [#1467](https://github.com/adap/flower/pull/1467))"
msgstr ""
"**更新文档** ([#1355](https://github.com/adap/flower/pull/1355), [#1558]"
"(https://github.com/adap/flower/pull/1558), [#1379](https://github.com/adap/"
"flower/pull/1379), [#1380](https://github.com/adap/flower/pull/1380), [#1381]"
"(https://github.com/adap/flower/pull/1381), [#1332](https://github.com/adap/"
"flower/pull/1332), [#1391](https://github.com/adap/flower/pull/1391), [#1403]"
"(https://github.com/adap/flower/pull/1403), [#1364](https://github. com/adap/"
"flower/pull/1364), [#1409](https://github.com/adap/flower/pull/1409), [#1419]"
"(https://github.com/adap/flower/pull/1419), [#1444](https://github.com/adap/"
"flower/pull/1444), [#1448](https://github.com/adap/flower/pull/1448), [#1417]"
"(https://github.com/adap/flower/pull/1417), [#1449](https://github.com/adap/"
"flower/pull/1449), [#1465](https://github.com/adap/flower/pull/1465), [#1467]"
"(https://github.com/adap/flower/pull/1467))"

#: ../../source/ref-changelog.md:394
msgid ""
"There have been so many documentation updates that it doesn't even make "
"sense to list them individually."
msgstr "文档更新的数量之多，甚至没有必要逐一列出。"

#: ../../source/ref-changelog.md:396
msgid ""
"**Restructured documentation** ([#1387](https://github.com/adap/flower/"
"pull/1387))"
msgstr "**重构文档**（[#1387](https://github.com/adap/flower/pull/1387)）"

#: ../../source/ref-changelog.md:398
msgid ""
"The documentation has been restructured to make it easier to navigate. This "
"is just the first step in a larger effort to make the Flower documentation "
"the best documentation of any project ever. Stay tuned!"
msgstr ""
"我们对文档进行了重组，使其更易于浏览。这只是让 Flower 文档成为所有项目中最好"
"文档的第一步。敬请期待！"

#: ../../source/ref-changelog.md:400
msgid ""
"**Open in Colab button** ([#1389](https://github.com/adap/flower/pull/1389))"
msgstr ""
"**在 Colab 中打开按钮** ([#1389](https://github.com/adap/flower/pull/1389))"

#: ../../source/ref-changelog.md:402
msgid ""
"The four parts of the Flower Federated Learning Tutorial now come with a new "
"`Open in Colab` button. No need to install anything on your local machine, "
"you can now use and learn about Flower in your browser, it's only a single "
"click away."
msgstr ""
"Flower 联邦学习教程的四个部分现在都带有一个新的 \"在 Colab 中打开 \"按钮。现"
"在，您无需在本地计算机上安装任何软件，只需点击一下，就可以在浏览器中使用和学"
"习 Flower。"

#: ../../source/ref-changelog.md:404
msgid ""
"**Improved tutorial** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), [#1472](https://github."
"com/adap/flower/pull/1472), [#1473](https://github.com/adap/flower/"
"pull/1473), [#1474](https://github.com/adap/flower/pull/1474), [#1475]"
"(https://github.com/adap/flower/pull/1475))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), [#1470]"
"(https://github.com/adap/flower/pull/1470), [#1472](https://github.com/adap/"
"flower/pull/1472), [#1473](https://github.com/adap/flower/pull/1473), [#1474]"
"(https://github.com/adap/flower/pull/1474), [#1475](https://github.com/adap/"
"flower/pull/1475)))"

#: ../../source/ref-changelog.md:406
msgid ""
"The Flower Federated Learning Tutorial has two brand-new parts covering "
"custom strategies (still WIP) and the distinction between `Client` and "
"`NumPyClient`. The existing parts one and two have also been improved (many "
"small changes and fixes)."
msgstr ""
"Flower 联邦学习教程有两个全新的部分，涉及自定义策略（仍处于 WIP 阶段）和 "
"`Client` 与 `NumPyClient` "
"之间的区别。现有的第一和第二部分也得到了改进（许多小改动和修正）。"

#: ../../source/ref-changelog.md:412
msgid "v1.0.0 (2022-07-28)"
msgstr "v1.0.0 (2022-07-28)"

#: ../../source/ref-changelog.md:414
msgid "Highlights"
msgstr "亮点"

#: ../../source/ref-changelog.md:416
msgid "Stable **Virtual Client Engine** (accessible via `start_simulation`)"
msgstr "稳定的**虚拟客户端引擎**（可通过`start_simulation`访问）"

#: ../../source/ref-changelog.md:417
msgid "All `Client`/`NumPyClient` methods are now optional"
msgstr "所有 `Client`/`NumPyClient` 方法现在都是可选的了"

#: ../../source/ref-changelog.md:418
msgid "Configurable `get_parameters`"
msgstr "可配置的`get_parameters`"

#: ../../source/ref-changelog.md:419
msgid ""
"Tons of small API cleanups resulting in a more coherent developer experience"
msgstr "对大量小型应用程序接口进行了清理，使开发人员的体验更加一致"

#: ../../source/ref-changelog.md:423
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made Flower 1.0 possible (in reverse [GitHub Contributors](https://github."
"com/adap/flower/graphs/contributors) order):"
msgstr ""
"在此，我们谨向所有促成 Flower 1.0 的贡献者致以**特别的谢意（按[GitHub 贡献者]"
"(https://github.com/adap/flower/graphs/contributors) 倒序排列）："

#: ../../source/ref-changelog.md:425
msgid ""
"[@rtaiello](https://github.com/rtaiello), [@g-pichler](https://github.com/g-"
"pichler), [@rob-luke](https://github.com/rob-luke), [@andreea-zaharia]"
"(https://github.com/andreea-zaharia), [@kinshukdua](https://github.com/"
"kinshukdua), [@nfnt](https://github.com/nfnt), [@tatiana-s](https://github."
"com/tatiana-s), [@TParcollet](https://github.com/TParcollet), [@vballoli]"
"(https://github.com/vballoli), [@negedng](https://github.com/negedng), "
"[@RISHIKESHAVAN](https://github.com/RISHIKESHAVAN), [@hei411](https://github."
"com/hei411), [@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), [@Rubiel1](https://github."
"com/Rubiel1), [@FANTOME-PAN](https://github.com/FANTOME-PAN), [@Rono-BC]"
"(https://github.com/Rono-BC), [@lbhm](https://github.com/lbhm), [@sishtiaq]"
"(https://github.com/sishtiaq), [@remde](https://github.com/remde), [@Jueun-"
"Park](https://github.com/Jueun-Park), [@architjen](https://github.com/"
"architjen), [@PratikGarai](https://github.com/PratikGarai), [@mrinaald]"
"(https://github.com/mrinaald), [@zliel](https://github.com/zliel), "
"[@MeiruiJiang](https://github.com/MeiruiJiang), [@sandracl72](https://github."
"com/sandracl72), [@gubertoli](https://github.com/gubertoli), [@Vingt100]"
"(https://github.com/Vingt100), [@MakGulati](https://github.com/MakGulati), "
"[@cozek](https://github.com/cozek), [@jafermarq](https://github.com/"
"jafermarq), [@sisco0](https://github.com/sisco0), [@akhilmathurs](https://"
"github.com/akhilmathurs), [@CanTuerk](https://github.com/CanTuerk), "
"[@mariaboerner1987](https://github.com/mariaboerner1987), [@pedropgusmao]"
"(https://github.com/pedropgusmao), [@tanertopal](https://github.com/"
"tanertopal), [@danieljanes](https://github.com/danieljanes)."
msgstr ""
"[@rtaiello](https://github.com/rtaiello), [@g-pichler](https://github.com/"
"g-pichler), [@rob-luke](https://github.com/rob-luke), [@andreea-"
"zaharia](https://github.com/andreea-zaharia), [@kinshukdua](https://github."
"com/kinshukdua), [@nfnt](https://github.com/nfnt), "
"[@tatiana-s](https://github.com/tatiana-s), [@TParcollet](https://github.com/"
"TParcollet), [@vballoli](https://github.com/vballoli), "
"[@negedng](https://github.com/negedng), [@RISHIKESHAVAN](https://github.com/"
"RISHIKESHAVAN), [@hei411](https://github.com/hei411), "
"[@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), [@Rubiel1](https://github."
"com/Rubiel1), [@FANTOME-PAN](https://github.com/FANTOME-PAN), [@Rono-"
"BC](https://github.com/Rono-BC), [@lbhm](https://github.com/lbhm), "
"[@sishtiaq](https://github.com/sishtiaq), [@remde](https://github.com/remde)"
", [@Jueun-Park](https://github.com/Jueun-Park), [@architjen](https://github."
"com/architjen), [@PratikGarai](https://github.com/PratikGarai), "
"[@mrinaald](https://github.com/mrinaald), [@zliel](https://github.com/zliel)"
", [@MeiruiJiang](https://github.com/MeiruiJiang), "
"[@sandracl72](https://github.com/sandracl72), [@gubertoli](https://github."
"com/gubertoli), [@Vingt100](https://github.com/Vingt100), "
"[@MakGulati](https://github.com/MakGulati), [@cozek](https://github.com/"
"cozek), [@jafermarq](https://github.com/jafermarq), [@sisco0](https://github."
"com/sisco0), [@akhilmathurs](https://github.com/akhilmathurs), "
"[@CanTuerk](https://github.com/CanTuerk), [@mariaboerner1987](https://github."
"com/mariaboerner1987), [@pedropgusmao](https://github.com/pedropgusmao), "
"[@tanertopal](https://github.com/tanertopal), [@danieljanes](https://github."
"com/danieljanes)."

#: ../../source/ref-changelog.md:429
msgid ""
"**All arguments must be passed as keyword arguments** ([#1338](https://"
"github.com/adap/flower/pull/1338))"
msgstr ""
"** 所有参数必须作为关键字参数传递** ([#1338](https://github.com/adap/flower/"
"pull/1338))"

#: ../../source/ref-changelog.md:431
msgid ""
"Pass all arguments as keyword arguments, positional arguments are not longer "
"supported. Code that uses positional arguments (e.g., "
"`start_client(\"127.0.0.1:8080\", FlowerClient())`) must add the keyword for "
"each positional argument (e.g., "
"`start_client(server_address=\"127.0.0.1:8080\", client=FlowerClient())`)."
msgstr ""
"以关键字参数传递所有参数，不再支持位置参数。使用位置参数的代码（例如，"
"`start_client(\"127.0.0.1:8080\", FlowerClient())`）必须为每个位置参数添加关"
"键字（例如，`start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())`）。"

#: ../../source/ref-changelog.md:433
msgid ""
"**Introduce configuration object** `ServerConfig` **in** `start_server` "
"**and** `start_simulation` ([#1317](https://github.com/adap/flower/"
"pull/1317))"
msgstr ""
"**在*** `start_server` ***和*** `start_simulation` 中引入配置对象*** "
"`ServerConfig` ([#1317](https://github.com/adap/flower/pull/1317))"

#: ../../source/ref-changelog.md:435
msgid ""
"Instead of a config dictionary `{\"num_rounds\": 3, \"round_timeout\": 600.0}"
"`, `start_server` and `start_simulation` now expect a configuration object "
"of type `flwr.server.ServerConfig`. `ServerConfig` takes the same arguments "
"that as the previous config dict, but it makes writing type-safe code easier "
"and the default parameters values more transparent."
msgstr ""
"并非配置字典`{\"num_rounds\"： 3, \"round_timeout\"： 600.0}`, `start_server`"
"和 `start_simulation`现在用一个类型为 `flwr.server."
"ServerConfig`的配置对象。`ServerConfig`接收的参数与之前的 config dict "
"相同，但它使编写类型安全代码变得更容易，默认参数值也更加透明。"

#: ../../source/ref-changelog.md:437
msgid ""
"**Rename built-in strategy parameters for clarity** ([#1334](https://github."
"com/adap/flower/pull/1334))"
msgstr ""
"**重新命名内置策略参数，使其更加清晰** ([#1334](https://github.com/adap/"
"flower/pull/1334))"

#: ../../source/ref-changelog.md:439
msgid ""
"The following built-in strategy parameters were renamed to improve "
"readability and consistency with other API's:"
msgstr "以下内置策略参数已重新命名，以提高可读性并与其他 API 保持一致："

#: ../../source/ref-changelog.md:441
msgid "`fraction_eval` --> `fraction_evaluate`"
msgstr "`fraction_eval` --> `fraction_evaluate`"

#: ../../source/ref-changelog.md:442
msgid "`min_eval_clients` --> `min_evaluate_clients`"
msgstr "`min_eval_clients` --> `min_evaluate_clients`"

#: ../../source/ref-changelog.md:443
msgid "`eval_fn` --> `evaluate_fn`"
msgstr "`eval_fn` --> `evaluate_fn`"

#: ../../source/ref-changelog.md:445
msgid ""
"**Update default arguments of built-in strategies** ([#1278](https://github."
"com/adap/flower/pull/1278))"
msgstr ""
"**更新内置策略的默认参数** ([#1278](https://github.com/adap/flower/"
"pull/1278))"

#: ../../source/ref-changelog.md:447
msgid ""
"All built-in strategies now use `fraction_fit=1.0` and "
"`fraction_evaluate=1.0`, which means they select *all* currently available "
"clients for training and evaluation. Projects that relied on the previous "
"default values can get the previous behaviour by initializing the strategy "
"in the following way:"
msgstr ""
"所有内置策略现在都使用 \"fraction_fit=1.0 \"和 \"fraction_evaluate=1.0\"，这"
"意味着它们会选择*所有*当前可用的客户端进行训练和评估。依赖以前默认值的项目可"
"以通过以下方式初始化策略，获得以前的行为："

#: ../../source/ref-changelog.md:449
msgid "`strategy = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"
msgstr "`strategy = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"

#: ../../source/ref-changelog.md:451
msgid ""
"**Add** `server_round` **to** `Strategy.evaluate` ([#1334](https://github."
"com/adap/flower/pull/1334))"
msgstr ""
"**添加*** `server_round` ***到*** `Strategy.evaluate` ([#1334](https://"
"github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:453
msgid ""
"The `Strategy` method `evaluate` now receives the current round of federated "
"learning/evaluation as the first parameter."
msgstr "`Strategy`的`evaluate` 方法现在会接收当前一轮联邦学习/评估作为第一个参数。"

#: ../../source/ref-changelog.md:455
msgid ""
"**Add** `server_round` **and** `config` **parameters to** `evaluate_fn` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""
"**将*** `server_round` **和*** `config` **参数添加到*** `evaluate_fn` "
"([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:457
msgid ""
"The `evaluate_fn` passed to built-in strategies like `FedAvg` now takes "
"three parameters: (1) The current round of federated learning/evaluation "
"(`server_round`), (2) the model parameters to evaluate (`parameters`), and "
"(3) a config dictionary (`config`)."
msgstr ""
"传递给内置策略（如 `FedAvg`）的 `evaluate_fn` 现在需要三个参数：(1) "
"当前一轮联邦学习/评估 (`server_round`)，(2) 要评估的模型参数 "
"(`parameters`)，(3) 配置字典 (`config`)。"

#: ../../source/ref-changelog.md:459
msgid ""
"**Rename** `rnd` **to** `server_round` ([#1321](https://github.com/adap/"
"flower/pull/1321))"
msgstr ""
"**重新命名** `rnd` ** to** `server_round` ([#1321](https://github.com/adap/"
"flower/pull/1321))"

#: ../../source/ref-changelog.md:461
msgid ""
"Several Flower methods and functions (`evaluate_fn`, `configure_fit`, "
"`aggregate_fit`, `configure_evaluate`, `aggregate_evaluate`) receive the "
"current round of federated learning/evaluation as their first parameter. To "
"improve reaability and avoid confusion with *random*, this parameter has "
"been renamed from `rnd` to `server_round`."
msgstr ""
"几个 Flower 方法和函数（`evaluate_fn`、`configure_fit`、`aggregate_fit`、`con"
"figure_evaluate`、`aggregate_evaluate`）的第一个参数是当前一轮的联邦学习/评估"
"。为提高可重复性并避免与 *random* 混淆，该参数已从 `rnd` 更名为 "
"`server_round`。"

#: ../../source/ref-changelog.md:463
msgid ""
"**Move** `flwr.dataset` **to** `flwr_baselines` ([#1273](https://github.com/"
"adap/flower/pull/1273))"
msgstr ""
"**移动*** `flwr.dataset` **到*** `flwr_baselines` ([#1273](https://github."
"com/adap/flower/pull/1273))"

#: ../../source/ref-changelog.md:465
msgid ""
"The experimental package `flwr.dataset` was migrated to Flower Baselines."
msgstr "实验软件包 `flwr.dataset` 已迁移至 Flower Baselines。"

#: ../../source/ref-changelog.md:467
msgid ""
"**Remove experimental strategies** ([#1280](https://github.com/adap/flower/"
"pull/1280))"
msgstr "**删除实验策略** ([#1280](https://github.com/adap/flower/pull/1280))"

#: ../../source/ref-changelog.md:469
msgid ""
"Remove unmaintained experimental strategies (`FastAndSlow`, `FedFSv0`, "
"`FedFSv1`)."
msgstr "移除未维护的试验性策略（`FastAndSlow`、`FedFSv0`、`FedFSv1`）。"

#: ../../source/ref-changelog.md:471
msgid ""
"**Rename** `Weights` **to** `NDArrays` ([#1258](https://github.com/adap/"
"flower/pull/1258), [#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"**重新命名** `Weights` **到** `NDArrays` ([#1258](https://github.com/adap/"
"flower/pull/1258), [#1259](https://github.com/adap/flower/pull/1259))"

#: ../../source/ref-changelog.md:473
msgid ""
"`flwr.common.Weights` was renamed to `flwr.common.NDArrays` to better "
"capture what this type is all about."
msgstr ""
"flwr.common.Weights \"更名为 \"flwr.common.NDArrays\"，以更好地反映该类型的含"
"义。"

#: ../../source/ref-changelog.md:475
msgid ""
"**Remove antiquated** `force_final_distributed_eval` **from** `start_server` "
"([#1258](https://github.com/adap/flower/pull/1258), [#1259](https://github."
"com/adap/flower/pull/1259))"
msgstr ""
"**从** `start_server` 中移除过时的** `force_final_distributed_eval` ([#1258]"
"(https://github.com/adap/flower/pull/1258), [#1259](https://github.com/adap/"
"flower/pull/1259))"

#: ../../source/ref-changelog.md:477
msgid ""
"The `start_server` parameter `force_final_distributed_eval` has long been a "
"historic artefact, in this release it is finally gone for good."
msgstr ""
"start_server \"参数 \"force_final_distributed_eval \"长期以来一直是个历史遗留"
"问题，在此版本中终于永远消失了。"

#: ../../source/ref-changelog.md:479
msgid ""
"**Make** `get_parameters` **configurable** ([#1242](https://github.com/adap/"
"flower/pull/1242))"
msgstr ""
"**使** `get_parameters` **可配置** ([#1242](https://github.com/adap/flower/"
"pull/1242))"

#: ../../source/ref-changelog.md:481
msgid ""
"The `get_parameters` method now accepts a configuration dictionary, just "
"like `get_properties`, `fit`, and `evaluate`."
msgstr ""
"现在，\"get_parameters \"方法与 \"get_properties\"、\"fit \"和 \"evaluate "
"\"一样，都接受配置字典。"

#: ../../source/ref-changelog.md:483
msgid ""
"**Replace** `num_rounds` **in** `start_simulation` **with new** `config` "
"**parameter** ([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""
"**用新的** `config` 参数** 替换** `num_rounds` ** in** `start_simulation` ** "
"([#1281](https://github.com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:485
msgid ""
"The `start_simulation` function now accepts a configuration dictionary "
"`config` instead of the `num_rounds` integer. This improves the consistency "
"between `start_simulation` and `start_server` and makes transitioning "
"between the two easier."
msgstr ""
"现在，`start_simulation`（开始模拟）` 函数接受配置字典 `config` 而不是 "
"`num_rounds` 整数。这改进了 `start_simulation` 和 `start_server` 之间的一致"
"性，并使两者之间的转换更容易。"

#: ../../source/ref-changelog.md:489
msgid ""
"**Support Python 3.10** ([#1320](https://github.com/adap/flower/pull/1320))"
msgstr ""
"** 支持 Python 3.10** ([#1320](https://github.com/adap/flower/pull/1320))"

#: ../../source/ref-changelog.md:491
msgid ""
"The previous Flower release introduced experimental support for Python 3.10, "
"this release declares Python 3.10 support as stable."
msgstr ""
"上一个 Flower 版本引入了对 Python 3.10 的实验支持，而本版本则宣布对 Python "
"3.10 的支持为稳定支持。"

#: ../../source/ref-changelog.md:493
msgid ""
"**Make all** `Client` **and** `NumPyClient` **methods optional** ([#1260]"
"(https://github.com/adap/flower/pull/1260), [#1277](https://github.com/adap/"
"flower/pull/1277))"
msgstr ""
"**使所有** `Client` **和** `NumPyClient` **方法成为可选** ([#1260](https://"
"github.com/adap/flower/pull/1260), [#1277](https://github.com/adap/flower/"
"pull/1277))"

#: ../../source/ref-changelog.md:495
msgid ""
"The `Client`/`NumPyClient` methods `get_properties`, `get_parameters`, "
"`fit`, and `evaluate` are all optional. This enables writing clients that "
"implement, for example, only `fit`, but no other method. No need to "
"implement `evaluate` when using centralized evaluation!"
msgstr ""
"`Client`/`NumPyClient`的 \"get_properties\"、\"get_parameters\"、\"fit \"和 "
"\"evaluate \"方法都是可选的。这样就可以编写只实现 `fit` "
"而不实现其他方法的客户端。使用集中评估时，无需实现 `evaluate`！"

#: ../../source/ref-changelog.md:497
msgid ""
"**Enable passing a** `Server` **instance to** `start_simulation` ([#1281]"
"(https://github.com/adap/flower/pull/1281))"
msgstr ""
"**启用向** `start_simulation` 传递** `Server` 实例 ([#1281](https://github."
"com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:499
msgid ""
"Similar to `start_server`, `start_simulation` now accepts a full `Server` "
"instance. This enables users to heavily customize the execution of "
"eperiments and opens the door to running, for example, async FL using the "
"Virtual Client Engine."
msgstr ""
"与 `start_server` 类似，`start_simulation` 现在也接受一个完整的 `Server` 实"
"例。这使得用户可以对实验的执行进行大量自定义，并为使用虚拟客户端引擎运行异步 "
"FL 等打开了大门。"

#: ../../source/ref-changelog.md:501
msgid ""
"**Update code examples** ([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), [#1282](https://github."
"com/adap/flower/pull/1282))"
msgstr ""
"**更新代码示例** ([#1291](https://github.com/adap/flower/pull/1291), [#1286]"
"(https://github.com/adap/flower/pull/1286), [#1282](https://github.com/adap/"
"flower/pull/1282))"

#: ../../source/ref-changelog.md:503
msgid ""
"Many code examples received small or even large maintenance updates, among "
"them are"
msgstr "许多代码示例都进行了小规模甚至大规模的维护更新，其中包括"

#: ../../source/ref-changelog.md:505
msgid "`scikit-learn`"
msgstr "`scikit-learn`"

#: ../../source/ref-changelog.md:506
msgid "`simulation_pytorch`"
msgstr "`simulation_pytorch`"

#: ../../source/ref-changelog.md:507
msgid "`quickstart_pytorch`"
msgstr "`quickstart_pytorch`"

#: ../../source/ref-changelog.md:508
msgid "`quickstart_simulation`"
msgstr "`quickstart_simulation`"

#: ../../source/ref-changelog.md:509
msgid "`quickstart_tensorflow`"
msgstr "`quickstart_tensorflow`"

#: ../../source/ref-changelog.md:510
msgid "`advanced_tensorflow`"
msgstr "`advanced_tensorflow`"

#: ../../source/ref-changelog.md:512
msgid ""
"**Remove the obsolete simulation example** ([#1328](https://github.com/adap/"
"flower/pull/1328))"
msgstr ""
"**删除过时的模拟示例** ([#1328](https://github.com/adap/flower/pull/1328))"

#: ../../source/ref-changelog.md:514
msgid ""
"Removes the obsolete `simulation` example and renames "
"`quickstart_simulation` to `simulation_tensorflow` so it fits withs the "
"naming of `simulation_pytorch`"
msgstr ""
"删除过时的 \"simulation \"示例，并将 \"quickstart_simulation \"重命名为 "
"\"simulation_tensorflow\"，使其与 \"simulation_pytorch \"的命名一致"

#: ../../source/ref-changelog.md:516
msgid ""
"**Update documentation** ([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), [#1251](https://github."
"com/adap/flower/pull/1251), [#1257](https://github.com/adap/flower/"
"pull/1257), [#1267](https://github.com/adap/flower/pull/1267), [#1268]"
"(https://github.com/adap/flower/pull/1268), [#1300](https://github.com/adap/"
"flower/pull/1300), [#1304](https://github.com/adap/flower/pull/1304), [#1305]"
"(https://github.com/adap/flower/pull/1305), [#1307](https://github.com/adap/"
"flower/pull/1307))"
msgstr ""
"**更新文档** ([#1223](https://github.com/adap/flower/pull/1223), [#1209]"
"(https://github.com/adap/flower/pull/1209), [#1251](https://github.com/adap/"
"flower/pull/1251), [#1257](https://github.com/adap/flower/pull/1257), [#1267]"
"(https://github.com/adap/flower/pull/1267), [#1268](https://github.com/adap/"
"flower/pull/1268), [#1300](https://github.com/adap/flower/pull/1300), [#1304]"
"(https://github.com/adap/flower/pull/1304), [#1305](https://github.com/adap/"
"flower/pull/1305), [#1307](https://github.com/adap/flower/pull/1307))"

#: ../../source/ref-changelog.md:518
msgid ""
"One substantial documentation update fixes multiple smaller rendering "
"issues, makes titles more succinct to improve navigation, removes a "
"deprecated library, updates documentation dependencies, includes the `flwr."
"common` module in the API reference, includes support for markdown-based "
"documentation, migrates the changelog from `.rst` to `.md`, and fixes a "
"number of smaller details!"
msgstr ""
"其中一个实质性的文档更新修复了多个较小的渲染问题，使标题更加简洁以改善导航，"
"删除了一个已废弃的库，更新了文档依赖关系，在 API 参考中包含了 `flwr.common` "
"模块，包含了对基于 markdown 的文档的支持，将更新日志从 `.rst` 移植到了 `."
"md`，并修复了一些较小的细节！"

#: ../../source/ref-changelog.md:520 ../../source/ref-changelog.md:575
#: ../../source/ref-changelog.md:644 ../../source/ref-changelog.md:683
msgid "**Minor updates**"
msgstr "**小规模更新**"

#: ../../source/ref-changelog.md:522
msgid ""
"Add round number to fit and evaluate log messages ([#1266](https://github."
"com/adap/flower/pull/1266))"
msgstr ""
"添加四舍五入数字，以适应和评估日志信息（[#1266](https://github.com/adap/"
"flower/pull/1266)）"

#: ../../source/ref-changelog.md:523
msgid ""
"Add secure gRPC connection to the `advanced_tensorflow` code example ([#847]"
"(https://github.com/adap/flower/pull/847))"
msgstr ""
"为 `advanced_tensorflow` 代码示例添加安全 gRPC 连接 ([#847](https://github."
"com/adap/flower/pull/847))"

#: ../../source/ref-changelog.md:524
msgid ""
"Update developer tooling ([#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), [#1301](https://github."
"com/adap/flower/pull/1301), [#1310](https://github.com/adap/flower/"
"pull/1310))"
msgstr ""
"更新开发人员工具（[#1231](https://github.com/adap/flower/pull/1231), [#1276]"
"(https://github.com/adap/flower/pull/1276), [#1301](https://github.com/adap/"
"flower/pull/1301), [#1310](https://github.com/adap/flower/pull/1310)"

#: ../../source/ref-changelog.md:525
msgid ""
"Rename ProtoBuf messages to improve consistency ([#1214](https://github.com/"
"adap/flower/pull/1214), [#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"重命名 ProtoBuf 消息以提高一致性（[#1214](https://github.com/adap/flower/"
"pull/1214), [#1258](https://github.com/adap/flower/pull/1258), [#1259]"
"(https://github.com/adap/flower/pull/1259)"

#: ../../source/ref-changelog.md:527
msgid "v0.19.0 (2022-05-18)"
msgstr "v0.19.0 (2022-05-18)"

#: ../../source/ref-changelog.md:531
msgid ""
"**Flower Baselines (preview): FedOpt, FedBN, FedAvgM** ([#919](https://"
"github.com/adap/flower/pull/919), [#1127](https://github.com/adap/flower/"
"pull/1127), [#914](https://github.com/adap/flower/pull/914))"
msgstr ""
"**Flower Baselines（预览）： FedOpt、FedBN、FedAvgM** ([#919](https://github."
"com/adap/flower/pull/919), [#1127](https://github.com/adap/flower/pull/1127)"
", [#914](https://github.com/adap/flower/pull/914))"

#: ../../source/ref-changelog.md:533
msgid ""
"The first preview release of Flower Baselines has arrived! We're "
"kickstarting Flower Baselines with implementations of FedOpt (FedYogi, "
"FedAdam, FedAdagrad), FedBN, and FedAvgM. Check the documentation on how to "
"use [Flower Baselines](https://flower.dev/docs/using-baselines.html). With "
"this first preview release we're also inviting the community to [contribute "
"their own baselines](https://flower.dev/docs/contributing-baselines.html)."
msgstr ""
"Flower Baselines 的第一个预览版已经发布！我们通过实现 "
"FedOpt（FedYogi、FedAdam、FedAdagrad）、FedBN 和 FedAvgM 来启动 Flower "
"Baselines。请查阅文档了解如何使用 [Flower Baselines](https://flower.dev/docs/"
"using-baselines.html)。在首次发布预览版时，我们还邀请社区成员[贡献自己的Basel"
"ines](https://flower.dev/docs/contributing-baselines.html)。"

#: ../../source/ref-changelog.md:535
msgid ""
"**C++ client SDK (preview) and code example** ([#1111](https://github.com/"
"adap/flower/pull/1111))"
msgstr ""
"**C++客户端SDK（预览版）和代码示例**（[#1111](https://github.com/adap/flower/"
"pull/1111)）"

#: ../../source/ref-changelog.md:537
msgid ""
"Preview support for Flower clients written in C++. The C++ preview includes "
"a Flower client SDK and a quickstart code example that demonstrates a simple "
"C++ client using the SDK."
msgstr ""
"预览版支持用 C++ 编写的 Flower 客户端。C++ 预览版包括一个 Flower 客户端 SDK "
"和一个快速入门代码示例，使用 SDK 演示了一个简单的 C++ 客户端。"

#: ../../source/ref-changelog.md:539
msgid ""
"**Add experimental support for Python 3.10 and Python 3.11** ([#1135]"
"(https://github.com/adap/flower/pull/1135))"
msgstr ""
"** 增加对 Python 3.10 和 Python 3.11 的实验支持** ([#1135](https://github."
"com/adap/flower/pull/1135))"

#: ../../source/ref-changelog.md:541
msgid ""
"Python 3.10 is the latest stable release of Python and Python 3.11 is due to "
"be released in October. This Flower release adds experimental support for "
"both Python versions."
msgstr ""
"Python 3.10 是 Python 的最新稳定版本，Python 3.11 将于 10 月份发布。Flower 版"
"本增加了对这两个 Python 版本的实验支持。"

#: ../../source/ref-changelog.md:543
msgid ""
"**Aggregate custom metrics through user-provided functions** ([#1144]"
"(https://github.com/adap/flower/pull/1144))"
msgstr ""
"**通过用户提供的函数聚合自定义指标**（[#1144](https://github.com/adap/flower/"
"pull/1144)）"

#: ../../source/ref-changelog.md:545
msgid ""
"Custom metrics (e.g., `accuracy`) can now be aggregated without having to "
"customize the strategy. Built-in strategies support two new arguments, "
"`fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`, that "
"allow passing custom metric aggregation functions."
msgstr ""
"现在无需定制策略即可聚合自定义度量（如`准确度`）。内置策略支持两个新参数："
"`fit_metrics_aggregation_fn` 和`evaluate_metrics_aggregation_fn`，允许传递自"
"定义度量聚合函数。"

#: ../../source/ref-changelog.md:547
msgid ""
"**User-configurable round timeout** ([#1162](https://github.com/adap/flower/"
"pull/1162))"
msgstr ""
"**用户可配置的回合超时**（[#1162](https://github.com/adap/flower/pull/1162)）"

#: ../../source/ref-changelog.md:549
msgid ""
"A new configuration value allows the round timeout to be set for "
"`start_server` and `start_simulation`. If the `config` dictionary contains a "
"`round_timeout` key (with a `float` value in seconds), the server will wait "
"*at least* `round_timeout` seconds before it closes the connection."
msgstr ""
"新的配置值允许为 `start_server` 和 `start_simulation` 设置回合超时。如果 "
"`config` 字典中包含一个 `round_timeout` 键（以秒为单位的 `float`值），服务器"
"将至少等待 ** `round_timeout` 秒后才关闭连接。"

#: ../../source/ref-changelog.md:551
msgid ""
"**Enable both federated evaluation and centralized evaluation to be used at "
"the same time in all built-in strategies** ([#1091](https://github.com/adap/"
"flower/pull/1091))"
msgstr ""
"**允许在所有内置策略中同时使用联邦评价和集中评估** ([#1091](https://github."
"com/adap/flower/pull/1091))"

#: ../../source/ref-changelog.md:553
msgid ""
"Built-in strategies can now perform both federated evaluation (i.e., client-"
"side) and centralized evaluation (i.e., server-side) in the same round. "
"Federated evaluation can be disabled by setting `fraction_eval` to `0.0`."
msgstr ""
"内置策略现在可以在同一轮中同时执行联邦评估（即客户端）和集中评估（即服务器端"
"）。可以通过将 `fraction_eval` 设置为 `0.0`来禁用联邦评估。"

#: ../../source/ref-changelog.md:555
msgid ""
"**Two new Jupyter Notebook tutorials** ([#1141](https://github.com/adap/"
"flower/pull/1141))"
msgstr ""
"**两本新的 Jupyter Notebook 教程** ([#1141](https://github.com/adap/flower/"
"pull/1141))"

#: ../../source/ref-changelog.md:557
msgid ""
"Two Jupyter Notebook tutorials (compatible with Google Colab) explain basic "
"and intermediate Flower features:"
msgstr ""
"两本 Jupyter Notebook 教程（与 Google Colab 兼容）介绍了 Flower 的基本和中级"
"功能："

#: ../../source/ref-changelog.md:559
msgid ""
"*An Introduction to Federated Learning*: [Open in Colab](https://colab."
"research.google.com/github/adap/flower/blob/main/tutorials/Flower-1-Intro-to-"
"FL-PyTorch.ipynb)"
msgstr ""
"*联邦学习简介*： [在 Colab 中打开](https://colab.research.google.com/github/"
"adap/flower/blob/main/tutorials/Flower-1-Intro-to-FL-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:561
msgid ""
"*Using Strategies in Federated Learning*: [Open in Colab](https://colab."
"research.google.com/github/adap/flower/blob/main/tutorials/Flower-2-"
"Strategies-in-FL-PyTorch.ipynb)"
msgstr ""
"*在联邦学习中使用策略*： [在 Colab 中打开](https://colab.research.google.com/"
"github/adap/flower/blob/main/tutorials/Flower-2-Strategies-in-FL-PyTorch."
"ipynb)"

#: ../../source/ref-changelog.md:563
msgid ""
"**New FedAvgM strategy (Federated Averaging with Server Momentum)** ([#1076]"
"(https://github.com/adap/flower/pull/1076))"
msgstr ""
"**新的 FedAvgM 策略（带服务器动量的联邦平均）** ([#1076](https://github.com/"
"adap/flower/pull/1076))"

#: ../../source/ref-changelog.md:565
msgid ""
"The new `FedAvgM` strategy implements Federated Averaging with Server "
"Momentum \\[Hsu et al., 2019\\]."
msgstr "新的 \"FedAvgM \"策略实现了带服务器动量的联邦平均[Hsu et al., 2019\\]."

#: ../../source/ref-changelog.md:567
msgid ""
"**New advanced PyTorch code example** ([#1007](https://github.com/adap/"
"flower/pull/1007))"
msgstr ""
"**新的 PyTorch 高级代码示例** ([#1007](https://github.com/adap/flower/"
"pull/1007))"

#: ../../source/ref-changelog.md:569
msgid ""
"A new code example (`advanced_pytorch`) demonstrates advanced Flower "
"concepts with PyTorch."
msgstr "新代码示例 (`advanced_pytorch`) 演示了 PyTorch 的高级 Flower 概念。"

#: ../../source/ref-changelog.md:571
msgid ""
"**New JAX code example** ([#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143))"
msgstr ""
"**新的 JAX 代码示例**（[#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143)"

#: ../../source/ref-changelog.md:573
msgid ""
"A new code example (`jax_from_centralized_to_federated`) shows federated "
"learning with JAX and Flower."
msgstr ""
"新代码示例（`jax_from_centralized_to_federated`）展示了使用 JAX 和 Flower 的"
"联邦学习。"

#: ../../source/ref-changelog.md:577
msgid ""
"New option to keep Ray running if Ray was already initialized in "
"`start_simulation` ([#1177](https://github.com/adap/flower/pull/1177))"
msgstr ""
"新增选项，用于在 \"start_simulation\"（开始模拟）中已初始化 Ray 的情况下保持 "
"Ray 运行（[#1177](https://github.com/adap/flower/pull/1177)）"

#: ../../source/ref-changelog.md:578
msgid ""
"Add support for custom `ClientManager` as a `start_simulation` parameter "
"([#1171](https://github.com/adap/flower/pull/1171))"
msgstr ""
"添加对自定义 \"客户端管理器 \"作为 \"start_simulation \"参数的支持（[#1171]"
"(https://github.com/adap/flower/pull/1171)）"

#: ../../source/ref-changelog.md:579
msgid ""
"New documentation for [implementing strategies](https://flower.dev/docs/"
"framework/how-to-implement-strategies.html) ([#1097](https://github.com/adap/"
"flower/pull/1097), [#1175](https://github.com/adap/flower/pull/1175))"
msgstr ""
"[实施战略](https://flower.dev/docs/framework/how-to-implement-strategies."
"html) 的新文件（[#1097](https://github.com/adap/flower/pull/1097), "
"[#1175](https://github.com/adap/flower/pull/1175)"

#: ../../source/ref-changelog.md:580
msgid ""
"New mobile-friendly documentation theme ([#1174](https://github.com/adap/"
"flower/pull/1174))"
msgstr ""
"新的移动友好型文档主题 ([#1174](https://github.com/adap/flower/pull/1174))"

#: ../../source/ref-changelog.md:581
msgid ""
"Limit version range for (optional) `ray` dependency to include only "
"compatible releases (`>=1.9.2,<1.12.0`) ([#1205](https://github.com/adap/"
"flower/pull/1205))"
msgstr ""
"限制（可选）`ray`依赖的版本范围，使其仅包含兼容版本（`>=1.9.2,<1.12.0`） "
"([#1205](https://github.com/adap/flower/pull/1205))"

#: ../../source/ref-changelog.md:585
msgid ""
"**Remove deprecated support for Python 3.6** ([#871](https://github.com/adap/"
"flower/pull/871))"
msgstr ""
"**删除对 Python 3.6 的过时支持** ([#871](https://github.com/adap/flower/"
"pull/871))"

#: ../../source/ref-changelog.md:586
msgid ""
"**Remove deprecated KerasClient** ([#857](https://github.com/adap/flower/"
"pull/857))"
msgstr ""
"**移除过时的 KerasClient**（[#857](https://github.com/adap/flower/pull/857)）"

#: ../../source/ref-changelog.md:587
msgid ""
"**Remove deprecated no-op extra installs** ([#973](https://github.com/adap/"
"flower/pull/973))"
msgstr ""
"**移除过时的不操作额外安装** ([#973](https://github.com/adap/flower/"
"pull/973))"

#: ../../source/ref-changelog.md:588
msgid ""
"**Remove deprecated proto fields from** `FitRes` **and** `EvaluateRes` "
"([#869](https://github.com/adap/flower/pull/869))"
msgstr ""
"**从** `FitRes` **和** `EvaluateRes` 中移除已废弃的 proto 字段 ([#869]"
"(https://github.com/adap/flower/pull/869))"

#: ../../source/ref-changelog.md:589
msgid ""
"**Remove deprecated QffedAvg strategy (replaced by QFedAvg)** ([#1107]"
"(https://github.com/adap/flower/pull/1107))"
msgstr ""
"**移除过时的 QffedAvg 策略（由 QFedAvg 取代）** ([#1107](https://github.com/"
"adap/flower/pull/1107))"

#: ../../source/ref-changelog.md:590
msgid ""
"**Remove deprecated DefaultStrategy strategy** ([#1142](https://github.com/"
"adap/flower/pull/1142))"
msgstr ""
"**删除过时的 DefaultStrategy 策略** ([#1142](https://github.com/adap/flower/"
"pull/1142))"

#: ../../source/ref-changelog.md:591
msgid ""
"**Remove deprecated support for eval_fn accuracy return value** ([#1142]"
"(https://github.com/adap/flower/pull/1142))"
msgstr ""
"**删除已过时的对 eval_fn 返回值准确性的支持** ([#1142](https://github.com/"
"adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:592
msgid ""
"**Remove deprecated support for passing initial parameters as NumPy "
"ndarrays** ([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**移除对以 NumPy ndarrays 传递初始参数的过时支持** ([#1142](https://github."
"com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:594
msgid "v0.18.0 (2022-02-28)"
msgstr "v0.18.0 (2022-02-28)"

#: ../../source/ref-changelog.md:598
msgid ""
"**Improved Virtual Client Engine compatibility with Jupyter Notebook / "
"Google Colab** ([#866](https://github.com/adap/flower/pull/866), [#872]"
"(https://github.com/adap/flower/pull/872), [#833](https://github.com/adap/"
"flower/pull/833), [#1036](https://github.com/adap/flower/pull/1036))"
msgstr ""
"**改进了虚拟客户端引擎与 Jupyter Notebook / Google Colab 的兼容性** ([#866]"
"(https://github.com/adap/flower/pull/866), [#872](https://github.com/adap/"
"flower/pull/872), [#833](https://github.com/adap/flower/pull/833), [#1036]"
"(https://github.com/adap/flower/pull/1036))"

#: ../../source/ref-changelog.md:600
msgid ""
"Simulations (using the Virtual Client Engine through `start_simulation`) now "
"work more smoothly on Jupyter Notebooks (incl. Google Colab) after "
"installing Flower with the `simulation` extra (`pip install "
"flwr[simulation]`)."
msgstr ""
"通过 `start_simulation` 在 Jupyter 笔记本（包括 Google Colab）上安装 Flower "
"并附加 `simulation` (`pip install flwr[simulation]`)后，模拟（通过 "
"`start_simulation` 使用虚拟客户端引擎）现在可以更流畅地运行。"

#: ../../source/ref-changelog.md:602
msgid ""
"**New Jupyter Notebook code example** ([#833](https://github.com/adap/flower/"
"pull/833))"
msgstr ""
"**新的 Jupyter Notebook 代码示例** ([#833](https://github.com/adap/flower/"
"pull/833))"

#: ../../source/ref-changelog.md:604
msgid ""
"A new code example (`quickstart_simulation`) demonstrates Flower simulations "
"using the Virtual Client Engine through Jupyter Notebook (incl. Google "
"Colab)."
msgstr ""
"新代码示例（`quickstart_simulation`）通过 Jupyter Notebook（包括 Google "
"Colab）演示了使用虚拟客户端引擎进行 Flower 模拟。"

#: ../../source/ref-changelog.md:606
msgid ""
"**Client properties (feature preview)** ([#795](https://github.com/adap/"
"flower/pull/795))"
msgstr ""
"**客户端属性（功能预览）** ([#795](https://github.com/adap/flower/pull/795))"

#: ../../source/ref-changelog.md:608
msgid ""
"Clients can implement a new method `get_properties` to enable server-side "
"strategies to query client properties."
msgstr ""
"客户端可以实现一个新方法 `get_properties`，以启用服务器端策略来查询客户端属"
"性。"

#: ../../source/ref-changelog.md:610
msgid ""
"**Experimental Android support with TFLite** ([#865](https://github.com/adap/"
"flower/pull/865))"
msgstr ""
"** 使用 TFLite 实验性支持安卓系统** ([#865](https://github.com/adap/flower/"
"pull/865))"

#: ../../source/ref-changelog.md:612
msgid ""
"Android support has finally arrived in `main`! Flower is both client-"
"agnostic and framework-agnostic by design. One can integrate arbitrary "
"client platforms and with this release, using Flower on Android has become a "
"lot easier."
msgstr ""
"`main`终于支持 Android 了！Flower "
"的设计与客户端和框架无关。我们可以集成任意客户端平台，有了这个版本，"
"在安卓系统上使用 Flower 就变得更容易了。"

#: ../../source/ref-changelog.md:614
msgid ""
"The example uses TFLite on the client side, along with a new `FedAvgAndroid` "
"strategy. The Android client and `FedAvgAndroid` are still experimental, but "
"they are a first step towards a fully-fledged Android SDK and a unified "
"`FedAvg` implementation that integrated the new functionality from "
"`FedAvgAndroid`."
msgstr ""
"该示例在客户端使用了 TFLite 以及新的 `FedAvgAndroid`策略。Android 客户端和 "
"`FedAvgAndroid`仍处于试验阶段，但这是向成熟的 Android SDK 和集成了 "
"`FedAvgAndroid`新功能的统一 `FedAvg`实现迈出的第一步。"

#: ../../source/ref-changelog.md:616
msgid ""
"**Make gRPC keepalive time user-configurable and decrease default keepalive "
"time** ([#1069](https://github.com/adap/flower/pull/1069))"
msgstr ""
"**使 gRPC 保持连接时间可由用户配置，并缩短默认保持连接时间** ([#1069]"
"(https://github.com/adap/flower/pull/1069))"

#: ../../source/ref-changelog.md:618
msgid ""
"The default gRPC keepalive time has been reduced to increase the "
"compatibility of Flower with more cloud environments (for example, Microsoft "
"Azure). Users can configure the keepalive time to customize the gRPC stack "
"based on specific requirements."
msgstr ""
"为提高 Flower 与更多云环境（如 Microsoft Azure）的兼容性，缩短了默认 gRPC 保"
"持时间。用户可以根据具体要求配置 keepalive 时间，自定义 gRPC 堆栈。"

#: ../../source/ref-changelog.md:620
msgid ""
"**New differential privacy example using Opacus and PyTorch** ([#805]"
"(https://github.com/adap/flower/pull/805))"
msgstr ""
"**使用 Opacus 和 PyTorch 的新差分隐私示例** ([#805](https://github.com/adap/"
"flower/pull/805))"

#: ../../source/ref-changelog.md:622
msgid ""
"A new code example (`opacus`) demonstrates differentially-private federated "
"learning with Opacus, PyTorch, and Flower."
msgstr "一个新的代码示例（\"opacus\"）演示了使用 Opacus、PyTorch 和 Flower "
"进行差分隐私的联邦学习。"

#: ../../source/ref-changelog.md:624
msgid ""
"**New Hugging Face Transformers code example** ([#863](https://github.com/"
"adap/flower/pull/863))"
msgstr ""
"**新的Hugging Face Transformers代码示例** ([#863](https://github.com/adap/"
"flower/pull/863))"

#: ../../source/ref-changelog.md:626
msgid ""
"A new code example (`quickstart_huggingface`) demonstrates usage of Hugging "
"Face Transformers with Flower."
msgstr ""
"新的代码示例(`quickstart_huggingface`)证明了结合Flower和Hugging Face "
"Transformers的实用性。"

#: ../../source/ref-changelog.md:628
msgid ""
"**New MLCube code example** ([#779](https://github.com/adap/flower/"
"pull/779), [#1034](https://github.com/adap/flower/pull/1034), [#1065]"
"(https://github.com/adap/flower/pull/1065), [#1090](https://github.com/adap/"
"flower/pull/1090))"
msgstr ""
"**新的 MLCube 代码示例** ([#779](https://github.com/adap/flower/pull/779), "
"[#1034](https://github.com/adap/flower/pull/1034), [#1065](https://github."
"com/adap/flower/pull/1065), [#1090](https://github.com/adap/flower/"
"pull/1090))"

#: ../../source/ref-changelog.md:630
msgid ""
"A new code example (`quickstart_mlcube`) demonstrates usage of MLCube with "
"Flower."
msgstr "新代码示例（\"quickstart_mlcube\"）演示了 MLCube 与 Flower 的用法。"

#: ../../source/ref-changelog.md:632
msgid ""
"**SSL-enabled server and client** ([#842](https://github.com/adap/flower/"
"pull/842),  [#844](https://github.com/adap/flower/pull/844),  [#845](https://"
"github.com/adap/flower/pull/845), [#847](https://github.com/adap/flower/"
"pull/847), [#993](https://github.com/adap/flower/pull/993), [#994](https://"
"github.com/adap/flower/pull/994))"
msgstr ""
"** 支持 SSL 的服务器和客户端** ([#842](https://github.com/adap/flower/"
"pull/842), [#844](https://github.com/adap/flower/pull/844), [#845](https://"
"github.com/adap/flower/pull/845), [#847](https://github.com/adap/flower/"
"pull/847), [#993](https://github.com/adap/flower/pull/993), [#994](https://"
"github.com/adap/flower/pull/994))"

#: ../../source/ref-changelog.md:634
msgid ""
"SSL enables secure encrypted connections between clients and servers. This "
"release open-sources the Flower secure gRPC implementation to make encrypted "
"communication channels accessible to all Flower users."
msgstr ""
"SSL 可实现客户端与服务器之间的安全加密连接。该版本开源了 Flower 安全 gRPC 实"
"现，使所有 Flower 用户都能访问加密通信通道。"

#: ../../source/ref-changelog.md:636
msgid ""
"**Updated** `FedAdam` **and** `FedYogi` **strategies** ([#885](https://"
"github.com/adap/flower/pull/885), [#895](https://github.com/adap/flower/"
"pull/895))"
msgstr ""
"**更新**`FedAdam`**和**`FedYogi`**战略** ([#885](https://github.com/adap/"
"flower/pull/885), [#895](https://github.com/adap/flower/pull/895))"

#: ../../source/ref-changelog.md:638
msgid ""
"`FedAdam` and `FedAdam` match the latest version of the Adaptive Federated "
"Optimization paper."
msgstr "FedAdam \"和 \"FedAdam \"与最新版本的 \"自适应联邦优化 \"论文相匹配。"

#: ../../source/ref-changelog.md:640
msgid ""
"**Initialize** `start_simulation` **with a list of client IDs** ([#860]"
"(https://github.com/adap/flower/pull/860))"
msgstr ""
"**初始化** `start_simulation` **使用客户端 ID 列表** ([#860](https://github."
"com/adap/flower/pull/860))"

#: ../../source/ref-changelog.md:642
msgid ""
"`start_simulation` can now be called with a list of client IDs "
"(`clients_ids`, type: `List[str]`). Those IDs will be passed to the "
"`client_fn` whenever a client needs to be initialized, which can make it "
"easier to load data partitions that are not accessible through `int` "
"identifiers."
msgstr ""
"现在可以使用客户端 ID 列表（`clients_ids`，类型：`List[str]`）调用 "
"`start_simulation`。每当需要初始化客户端时，这些 ID 就会被传递到 `client_fn` "
"中，这样就能更轻松地加载无法通过 `int` 标识符访问的数据分区。"

#: ../../source/ref-changelog.md:646
msgid ""
"Update `num_examples` calculation in PyTorch code examples in ([#909]"
"(https://github.com/adap/flower/pull/909))"
msgstr ""
"更新 PyTorch 代码示例中的 \"num_examples \"计算 ([#909](https://github.com/"
"adap/flower/pull/909))"

#: ../../source/ref-changelog.md:647
msgid ""
"Expose Flower version through `flwr.__version__` ([#952](https://github.com/"
"adap/flower/pull/952))"
msgstr ""
"通过 `flwr.__version__` 公开 Flower 版本 ([#952](https://github.com/adap/"
"flower/pull/952))"

#: ../../source/ref-changelog.md:648
msgid ""
"`start_server` in `app.py` now returns a `History` object containing metrics "
"from training ([#974](https://github.com/adap/flower/pull/974))"
msgstr ""
"`app.py`中的 `start_server`现在会返回一个 `History` "
"对象，其中包含训练中的指标（[#974](https://github.com/adap/flower/pull/974)）"

#: ../../source/ref-changelog.md:649
msgid ""
"Make `max_workers` (used by `ThreadPoolExecutor`) configurable ([#978]"
"(https://github.com/adap/flower/pull/978))"
msgstr ""
"使 `max_workers`（由 `ThreadPoolExecutor`使用）可配置（[#978](https://github."
"com/adap/flower/pull/978)）"

#: ../../source/ref-changelog.md:650
msgid ""
"Increase sleep time after server start to three seconds in all code examples "
"([#1086](https://github.com/adap/flower/pull/1086))"
msgstr ""
"在所有代码示例中，将服务器启动后的休眠时间延长至三秒（[#1086](https://github."
"com/adap/flower/pull/1086)）"

#: ../../source/ref-changelog.md:651
msgid ""
"Added a new FAQ section to the documentation ([#948](https://github.com/adap/"
"flower/pull/948))"
msgstr ""
"在文档中添加了新的常见问题部分 ([#948](https://github.com/adap/flower/"
"pull/948))"

#: ../../source/ref-changelog.md:652
msgid ""
"And many more under-the-hood changes, library updates, documentation "
"changes, and tooling improvements!"
msgstr "还有更多底层更改、库更新、文档更改和工具改进！"

#: ../../source/ref-changelog.md:656
msgid ""
"**Removed** `flwr_example` **and** `flwr_experimental` **from release "
"build** ([#869](https://github.com/adap/flower/pull/869))"
msgstr ""
"**从发布版中删除**`flwr_example`**和**`flwr_experimental`** ([#869](https://"
"github.com/adap/flower/pull/869))"

#: ../../source/ref-changelog.md:658
msgid ""
"The packages `flwr_example` and `flwr_experimental` have been deprecated "
"since Flower 0.12.0 and they are not longer included in Flower release "
"builds. The associated extras (`baseline`, `examples-pytorch`, `examples-"
"tensorflow`, `http-logger`, `ops`) are now no-op and will be removed in an "
"upcoming release."
msgstr ""
"自 Flower 0.12.0 起，软件包 `flwr_example` 和 `flwr_experimental` 已被弃用，"
"它们不再包含在 Flower 的发布版本中。相关的额外包（`baseline`, `examples-"
"pytorch`, `examples-tensorflow`, `http-logger`, `ops`）现在已不再使用，并将在"
"即将发布的版本中移除。"

#: ../../source/ref-changelog.md:660
msgid "v0.17.0 (2021-09-24)"
msgstr "v0.17.0 (2021-09-24)"

#: ../../source/ref-changelog.md:664
msgid ""
"**Experimental virtual client engine** ([#781](https://github.com/adap/"
"flower/pull/781) [#790](https://github.com/adap/flower/pull/790) [#791]"
"(https://github.com/adap/flower/pull/791))"
msgstr ""
"**实验性虚拟客户端引擎** ([#781](https://github.com/adap/flower/pull/781) "
"[#790](https://github.com/adap/flower/pull/790) [#791](https://github.com/"
"adap/flower/pull/791))"

#: ../../source/ref-changelog.md:666
msgid ""
"One of Flower's goals is to enable research at scale. This release enables a "
"first (experimental) peek at a major new feature, codenamed the virtual "
"client engine. Virtual clients enable simulations that scale to a (very) "
"large number of clients on a single machine or compute cluster. The easiest "
"way to test the new functionality is to look at the two new code examples "
"called `quickstart_simulation` and `simulation_pytorch`."
msgstr ""
"Flower 的目标之一是实现大规模研究。这一版本首次（试验性地）展示了代号为 "
"\"虚拟客户端引擎 \"的重要新功能"
"。虚拟客户端可以在单台机器或计算集群上对大量客户端进行模拟。"
"测试新功能的最简单方法是查看名为 \"quickstart_simulation \"和 "
"\"simulation_pytorch \"的两个新代码示例。"

#: ../../source/ref-changelog.md:668
msgid ""
"The feature is still experimental, so there's no stability guarantee for the "
"API. It's also not quite ready for prime time and comes with a few known "
"caveats. However, those who are curious are encouraged to try it out and "
"share their thoughts."
msgstr ""
"该功能仍处于试验阶段，因此无法保证 API 的稳定性。此外，它还没有完全准备好进入"
"黄金时间，并有一些已知的注意事项。不过，我们鼓励好奇的用户尝试使用并分享他们"
"的想法。"

#: ../../source/ref-changelog.md:670
msgid ""
"**New built-in strategies** ([#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822))"
msgstr ""
"**新的内置策略**（[#828](https://github.com/adap/flower/pull/828) [#822]"
"(https://github.com/adap/flower/pull/822)"

#: ../../source/ref-changelog.md:672
msgid ""
"FedYogi - Federated learning strategy using Yogi on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr "FedYogi - 在服务器端使用 Yogi 的联邦学习策略。基于 https://arxiv.org/abs/"
"2003.00295 实现"

#: ../../source/ref-changelog.md:673
msgid ""
"FedAdam - Federated learning strategy using Adam on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr ""
"FedAdam - 在服务器端使用 Adam 的联邦学习策略。基于 https://arxiv.org/"
"abs/2003.00295 实现"

#: ../../source/ref-changelog.md:675
msgid ""
"**New PyTorch Lightning code example** ([#617](https://github.com/adap/"
"flower/pull/617))"
msgstr ""
"**新的 PyTorch Lightning 代码示例** ([#617](https://github.com/adap/flower/"
"pull/617))"

#: ../../source/ref-changelog.md:677
msgid ""
"**New Variational Auto-Encoder code example** ([#752](https://github.com/"
"adap/flower/pull/752))"
msgstr ""
"**新的变分自动编码器代码示例** ([#752](https://github.com/adap/flower/"
"pull/752))"

#: ../../source/ref-changelog.md:679
msgid ""
"**New scikit-learn code example** ([#748](https://github.com/adap/flower/"
"pull/748))"
msgstr ""
"**新的 scikit-learn 代码示例** ([#748](https://github.com/adap/flower/"
"pull/748))"

#: ../../source/ref-changelog.md:681
msgid ""
"**New experimental TensorBoard strategy** ([#789](https://github.com/adap/"
"flower/pull/789))"
msgstr ""
"**新的实验性 TensorBoard 策略**（[#789](https://github.com/adap/flower/"
"pull/789)）"

#: ../../source/ref-changelog.md:685
msgid ""
"Improved advanced TensorFlow code example ([#769](https://github.com/adap/"
"flower/pull/769))"
msgstr ""
"改进的高级 TensorFlow 代码示例（[#769](https://github.com/adap/flower/"
"pull/769)"

#: ../../source/ref-changelog.md:686
msgid ""
"Warning when `min_available_clients` is misconfigured ([#830](https://github."
"com/adap/flower/pull/830))"
msgstr ""
"当 `min_available_clients` 配置错误时发出警告 ([#830](https://github.com/"
"adap/flower/pull/830))"

#: ../../source/ref-changelog.md:687
msgid ""
"Improved gRPC server docs ([#841](https://github.com/adap/flower/pull/841))"
msgstr ""
"改进了 gRPC 服务器文档（[#841](https://github.com/adap/flower/pull/841)）"

#: ../../source/ref-changelog.md:688
msgid ""
"Improved error message in `NumPyClient` ([#851](https://github.com/adap/"
"flower/pull/851))"
msgstr ""
"改进了 `NumPyClient` 中的错误信息 ([#851](https://github.com/adap/flower/"
"pull/851))"

#: ../../source/ref-changelog.md:689
msgid ""
"Improved PyTorch quickstart code example ([#852](https://github.com/adap/"
"flower/pull/852))"
msgstr ""
"改进的 PyTorch 快速启动代码示例 ([#852](https://github.com/adap/flower/"
"pull/852))"

#: ../../source/ref-changelog.md:693
msgid ""
"**Disabled final distributed evaluation** ([#800](https://github.com/adap/"
"flower/pull/800))"
msgstr ""
"**禁用最终分布式评价** ([#800](https://github.com/adap/flower/pull/800))"

#: ../../source/ref-changelog.md:695
msgid ""
"Prior behaviour was to perform a final round of distributed evaluation on "
"all connected clients, which is often not required (e.g., when using server-"
"side evaluation). The prior behaviour can be enabled by passing "
"`force_final_distributed_eval=True` to `start_server`."
msgstr ""
"之前的行为是在所有连接的客户端上执行最后一轮分布式评估，而这通常是不需要的"
"（例如，在使用服务器端评估时）。可以通过向 `start_server` 传递 "
"`force_final_distributed_eval=True` 来启用之前的行为。"

#: ../../source/ref-changelog.md:697
msgid ""
"**Renamed q-FedAvg strategy** ([#802](https://github.com/adap/flower/"
"pull/802))"
msgstr ""
"**更名为 q-FedAvg 策略** ([#802](https://github.com/adap/flower/pull/802))"

#: ../../source/ref-changelog.md:699
msgid ""
"The strategy named `QffedAvg` was renamed to `QFedAvg` to better reflect the "
"notation given in the original paper (q-FFL is the optimization objective, q-"
"FedAvg is the proposed solver). Note the the original (now deprecated) "
"`QffedAvg` class is still available for compatibility reasons (it will be "
"removed in a future release)."
msgstr ""
"名为 `QffedAvg` 的策略已更名为 `QFedAvg`，以更好地反映原始论文中给出的符号"
"（q-FFL 是优化目标，q-FedAvg 是建议的求解器）。请注意，出于兼容性原因，原始"
"（现已废弃）的 `QffedAvg` 类仍然可用（它将在未来的版本中移除）。"

#: ../../source/ref-changelog.md:701
msgid ""
"**Deprecated and renamed code example** `simulation_pytorch` **to** "
"`simulation_pytorch_legacy` ([#791](https://github.com/adap/flower/pull/791))"
msgstr ""
"**删除并重命名代码示例**`simulation_pytorch`**为"
"**`simulation_pytorch_legacy` ([#791](https://github.com/adap/flower/"
"pull/791))"

#: ../../source/ref-changelog.md:703
msgid ""
"This example has been replaced by a new example. The new example is based on "
"the experimental virtual client engine, which will become the new default "
"way of doing most types of large-scale simulations in Flower. The existing "
"example was kept for reference purposes, but it might be removed in the "
"future."
msgstr ""
"该示例已被新示例取代。新示例基于试验性虚拟客户端引擎，它将成为在 Flower 中进"
"行大多数类型大规模模拟的新的默认方式。现有示例将作为参考保留，但将来可能会删"
"除。"

#: ../../source/ref-changelog.md:705
msgid "v0.16.0 (2021-05-11)"
msgstr "v0.16.0 (2021-05-11)"

#: ../../source/ref-changelog.md:709
msgid ""
"**New built-in strategies** ([#549](https://github.com/adap/flower/pull/549))"
msgstr "**新的内置策略** ([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:711
msgid "(abstract) FedOpt"
msgstr "（摘要） FedOpt"

#: ../../source/ref-changelog.md:712
msgid "FedAdagrad"
msgstr "FedAdagrad"

#: ../../source/ref-changelog.md:714
msgid ""
"**Custom metrics for server and strategies** ([#717](https://github.com/adap/"
"flower/pull/717))"
msgstr ""
"**服务器和策略的自定义指标** ([#717](https://github.com/adap/flower/"
"pull/717))"

#: ../../source/ref-changelog.md:716
msgid ""
"The Flower server is now fully task-agnostic, all remaining instances of "
"task-specific metrics (such as `accuracy`) have been replaced by custom "
"metrics dictionaries. Flower 0.15 introduced the capability to pass a "
"dictionary containing custom metrics from client to server. As of this "
"release, custom metrics replace task-specific metrics on the server."
msgstr ""
"Flower 服务器现在完全与任务无关，所有剩余的任务特定度量（如 \"准确度\"）都已"
"被自定义度量字典取代。Flower 0.15 引入了从客户端向服务器传递包含自定义指标的"
"字典的功能。从本版本开始，自定义指标将取代服务器上的特定任务指标。"

#: ../../source/ref-changelog.md:718
msgid ""
"Custom metric dictionaries are now used in two user-facing APIs: they are "
"returned from Strategy methods `aggregate_fit`/`aggregate_evaluate` and they "
"enable evaluation functions passed to build-in strategies (via `eval_fn`) to "
"return more than two evaluation metrics. Strategies can even return "
"*aggregated* metrics dictionaries for the server to keep track of."
msgstr ""
"自定义度量字典现在可在两个面向用户的 API 中使用：它们可从策略方法 "
"`aggregate_fit`/`aggregate_evaluate` 返回，还可使传递给内置策略（通过 "
"`eval_fn`）的评估函数返回两个以上的评估度量。策略甚至可以返回 *aggregated* 指"
"标字典，以便服务器跟踪。"

#: ../../source/ref-changelog.md:720
msgid ""
"Stratey implementations should migrate their `aggregate_fit` and "
"`aggregate_evaluate` methods to the new return type (e.g., by simply "
"returning an empty `{}`), server-side evaluation functions should migrate "
"from `return loss, accuracy` to `return loss, {\"accuracy\": accuracy}`."
msgstr ""
"Stratey 实现应将其 `aggregate_fit` 和 `aggregate_evaluate` 方法迁移到新的返回"
"类型（例如，只需返回空的 `{}`），服务器端评估函数应从 `return loss, "
"accuracy` 迁移到 `return loss, {\"accuracy\": accuracy}`。"

#: ../../source/ref-changelog.md:722
msgid ""
"Flower 0.15-style return types are deprecated (but still supported), "
"compatibility will be removed in a future release."
msgstr ""
"Flower 0.15 风格的返回类型已被弃用（但仍受支持），兼容性将在未来的版本中移"
"除。"

#: ../../source/ref-changelog.md:724
msgid ""
"**Migration warnings for deprecated functionality** ([#690](https://github."
"com/adap/flower/pull/690))"
msgstr ""
"** 过时功能的迁移警告** ([#690](https://github.com/adap/flower/pull/690))"

#: ../../source/ref-changelog.md:726
msgid ""
"Earlier versions of Flower were often migrated to new APIs, while "
"maintaining compatibility with legacy APIs. This release introduces detailed "
"warning messages if usage of deprecated APIs is detected. The new warning "
"messages often provide details on how to migrate to more recent APIs, thus "
"easing the transition from one release to another."
msgstr ""
"Flower 早期版本通常会迁移到新的应用程序接口，同时保持与旧版应用程序接口的兼"
"容。如果检测到使用了过时的 API，本版本将引入详细的警告信息。新的警告信息通常"
"会详细说明如何迁移到更新的 API，从而简化从一个版本到另一个版本的过渡。"

#: ../../source/ref-changelog.md:728
msgid ""
"Improved docs and docstrings ([#691](https://github.com/adap/flower/"
"pull/691) [#692](https://github.com/adap/flower/pull/692) [#713](https://"
"github.com/adap/flower/pull/713))"
msgstr ""
"改进了文档和文档说明 ([#691](https://github.com/adap/flower/pull/691) [#692]"
"(https://github.com/adap/flower/pull/692) [#713](https://github.com/adap/"
"flower/pull/713))"

#: ../../source/ref-changelog.md:730
msgid "MXNet example and documentation"
msgstr "MXNet 示例和文档"

#: ../../source/ref-changelog.md:732
msgid ""
"FedBN implementation in example PyTorch: From Centralized To Federated "
"([#696](https://github.com/adap/flower/pull/696) [#702](https://github.com/"
"adap/flower/pull/702) [#705](https://github.com/adap/flower/pull/705))"
msgstr ""
"PyTorch 示例中的 FedBN 实现： 从集中到联邦 ([#696](https://github.com/adap/"
"flower/pull/696) [#702](https://github.com/adap/flower/pull/702) "
"[#705](https://github.com/adap/flower/pull/705))"

#: ../../source/ref-changelog.md:736
msgid ""
"**Serialization-agnostic server** ([#721](https://github.com/adap/flower/"
"pull/721))"
msgstr "**序列化无关服务器** ([#721](https://github.com/adap/flower/pull/721))"

#: ../../source/ref-changelog.md:738
msgid ""
"The Flower server is now fully serialization-agnostic. Prior usage of class "
"`Weights` (which represents parameters as deserialized NumPy ndarrays) was "
"replaced by class `Parameters` (e.g., in `Strategy`). `Parameters` objects "
"are fully serialization-agnostic and represents parameters as byte arrays, "
"the `tensor_type` attributes indicates how these byte arrays should be "
"interpreted (e.g., for serialization/deserialization)."
msgstr ""
"Flower 服务器现在完全不依赖序列化。之前使用的 `Weights` 类（以反序列化的 "
"NumPy ndarrays 表示参数）已被 `Parameters` 类取代（例如在 `Strategy`中）。参"
"数 \"对象与序列化完全无关，它以字节数组的形式表示参数，\"tensor_type \"属性表"
"示如何解释这些字节数组（例如，用于序列化/反序列化）。"

#: ../../source/ref-changelog.md:740
msgid ""
"Built-in strategies implement this approach by handling serialization and "
"deserialization to/from `Weights` internally. Custom/3rd-party Strategy "
"implementations should update to the slighly changed Strategy method "
"definitions. Strategy authors can consult PR [#721](https://github.com/adap/"
"flower/pull/721) to see how strategies can easily migrate to the new format."
msgstr ""
"内置策略通过在内部处理序列化和反序列化到/从`Weights`来实现这种方法。自定义/第"
"三方策略实现应更新为稍有改动的策略方法定义。策略作者可查阅 PR "
"[#721](https://github.com/adap/flower/pull/721) "
"以了解如何将策略轻松迁移到新格式。"

#: ../../source/ref-changelog.md:742
msgid ""
"Deprecated `flwr.server.Server.evaluate`, use `flwr.server.Server."
"evaluate_round` instead ([#717](https://github.com/adap/flower/pull/717))"
msgstr ""
"已弃用 `flwr.server.Server.evaluate`，改用 `flwr.server.Server."
"evaluate_round`（[#717](https://github.com/adap/flower/pull/717)"

#: ../../source/ref-changelog.md:744
msgid "v0.15.0 (2021-03-12)"
msgstr "v0.15.0 (2021-03-12)"

#: ../../source/ref-changelog.md:748
msgid ""
"**Server-side parameter initialization** ([#658](https://github.com/adap/"
"flower/pull/658))"
msgstr ""
"**服务器端参数初始化** ([#658](https://github.com/adap/flower/pull/658))"

#: ../../source/ref-changelog.md:750
msgid ""
"Model parameters can now be initialized on the server-side. Server-side "
"parameter initialization works via a new `Strategy` method called "
"`initialize_parameters`."
msgstr ""
"现在可以在服务器端初始化模型参数。服务器端参数初始化通过名为 "
"\"initialize_parameters \"的新 \"Strategy \"方法进行。"

#: ../../source/ref-changelog.md:752
msgid ""
"Built-in strategies support a new constructor argument called "
"`initial_parameters` to set the initial parameters. Built-in strategies will "
"provide these initial parameters to the server on startup and then delete "
"them to free the memory afterwards."
msgstr ""
"内置策略支持名为 \"initial_parameters \"的新构造函数参数，用于设置初始参数。"
"内置策略会在启动时向服务器提供这些初始参数，然后删除它们以释放内存。"

#: ../../source/ref-changelog.md:771
msgid ""
"If no initial parameters are provided to the strategy, the server will "
"continue to use the current behaviour (namely, it will ask one of the "
"connected clients for its parameters and use these as the initial global "
"parameters)."
msgstr ""
"如果没有向策略提供初始参数，服务器将继续使用当前行为（即向其中一个已连接的客"
"户端询问参数，并将这些参数用作初始全局参数）。"

#: ../../source/ref-changelog.md:773
msgid "Deprecations"
msgstr "停用"

#: ../../source/ref-changelog.md:775
msgid ""
"Deprecate `flwr.server.strategy.DefaultStrategy` (migrate to `flwr.server."
"strategy.FedAvg`, which is equivalent)"
msgstr ""
"停用 `flwr.server.strategy.DefaultStrategy`（迁移到等价的 `flwr.server."
"strategy.FedAvg`）"

#: ../../source/ref-changelog.md:777
msgid "v0.14.0 (2021-02-18)"
msgstr "v0.14.0 (2021-02-18)"

#: ../../source/ref-changelog.md:781
msgid ""
"**Generalized** `Client.fit` **and** `Client.evaluate` **return values** "
"([#610](https://github.com/adap/flower/pull/610) [#572](https://github.com/"
"adap/flower/pull/572) [#633](https://github.com/adap/flower/pull/633))"
msgstr ""
"**通用** `Client.fit` **和** `Client.evaluate` **返回值** ([#610](https://"
"github.com/adap/flower/pull/610) [#572](https://github.com/adap/flower/"
"pull/572) [#633](https://github.com/adap/flower/pull/633))"

#: ../../source/ref-changelog.md:783
msgid ""
"Clients can now return an additional dictionary mapping `str` keys to values "
"of the following types: `bool`, `bytes`, `float`, `int`, `str`. This means "
"one can return almost arbitrary values from `fit`/`evaluate` and make use of "
"them on the server side!"
msgstr ""
"客户端现在可以返回一个额外的字典，将 `str` 键映射为以下类型的值： bool`、"
"`bytes`、`float`、`int`、`str`。这意味着我们可以从 `fit`/`evaluate` 返回几乎"
"任意的值，并在服务器端使用它们！"

#: ../../source/ref-changelog.md:785
msgid ""
"This improvement also allowed for more consistent return types between `fit` "
"and `evaluate`: `evaluate` should now return a tuple `(float, int, dict)` "
"representing the loss, number of examples, and a dictionary holding "
"arbitrary problem-specific values like accuracy."
msgstr ""
"这一改进还使 `fit` 和 `evaluate` 之间的返回类型更加一致：`evaluate` 现在应返"
"回一个元组`(float, int, dict)`，代表损失、示例数和一个包含特定问题任意值（如"
"准确度）的字典。"

#: ../../source/ref-changelog.md:787
msgid ""
"In case you wondered: this feature is compatible with existing projects, the "
"additional dictionary return value is optional. New code should however "
"migrate to the new return types to be compatible with upcoming Flower "
"releases (`fit`: `List[np.ndarray], int, Dict[str, Scalar]`, `evaluate`: "
"`float, int, Dict[str, Scalar]`). See the example below for details."
msgstr ""
"如果你想知道：此功能与现有项目兼容，额外的字典返回值是可选的。不过，新代码应"
"迁移到新的返回类型，以便与即将发布的 Flower 版本兼容（`fit`: `List[np."
"ndarray], int, Dict[str, Scalar]`，`evaluate`: `float, int, Dict[str, "
"Scalar]`）。详见下面的示例。"

#: ../../source/ref-changelog.md:789
msgid ""
"*Code example:* note the additional dictionary return values in both "
"`FlwrClient.fit` and `FlwrClient.evaluate`:"
msgstr ""
"*代码示例：* 注意 `FlwrClient.fit` 和 `FlwrClient.evaluate` 中的附加字典返回"
"值："

#: ../../source/ref-changelog.md:804
msgid ""
"**Generalized** `config` **argument in** `Client.fit` **and** `Client."
"evaluate` ([#595](https://github.com/adap/flower/pull/595))"
msgstr ""
"**在**`Client.fit` **和**`Client.evaluate`中泛化**`config`参数（[#595]"
"(https://github.com/adap/flower/pull/595)）"

#: ../../source/ref-changelog.md:806
msgid ""
"The `config` argument used to be of type `Dict[str, str]`, which means that "
"dictionary values were expected to be strings. The new release generalizes "
"this to enable values of the following types: `bool`, `bytes`, `float`, "
"`int`, `str`."
msgstr ""
"`config`参数曾是 \"字典[str, str]\"类型"
"，这意味着字典值应是字符串。新版本将其扩展为以下类型的值： "
"bool`、`bytes`、`float`、`int`、`str`。"

#: ../../source/ref-changelog.md:808
msgid ""
"This means one can now pass almost arbitrary values to `fit`/`evaluate` "
"using the `config` dictionary. Yay, no more `str(epochs)` on the server-side "
"and `int(config[\"epochs\"])` on the client side!"
msgstr ""
"这意味着现在可以使用 `config` 字典向 `fit`/`evaluate` 传递几乎任意的值。耶，"
"服务器端不再需要 `str(epochs)`，客户端不再需要 `int(config[\"epochs\"])`！"

#: ../../source/ref-changelog.md:810
msgid ""
"*Code example:* note that the `config` dictionary now contains non-`str` "
"values in both `Client.fit` and `Client.evaluate`:"
msgstr ""
"*代码示例：* 注意 `config` 字典现在在 `Client.fit` 和 `Client.evaluate` 中都"
"包含非 `str` 值："

#: ../../source/ref-changelog.md:827
msgid "v0.13.0 (2021-01-08)"
msgstr "v0.13.0 (2021-01-08)"

#: ../../source/ref-changelog.md:831
msgid ""
"New example: PyTorch From Centralized To Federated ([#549](https://github."
"com/adap/flower/pull/549))"
msgstr "新示例： PyTorch 从集中到联邦 ([#549](https://github.com/adap/flower/pull/"
"549))"

#: ../../source/ref-changelog.md:832
msgid "Improved documentation"
msgstr "改进文档"

#: ../../source/ref-changelog.md:833
msgid ""
"New documentation theme ([#551](https://github.com/adap/flower/pull/551))"
msgstr "新文档主题 ([#551](https://github.com/adap/flower/pull/551))"

#: ../../source/ref-changelog.md:834
msgid "New API reference ([#554](https://github.com/adap/flower/pull/554))"
msgstr "新的 API 参考 ([#554](https://github.com/adap/flower/pull/554))"

#: ../../source/ref-changelog.md:835
msgid ""
"Updated examples documentation ([#549](https://github.com/adap/flower/"
"pull/549))"
msgstr "更新了示例文档 ([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:836
msgid ""
"Removed obsolete documentation ([#548](https://github.com/adap/flower/"
"pull/548))"
msgstr "删除了过时的文档 ([#548](https://github.com/adap/flower/pull/548))"

#: ../../source/ref-changelog.md:838
msgid "Bugfix:"
msgstr "错误修正："

#: ../../source/ref-changelog.md:840
msgid ""
"`Server.fit` does not disconnect clients when finished, disconnecting the "
"clients is now handled in `flwr.server.start_server` ([#553](https://github."
"com/adap/flower/pull/553) [#540](https://github.com/adap/flower/issues/540))."
msgstr ""
"Server.fit \"完成后不会断开客户端连接，现在断开客户端连接是在 \"flwr.server."
"start_server \"中处理的（[#553](https://github.com/adap/flower/pull/553) "
"[#540](https://github.com/adap/flower/issues/540)）。"

#: ../../source/ref-changelog.md:842
msgid "v0.12.0 (2020-12-07)"
msgstr "v0.12.0 (2020-12-07)"

#: ../../source/ref-changelog.md:844 ../../source/ref-changelog.md:860
msgid "Important changes:"
msgstr "重要变更："

#: ../../source/ref-changelog.md:846
msgid ""
"Added an example for embedded devices ([#507](https://github.com/adap/flower/"
"pull/507))"
msgstr "添加了嵌入式设备示例 ([#507](https://github.com/adap/flower/pull/507))"

#: ../../source/ref-changelog.md:847
msgid ""
"Added a new NumPyClient (in addition to the existing KerasClient) ([#504]"
"(https://github.com/adap/flower/pull/504) [#508](https://github.com/adap/"
"flower/pull/508))"
msgstr ""
"添加了一个新的 NumPyClient（除现有的 KerasClient 之外）（[#504](https://"
"github.com/adap/flower/pull/504) [#508](https://github.com/adap/flower/"
"pull/508)"

#: ../../source/ref-changelog.md:848
msgid ""
"Deprecated `flwr_example` package and started to migrate examples into the "
"top-level `examples` directory ([#494](https://github.com/adap/flower/"
"pull/494) [#512](https://github.com/adap/flower/pull/512))"
msgstr ""
"弃用 `flwr_example` 软件包，并开始将示例迁移到顶层的 `examples` 目录 ([#494]"
"(https://github.com/adap/flower/pull/494) [#512](https://github.com/adap/"
"flower/pull/512))"

#: ../../source/ref-changelog.md:850
msgid "v0.11.0 (2020-11-30)"
msgstr "v0.11.0 (2020-11-30)"

#: ../../source/ref-changelog.md:852
msgid "Incompatible changes:"
msgstr "不兼容的更改："

#: ../../source/ref-changelog.md:854
msgid ""
"Renamed strategy methods ([#486](https://github.com/adap/flower/pull/486)) "
"to unify the naming of Flower's public APIs. Other public methods/functions "
"(e.g., every method in `Client`, but also `Strategy.evaluate`) do not use "
"the `on_` prefix, which is why we're removing it from the four methods in "
"Strategy. To migrate rename the following `Strategy` methods accordingly:"
msgstr ""
"重命名了策略方法（[#486](https://github.com/adap/flower/pull/486)），以统一 "
"Flower公共 API 的命名。其他公共方法/函数（例如 `Client` 中的每个方法，以及 "
"`Strategy.evaluate`）不使用 `on_` 前缀，这就是我们从 Strategy "
"中的四个方法中移除它的原因。迁移时，请相应地重命名以下 `Strategy` 方法："

#: ../../source/ref-changelog.md:855
msgid "`on_configure_evaluate` => `configure_evaluate`"
msgstr "`on_configure_evaluate` => `configure_evaluate`"

#: ../../source/ref-changelog.md:856
msgid "`on_aggregate_evaluate` => `aggregate_evaluate`"
msgstr "`on_aggregate_evaluate` => `aggregate_evaluate`"

#: ../../source/ref-changelog.md:857
msgid "`on_configure_fit` => `configure_fit`"
msgstr "`on_configure_fit` => `configure_fit`"

#: ../../source/ref-changelog.md:858
msgid "`on_aggregate_fit` => `aggregate_fit`"
msgstr "`on_aggregate_fit` => `aggregate_fit`"

#: ../../source/ref-changelog.md:862
msgid ""
"Deprecated `DefaultStrategy` ([#479](https://github.com/adap/flower/"
"pull/479)). To migrate use `FedAvg` instead."
msgstr ""
"已废弃的 `DefaultStrategy` ([#479](https://github.com/adap/flower/"
"pull/479)) 。迁移时请使用 `FedAvg`。"

#: ../../source/ref-changelog.md:863
msgid ""
"Simplified examples and baselines ([#484](https://github.com/adap/flower/"
"pull/484))."
msgstr "简化示例和baselines（[#484](https://github.com/adap/flower/pull/484)）。"

#: ../../source/ref-changelog.md:864
msgid ""
"Removed presently unused `on_conclude_round` from strategy interface ([#483]"
"(https://github.com/adap/flower/pull/483))."
msgstr ""
"删除了策略界面中目前未使用的 \"on_conclude_round\"（[#483](https://github."
"com/adap/flower/pull/483)）。"

#: ../../source/ref-changelog.md:865
msgid ""
"Set minimal Python version to 3.6.1 instead of 3.6.9 ([#471](https://github."
"com/adap/flower/pull/471))."
msgstr ""
"将最小 Python 版本设为 3.6.1，而不是 3.6.9 ([#471](https://github.com/adap/"
"flower/pull/471))."

#: ../../source/ref-changelog.md:866
msgid ""
"Improved `Strategy` docstrings ([#470](https://github.com/adap/flower/"
"pull/470))."
msgstr ""
"改进了 `Strategy` docstrings（[#470](https://github.com/adap/flower/"
"pull/470)）。"

#: ../../source/ref-example-projects.rst:2
msgid "Example projects"
msgstr "项目实例"

#: ../../source/ref-example-projects.rst:4
msgid ""
"Flower comes with a number of usage examples. The examples demonstrate how "
"Flower can be used to federate different kinds of existing machine learning "
"pipelines, usually leveraging popular machine learning frameworks such as "
"`PyTorch <https://pytorch.org/>`_ or `TensorFlow <https://www.tensorflow.org/"
">`_."
msgstr ""
"Flower 附带了许多使用示例。这些示例演示了如何使用 Flower "
"联邦不同类型的现有机器学习形式，通常是利用流行的机器学习框架，如 `PyTorch "
"<https://pytorch.org/>`_ 或 `TensorFlow <https://www.tensorflow.org/>`_。"

#: ../../source/ref-example-projects.rst:11
msgid ""
"Flower usage examples used to be bundled with Flower in a package called "
"``flwr_example``. We are migrating those examples to standalone projects to "
"make them easier to use. All new examples are based in the directory "
"`examples <https://github.com/adap/flower/tree/main/examples>`_."
msgstr ""
"Flower 的使用示例曾与 Flower 捆绑在一个名为 ``flwr_example`` 的软件包中。我们"
"正在将这些示例迁移到独立项目中，以使它们更易于使用。所有新示例都位于目录 "
"`examples <https://github.com/adap/flower/tree/main/examples>`_。"

#: ../../source/ref-example-projects.rst:16
msgid "The following examples are available as standalone projects."
msgstr "以下示例可作为独立项目使用。"

#: ../../source/ref-example-projects.rst:20
msgid "Quickstart TensorFlow/Keras"
msgstr "快速入门 TensorFlow/Keras"

#: ../../source/ref-example-projects.rst:22
msgid ""
"The TensorFlow/Keras quickstart example shows CIFAR-10 image classification "
"with MobileNetV2:"
msgstr ""
"TensorFlow/Keras 快速入门示例展示了使用 MobileNetV2 进行的 CIFAR-10 图像分"
"类："

#: ../../source/ref-example-projects.rst:25
msgid ""
"`Quickstart TensorFlow (Code) <https://github.com/adap/flower/tree/main/"
"examples/quickstart-tensorflow>`_"
msgstr ""
"`TensorFlow快速入门 (代码) <https://github.com/adap/flower/tree/main/"
"examples/quickstart-tensorflow>`_"

#: ../../source/ref-example-projects.rst:26
msgid ""
"`Quickstart TensorFlow (Tutorial) <https://flower.dev/docs/framework/"
"tutorial-quickstart-tensorflow.html>`_"
msgstr ""
"`TensorFlow快速入门 (教程) <https://flower.dev/docs/framework/tutorial-"
"quickstart-tensorflow.html>`_"

#: ../../source/ref-example-projects.rst:27
msgid ""
"`Quickstart TensorFlow (Blog Post) <https://flower.dev/blog/2020-12-11-"
"federated-learning-in-less-than-20-lines-of-code>`_"
msgstr ""
"`TensorFlow快速入门 (博客) <https://flower.dev/blog/2020-12-11-federated-"
"learning-in-less-than-20-lines-of-code>`_"

#: ../../source/ref-example-projects.rst:31
#: ../../source/tutorial-quickstart-pytorch.rst:5
msgid "Quickstart PyTorch"
msgstr "PyTorch快速入门"

#: ../../source/ref-example-projects.rst:33
msgid ""
"The PyTorch quickstart example shows CIFAR-10 image classification with a "
"simple Convolutional Neural Network:"
msgstr ""
"PyTorch 快速入门范例展示了使用简单卷积神经网络进行 CIFAR-10 图像分类的情况："

#: ../../source/ref-example-projects.rst:36
msgid ""
"`Quickstart PyTorch (Code) <https://github.com/adap/flower/tree/main/"
"examples/quickstart-pytorch>`_"
msgstr ""
"`PyTorch快速入门 (代码) <https://github.com/adap/flower/tree/main/examples/"
"quickstart-pytorch>`_"

#: ../../source/ref-example-projects.rst:37
msgid ""
"`Quickstart PyTorch (Tutorial) <https://flower.dev/docs/framework/tutorial-"
"quickstart-pytorch.html>`_"
msgstr ""
"`PyTorch快速入门 (教程) <https://flower.dev/docs/framework/tutorial-"
"quickstart-pytorch.html>`_"

#: ../../source/ref-example-projects.rst:41
msgid "PyTorch: From Centralized To Federated"
msgstr "PyTorch： 从集中式到联邦式"

#: ../../source/ref-example-projects.rst:43
msgid ""
"This example shows how a regular PyTorch project can be federated using "
"Flower:"
msgstr "本例展示了如何使用 Flower 联邦化一个普通的 PyTorch 项目："

#: ../../source/ref-example-projects.rst:45
msgid ""
"`PyTorch: From Centralized To Federated (Code) <https://github.com/adap/"
"flower/tree/main/examples/pytorch-from-centralized-to-federated>`_"
msgstr ""
"PyTorch： 从集中式到联邦式（代码） <https://github.com/adap/flower/tree/main/"
"examples/pytorch-from-centralized-to-federated>`_"

#: ../../source/ref-example-projects.rst:46
msgid ""
"`PyTorch: From Centralized To Federated (Tutorial) <https://flower.dev/docs/"
"framework/example-pytorch-from-centralized-to-federated.html>`_"
msgstr ""
"PyTorch： 从集中式到联邦式（教程） <https://flower.dev/docs/framework/"
"example-pytorch-from-centralized-to-federated.html>`_"

#: ../../source/ref-example-projects.rst:50
msgid "Federated Learning on Raspberry Pi and Nvidia Jetson"
msgstr "树莓派和 Nvidia Jetson 上的联邦学习"

#: ../../source/ref-example-projects.rst:52
msgid ""
"This example shows how Flower can be used to build a federated learning "
"system that run across Raspberry Pi and Nvidia Jetson:"
msgstr "本示例展示了如何利用 Flower 建立一个跨 Raspberry Pi 和 Nvidia Jetson "
"运行的联邦学习系统："

#: ../../source/ref-example-projects.rst:54
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Code) <https://github."
"com/adap/flower/tree/main/examples/embedded-devices>`_"
msgstr ""
"Raspberry Pi 和 Nvidia Jetson 上的联邦学习（代码） <https://github.com/adap/"
"flower/tree/main/examples/embedded-devices>`_"

#: ../../source/ref-example-projects.rst:55
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Blog Post) <https://"
"flower.dev/blog/2020-12-16-"
"running_federated_learning_applications_on_embedded_devices_with_flower>`_"
msgstr ""
"Raspberry Pi和 Nvidia Jetson 上的联邦学习（博客） <https://flower.dev/blog/20"
"20-12-16-running_federated_learning_applications_on_embedded_devices_with_flo"
"wer>`_"

#: ../../source/ref-example-projects.rst:60
msgid "Legacy Examples (`flwr_example`)"
msgstr "传统示例 (`flwr_example`)"

#: ../../source/ref-example-projects.rst:63
msgid ""
"The useage examples in `flwr_example` are deprecated and will be removed in "
"the future. New examples are provided as standalone projects in `examples "
"<https://github.com/adap/flower/tree/main/examples>`_."
msgstr ""
"在 `flwr_example` 中的使用示例已被弃用，今后将被移除。新示例将作为独立项目在 "
"`examples <https://github.com/adap/flower/tree/main/examples>`_ 中提供。"

#: ../../source/ref-example-projects.rst:69
msgid "Extra Dependencies"
msgstr "额外依赖"

#: ../../source/ref-example-projects.rst:71
msgid ""
"The core Flower framework keeps a minimal set of dependencies. The examples "
"demonstrate Flower in the context of different machine learning frameworks, "
"so additional dependencies need to be installed before an example can be run."
msgstr ""
"Flower 核心框架只保留了最低限度的依赖项。这些示例在不同机器学习框架的背景下演"
"示了 Flower，因此在运行示例之前需要安装额外的依赖项。"

#: ../../source/ref-example-projects.rst:75
msgid "For PyTorch examples::"
msgstr "PyTorch 示例：："

#: ../../source/ref-example-projects.rst:79
msgid "For TensorFlow examples::"
msgstr "TensorFlow 示例：："

#: ../../source/ref-example-projects.rst:83
msgid "For both PyTorch and TensorFlow examples::"
msgstr "PyTorch 和 TensorFlow 示例：："

#: ../../source/ref-example-projects.rst:87
msgid ""
"Please consult :code:`pyproject.toml` for a full list of possible extras "
"(section :code:`[tool.poetry.extras]`)."
msgstr ""
"请参阅 :code:`pyproject.toml`，了解可能的 extras 的完整列表（章节 :code:"
"`[tool.poems.extras]`）。"

#: ../../source/ref-example-projects.rst:92
msgid "PyTorch Examples"
msgstr "PyTorch 示例"

#: ../../source/ref-example-projects.rst:94
msgid ""
"Our PyTorch examples are based on PyTorch 1.7. They should work with other "
"releases as well. So far, we provide the following examples."
msgstr ""
"我们的 PyTorch 示例基于 PyTorch 1.7。它们应该也能在其他版本中使用。到目前为"
"止，我们提供了以下示例。"

#: ../../source/ref-example-projects.rst:98
msgid "CIFAR-10 Image Classification"
msgstr "CIFAR-10 图像分类"

#: ../../source/ref-example-projects.rst:100
msgid ""
"`CIFAR-10 and CIFAR-100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ are "
"popular RGB image datasets. The Flower CIFAR-10 example uses PyTorch to "
"train a simple CNN classifier in a federated learning setup with two clients."
msgstr ""
"CIFAR-10 和 CIFAR-100 <https://www.cs.toronto.edu/~kriz/cifar.html>``_ "
"是流行的 RGB 图像数据集。Flower CIFAR-10 示例使用 PyTorch "
"在有两个客户端的联邦学习设置中训练一个简单的 CNN 分类器。"

#: ../../source/ref-example-projects.rst:104
#: ../../source/ref-example-projects.rst:121
#: ../../source/ref-example-projects.rst:146
msgid "First, start a Flower server:"
msgstr "首先，启动 Flower 服务器："

#: ../../source/ref-example-projects.rst:106
msgid "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"
msgstr "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"

#: ../../source/ref-example-projects.rst:108
#: ../../source/ref-example-projects.rst:125
#: ../../source/ref-example-projects.rst:150
msgid "Then, start the two clients in a new terminal window:"
msgstr "然后，在新的终端窗口中启动两个客户端："

#: ../../source/ref-example-projects.rst:110
msgid "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"
msgstr "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"

#: ../../source/ref-example-projects.rst:112
msgid "For more details, see :code:`src/py/flwr_example/pytorch_cifar`."
msgstr "更多详情，请参阅 :code:`src/py/flwr_example/pytorch_cifar`。"

#: ../../source/ref-example-projects.rst:115
msgid "ImageNet-2012 Image Classification"
msgstr "ImageNet-2012 图像分类"

#: ../../source/ref-example-projects.rst:117
msgid ""
"`ImageNet-2012 <http://www.image-net.org/>`_ is one of the major computer "
"vision datasets. The Flower ImageNet example uses PyTorch to train a "
"ResNet-18 classifier in a federated learning setup with ten clients."
msgstr ""
"ImageNet-2012 <http://www.image-net.org/>`_ 是主要的计算机视觉数据集之一。"
"Flower ImageNet 示例使用 PyTorch 在有十个客户端的联邦学习设置中训练 ResNet-"
"18 分类器。"

#: ../../source/ref-example-projects.rst:123
msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"
msgstr "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"

#: ../../source/ref-example-projects.rst:127
msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"
msgstr "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"

#: ../../source/ref-example-projects.rst:129
msgid "For more details, see :code:`src/py/flwr_example/pytorch_imagenet`."
msgstr "更多详情，请参阅 :code:`src/py/flwr_example/pytorch_imagenet`。"

#: ../../source/ref-example-projects.rst:133
msgid "TensorFlow Examples"
msgstr "TensorFlow 示例"

#: ../../source/ref-example-projects.rst:135
msgid ""
"Our TensorFlow examples are based on TensorFlow 2.0 or newer. So far, we "
"provide the following examples."
msgstr ""
"我们的 TensorFlow 示例基于 TensorFlow 2.0 或更新版本。到目前为止，我们提供了"
"以下示例。"

#: ../../source/ref-example-projects.rst:139
msgid "Fashion-MNIST Image Classification"
msgstr "Fashion-MNIST 图像分类"

#: ../../source/ref-example-projects.rst:141
msgid ""
"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ is often "
"used as the \"Hello, world!\" of machine learning. We follow this tradition "
"and provide an example which samples random local datasets from Fashion-"
"MNIST and trains a simple image classification model over those partitions."
msgstr ""
"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ "
"经常被用作机器学习的 \"你好，世界！\"。我们遵循这一传统，提供了一个从Fashion-"
"MNIST 中随机抽样本地数据集的示例，并在这些分区上训练一个简单的图像分类模型。"

#: ../../source/ref-example-projects.rst:148
msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"
msgstr "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"

#: ../../source/ref-example-projects.rst:152
msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"
msgstr "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"

#: ../../source/ref-example-projects.rst:154
msgid ""
"For more details, see :code:`src/py/flwr_example/tensorflow_fashion_mnist`."
msgstr ""
"更多详情，请参阅 :code:`src/py/flwr_example/tensorflow_fashion_mnist`。"

#: ../../source/ref-faq.rst:4
msgid ""
"This page collects answers to commonly asked questions about Federated "
"Learning with Flower."
msgstr "本页收集了有关 \"Flower 联邦学习 \"常见问题的答案。"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can Flower run on Juptyter Notebooks / Google Colab?"
msgstr ""
":fa:`eye,mr-1` Flower 可以在 Juptyter Notebooks / Google Colab 上运行吗？"

#: ../../source/ref-faq.rst:8
msgid ""
"Yes, it can! Flower even comes with a few under-the-hood optimizations to "
"make it work even better on Colab. Here's a quickstart example:"
msgstr ""
"是的，它可以！Flower 甚至还进行了一些底层优化，使其在 Colab 上运行得更好。下"
"面是一个快速启动示例："

#: ../../source/ref-faq.rst:10
msgid ""
"`Flower simulation PyTorch <https://colab.research.google.com/github/adap/"
"flower/blob/main/examples/simulation-pytorch/sim.ipynb>`_"
msgstr ""
"`Flower 模拟 PyTorch <https://colab.research.google.com/github/adap/flower/"
"blob/main/examples/simulation-pytorch/sim.ipynb>`_"

#: ../../source/ref-faq.rst:11
msgid ""
"`Flower simulation TensorFlow/Keras <https://colab.research.google.com/"
"github/adap/flower/blob/main/examples/simulation-tensorflow/sim.ipynb>`_"
msgstr ""
"`Flower模拟TensorFlow/Keras <https://colab.research.google.com/github/adap/"
"flower/blob/main/examples/simulation-tensorflow/sim.ipynb>`_"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` How can I run Federated Learning on a Raspberry Pi?"
msgstr ":fa:`eye,mr-1` 如何在 Raspberry Pi 上运行联邦学习？"

#: ../../source/ref-faq.rst:15
msgid ""
"Find the `blog post about federated learning on embedded device here "
"<https://flower.dev/blog/2020-12-16-"
"running_federated_learning_applications_on_embedded_devices_with_flower>`_ "
"and the corresponding `GitHub code example <https://github.com/adap/flower/"
"tree/main/examples/embedded-devices>`_."
msgstr ""
"请点击此处查看有关嵌入式设备联邦学习的 \"博文\"<https://flower.dev/blog/2020-"
"12-16-running_federated_learning_applications_on_embedded_devices_with_flower"
">`_和相应的 \"GitHub 代码示例\"<https://github.com/adap/flower/tree/main/"
"examples/embedded-devices>`_。"

#: ../../source/ref-faq.rst
msgid ""
":fa:`eye,mr-1` Does Flower support federated learning on Android devices?"
msgstr ":fa:`eye,mr-1` Flower 是否支持安卓设备上的联邦学习？"

#: ../../source/ref-faq.rst:19
msgid ""
"Yes, it does. Please take a look at our `blog post <https://flower.dev/"
"blog/2021-12-15-federated-learning-on-android-devices-with-flower>`_ or "
"check out the code examples:"
msgstr ""
"是的，确实如此。请查看我们的 \"博客文章 <https://flower.dev/blog/2021-12-15-"
"federated-learning-on-android-devices-with-flower>`_\" 或查看代码示例："

#: ../../source/ref-faq.rst:21
msgid ""
"`Android Kotlin example <https://flower.dev/docs/examples/android-kotlin."
"html>`_"
msgstr ""
"`Android Kotlin 示例 <https://flower.dev/docs/examples/android-kotlin.html>`_"

#: ../../source/ref-faq.rst:22
msgid "`Android Java example <https://flower.dev/docs/examples/android.html>`_"
msgstr "Android Java 示例 <https://flower.dev/docs/examples/android.html>`_"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can I combine federated learning with blockchain?"
msgstr ":fa:`eye,mr-1` 我可以将联邦学习与区块链结合起来吗？"

#: ../../source/ref-faq.rst:26
msgid ""
"Yes, of course. A list of available examples using Flower within a "
"blockchain environment is available here:"
msgstr "当然可以。有关在区块链环境中使用 Flower 的可用示例列表，请点击此处："

#: ../../source/ref-faq.rst:28
msgid ""
"`Flower meets Nevermined GitHub Repository <https://github.com/nevermined-io/"
"fl-demo/tree/master/image-classification-flower>`_."
msgstr ""
"`Flower meets Nevermined GitHub Repository <https://github.com/nevermined-io/"
"fl-demo/tree/master/image-classification-flower>`_."

#: ../../source/ref-faq.rst:29
msgid ""
"`Flower meets Nevermined YouTube video <https://www.youtube.com/watch?"
"v=A0A9hSlPhKI>`_."
msgstr ""
"`Flower meets Nevermined YouTube 视频 <https://www.youtube.com/"
"watch?v=A0A9hSlPhKI>`_."

#: ../../source/ref-faq.rst:30
msgid ""
"`Flower meets KOSMoS <https://www.kosmos-bmbf.de/wp-content/uploads/"
"sites/13/2021/05/Talk-Flower-Summit-2021.pdf>`_."
msgstr ""
"`Flower meets KOSMoS <https://www.kosmos-bmbf.de/wp-content/uploads/sites/13/"
"2021/05/Talk-Flower-Summit-2021.pdf>`_."

#: ../../source/ref-faq.rst:31
msgid ""
"`Flower meets Talan blog post <https://www.linkedin.com/pulse/federated-"
"learning-same-mask-different-faces-imen-ayari/?"
"trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ ."
msgstr ""
"`Flower meets Talan博文 <https://www.linkedin.com/pulse/"
"federated-learning-same-mask-different-faces-imen-ayari/"
"?trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ 。"

#: ../../source/ref-faq.rst:32
msgid ""
"`Flower meets Talan GitHub Repository <https://gitlab.com/"
"Talan_Innovation_Factory/food-waste-prevention>`_ ."
msgstr ""
"`Flower meets Talan GitHub Repository <https://gitlab.com/"
"Talan_Innovation_Factory/food-waste-prevention>`_ ."

#: ../../source/ref-telemetry.md:1
msgid "Telemetry"
msgstr "遥测功能"

#: ../../source/ref-telemetry.md:3
msgid ""
"The Flower open-source project collects **anonymous** usage metrics to make "
"well-informed decisions to improve Flower. Doing this enables the Flower "
"team to understand how Flower is used and what challenges users might face."
msgstr ""
"Flower 开源项目收集**匿名**使用指标，以便在充分知情的情况下做出改进 Flower 的"
"决定。这样做能让 Flower 团队了解 Flower 的使用情况以及用户可能面临的挑战。"

#: ../../source/ref-telemetry.md:5
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.** "
"Staying true to this statement, Flower makes it easy to disable telemetry "
"for users that do not want to share anonymous usage metrics."
msgstr ""
"**Flower 是一个用于协作式人工智能和数据科学的友好框架。** Flower 遵循这一声"
"明，让不想分享匿名使用指标的用户可以轻松禁用遥测技术。"

#: ../../source/ref-telemetry.md:7
msgid "Principles"
msgstr "原则"

#: ../../source/ref-telemetry.md:9
msgid ""
"We follow strong principles guarding anonymous usage metrics collection:"
msgstr "我们遵循严格的匿名使用指标收集原则："

#: ../../source/ref-telemetry.md:11
msgid ""
"**Optional:** You will always be able to disable telemetry; read on to learn "
"“[How to opt-out](#how-to-opt-out)”."
msgstr ""
"**可选：** 您始终可以禁用遥测功能；请继续阅读\"[如何退出](#how-to-opt-"
"out)\"。"

#: ../../source/ref-telemetry.md:12
msgid ""
"**Anonymous:** The reported usage metrics are anonymous and do not contain "
"any personally identifiable information (PII). See “[Collected metrics]"
"(#collected-metrics)” to understand what metrics are being reported."
msgstr ""
"**匿名：** 报告的使用指标是匿名的，不包含任何个人身份信息 (PII)。请参阅\"[收"
"集的指标](#collected-metrics) \"了解报告的指标。"

#: ../../source/ref-telemetry.md:13
msgid ""
"**Transparent:** You can easily inspect what anonymous metrics are being "
"reported; see the section “[How to inspect what is being reported](#how-to-"
"inspect-what-is-being-reported)”"
msgstr ""
"**透明：** 您可以轻松查看正在报告的匿名指标；请参阅\"[如何查看正在报告的指标]"
"（#how-to-inspect-what-is-being-reported）\"部分"

#: ../../source/ref-telemetry.md:14
msgid ""
"**Open for feedback:** You can always reach out to us if you have feedback; "
"see the section “[How to contact us](#how-to-contact-us)” for details."
msgstr ""
"**欢迎反馈：** 如果您有反馈意见，可以随时联系我们；详情请参见\"[如何联系我们]"
"(#how-to-contact-us) \"部分。"

#: ../../source/ref-telemetry.md:16
msgid "How to opt-out"
msgstr "如何退出"

#: ../../source/ref-telemetry.md:18
msgid ""
"When Flower starts, it will check for an environment variable called "
"`FLWR_TELEMETRY_ENABLED`. Telemetry can easily be disabled by setting "
"`FLWR_TELEMETRY_ENABLED=0`. Assuming you are starting a Flower server or "
"client, simply do so by prepending your command as in:"
msgstr ""
"Flower 启动时，会检查环境变量 `FLWR_TELEMETRY_ENABLED` 是否存在。通过设置 "
"`FLWR_TELEMETRY_ENABLED=0` 可以轻松禁用遥测功能。假设你启动的是 Flower 服务器"
"或客户端，只需在命令前添加以下内容即可："

#: ../../source/ref-telemetry.md:24
msgid ""
"Alternatively, you can export `FLWR_TELEMETRY_ENABLED=0` in, for example, `."
"bashrc` (or whatever configuration file applies to your environment) to "
"disable Flower telemetry permanently."
msgstr ""
"或者，你也可以在 `.bashrc`（或任何适用于你的环境的配置文件）中导出 "
"`FLWR_TELEMETRY_ENABLED=0` 来永久禁用 Flower telemetry。"

#: ../../source/ref-telemetry.md:26
msgid "Collected metrics"
msgstr "收集的指标"

#: ../../source/ref-telemetry.md:28
msgid "Flower telemetry collects the following metrics:"
msgstr "Flower 遥测技术收集以下指标："

#: ../../source/ref-telemetry.md:30
msgid ""
"**Flower version.** Understand which versions of Flower are currently being "
"used. This helps us to decide whether we should invest effort into releasing "
"a patch version for an older version of Flower or instead use the bandwidth "
"to build new features."
msgstr ""
"**了解目前使用的 Flower 版本。这有助于我们决定是否应该投入精力为旧版本的 "
"Flower 发布补丁版本，还是利用带宽来构建新功能。"

#: ../../source/ref-telemetry.md:32
msgid ""
"**Operating system.** Enables us to answer questions such as: *Should we "
"create more guides for Linux, macOS, or Windows?*"
msgstr ""
"**操作系统**使我们能够回答以下问题： *我们应该为 Linux、macOS 还是 Windows 创"
"建更多指南？*"

#: ../../source/ref-telemetry.md:34
msgid ""
"**Python version.** Knowing the Python version helps us, for example, to "
"decide whether we should invest effort into supporting old versions of "
"Python or stop supporting them and start taking advantage of new Python "
"features."
msgstr ""
"**例如，了解 Python 版本有助于我们决定是否应该投入精力支持旧版本的 Python，还"
"是停止支持这些版本并开始利用新的 Python 功能。"

#: ../../source/ref-telemetry.md:36
msgid ""
"**Hardware properties.** Understanding the hardware environment that Flower "
"is being used in helps to decide whether we should, for example, put more "
"effort into supporting low-resource environments."
msgstr ""
"**硬件属性** 了解 Flower 的硬件使用环境，有助于决定我们是否应在支持低资源环境"
"等方面投入更多精力。"

#: ../../source/ref-telemetry.md:38
msgid ""
"**Execution mode.** Knowing what execution mode Flower starts in enables us "
"to understand how heavily certain features are being used and better "
"prioritize based on that."
msgstr ""
"** 执行模式** 了解 Flower 的启动执行模式，能让我们了解某些功能的使用率，并据"
"此更好地确定优先级。"

#: ../../source/ref-telemetry.md:40
msgid ""
"**Cluster.** Flower telemetry assigns a random in-memory cluster ID each "
"time a Flower workload starts. This allows us to understand which device "
"types not only start Flower workloads but also successfully complete them."
msgstr ""
"**每次 Flower 工作负载启动时，Flower 遥测都会随机分配一个内存集群 ID。这样，"
"我们就能了解哪些设备类型不仅启动了 Flower 工作负载，而且还成功完成了它们。"

#: ../../source/ref-telemetry.md:42
msgid ""
"**Source.** Flower telemetry tries to store a random source ID in `~/.flwr/"
"source` the first time a telemetry event is generated. The source ID is "
"important to identify whether an issue is recurring or whether an issue is "
"triggered by multiple clusters running concurrently (which often happens in "
"simulation). For example, if a device runs multiple workloads at the same "
"time, and this results in an issue, then, in order to reproduce the issue, "
"multiple workloads must be started at the same time."
msgstr ""
"**Source.** Flower 遥测会在第一次生成遥测事件时，尝试在 `~/.flwr/source` 中存"
"储一个随机源 ID。源 ID 对于识别问题是否反复出现或问题是否由多个集群同时运行触"
"发（这在模拟中经常发生）非常重要。例如，如果设备同时运行多个工作负载并导致问"
"题，那么为了重现问题，必须同时启动多个工作负载。"

#: ../../source/ref-telemetry.md:44
msgid ""
"You may delete the source ID at any time. If you wish for all events logged "
"under a specific source ID to be deleted, you can send a deletion request "
"mentioning the source ID to `telemetry@flower.dev`. All events related to "
"that source ID will then be permanently deleted."
msgstr ""
"您可以随时删除源 ID。如果您希望删除特定源 ID 下记录的所有事件，可以向 "
"`telemetry@flower.dev` 发送删除请求，并提及该源 ID。届时，与该源 ID 相关的所"
"有事件都将被永久删除。"

#: ../../source/ref-telemetry.md:46
msgid ""
"We will not collect any personally identifiable information. If you think "
"any of the metrics collected could be misused in any way, please [get in "
"touch with us](#how-to-contact-us). We will update this page to reflect any "
"changes to the metrics collected and publish changes in the changelog."
msgstr ""
"我们不会收集任何个人身份信息。如果您认为所收集的任何指标可能以任何方式被滥"
"用，请[与我们联系]（#how-to-contact-us）。我们将更新本页面，以反映对所收集指"
"标的任何更改，并在更新日志中公布更改内容。"

#: ../../source/ref-telemetry.md:48
msgid ""
"If you think other metrics would be helpful for us to better guide our "
"decisions, please let us know! We will carefully review them; if we are "
"confident that they do not compromise user privacy, we may add them."
msgstr ""
"如果您认为其他指标有助于我们更好地指导决策，请告诉我们！我们将仔细审查这些指"
"标；如果我们确信它们不会损害用户隐私，我们可能会添加这些指标。"

#: ../../source/ref-telemetry.md:50
msgid "How to inspect what is being reported"
msgstr "如何检查报告中的内容"

#: ../../source/ref-telemetry.md:52
msgid ""
"We wanted to make it very easy for you to inspect what anonymous usage "
"metrics are reported. You can view all the reported telemetry information by "
"setting the environment variable `FLWR_TELEMETRY_LOGGING=1`. Logging is "
"disabled by default. You may use logging independently from "
"`FLWR_TELEMETRY_ENABLED` so that you can inspect the telemetry feature "
"without sending any metrics."
msgstr ""
"我们希望能让您轻松查看所报告的匿名使用指标。通过设置环境变量 "
"`FLWR_TELEMETRY_LOGGING=1` 可以查看所有报告的遥测信息。日志记录默认为禁用。您"
"可以不使用 `FLWR_TELEMETRY_ENABLED` 而单独使用日志记录，这样就可以在不发送任"
"何指标的情况下检查遥测功能。"

#: ../../source/ref-telemetry.md:58
msgid ""
"The inspect Flower telemetry without sending any anonymous usage metrics, "
"use both environment variables:"
msgstr ""
"在不发送任何匿名使用指标的情况下检查 Flower 遥测，可使用这两个环境变量："

#: ../../source/ref-telemetry.md:64
msgid "How to contact us"
msgstr "如何联系我们"

#: ../../source/ref-telemetry.md:66
msgid ""
"We want to hear from you. If you have any feedback or ideas on how to "
"improve the way we handle anonymous usage metrics, reach out to us via "
"[Slack](https://flower.dev/join-slack/) (channel `#telemetry`) or email "
"(`telemetry@flower.dev`)."
msgstr ""
"我们希望听到您的意见。如果您对如何改进我们处理匿名使用指标的方式有任何反馈或"
"想法，请通过 [Slack](https://flower.dev/join-slack/) （频道 `#telemetry`）或"
"电子邮件 (`telemetry@flower.dev`)与我们联系。"

#: ../../source/tutorial-quickstart-android.rst:-1
msgid ""
"Read this Federated Learning quickstart tutorial for creating an Android app "
"using Flower."
msgstr "阅读本联邦学习快速入门教程，了解如何使用 Flower 创建 Android 应用程序。"

#: ../../source/tutorial-quickstart-android.rst:5
msgid "Quickstart Android"
msgstr "快速入门 Android"

#: ../../source/tutorial-quickstart-android.rst:10
msgid ""
"Let's build a federated learning system using TFLite and Flower on Android!"
msgstr "让我们在 Android 上使用 TFLite 和 Flower 构建一个联邦学习系统！"

#: ../../source/tutorial-quickstart-android.rst:12
msgid ""
"Please refer to the `full code example <https://github.com/adap/flower/tree/"
"main/examples/android>`_ to learn more."
msgstr ""
"请参阅`完整代码示例 <https://github.com/adap/flower/tree/main/examples/"
"android>`_了解更多信息。"

#: ../../source/tutorial-quickstart-fastai.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"FastAI to train a vision model on CIFAR-10."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 FastAI 在 CIFAR-10 "
"上训练视觉模型。"

#: ../../source/tutorial-quickstart-fastai.rst:5
msgid "Quickstart fastai"
msgstr "快速入门 fastai"

#: ../../source/tutorial-quickstart-fastai.rst:10
msgid "Let's build a federated learning system using fastai and Flower!"
msgstr "让我们用 fastai 和 Flower 建立一个联邦学习系统！"

#: ../../source/tutorial-quickstart-fastai.rst:12
msgid ""
"Please refer to the `full code example <https://github.com/adap/flower/tree/"
"main/examples/quickstart-fastai>`_ to learn more."
msgstr ""
"请参阅 `完整代码示例 <https://github.com/adap/flower/tree/main/examples/"
"quickstart-fastai>`_了解更多信息。"

#: ../../source/tutorial-quickstart-huggingface.rst:-1
msgid ""
"Check out this Federating Learning quickstart tutorial for using Flower with "
"HuggingFace Transformers in order to fine-tune an LLM."
msgstr "查看此联邦学习 快速入门教程，了解如何使用 Flower 和 HuggingFace Transformers "
"来微调 LLM。"

#: ../../source/tutorial-quickstart-huggingface.rst:5
msgid "Quickstart 🤗 Transformers"
msgstr "🤗 Transformers快速入门"

#: ../../source/tutorial-quickstart-huggingface.rst:10
msgid ""
"Let's build a federated learning system using Hugging Face Transformers and "
"Flower!"
msgstr "让我们用Hugging Face Transformers和Flower来构建一个联邦学习系统！"

#: ../../source/tutorial-quickstart-huggingface.rst:12
msgid ""
"We will leverage Hugging Face to federate the training of language models "
"over multiple clients using Flower. More specifically, we will fine-tune a "
"pre-trained Transformer model (distilBERT) for sequence classification over "
"a dataset of IMDB ratings. The end goal is to detect if a movie rating is "
"positive or negative."
msgstr ""
"我们将利用Hugging Face技术，使用 Flower "
"在多个客户端上联邦训练语言模型。更具体地说，我们将对预先训练好的 Transformer "
"模型（distilBERT）进行微调，以便在 IMDB "
"评分数据集上进行序列分类。最终目标是检测电影评分是正面还是负面。"

#: ../../source/tutorial-quickstart-huggingface.rst:18
msgid "Dependencies"
msgstr "依赖关系"

#: ../../source/tutorial-quickstart-huggingface.rst:20
msgid ""
"To follow along this tutorial you will need to install the following "
"packages: :code:`datasets`, :code:`evaluate`, :code:`flwr`, :code:`torch`, "
"and :code:`transformers`. This can be done using :code:`pip`:"
msgstr ""
"要学习本教程，您需要安装以下软件包： :code:`datasets`、 :code:`evaluate`、 :"
"code:`flwr`、 :code:`torch`和 :code:`transformers`。这可以通过 :code:`pip` 来"
"完成："

#: ../../source/tutorial-quickstart-huggingface.rst:30
msgid "Standard Hugging Face workflow"
msgstr "标准Hugging Face工作流程"

#: ../../source/tutorial-quickstart-huggingface.rst:33
msgid "Handling the data"
msgstr "处理数据"

#: ../../source/tutorial-quickstart-huggingface.rst:35
msgid ""
"To fetch the IMDB dataset, we will use Hugging Face's :code:`datasets` "
"library. We then need to tokenize the data and create :code:`PyTorch` "
"dataloaders, this is all done in the :code:`load_data` function:"
msgstr ""
"为了获取 IMDB 数据集，我们将使用 Hugging Face 的 :code:`datasets` 库。然后，"
"我们需要对数据进行标记化，并创建 :code:`PyTorch` 数据加载器，这些都将在 :"
"code:`load_data` 函数中完成："

#: ../../source/tutorial-quickstart-huggingface.rst:81
msgid "Training and testing the model"
msgstr "训练和测试模型"

#: ../../source/tutorial-quickstart-huggingface.rst:83
msgid ""
"Once we have a way of creating our trainloader and testloader, we can take "
"care of the training and testing. This is very similar to any :code:"
"`PyTorch` training or testing loop:"
msgstr ""
"有了创建 trainloader 和 testloader 的方法后，我们就可以进行训练和测试了。这与"
"任何 :code:`PyTorch` 训练或测试循环都非常相似："

#: ../../source/tutorial-quickstart-huggingface.rst:121
msgid "Creating the model itself"
msgstr "创建模型本身"

#: ../../source/tutorial-quickstart-huggingface.rst:123
msgid ""
"To create the model itself, we will just load the pre-trained distillBERT "
"model using Hugging Face’s :code:`AutoModelForSequenceClassification` :"
msgstr ""
"要创建模型本身，我们只需使用 Hugging Face 的 :code:"
"`AutoModelForSequenceClassification` 加载预训练的 distillBERT 模型："

#: ../../source/tutorial-quickstart-huggingface.rst:136
msgid "Federating the example"
msgstr "将示例联邦化"

#: ../../source/tutorial-quickstart-huggingface.rst:139
msgid "Creating the IMDBClient"
msgstr "创建 IMDBClient"

#: ../../source/tutorial-quickstart-huggingface.rst:141
msgid ""
"To federate our example to multiple clients, we first need to write our "
"Flower client class (inheriting from :code:`flwr.client.NumPyClient`). This "
"is very easy, as our model is a standard :code:`PyTorch` model:"
msgstr ""
"要将我们的示例联邦到多个客户端，我们首先需要编写 Flower 客户端类（继承自 "
":code:`flwr.client.NumPyClient`）。这很容易，因为我们的模型是一个标准的 "
":code:`PyTorch` 模型："

#: ../../source/tutorial-quickstart-huggingface.rst:169
msgid ""
"The :code:`get_parameters` function lets the server get the client's "
"parameters. Inversely, the :code:`set_parameters` function allows the server "
"to send its parameters to the client. Finally, the :code:`fit` function "
"trains the model locally for the client, and the :code:`evaluate` function "
"tests the model locally and returns the relevant metrics."
msgstr ""
":code:`get_parameters` 函数允许服务器获取客户端的参数。相反，:code:"
"`set_parameters`函数允许服务器将其参数发送给客户端。最后，:code:`fit`函数在本"
"地为客户端训练模型，:code:`evaluate`函数在本地测试模型并返回相关指标。"

#: ../../source/tutorial-quickstart-huggingface.rst:175
msgid "Starting the server"
msgstr "启动服务器"

#: ../../source/tutorial-quickstart-huggingface.rst:177
msgid ""
"Now that we have a way to instantiate clients, we need to create our server "
"in order to aggregate the results. Using Flower, this can be done very "
"easily by first choosing a strategy (here, we are using :code:`FedAvg`, "
"which will define the global weights as the average of all the clients' "
"weights at each round) and then using the :code:`flwr.server.start_server` "
"function:"
msgstr ""
"现在我们有了实例化客户端的方法，我们需要创建服务器，以便汇总结果。使用 "
"Flower，首先选择一个策略（这里我们使用 "
":code:`FedAvg`，它将把全局模型参数定义为每轮所有客户端模型参数的平均值），"
"然后使用 :code:`flwr.server.start_server`函数，就可以非常轻松地完成这项工作："

#: ../../source/tutorial-quickstart-huggingface.rst:205
msgid ""
"The :code:`weighted_average` function is there to provide a way to aggregate "
"the metrics distributed amongst the clients (basically this allows us to "
"display a nice average accuracy and loss for every round)."
msgstr ""
"使用 :code:`weighted_average` 函数是为了提供一种方法来汇总分布在客户端的指标"
"（基本上，这可以让我们显示每一轮的平均精度和损失值）。"

#: ../../source/tutorial-quickstart-huggingface.rst:209
msgid "Putting everything together"
msgstr "把所有东西放在一起"

#: ../../source/tutorial-quickstart-huggingface.rst:211
msgid "We can now start client instances using:"
msgstr "现在我们可以使用："

#: ../../source/tutorial-quickstart-huggingface.rst:221
msgid ""
"And they will be able to connect to the server and start the federated "
"training."
msgstr "他们就能连接到服务器，开始联邦训练。"

#: ../../source/tutorial-quickstart-huggingface.rst:223
msgid ""
"If you want to check out everything put together, you should check out the "
"full code example: [https://github.com/adap/flower/tree/main/examples/"
"quickstart-huggingface](https://github.com/adap/flower/tree/main/examples/"
"quickstart-huggingface)."
msgstr ""
"如果您想查看所有内容，请查看完整的代码示例： [https://github.com/adap/flower/"
"tree/main/examples/quickstart-huggingface](https://github.com/adap/flower/"
"tree/main/examples/quickstart-huggingface)."

#: ../../source/tutorial-quickstart-huggingface.rst:227
msgid ""
"Of course, this is a very basic example, and a lot can be added or modified, "
"it was just to showcase how simply we could federate a Hugging Face workflow "
"using Flower."
msgstr ""
"当然，这只是一个非常基本的示例，还可以添加或修改很多内容，"
"只是为了展示我们可以如何简单地使用 Flower 联合Hugging Face的工作流程。"

#: ../../source/tutorial-quickstart-huggingface.rst:230
msgid ""
"Note that in this example we used :code:`PyTorch`, but we could have very "
"well used :code:`TensorFlow`."
msgstr ""
"请注意，在本例中我们使用了 :code:`PyTorch`，但也完全可以使用 :code:"
"`TensorFlow`。"

#: ../../source/tutorial-quickstart-ios.rst:-1
msgid ""
"Read this Federated Learning quickstart tutorial for creating an iOS app "
"using Flower to train a neural network on MNIST."
msgstr "阅读本联邦学习快速入门教程，了解如何使用 Flower 创建 iOS 应用程序，并在 "
"MNIST 上训练神经网络。"

#: ../../source/tutorial-quickstart-ios.rst:5
msgid "Quickstart iOS"
msgstr "快速入门 iOS"

#: ../../source/tutorial-quickstart-ios.rst:10
msgid ""
"In this tutorial we will learn how to train a Neural Network on MNIST using "
"Flower and CoreML on iOS devices."
msgstr ""
"在本教程中，我们将学习如何在 iOS 设备上使用 Flower 和 CoreML 在 MNIST 上训练"
"神经网络。"

#: ../../source/tutorial-quickstart-ios.rst:12
msgid ""
"First of all, for running the Flower Python server, it is recommended to "
"create a virtual environment and run everything within a `virtualenv "
"<https://flower.dev/docs/recommended-env-setup.html>`_. For the Flower "
"client implementation in iOS, it is recommended to use Xcode as our IDE."
msgstr ""
"首先，为了运行 Flower Python 服务器，建议创建一个虚拟环境，并在 `virtualenv "
"<https://flower.dev/docs/recommended-env-setup.html>`_ 中运行一切。对于在 "
"iOS 中实现 Flower 客户端，建议使用 Xcode 作为我们的集成开发环境。"

#: ../../source/tutorial-quickstart-ios.rst:15
msgid ""
"Our example consists of one Python *server* and two iPhone *clients* that "
"all have the same model."
msgstr "我们的示例包括一个 Python *服务器*和两个 iPhone "
"*客户端*，它们都具有相同的模型。"

#: ../../source/tutorial-quickstart-ios.rst:17
msgid ""
"*Clients* are responsible for generating individual weight updates for the "
"model based on their local datasets. These updates are then sent to the "
"*server* which will aggregate them to produce a better model. Finally, the "
"*server* sends this improved version of the model back to each *client*. A "
"complete cycle of weight updates is called a *round*."
msgstr ""
"*客户端*负责根据其本地数据集为模型生成独立的模型参数。然后，这些参数更新会被"
"发送到*服务器*，由*服务器*汇总后生成一个更好的模型。最后，*服务器*将改进后的"
"模型发送回每个*客户端*。一个完整的参数更新周期称为一*轮*。"

#: ../../source/tutorial-quickstart-ios.rst:21
msgid ""
"Now that we have a rough idea of what is going on, let's get started to "
"setup our Flower server environment. We first need to install Flower. You "
"can do this by using pip:"
msgstr ""
"现在我们已经有了一个大致的概念，让我们开始设置 Flower 服务器环境吧。首先，我"
"们需要安装 Flower。你可以使用 pip 来安装："

#: ../../source/tutorial-quickstart-ios.rst:27
msgid "Or Poetry:"
msgstr "或者Poetry："

#: ../../source/tutorial-quickstart-ios.rst:36
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training using CoreML as our local training pipeline and MNIST "
"as our dataset. For simplicity reasons we will use the complete Flower "
"client with CoreML, that has been implemented and stored inside the Swift "
"SDK. The client implementation can be seen below:"
msgstr ""
"现在我们已经安装了所有依赖项，让我们使用 CoreML 作为本地训练框架和 MNIST "
"作为数据集，运行一个简单的分布式训练。为了简单起见，我们将使用 CoreML 的完整 "
"Flower 客户端，该客户端已在 Swift SDK 中实现并存储。客户端实现如下："

#: ../../source/tutorial-quickstart-ios.rst:72
msgid ""
"Let's create a new application project in Xcode and add :code:`flwr` as a "
"dependency in your project. For our application, we will store the logic of "
"our app in :code:`FLiOSModel.swift` and the UI elements in :code:"
"`ContentView.swift`. We will focus more on :code:`FLiOSModel.swift` in this "
"quickstart. Please refer to the `full code example <https://github.com/adap/"
"flower/tree/main/examples/ios>`_ to learn more about the app."
msgstr ""
"让我们在 Xcode 中创建一个新的应用程序项目，并在项目中添加 :code:`flwr` "
"作为依赖关系。对于我们的应用程序，我们将在 :code:`FLiOSModel.swift` "
"中存储应用程序的逻辑，在 :code:`ContentView.swift` 中存储 UI "
"元素。在本快速入门中，我们将更多地关注 :code:`FLiOSModel.swift`。请参阅 `"
"完整代码示例 <https://github.com/adap/flower/tree/main/examples/ios>`_ "
"以了解更多有关应用程序的信息。"

#: ../../source/tutorial-quickstart-ios.rst:75
msgid "Import Flower and CoreML related packages in :code:`FLiOSModel.swift`:"
msgstr "在 :code:`FLiOSModel.swift` 中导入 Flower 和 CoreML 相关软件包："

#: ../../source/tutorial-quickstart-ios.rst:83
msgid ""
"Then add the mlmodel to the project simply by drag-and-drop, the mlmodel "
"will be bundled inside the application during deployment to your iOS device. "
"We need to pass the url to access mlmodel and run CoreML machine learning "
"processes, it can be retrieved by calling the function :code:`Bundle.main."
"url`. For the MNIST dataset, we need to preprocess it into :code:"
"`MLBatchProvider` object. The preprocessing is done inside :code:`DataLoader."
"swift`."
msgstr ""
"然后通过拖放将 mlmodel 添加到项目中，在部署到 iOS 设备时，mlmodel 将被捆绑到"
"应用程序中。我们需要传递 url 以访问 mlmodel 并运行 CoreML 机器学习进程，可通"
"过调用函数 :code:`Bundle.main.url` 获取。对于 MNIST 数据集，我们需要将其预处"
"理为 :code:`MLBatchProvider` 对象。预处理在 :code:`DataLoader.swift` 中完成。"

#: ../../source/tutorial-quickstart-ios.rst:99
msgid ""
"Since CoreML does not allow the model parameters to be seen before training, "
"and accessing the model parameters during or after the training can only be "
"done by specifying the layer name, we need to know this informations "
"beforehand, through looking at the model specification, which are written as "
"proto files. The implementation can be seen in :code:`MLModelInspect`."
msgstr ""
"由于 CoreML 不允许在训练前查看模型参数，而在训练过程中或训练后访问模型参数只"
"能通过指定层名来完成，因此我们需要事先通过查看模型规范（写成 proto 文件）来了"
"解这些信息。具体实现可参见 :code:`MLModelInspect`。"

#: ../../source/tutorial-quickstart-ios.rst:102
msgid ""
"After we have all of the necessary informations, let's create our Flower "
"client."
msgstr "获得所有必要信息后，让我们创建 Flower 客户端。"

#: ../../source/tutorial-quickstart-ios.rst:117
msgid ""
"Then start the Flower gRPC client and start communicating to the server by "
"passing our Flower client to the function :code:`startFlwrGRPC`."
msgstr ""
"然后启动 Flower gRPC 客户端，并通过将 Flower 客户端传递给函数 :code:"
"`startFlwrGRPC` 来开始与服务器通信。"

#: ../../source/tutorial-quickstart-ios.rst:124
msgid ""
"That's it for the client. We only have to implement :code:`Client` or call "
"the provided :code:`MLFlwrClient` and call :code:`startFlwrGRPC()`. The "
"attribute :code:`hostname` and :code:`port` tells the client which server to "
"connect to. This can be done by entering the hostname and port in the "
"application before clicking the start button to start the federated learning "
"process."
msgstr ""
"这就是客户端。我们只需实现 :code:`Client` 或调用提供的 :code:`MLFlwrClient` "
"并调用 :code:`startFlwrGRPC()`。属性 :code:`hostname` 和 :code:`port` 会告诉"
"客户端要连接到哪个服务器。这可以通过在应用程序中输入主机名和端口来实现，然后"
"再点击开始按钮启动联邦学习进程。"

#: ../../source/tutorial-quickstart-ios.rst:131
#: ../../source/tutorial-quickstart-mxnet.rst:226
#: ../../source/tutorial-quickstart-pytorch.rst:205
#: ../../source/tutorial-quickstart-tensorflow.rst:100
msgid ""
"For simple workloads we can start a Flower server and leave all the "
"configuration possibilities at their default values. In a file named :code:"
"`server.py`, import Flower and start the server:"
msgstr ""
"对于简单的工作负载，我们可以启动 Flower 服务器，并将所有配置选项保留为默认"
"值。在名为 :code:`server.py` 的文件中，导入 Flower 并启动服务器："

#: ../../source/tutorial-quickstart-ios.rst:142
#: ../../source/tutorial-quickstart-mxnet.rst:237
#: ../../source/tutorial-quickstart-pytorch.rst:216
#: ../../source/tutorial-quickstart-scikitlearn.rst:215
#: ../../source/tutorial-quickstart-tensorflow.rst:112
msgid "Train the model, federated!"
msgstr "联邦训练模型！"

#: ../../source/tutorial-quickstart-ios.rst:144
#: ../../source/tutorial-quickstart-pytorch.rst:218
#: ../../source/tutorial-quickstart-tensorflow.rst:114
#: ../../source/tutorial-quickstart-xgboost.rst:522
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. FL systems usually have a server and multiple "
"clients. We therefore have to start the server first:"
msgstr "客户端和服务器都已准备就绪，我们现在可以运行一切，看看联邦学习的实际效果。FL "
"系统通常有一个服务器和多个客户端。因此，我们必须先启动服务器："

#: ../../source/tutorial-quickstart-ios.rst:152
msgid ""
"Once the server is running we can start the clients in different terminals. "
"Build and run the client through your Xcode, one through Xcode Simulator and "
"the other by deploying it to your iPhone. To see more about how to deploy "
"your app to iPhone or Simulator visit `here <https://developer.apple.com/"
"documentation/xcode/running-your-app-in-simulator-or-on-a-device>`_."
msgstr ""
"服务器运行后，我们就可以在不同的终端启动客户端。通过 Xcode 构建并运行客户端，"
"一个通过 Xcode 模拟器，另一个通过部署到 iPhone。要了解更多有关如何将应用程序"
"部署到 iPhone 或模拟器的信息，请访问 `此处 <https://developer.apple.com/"
"documentation/xcode/running-your-app-in-simulator-or-on-a-device>`_。"

#: ../../source/tutorial-quickstart-ios.rst:156
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system in your ios device. The full `source code <https://github."
"com/adap/flower/blob/main/examples/ios>`_ for this example can be found in :"
"code:`examples/ios`."
msgstr ""
"恭喜您！ 您已经成功地在 ios 设备中构建并运行了第一个联邦学习系统。本示例的`"
"完整源代码 <https://github.com/adap/flower/blob/main/examples/ios>`_ 可在 "
":code:`examples/ios` 中找到。"

#: ../../source/tutorial-quickstart-jax.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"Jax to train a linear regression model on a scikit-learn dataset."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 Jax 在 scikit-learn "
"数据集上训练线性回归模型。"

#: ../../source/tutorial-quickstart-jax.rst:5
msgid "Quickstart JAX"
msgstr "快速入门 JAX"

#: ../../source/tutorial-quickstart-mxnet.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"MXNet to train a Sequential model on MNIST."
msgstr "查看此联邦学习 快速入门教程，了解如何使用 Flower 和 MXNet 在 MNIST "
"上训练序列模型。"

#: ../../source/tutorial-quickstart-mxnet.rst:5
msgid "Quickstart MXNet"
msgstr "快速入门 MXNet"

#: ../../source/tutorial-quickstart-mxnet.rst:10
msgid ""
"In this tutorial, we will learn how to train a :code:`Sequential` model on "
"MNIST using Flower and MXNet."
msgstr ""
"在本教程中，我们将学习如何使用 Flower 和 MXNet 在 MNIST 上训练 :code:"
"`Sequential` 模型。"

#: ../../source/tutorial-quickstart-mxnet.rst:12
#: ../../source/tutorial-quickstart-scikitlearn.rst:12
msgid ""
"It is recommended to create a virtual environment and run everything within "
"this `virtualenv <https://flower.dev/docs/recommended-env-setup.html>`_."
msgstr ""
"建议创建一个虚拟环境，并在此 `virtualenv <https://flower.dev/docs/"
"recommended-env-setup.html>`_ 中运行所有内容。"

#: ../../source/tutorial-quickstart-mxnet.rst:16
#: ../../source/tutorial-quickstart-scikitlearn.rst:16
msgid ""
"*Clients* are responsible for generating individual model parameter updates "
"for the model based on their local datasets. These updates are then sent to "
"the *server* which will aggregate them to produce an updated global model. "
"Finally, the *server* sends this improved version of the model back to each "
"*client*. A complete cycle of parameters updates is called a *round*."
msgstr ""
"*客户端*负责根据其本地数据集为模型生成单独的模型参数更新。然后，这些参数更新"
"将被发送到*服务器*，由*服务器*汇总后生成一个更新的全局模型。最后，*服务器*将"
"这一改进版模型发回给每个*客户端*。一个完整的参数更新周期称为一*轮*。"

#: ../../source/tutorial-quickstart-mxnet.rst:20
#: ../../source/tutorial-quickstart-scikitlearn.rst:20
msgid ""
"Now that we have a rough idea of what is going on, let's get started. We "
"first need to install Flower. You can do this by running:"
msgstr ""
"现在，我们已经有了一个大致的概念，让我们开始吧。首先，我们需要安装 Flower。运"
"行："

#: ../../source/tutorial-quickstart-mxnet.rst:26
msgid "Since we want to use MXNet, let's go ahead and install it:"
msgstr "既然我们要使用 MXNet，那就继续安装吧："

#: ../../source/tutorial-quickstart-mxnet.rst:36
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training procedure "
"and network architecture are based on MXNet´s `Hand-written Digit "
"Recognition tutorial <https://mxnet.apache.org/api/python/docs/tutorials/"
"packages/gluon/image/mnist.html>`_."
msgstr ""
"现在，我们已经安装了所有依赖项，让我们用两个客户端和一个服务器来运行一个简单"
"的分布式训练。我们的训练程序和网络架构基于 MXNet 的 `手写数字识别教程 "
"<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/"
"mnist.html>`_\"。"

#: ../../source/tutorial-quickstart-mxnet.rst:38
msgid ""
"In a file called :code:`client.py`, import Flower and MXNet related packages:"
msgstr "在名为 :code:`client.py` 的文件中，导入 Flower 和 MXNet 相关软件包："

#: ../../source/tutorial-quickstart-mxnet.rst:53
msgid "In addition, define the device allocation in MXNet with:"
msgstr "此外，还可以在 MXNet 中定义设备分配："

#: ../../source/tutorial-quickstart-mxnet.rst:59
msgid ""
"We use MXNet to load MNIST, a popular image classification dataset of "
"handwritten digits for machine learning. The MXNet utility :code:`mx."
"test_utils.get_mnist()` downloads the training and test data."
msgstr ""
"我们使用 MXNet 加载 MNIST，这是一个用于机器学习的流行手写数字图像分类数据集。"
"MXNet 工具 :code:`mx.test_utils.get_mnist()` 会下载训练和测试数据。"

#: ../../source/tutorial-quickstart-mxnet.rst:73
msgid ""
"Define the training and loss with MXNet. We train the model by looping over "
"the dataset, measure the corresponding loss, and optimize it."
msgstr "用 MXNet 定义训练和损失值。我们在数据集上循环训练模型，测量相应的损失值，并对"
"其进行优化。"

#: ../../source/tutorial-quickstart-mxnet.rst:111
msgid ""
"Next, we define the validation of our machine learning model. We loop over "
"the test set and measure both loss and accuracy on the test set."
msgstr "接下来，我们定义机器学习模型的验证。我们在测试集上循环，测量测试集上的损失值"
"和准确率。"

#: ../../source/tutorial-quickstart-mxnet.rst:135
msgid ""
"After defining the training and testing of a MXNet machine learning model, "
"we use these functions to implement a Flower client."
msgstr ""
"在定义了 MXNet 机器学习模型的训练和测试后，我们使用这些函数实现了 Flower 客户"
"端。"

#: ../../source/tutorial-quickstart-mxnet.rst:137
msgid "Our Flower clients will use a simple :code:`Sequential` model:"
msgstr "我们的 Flower 客户端将使用简单的 :code:`Sequential` 模型："

#: ../../source/tutorial-quickstart-mxnet.rst:156
msgid ""
"After loading the dataset with :code:`load_data()` we perform one forward "
"propagation to initialize the model and model parameters with :code:"
"`model(init)`. Next, we implement a Flower client."
msgstr ""
"使用 :code:`load_data()` 加载数据集后，我们会执行一次前向传播，使用 :code:"
"`model(init)` 初始化模型和模型参数。接下来，我们实现一个 Flower 客户端。"

#: ../../source/tutorial-quickstart-mxnet.rst:158
#: ../../source/tutorial-quickstart-pytorch.rst:144
#: ../../source/tutorial-quickstart-tensorflow.rst:54
msgid ""
"The Flower server interacts with clients through an interface called :code:"
"`Client`. When the server selects a particular client for training, it sends "
"training instructions over the network. The client receives those "
"instructions and calls one of the :code:`Client` methods to run your code (i."
"e., to train the neural network we defined earlier)."
msgstr ""
"Flower 服务器通过一个名为 :code:`Client` 的接口与客户端交互。当服务器选择一个"
"特定的客户端进行训练时，它会通过网络发送训练指令。客户端接收到这些指令后，"
"会调用 :code:`Client` "
"方法之一来运行您的代码（即训练我们之前定义的神经网络）。"

#: ../../source/tutorial-quickstart-mxnet.rst:164
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which makes "
"it easier to implement the :code:`Client` interface when your workload uses "
"MXNet. Implementing :code:`NumPyClient` usually means defining the following "
"methods (:code:`set_parameters` is optional though):"
msgstr ""
"Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当您的工作负载使用 MXNet "
"时，它可以让您更轻松地实现 :code:`Client` 接口。实现 :code:`NumPyClient` "
"通常意味着定义以下方法（:code:`set_parameters` 是可选的）："

#: ../../source/tutorial-quickstart-mxnet.rst:170
#: ../../source/tutorial-quickstart-pytorch.rst:156
#: ../../source/tutorial-quickstart-scikitlearn.rst:109
msgid "return the model weight as a list of NumPy ndarrays"
msgstr "以 NumPy ndarrays 列表形式返回模型参数"

#: ../../source/tutorial-quickstart-mxnet.rst:171
#: ../../source/tutorial-quickstart-pytorch.rst:157
#: ../../source/tutorial-quickstart-scikitlearn.rst:111
msgid ":code:`set_parameters` (optional)"
msgstr ":code:`set_parameters` （可选）"

#: ../../source/tutorial-quickstart-mxnet.rst:172
#: ../../source/tutorial-quickstart-pytorch.rst:158
#: ../../source/tutorial-quickstart-scikitlearn.rst:111
msgid ""
"update the local model weights with the parameters received from the server"
msgstr "用从服务器接收到的参数更新本地模型参数"

#: ../../source/tutorial-quickstart-mxnet.rst:174
#: ../../source/tutorial-quickstart-pytorch.rst:160
#: ../../source/tutorial-quickstart-scikitlearn.rst:114
msgid "set the local model weights"
msgstr "设置本地模型参数"

#: ../../source/tutorial-quickstart-mxnet.rst:175
#: ../../source/tutorial-quickstart-pytorch.rst:161
#: ../../source/tutorial-quickstart-scikitlearn.rst:115
msgid "train the local model"
msgstr "训练本地模型"

#: ../../source/tutorial-quickstart-mxnet.rst:176
#: ../../source/tutorial-quickstart-pytorch.rst:162
#: ../../source/tutorial-quickstart-scikitlearn.rst:116
msgid "receive the updated local model weights"
msgstr "接收更新的本地模型参数"

#: ../../source/tutorial-quickstart-mxnet.rst:178
#: ../../source/tutorial-quickstart-pytorch.rst:164
#: ../../source/tutorial-quickstart-scikitlearn.rst:118
msgid "test the local model"
msgstr "测试本地模型"

#: ../../source/tutorial-quickstart-mxnet.rst:180
msgid "They can be implemented in the following way:"
msgstr "它们可以通过以下方式实现："

#: ../../source/tutorial-quickstart-mxnet.rst:210
msgid ""
"We can now create an instance of our class :code:`MNISTClient` and add one "
"line to actually run this client:"
msgstr ""
"现在我们可以创建一个 :code:`MNISTClient` 类的实例，并添加一行来实际运行该客户"
"端："

#: ../../source/tutorial-quickstart-mxnet.rst:217
#: ../../source/tutorial-quickstart-scikitlearn.rst:150
msgid ""
"That's it for the client. We only have to implement :code:`Client` or :code:"
"`NumPyClient` and call :code:`fl.client.start_client()`. The string :code:"
"`\"0.0.0.0:8080\"` tells the client which server to connect to. In our case "
"we can run the server and the client on the same machine, therefore we use :"
"code:`\"0.0.0.0:8080\"`. If we run a truly federated workload with the "
"server and clients running on different machines, all that needs to change "
"is the :code:`server_address` we pass to the client."
msgstr ""
"对于客户端就需要做这么多。我们仅需要实现 "
":code:`Client`或者:code:`NumPyClient`然后调用:code:`fl.client."
"start_client()`。字符串 :code:`\"0.0.0.0:8080\"` 告诉客户端要连接到哪个服务器"
"。在我们的例子中，我们可以在同一台机器上运行服务器和客户端，因此我们使用:code"
":`\"0.0.0.0:8080\""
"`。如果我们运行真正联邦学习的工作负载，服务器和客户端在不同的机器上运行，"
"则需要更改的只是我们传递给客户端的 server_address 。"

#: ../../source/tutorial-quickstart-mxnet.rst:239
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. Federated learning systems usually have a "
"server and multiple clients. We therefore have to start the server first:"
msgstr ""
"客户端和服务器都准备就绪后，我们现在就可以运行一切，看看联邦学习的运行情况。"
"联邦学习系统通常有一个服务器和多个客户端。因此，我们必须先启动服务器："

#: ../../source/tutorial-quickstart-mxnet.rst:247
#: ../../source/tutorial-quickstart-pytorch.rst:226
#: ../../source/tutorial-quickstart-scikitlearn.rst:224
#: ../../source/tutorial-quickstart-tensorflow.rst:122
#: ../../source/tutorial-quickstart-xgboost.rst:530
msgid ""
"Once the server is running we can start the clients in different terminals. "
"Open a new terminal and start the first client:"
msgstr ""
"服务器运行后，我们就可以在不同终端启动客户端了。打开一个新终端，启动第一个客"
"户端："

#: ../../source/tutorial-quickstart-mxnet.rst:254
#: ../../source/tutorial-quickstart-pytorch.rst:233
#: ../../source/tutorial-quickstart-scikitlearn.rst:231
#: ../../source/tutorial-quickstart-tensorflow.rst:129
#: ../../source/tutorial-quickstart-xgboost.rst:537
msgid "Open another terminal and start the second client:"
msgstr "打开另一台终端，启动第二个客户端："

#: ../../source/tutorial-quickstart-mxnet.rst:260
#: ../../source/tutorial-quickstart-pytorch.rst:239
#: ../../source/tutorial-quickstart-scikitlearn.rst:237
#: ../../source/tutorial-quickstart-xgboost.rst:543
msgid ""
"Each client will have its own dataset. You should now see how the training "
"does in the very first terminal (the one that started the server):"
msgstr ""
"每个客户端都有自己的数据集。现在你应该看到第一个终端（启动服务器的终端）的训"
"练效果了："

#: ../../source/tutorial-quickstart-mxnet.rst:292
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code <https://github.com/adap/flower/blob/"
"main/examples/quickstart-mxnet/client.py>`_ for this example can be found "
"in :code:`examples/quickstart-mxnet`."
msgstr ""
"恭喜您！您已经成功构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
"<https://github.com/adap/flower/blob/main/examples/quickstart-mxnet/client."
"py>`_ 可在 :code:`examples/quickstart-mxnet` 中找到。"

#: ../../source/tutorial-quickstart-pandas.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"Pandas to perform Federated Analytics."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 Pandas 执行联邦分析。"

#: ../../source/tutorial-quickstart-pandas.rst:5
msgid "Quickstart Pandas"
msgstr "快速入门Pandas"

#: ../../source/tutorial-quickstart-pandas.rst:10
msgid "Let's build a federated analytics system using Pandas and Flower!"
msgstr "让我们使用 Pandas 和 Flower 建立一个联邦分析系统！"

#: ../../source/tutorial-quickstart-pandas.rst:12
msgid ""
"Please refer to the `full code example <https://github.com/adap/flower/tree/"
"main/examples/quickstart-pandas>`_ to learn more."
msgstr ""
"请参阅 `完整代码示例 <https://github.com/adap/flower/tree/main/examples/"
"quickstart-pandas>`_\" 了解更多信息。"

#: ../../source/tutorial-quickstart-pytorch.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"PyTorch to train a CNN model on MNIST."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 PyTorch 在 MNIST 上训练 "
"CNN 模型。"

#: ../../source/tutorial-quickstart-pytorch.rst:13
msgid ""
"In this tutorial we will learn how to train a Convolutional Neural Network "
"on CIFAR10 using Flower and PyTorch."
msgstr ""
"在本教程中，我们将学习如何使用 Flower 和 PyTorch 在 CIFAR10 上训练卷积神经网"
"络。"

#: ../../source/tutorial-quickstart-pytorch.rst:15
#: ../../source/tutorial-quickstart-xgboost.rst:36
msgid ""
"First of all, it is recommended to create a virtual environment and run "
"everything within a `virtualenv <https://flower.dev/docs/recommended-env-"
"setup.html>`_."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.dev/docs/"
"recommended-env-setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-pytorch.rst:29
msgid ""
"Since we want to use PyTorch to solve a computer vision task, let's go ahead "
"and install PyTorch and the **torchvision** library:"
msgstr ""
"既然我们想用 PyTorch 解决计算机视觉任务，那就继续安装 PyTorch 和 "
"**torchvision** 库吧："

#: ../../source/tutorial-quickstart-pytorch.rst:39
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training procedure "
"and network architecture are based on PyTorch's `Deep Learning with PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
msgstr ""
"现在我们已经安装了所有的依赖项，让我们用两个客户端和一个服务器来运行一个简单"
"的分布式训练。我们的训练过程和网络架构基于 PyTorch 的《Deep Learning with "
"PyTorch <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial."
"html>`_》。"

#: ../../source/tutorial-quickstart-pytorch.rst:41
msgid ""
"In a file called :code:`client.py`, import Flower and PyTorch related "
"packages:"
msgstr "在名为 :code:`client.py` 的文件中，导入 Flower 和 PyTorch 相关软件包："

#: ../../source/tutorial-quickstart-pytorch.rst:56
msgid "In addition, we define the device allocation in PyTorch with:"
msgstr "此外，我们还在 PyTorch 中定义了设备分配："

#: ../../source/tutorial-quickstart-pytorch.rst:62
msgid ""
"We use PyTorch to load CIFAR10, a popular colored image classification "
"dataset for machine learning. The PyTorch :code:`DataLoader()` downloads the "
"training and test data that are then normalized."
msgstr ""
"我们使用 PyTorch 来加载 CIFAR10，这是一个用于机器学习的流行彩色图像分类数据"
"集。PyTorch :code:`DataLoader()`下载训练数据和测试数据，然后进行归一化处理。"

#: ../../source/tutorial-quickstart-pytorch.rst:78
msgid ""
"Define the loss and optimizer with PyTorch. The training of the dataset is "
"done by looping over the dataset, measure the corresponding loss and "
"optimize it."
msgstr "使用 PyTorch 定义损失和优化器。数据集的训练是通过循环数据集、测量相应的损失值"
"并对其进行优化来完成的。"

#: ../../source/tutorial-quickstart-pytorch.rst:94
msgid ""
"Define then the validation of the  machine learning network. We loop over "
"the test set and measure the loss and accuracy of the test set."
msgstr "然后定义机器学习网络的验证。我们在测试集上循环，计算测试集的损失值和准确率。"

#: ../../source/tutorial-quickstart-pytorch.rst:113
msgid ""
"After defining the training and testing of a PyTorch machine learning model, "
"we use the functions for the Flower clients."
msgstr ""
"在定义了 PyTorch 机器学习模型的训练和测试之后，我们将这些功能用于 Flower 客户"
"端。"

#: ../../source/tutorial-quickstart-pytorch.rst:115
msgid ""
"The Flower clients will use a simple CNN adapted from 'PyTorch: A 60 Minute "
"Blitz':"
msgstr "Flower 客户端将使用一个简单的从“PyTorch： 60 分钟突击\"改编的CNN："

#: ../../source/tutorial-quickstart-pytorch.rst:142
msgid ""
"After loading the data set with :code:`load_data()` we define the Flower "
"interface."
msgstr "使用 :code:`load_data()` 加载数据集后，我们定义了 Flower 接口。"

#: ../../source/tutorial-quickstart-pytorch.rst:150
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which makes "
"it easier to implement the :code:`Client` interface when your workload uses "
"PyTorch. Implementing :code:`NumPyClient` usually means defining the "
"following methods (:code:`set_parameters` is optional though):"
msgstr ""
"Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当您的工作负载使用 "
"PyTorch 时，它使 :code:`Client` 接口的实现变得更容易。实现 "
":code:`NumPyClient` 通常意味着定义以下方法（:code:`set_parameters` "
"是可选的）："

#: ../../source/tutorial-quickstart-pytorch.rst:166
msgid "which can be implemented in the following way:"
msgstr "可以通过以下方式实现："

#: ../../source/tutorial-quickstart-pytorch.rst:189
#: ../../source/tutorial-quickstart-tensorflow.rst:82
msgid ""
"We can now create an instance of our class :code:`CifarClient` and add one "
"line to actually run this client:"
msgstr ""
"现在我们可以创建一个 :code:`CifarClient` 类的实例，并添加一行来实际运行该客户"
"端："

#: ../../source/tutorial-quickstart-pytorch.rst:196
#: ../../source/tutorial-quickstart-tensorflow.rst:90
msgid ""
"That's it for the client. We only have to implement :code:`Client` or :code:"
"`NumPyClient` and call :code:`fl.client.start_client()`. The string :code:"
"`\"[::]:8080\"` tells the client which server to connect to. In our case we "
"can run the server and the client on the same machine, therefore we use :"
"code:`\"[::]:8080\"`. If we run a truly federated workload with the server "
"and clients running on different machines, all that needs to change is the :"
"code:`server_address` we point the client at."
msgstr ""
"对于客户来说就是这样了。我们只需实现 :code:`Client` 或 :code:`NumPyClient` "
"并调用:code:`fl.client.start_client()` 即可。字符串 :code:`\"[::]:8080\"` 告"
"诉客户端要连接到哪个服务器。在我们的例子中，我们可以在同一台机器上运行服务器"
"和客户端，因此我们使用 :code:`\"[::]:8080\""
"`。如果我们运行真正联邦的工作负载，服务器和客户端运行在不同的机器上，"
"则需要更改的只是我们指向客户端的 server_address 。"

#: ../../source/tutorial-quickstart-pytorch.rst:271
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code <https://github.com/adap/flower/blob/"
"main/examples/quickstart-pytorch/client.py>`_ for this example can be found "
"in :code:`examples/quickstart-pytorch`."
msgstr ""
"恭喜您！您已经成功构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
"<https://github.com/adap/flower/blob/main/examples/quickstart-pytorch/client."
"py>`_ 可以在 :code:`examples/quickstart-pytorch` 中找到。"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"PyTorch Lightning to train an Auto Encoder model on MNIST."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 PyTorch Lightning 在 "
"MNIST 上训练自动编码器模型。"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:5
msgid "Quickstart PyTorch Lightning"
msgstr "快速入门 PyTorch Lightning"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:10
msgid ""
"Let's build a horizontal federated learning system using PyTorch Lightning "
"and Flower!"
msgstr "让我们使用 PyTorch Lightning 和 Flower 构建一个水平联邦学习系统！"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:12
msgid ""
"Please refer to the `full code example <https://github.com/adap/flower/tree/"
"main/examples/quickstart-pytorch-lightning>`_ to learn more."
msgstr ""
"请参阅 `完整代码示例 <https://github.com/adap/flower/tree/main/examples/"
"quickstart-pytorch-lightning>`_ 了解更多信息。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"scikit-learn to train a linear regression model."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 scikit-learn "
"训练线性回归模型。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:5
msgid "Quickstart scikit-learn"
msgstr "scikit-learn快速入门"

#: ../../source/tutorial-quickstart-scikitlearn.rst:10
msgid ""
"In this tutorial, we will learn how to train a :code:`Logistic Regression` "
"model on MNIST using Flower and scikit-learn."
msgstr ""
"在本教程中，我们将学习如何使用 Flower 和 scikit-learn 在 MNIST 上训练一个 :"
"code:`Logistic Regression` 模型。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:26
msgid "Since we want to use scikt-learn, let's go ahead and install it:"
msgstr "既然我们要使用 scikt-learn，那就继续安装吧："

#: ../../source/tutorial-quickstart-scikitlearn.rst:32
msgid "Or simply install all dependencies using Poetry:"
msgstr "或者直接使用 Poetry 安装所有依赖项："

#: ../../source/tutorial-quickstart-scikitlearn.rst:42
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. However, before "
"setting up the client and server, we will define all functionalities that we "
"need for our federated learning setup within :code:`utils.py`. The :code:"
"`utils.py` contains different functions defining all the machine learning "
"basics:"
msgstr ""
"现在我们已经安装了所有的依赖项，让我们用两个客户端和一个服务器来运行一个简单"
"的分布式训练。不过，在设置客户端和服务器之前，我们将在 :code:`utils.py` "
"中定义联邦学习设置所需的所有功能。:code:`utils."
"py`包含定义所有机器学习基础知识的不同函数："

#: ../../source/tutorial-quickstart-scikitlearn.rst:45
msgid ":code:`get_model_parameters()`"
msgstr ":code:`get_model_parameters()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:46
msgid "Returns the paramters of a :code:`sklearn` LogisticRegression model"
msgstr "返回 :code:`sklearn` LogisticRegression 模型的参数"

#: ../../source/tutorial-quickstart-scikitlearn.rst:47
msgid ":code:`set_model_params()`"
msgstr ":code:`set_model_params()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:48
msgid "Sets the parameters of a :code:`sklean` LogisticRegression model"
msgstr "设置:code:`sklean`的LogisticRegression模型的参数"

#: ../../source/tutorial-quickstart-scikitlearn.rst:49
msgid ":code:`set_initial_params()`"
msgstr ":code:`set_initial_params()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:50
msgid "Initializes the model parameters that the Flower server will ask for"
msgstr "初始化 Flower 服务器将要求的模型参数"

#: ../../source/tutorial-quickstart-scikitlearn.rst:51
msgid ":code:`load_mnist()`"
msgstr ":code:`load_mnist()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:52
msgid "Loads the MNIST dataset using OpenML"
msgstr "使用 OpenML 加载 MNIST 数据集"

#: ../../source/tutorial-quickstart-scikitlearn.rst:53
msgid ":code:`shuffle()`"
msgstr ":code:`shuffle()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:54
msgid "Shuffles data and its label"
msgstr "对数据及其标签进行洗牌"

#: ../../source/tutorial-quickstart-scikitlearn.rst:56
msgid ":code:`partition()`"
msgstr ":code:`partition()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:56
msgid "Splits datasets into a number of partitions"
msgstr "将数据集分割成多个分区"

#: ../../source/tutorial-quickstart-scikitlearn.rst:58
msgid ""
"Please check out :code:`utils.py` `here <https://github.com/adap/flower/blob/"
"main/examples/sklearn-logreg-mnist/utils.py>`_ for more details. The pre-"
"defined functions are used in the :code:`client.py` and imported. The :code:"
"`client.py` also requires to import several packages such as Flower and "
"scikit-learn:"
msgstr ""
"更多详情请查看 :code:`utils.py`` 这里 <https://github.com/adap/flower/blob/"
"main/examples/sklearn-logreg-mnist/utils.py>`_。在 :code:`client.py` 中使用并"
"导入了预定义函数。:code:`client.py` 还需要导入几个软件包，如 Flower 和 "
"scikit-learn："

#: ../../source/tutorial-quickstart-scikitlearn.rst:73
msgid ""
"We load the MNIST dataset from `OpenML <https://www.openml.org/d/554>`_, a "
"popular image classification dataset of handwritten digits for machine "
"learning. The utility :code:`utils.load_mnist()` downloads the training and "
"test data. The training set is split afterwards into 10 partitions with :"
"code:`utils.partition()`."
msgstr ""
"我们从 `OpenML <https://www.openml.org/d/554>`_ 中加载 MNIST 数据集，这是一个"
"用于机器学习的流行手写数字图像分类数据集。实用程序 :code:`utils."
"load_mnist()` 下载训练和测试数据。然后使用 :code:`utils.partition()`将训练集"
"分割成 10 个分区。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:85
msgid ""
"Next, the logistic regression model is defined and initialized with :code:"
"`utils.set_initial_params()`."
msgstr ""
"接下来，使用 :code:`utils.set_initial_params()` 对逻辑回归模型进行定义和初始"
"化。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:97
msgid ""
"The Flower server interacts with clients through an interface called :code:"
"`Client`. When the server selects a particular client for training, it sends "
"training instructions over the network. The client receives those "
"instructions and calls one of the :code:`Client` methods to run your code (i."
"e., to fit the logistic regression we defined earlier)."
msgstr ""
"Flower 服务器通过一个名为 :code:`Client` 的接口与客户端交互。当服务器选择一个"
"特定的客户端进行训练时，它会通过网络发送训练指令。客户端接收到这些指令后，会"
"调用 :code:`Client` 方法之一来运行您的代码（即拟合我们之前定义的逻辑回归）。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:103
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which makes "
"it easier to implement the :code:`Client` interface when your workload uses "
"scikit-learn. Implementing :code:`NumPyClient` usually means defining the "
"following methods (:code:`set_parameters` is optional though):"
msgstr ""
"Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当你的工作负载使用 "
"scikit-learn 时，它可以让你更容易地实现 :code:`Client` 接口。实现 "
":code:`NumPyClient` 通常意味着定义以下方法（:code:`set_parameters` "
"是可选的）："

#: ../../source/tutorial-quickstart-scikitlearn.rst:112
msgid "is directly imported with :code:`utils.set_model_params()`"
msgstr "直接导入 :code:`utils.set_model_params()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:120
msgid "The methods can be implemented in the following way:"
msgstr "这些方法可以通过以下方式实现："

#: ../../source/tutorial-quickstart-scikitlearn.rst:143
msgid ""
"We can now create an instance of our class :code:`MnistClient` and add one "
"line to actually run this client:"
msgstr ""
"现在我们可以创建一个 :code:`MnistClient` 类的实例，并添加一行来实际运行该客户"
"端："

#: ../../source/tutorial-quickstart-scikitlearn.rst:159
msgid ""
"The following Flower server is a little bit more advanced and returns an "
"evaluation function for the server-side evaluation. First, we import again "
"all required libraries such as Flower and scikit-learn."
msgstr ""
"下面的 Flower 服务器更先进一些，会返回一个用于服务器端评估的评估函数。首先，"
"我们再次导入所有需要的库，如 Flower 和 scikit-learn。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:162
msgid ":code:`server.py`, import Flower and start the server:"
msgstr ":code:`server.py`, 导入 Flower 并启动服务器："

#: ../../source/tutorial-quickstart-scikitlearn.rst:173
msgid ""
"The number of federated learning rounds is set in :code:`fit_round()` and "
"the evaluation is defined in :code:`get_evaluate_fn()`. The evaluation "
"function is called after each federated learning round and gives you "
"information about loss and accuracy."
msgstr ""
"联邦学习轮数在 :code:`fit_round()` 中设置，评估在 :code:`get_evaluate_fn()` "
"中定义。每轮联邦学习后都会调用评估函数，并提供有关损失值和准确率的信息。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:198
msgid ""
"The :code:`main` contains the server-side parameter initialization :code:"
"`utils.set_initial_params()` as well as the aggregation strategy :code:`fl."
"server.strategy:FedAvg()`. The strategy is the default one, federated "
"averaging (or FedAvg), with two clients and evaluation after each federated "
"learning round. The server can be started with the command :code:`fl.server."
"start_server(server_address=\"0.0.0.0:8080\", strategy=strategy, config=fl."
"server.ServerConfig(num_rounds=3))`."
msgstr ""
":code:`main`包含服务器端参数初始化:code:`utils.set_initial_params()`"
"以及聚合策略 :code:`fl.server.strategy:FedAvg()`。该策略是默认的联邦平均（或 "
"FedAvg）策略，有两个客户端，在每轮联邦学习后进行评估。可以使用 :code:`fl."
"server.start_server(server_address=\"0.0.0.0:8080\", strategy=strategy, "
"config=fl.server.ServerConfig(num_rounds=3))` 命令启动服务器。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:217
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. Federated learning systems usually have a "
"server and multiple clients. We, therefore, have to start the server first:"
msgstr ""
"客户端和服务器都准备就绪后，我们现在就可以运行一切，看看联邦学习的运行情况。"
"联邦学习系统通常有一个服务器和多个客户端。因此，我们必须先启动服务器："

#: ../../source/tutorial-quickstart-scikitlearn.rst:271
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code <https://github.com/adap/flower/tree/"
"main/examples/sklearn-logreg-mnist>`_ for this example can be found in :code:"
"`examples/sklearn-logreg-mnist`."
msgstr ""
"恭喜您！您已经成功构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
"<https://github.com/adap/flower/tree/main/examples/sklearn-logreg-mnist>`_ "
"可以在 :code:`examples/sklearn-logreg-mnist` 中找到。"

#: ../../source/tutorial-quickstart-tensorflow.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"TensorFlow to train a MobilNetV2 model on CIFAR-10."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 TensorFlow 在 CIFAR-10 "
"上训练 MobilNetV2 模型。"

#: ../../source/tutorial-quickstart-tensorflow.rst:5
msgid "Quickstart TensorFlow"
msgstr "快速入门 TensorFlow"

#: ../../source/tutorial-quickstart-tensorflow.rst:13
msgid "Let's build a federated learning system in less than 20 lines of code!"
msgstr "让我们用不到 20 行代码构建一个联邦学习系统！"

#: ../../source/tutorial-quickstart-tensorflow.rst:15
msgid "Before Flower can be imported we have to install it:"
msgstr "在导入 Flower 之前，我们必须先安装它："

#: ../../source/tutorial-quickstart-tensorflow.rst:21
msgid ""
"Since we want to use the Keras API of TensorFlow (TF), we have to install TF "
"as well:"
msgstr "由于我们要使用 TensorFlow (TF) 的 Keras API，因此还必须安装 TF："

#: ../../source/tutorial-quickstart-tensorflow.rst:31
msgid "Next, in a file called :code:`client.py`, import Flower and TensorFlow:"
msgstr "接下来，在名为 :code:`client.py` 的文件中导入 Flower 和 TensorFlow："

#: ../../source/tutorial-quickstart-tensorflow.rst:38
msgid ""
"We use the Keras utilities of TF to load CIFAR10, a popular colored image "
"classification dataset for machine learning. The call to :code:`tf.keras."
"datasets.cifar10.load_data()` downloads CIFAR10, caches it locally, and then "
"returns the entire training and test set as NumPy ndarrays."
msgstr ""
"我们使用 TF 的 Keras 实用程序加载 CIFAR10，这是一个用于机器学习的流行彩色图像"
"分类数据集。调用 :code:`tf.keras.datasets.cifar10.load_data()` 会下载 "
"CIFAR10，将其缓存到本地，然后以 NumPy ndarrays 的形式返回整个训练集和测试集。"

#: ../../source/tutorial-quickstart-tensorflow.rst:47
msgid ""
"Next, we need a model. For the purpose of this tutorial, we use MobilNetV2 "
"with 10 output classes:"
msgstr ""
"接下来，我们需要一个模型。在本教程中，我们使用带有 10 个输出类的 MobilNetV2："

#: ../../source/tutorial-quickstart-tensorflow.rst:60
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which makes "
"it easier to implement the :code:`Client` interface when your workload uses "
"Keras. The :code:`NumPyClient` interface defines three methods which can be "
"implemented in the following way:"
msgstr ""
"Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当您的工作负载使用 Keras "
"时，该类可以更轻松地实现 :code:`Client` 接口。:code:`NumPyClient` "
"接口定义了三个方法，可以通过以下方式实现："

#: ../../source/tutorial-quickstart-tensorflow.rst:135
msgid "Each client will have its own dataset."
msgstr "每个客户都有自己的数据集。"

#: ../../source/tutorial-quickstart-tensorflow.rst:137
msgid ""
"You should now see how the training does in the very first terminal (the one "
"that started the server):"
msgstr "现在你应该能在第一个终端（启动服务器的终端）看到训练的效果了："

#: ../../source/tutorial-quickstart-tensorflow.rst:169
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code <https://github.com/adap/flower/blob/"
"main/examples/quickstart-tensorflow/client.py>`_ for this can be found in :"
"code:`examples/quickstart-tensorflow/client.py`."
msgstr ""
"恭喜您！您已经成功构建并运行了第一个联邦学习系统。`完整的源代码 "
"<https://github.com/adap/flower/blob/main/examples/quickstart-tensorflow/"
"client.py>`_ 可以在 :code:`examples/quickstart-tensorflow/client.py` 中找到。"

#: ../../source/tutorial-quickstart-xgboost.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower with "
"XGBoost to train classification models on trees."
msgstr "查看此联邦学习 快速入门教程，了解如何使用 Flower 和 XGBoost 上训练分类模型。"

#: ../../source/tutorial-quickstart-xgboost.rst:5
msgid "Quickstart XGBoost"
msgstr "XGBoost快速入门"

#: ../../source/tutorial-quickstart-xgboost.rst:11
msgid "Federated XGBoost"
msgstr "联邦化 XGBoost"

#: ../../source/tutorial-quickstart-xgboost.rst:13
msgid ""
"EXtreme Gradient Boosting (**XGBoost**) is a robust and efficient "
"implementation of gradient-boosted decision tree (**GBDT**), that maximises "
"the computational boundaries for boosted tree methods. It's primarily "
"designed to enhance both the performance and computational speed of machine "
"learning models. In XGBoost, trees are constructed concurrently, unlike the "
"sequential approach taken by GBDT."
msgstr ""
"EXtreme Gradient Boosting（**XGBoost**）是梯度提升决策树（**GBDT**）的一种稳"
"健而高效的实现方法，能最大限度地提高提升树方法的计算边界。它主要用于提高机器"
"学习模型的性能和计算速度。在 XGBoost 中，决策树是并发构建的，与 GBDT 采用的顺"
"序方法不同。"

#: ../../source/tutorial-quickstart-xgboost.rst:17
msgid ""
"Often, for tabular data on medium-sized datasets with fewer than 10k "
"training examples, XGBoost surpasses the results of deep learning techniques."
msgstr ""
"对于训练示例少于 10k 的中型数据集上的表格数据，XGBoost 的结果往往超过深度学习"
"技术。"

#: ../../source/tutorial-quickstart-xgboost.rst:20
msgid "Why federated XGBoost?"
msgstr "为什么选择联邦 XGBoost？"

#: ../../source/tutorial-quickstart-xgboost.rst:22
msgid ""
"Indeed, as the demand for data privacy and decentralized learning grows, "
"there's an increasing requirement to implement federated XGBoost systems for "
"specialised applications, like survival analysis and financial fraud "
"detection."
msgstr ""
"事实上，随着对数据隐私和分散学习的需求不断增长，越来越多的专业应用（如生存分"
"析和金融欺诈检测）需要实施联邦 XGBoost 系统。"

#: ../../source/tutorial-quickstart-xgboost.rst:24
msgid ""
"Federated learning ensures that raw data remains on the local device, making "
"it an attractive approach for sensitive domains where data security and "
"privacy are paramount. Given the robustness and efficiency of XGBoost, "
"combining it with federated learning offers a promising solution for these "
"specific challenges."
msgstr ""
"联邦学习可确保原始数据保留在本地设备上，因此对于数据安全和隐私至关重要的敏感"
"领域来说，这是一种极具吸引力的方法。鉴于 XGBoost 的稳健性和高效性，将其与联邦"
"学习相结合为应对这些特定挑战提供了一种前景广阔的解决方案。"

#: ../../source/tutorial-quickstart-xgboost.rst:27
msgid ""
"In this tutorial we will learn how to train a federated XGBoost model on "
"HIGGS dataset using Flower and :code:`xgboost` package. We use a simple "
"example (`full code xgboost-quickstart <https://github.com/adap/flower/tree/"
"main/examples/xgboost-quickstart>`_) with two *clients* and one *server* to "
"demonstrate how federated XGBoost works, and then we dive into a more "
"complex example (`full code xgboost-comprehensive <https://github.com/adap/"
"flower/tree/main/examples/xgboost-comprehensive>`_) to run various "
"experiments."
msgstr ""
"在本教程中，我们将学习如何使用 Flower 和 :code:`xgboost` 软件包在 HIGGS 数据"
"集上训练联邦 XGBoost 模型。我们将使用一个包含两个 * 客户端* 和一个 * 服务器* "
"的简单示例 (`完整代码 xgboost-quickstart <https://github.com/adap/flower/"
"tree/main/examples/xgboost-quickstart>`_)来演示联邦 XGBoost 如何工作，然后我"
"们将深入到一个更复杂的示例 (`完整代码 xgboost-comprehensive <https://github."
"com/adap/flower/tree/main/examples/xgboost-comprehensive>`_)，以运行各种实"
"验。"

#: ../../source/tutorial-quickstart-xgboost.rst:34
msgid "Environment Setup"
msgstr "环境设定"

#: ../../source/tutorial-quickstart-xgboost.rst:38
msgid ""
"We first need to install Flower and Flower Datasets. You can do this by "
"running :"
msgstr "我们首先需要安装 Flower 和 Flower Datasets。您可以通过运行 ："

#: ../../source/tutorial-quickstart-xgboost.rst:44
msgid ""
"Since we want to use :code:`xgboost` package to build up XGBoost trees, "
"let's go ahead and install :code:`xgboost`:"
msgstr ""
"既然我们要使用 :code:`xgboost` 软件包来构建 XGBoost 树，那就继续安装 :code:"
"`xgboost`："

#: ../../source/tutorial-quickstart-xgboost.rst:54
msgid ""
"*Clients* are responsible for generating individual weight-updates for the "
"model based on their local datasets. Now that we have all our dependencies "
"installed, let's run a simple distributed training with two clients and one "
"server."
msgstr ""
"*客户端*负责根据其本地数据集为模型生成单独的模型参数更新。现在我们已经安装了"
"所有的依赖项，让我们用两个客户端和一个服务器来运行一个简单的分布式训练。"

#: ../../source/tutorial-quickstart-xgboost.rst:57
msgid ""
"In a file called :code:`client.py`, import xgboost, Flower, Flower Datasets "
"and other related functions:"
msgstr ""
"在名为 :code:`client.py` 的文件中，导入 xgboost、Flower、Flower Datasets 和其"
"他相关函数："

#: ../../source/tutorial-quickstart-xgboost.rst:84
msgid "Dataset partition and hyper-parameter selection"
msgstr "数据集划分和超参数选择"

#: ../../source/tutorial-quickstart-xgboost.rst:86
msgid ""
"Prior to local training, we require loading the HIGGS dataset from Flower "
"Datasets and conduct data partitioning for FL:"
msgstr ""
"在本地训练之前，我们需要从 Flower Datasets 加载 HIGGS 数据集，并对 FL 进行数"
"据分区："

#: ../../source/tutorial-quickstart-xgboost.rst:99
msgid ""
"In this example, we split the dataset into two partitions with uniform "
"distribution (:code:`IidPartitioner(num_partitions=2)`). Then, we load the "
"partition for the given client based on :code:`node_id`:"
msgstr ""
"在此示例中，我们将数据集分割成两个均匀分布的分区（:code:"
"`IidPartitioner(num_partitions=2)`）。然后，我们根据 :code:`node_id` 为给定客"
"户端加载分区："

#: ../../source/tutorial-quickstart-xgboost.rst:118
msgid ""
"After that, we do train/test splitting on the given partition (client's "
"local data), and transform data format for :code:`xgboost` package."
msgstr ""
"然后，我们在给定的分区（客户端的本地数据）上进行训练/测试分割，并为 :code:"
"`xgboost` 软件包转换数据格式。"

#: ../../source/tutorial-quickstart-xgboost.rst:131
msgid ""
"The functions of :code:`train_test_split` and :code:"
"`transform_dataset_to_dmatrix` are defined as below:"
msgstr ""
":code:`train_test_split` 和 :code:`transform_dataset_too_dmatrix` 的函数定义"
"如下："

#: ../../source/tutorial-quickstart-xgboost.rst:155
msgid "Finally, we define the hyper-parameters used for XGBoost training."
msgstr "最后，我们定义了用于 XGBoost 训练的超参数。"

#: ../../source/tutorial-quickstart-xgboost.rst:171
msgid ""
"The :code:`num_local_round` represents the number of iterations for local "
"tree boost. We use CPU for the training in default. One can shift it to GPU "
"by setting :code:`tree_method` to :code:`gpu_hist`. We use AUC as evaluation "
"metric."
msgstr ""
"代码:`num_local_round`表示本地树的迭代次数。我们默认使用 CPU 进行训练。"
"可以通过将 :code:`tree_method` 设置为 :code:`gpu_hist`，将其转换为 GPU。"
"我们使用 AUC 作为评估指标。"

#: ../../source/tutorial-quickstart-xgboost.rst:178
msgid "Flower client definition for XGBoost"
msgstr "用于 XGBoost 的 Flower 客户端定义"

#: ../../source/tutorial-quickstart-xgboost.rst:180
msgid ""
"After loading the dataset we define the Flower client. We follow the general "
"rule to define :code:`XgbClient` class inherited from :code:`fl.client."
"Client`."
msgstr ""
"加载数据集后，我们定义 Flower 客户端。我们按照一般规则定义从 :code:`fl."
"client.Client` 继承而来的 :code:`XgbClient` 类。"

#: ../../source/tutorial-quickstart-xgboost.rst:190
msgid ""
"The :code:`self.bst` is used to keep the Booster objects that remain "
"consistent across rounds, allowing them to store predictions from trees "
"integrated in earlier rounds and maintain other essential data structures "
"for training."
msgstr ""
"代码:`self.bst`用于保存在各轮中保持一致的 Booster 对象，使其能够存储在前几轮"
"中集成的树的预测结果，并维护其他用于训练的重要数据结构。"

#: ../../source/tutorial-quickstart-xgboost.rst:193
msgid ""
"Then, we override :code:`get_parameters`, :code:`fit` and :code:`evaluate` "
"methods insides :code:`XgbClient` class as follows."
msgstr ""
"然后，我们在 :code:`XgbClient` 类中重写 :code:`get_parameters`、:code:`fit` "
"和 :code:`evaluate` 方法如下。"

#: ../../source/tutorial-quickstart-xgboost.rst:207
msgid ""
"Unlike neural network training, XGBoost trees are not started from a "
"specified random weights. In this case, we do not use :code:`get_parameters` "
"and :code:`set_parameters` to initialise model parameters for XGBoost. As a "
"result, let's return an empty tensor in :code:`get_parameters` when it is "
"called by the server at the first round."
msgstr ""
"与神经网络训练不同，XGBoost 树不是从指定的随机参数开始的。在这种情况下，"
"我们不使用 :code:`get_parameters` 和 :code:`set_parameters` 来初始化 XGBoost "
"的模型参数。因此，当服务器在第一轮调用 :code:`get_parameters` 时，让我们在 "
":code:`get_parameters` 中返回一个空张量。"

#: ../../source/tutorial-quickstart-xgboost.rst:248
msgid ""
"In :code:`fit`, at the first round, we call :code:`xgb.train()` to build up "
"the first set of trees. the returned Booster object and config are stored "
"in :code:`self.bst` and :code:`self.config`, respectively. From the second "
"round, we load the global model sent from server to :code:`self.bst`, and "
"then update model weights on local training data with function :code:"
"`local_boost` as follows:"
msgstr ""
"在 :code:`fit`中，第一轮我们调用 :code:`xgb.train()`来建立第一组树，返回的 "
"Booster 对象和 config 分别存储在 :code:`self.bst` 和 :code:`self.config` 中。"
"从第二轮开始，我们将服务器发送的全局模型加载到 :code:`self.bst`，然后使用函"
"数 :code:`local_boost`更新本地训练数据的模型权重，如下所示："

#: ../../source/tutorial-quickstart-xgboost.rst:266
msgid ""
"Given :code:`num_local_round`, we update trees by calling :code:`self.bst."
"update` method. After training, the last :code:`N=num_local_round` trees "
"will be extracted to send to the server."
msgstr ""
"给定 :code:`num_local_round`，我们通过调用 :code:`self.bst.update`方法更新"
"树。训练结束后，我们将提取最后一个 :code:`N=num_local_round` 树并发送给服务"
"器。"

#: ../../source/tutorial-quickstart-xgboost.rst:288
msgid ""
"In :code:`evaluate`, we call :code:`self.bst.eval_set` function to conduct "
"evaluation on valid set. The AUC value will be returned."
msgstr ""
"在 :code:`evaluate`中，我们调用 :code:`self.bst.eval_set`函数对有效集合进行评"
"估。将返回 AUC 值。"

#: ../../source/tutorial-quickstart-xgboost.rst:291
msgid ""
"Now, we can create an instance of our class :code:`XgbClient` and add one "
"line to actually run this client:"
msgstr ""
"现在，我们可以创建一个 :code:`XgbClient` 类的实例，并添加一行来实际运行该客户"
"端："

#: ../../source/tutorial-quickstart-xgboost.rst:297
msgid ""
"That's it for the client. We only have to implement :code:`Client`and call :"
"code:`fl.client.start_client()`. The string :code:`\"[::]:8080\"` tells the "
"client which server to connect to. In our case we can run the server and the "
"client on the same machine, therefore we use :code:`\"[::]:8080\"`. If we "
"run a truly federated workload with the server and clients running on "
"different machines, all that needs to change is the :code:`server_address` "
"we point the client at."
msgstr ""
"这就是客户端。我们只需实现 :code:`客户端`并调用 :code:`fl.client."
"start_client()`。字符串 :code:`\"[::]:8080\"`会告诉客户端要连接的服务器。在本"
"例中，我们可以在同一台机器上运行服务器和客户端，因此我们使用 :code:`\"[::]:"
"8080\""
"`。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，"
"那么需要改变的只是客户端指向的 :code:`server_address`。"

#: ../../source/tutorial-quickstart-xgboost.rst:308
msgid ""
"These updates are then sent to the *server* which will aggregate them to "
"produce a better model. Finally, the *server* sends this improved version of "
"the model back to each *client* to finish a complete FL round."
msgstr ""
"然后，这些更新会被发送到*服务器*，由*服务器*聚合后生成一个更好的模型。最后，*"
"服务器*将这个改进版的模型发回给每个*客户端*，以完成一轮完整的 FL。"

#: ../../source/tutorial-quickstart-xgboost.rst:311
msgid ""
"In a file named :code:`server.py`, import Flower and FedXgbBagging from :"
"code:`flwr.server.strategy`."
msgstr ""
"在名为 :code:`server.py` 的文件中，从 :code:`flwr.server.strategy` 导入 "
"Flower 和 FedXgbBagging。"

#: ../../source/tutorial-quickstart-xgboost.rst:313
msgid "We first define a strategy for XGBoost bagging aggregation."
msgstr "我们首先定义了 XGBoost bagging聚合策略。"

#: ../../source/tutorial-quickstart-xgboost.rst:336
msgid ""
"We use two clients for this example. An :code:`evaluate_metrics_aggregation` "
"function is defined to collect and wighted average the AUC values from "
"clients."
msgstr ""
"本示例使用两个客户端。我们定义了一个 :code:`evaluate_metrics_aggregation` 函"
"数，用于收集客户机的 AUC 值并求取平均值。"

#: ../../source/tutorial-quickstart-xgboost.rst:339
msgid "Then, we start the server:"
msgstr "然后，我们启动服务器："

#: ../../source/tutorial-quickstart-xgboost.rst:351
msgid "Tree-based bagging aggregation"
msgstr "基于树的bagging聚合"

#: ../../source/tutorial-quickstart-xgboost.rst:353
msgid ""
"You must be curious about how bagging aggregation works. Let's look into the "
"details."
msgstr "您一定很好奇bagging聚合是如何工作的。让我们来详细了解一下。"

#: ../../source/tutorial-quickstart-xgboost.rst:355
msgid ""
"In file :code:`flwr.server.strategy.fedxgb_bagging.py`, we define :code:"
"`FedXgbBagging` inherited from :code:`flwr.server.strategy.FedAvg`. Then, we "
"override the :code:`aggregate_fit`, :code:`aggregate_evaluate` and :code:"
"`evaluate` methods as follows:"
msgstr ""
"在文件 :code:`flwr.server.strategy.fedxgb_bagging.py`中，我们定义了从 :code:"
"`flwr.server.strategy.FedAvg`继承的 :code:`FedXgbBagging`。然后，我们覆盖 :"
"code:`aggregate_fit`、:code:`aggregate_evaluate` 和 :code:`evaluate` 方法如"
"下："

#: ../../source/tutorial-quickstart-xgboost.rst:451
msgid ""
"In :code:`aggregate_fit`, we sequentially aggregate the clients' XGBoost "
"trees by calling :code:`aggregate()` function:"
msgstr ""
"在 :code:`aggregate_fit` 中，我们通过调用 :code:`aggregate()` 函数，"
"按顺序聚合客户端的 XGBoost 树："

#: ../../source/tutorial-quickstart-xgboost.rst:510
msgid ""
"In this function, we first fetch the number of trees and the number of "
"parallel trees for the current and previous model by calling :code:"
"`_get_tree_nums`. Then, the fetched information will be aggregated. After "
"that, the trees (containing model weights) are aggregated to generate a new "
"tree model."
msgstr ""
"在该函数中，我们首先通过调用 :code:`_get_tree_nums` 获取当前模型和上一个模型"
"的树数和并行树数。然后，对获取的信息进行聚合。然后，聚合树（包含模型参数）生"
"成新的树模型。"

#: ../../source/tutorial-quickstart-xgboost.rst:515
msgid ""
"After traversal of all clients' models, a new global model is generated, "
"followed by the serialisation, and sending back to each client."
msgstr "在遍历所有客户端的模型后，会生成一个新的全局模型，然后进行序列化，并发回给每"
"个客户端。"

#: ../../source/tutorial-quickstart-xgboost.rst:520
msgid "Launch Federated XGBoost!"
msgstr "启动联邦 XGBoost！"

#: ../../source/tutorial-quickstart-xgboost.rst:582
msgid ""
"Congratulations! You've successfully built and run your first federated "
"XGBoost system. The AUC values can be checked in :code:"
"`metrics_distributed`. One can see that the average AUC increases over FL "
"rounds."
msgstr ""
"恭喜您！您已成功构建并运行了第一个联邦 XGBoost 系统。可以在 "
":code:`metrics_distributed` 中查看 AUC 值。我们可以看到，平均 AUC 随 FL "
"轮数的增加而增加。"

#: ../../source/tutorial-quickstart-xgboost.rst:587
msgid ""
"The full `source code <https://github.com/adap/flower/blob/main/examples/"
"xgboost-quickstart/>`_ for this example can be found in :code:`examples/"
"xgboost-quickstart`."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/"
"xgboost-quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-xgboost.rst:591
msgid "Comprehensive Federated XGBoost"
msgstr "综合的联邦 XGBoost"

#: ../../source/tutorial-quickstart-xgboost.rst:593
msgid ""
"Now that you have known how federated XGBoost work with Flower, it's time to "
"run some more comprehensive experiments by customising the experimental "
"settings. In the xgboost-comprehensive example (`full code <https://github."
"com/adap/flower/tree/main/examples/xgboost-comprehensive>`_), we provide "
"more options to define various experimental setups, including data "
"partitioning and centralised/distributed evaluation. Let's take a look!"
msgstr ""
"既然您已经知道联合 XGBoost 如何与 Flower "
"协同工作，那么现在就该通过自定义实验设置来运行一些更综合的实验了。在 xgboost-"
"comprehensive 示例 (`完整代码 <https://github.com/adap/flower/tree/main/"
"examples/xgboost-comprehensive>`_)中，我们提供了更多选项来定义各种实验设置，"
"包括数据分区和集中/分布式评估。让我们一起来看看！"

#: ../../source/tutorial-quickstart-xgboost.rst:599
msgid "Customised data partitioning"
msgstr "定制数据分区"

#: ../../source/tutorial-quickstart-xgboost.rst:601
msgid ""
"In :code:`dataset.py`, we have a function :code:`instantiate_partitioner` to "
"instantiate the data partitioner based on the given :code:`num_partitions` "
"and :code:`partitioner_type`. Currently, we provide four supported "
"partitioner type to simulate the uniformity/non-uniformity in data quantity "
"(uniform, linear, square, exponential)."
msgstr ""
"在 :code:`dataset.py` 中，我们有一个函数 :code:`instantiate_partitioner` 来根"
"据给定的 :code:`num_partitions` 和 :code:`partitioner_type` 来实例化数据分区"
"器。目前，我们提供四种支持的分区器类型（均匀、线性、正方形、指数）来模拟数据"
"量的均匀性/非均匀性。"

#: ../../source/tutorial-quickstart-xgboost.rst:632
msgid "Customised centralised/distributed evaluation"
msgstr "定制的集中/分布式评估"

#: ../../source/tutorial-quickstart-xgboost.rst:634
msgid ""
"To facilitate centralised evaluation, we define a function in :code:`server."
"py`:"
msgstr "为便于集中评估，我们在 :code:`server.py` 中定义了一个函数："

#: ../../source/tutorial-quickstart-xgboost.rst:666
msgid ""
"This function returns a evaluation function which instantiates a :code:"
"`Booster` object and loads the global model weights to it. The evaluation is "
"conducted by calling :code:`eval_set()` method, and the tested AUC value is "
"reported."
msgstr ""
"此函数返回一个评估函数，该函数实例化一个 :code:`Booster` "
"对象，并向其加载全局模型参数。评估通过调用 :code:`eval_set()` 方法进行，"
"并报告测试的 AUC 值。"

#: ../../source/tutorial-quickstart-xgboost.rst:669
msgid ""
"As for distributed evaluation on the clients, it's same as the quick-start "
"example by overriding the :code:`evaluate()` method insides the :code:"
"`XgbClient` class in :code:`client.py`."
msgstr ""
"至于客户端上的分布式评估，与快速启动示例相同，通过覆盖 :code:`client.py` 中 :"
"code:`XgbClient` 类内部的 :code:`evaluate()` 方法。"

#: ../../source/tutorial-quickstart-xgboost.rst:673
msgid "Arguments parser"
msgstr "参数解析器"

#: ../../source/tutorial-quickstart-xgboost.rst:675
msgid ""
"In :code:`utils.py`, we define the arguments parsers for clients and server, "
"allowing users to specify different experimental settings. Let's first see "
"the sever side:"
msgstr ""
"在 :code:`utils.py` 中，我们定义了客户端和服务器端的参数解析器，允许用户指定"
"不同的实验设置。让我们先看看服务器端："

#: ../../source/tutorial-quickstart-xgboost.rst:714
msgid ""
"This allows user to specify the number of total clients / FL rounds / "
"participating clients / clients for evaluation, and evaluation fashion. Note "
"that with :code:`--centralised-eval`, the sever will do centralised "
"evaluation and all functionalities for client evaluation will be disabled."
msgstr ""
"这允许用户指定总客户数/FL 轮数/参与客户数/评估客户数以及评估方式。请注意，"
"如果使用 :code:`--centralised-"
"eval`，服务器将进行集中评估，客户端评估的所有功能将被禁用。"

#: ../../source/tutorial-quickstart-xgboost.rst:718
msgid "Then, the argument parser on client side:"
msgstr "然后是客户端的参数解析器："

#: ../../source/tutorial-quickstart-xgboost.rst:760
msgid ""
"This defines various options for client data partitioning. Besides, clients "
"also have a option to conduct evaluation on centralised test set by setting :"
"code:`--centralised-eval`."
msgstr ""
"这定义了客户端数据分区的各种选项。此外，通过设置 :code:`-centralised-eval`，"
"客户端还可以选择在集中测试集上进行评估。"

#: ../../source/tutorial-quickstart-xgboost.rst:764
msgid "Example commands"
msgstr "命令示例"

#: ../../source/tutorial-quickstart-xgboost.rst:766
msgid ""
"To run a centralised evaluated experiment on 5 clients with exponential "
"distribution for 50 rounds, we first start the server as below:"
msgstr ""
"为了在 5 个客户端上进行 50 轮指数分布的集中评估实验，我们首先启动服务器，如下"
"所示："

#: ../../source/tutorial-quickstart-xgboost.rst:773
msgid "Then, on each client terminal, we start the clients:"
msgstr "然后，我们在每个客户终端上启动客户机："

#: ../../source/tutorial-quickstart-xgboost.rst:779
msgid ""
"The full `source code <https://github.com/adap/flower/blob/main/examples/"
"xgboost-comprehensive/>`_ for this comprehensive example can be found in :"
"code:`examples/xgboost-comprehensive`."
msgstr ""
"此综合示例的全部`源代码 <https://github.com/adap/flower/blob/main/examples/"
"xgboost-comprehensive/>`_ 可在 :code:`examples/xgboost-comprehensive` "
"中找到。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:9
msgid "Build a strategy from scratch"
msgstr "从零开始制定策略"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:11
msgid ""
"Welcome to the third part of the Flower federated learning tutorial. In "
"previous parts of this tutorial, we introduced federated learning with "
"PyTorch and Flower (`part 1 <https://flower.dev/docs/framework/tutorial-get-"
"started-with-flower-pytorch.html>`__) and we learned how strategies can be "
"used to customize the execution on both the server and the clients (`part 2 "
"<https://flower.dev/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__)."
msgstr ""
"欢迎来到 Flower 联邦学习教程的第三部分。在本教程的前几部分，我们介绍了 "
"PyTorch 和 Flower 的联邦学习（`part 1 <https://flower.dev/docs/framework/"
"tutorial-get-started-with-flower-pytorch."
"html>`__），并学习了如何使用策略来定制服务器和客户端的执行（`part 2 "
"<https://flower.dev/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__）。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:13
msgid ""
"In this notebook, we'll continue to customize the federated learning system "
"we built previously by creating a custom version of FedAvg (again, using "
"`Flower <https://flower.dev/>`__ and `PyTorch <https://pytorch.org/>`__)."
msgstr ""
"在本笔记中，我们将通过创建 FedAvg 的自定义版本（再次使用 `Flower "
"<https://flower.dev/>`__ 和 `PyTorch <https://pytorch.org/"
">`__），继续定制我们之前构建的联邦学习系统。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:15
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:16
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:15
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:15
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join the "
"Flower community on Slack to connect, ask questions, and get help: `Join "
"Slack <https://flower.dev/join-slack>`__ 🌼 We'd love to hear from you in "
"the ``#introductions`` channel! And if anything is unclear, head over to the "
"``#questions`` channel."
msgstr ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ 并加入 Slack 上"
"的 Flower 社区，进行交流、提问并获得帮助： 加入 Slack <https://flower.dev/"
"join-slack>`__ 🌼 我们希望在 ``#introductions`` 频道听到您的声音！如果有任何"
"不清楚的地方，请访问 ``#questions`` 频道。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:17
msgid "Let's build a new ``Strategy`` from scratch!"
msgstr "让我们从头开始构建一个新的``Strategy``！"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:29
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:29
msgid "Preparation"
msgstr "准备工作"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:31
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:32
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:31
msgid ""
"Before we begin with the actual code, let's make sure that we have "
"everything we need."
msgstr "在开始实际代码之前，让我们先确保我们已经准备好了所需的一切。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:43
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:44
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:43
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:43
msgid "Installing dependencies"
msgstr "安装依赖项"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:45
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:46
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:45
msgid "First, we install the necessary packages:"
msgstr "首先，我们安装必要的软件包："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:65
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:66
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:65
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:65
msgid ""
"Now that we have all dependencies installed, we can import everything we "
"need for this tutorial:"
msgstr "现在我们已经安装了所有依赖项，可以导入本教程所需的所有内容："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:101
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:102
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:104
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:101
msgid ""
"It is possible to switch to a runtime that has GPU acceleration enabled (on "
"Google Colab: ``Runtime > Change runtime type > Hardware acclerator: GPU > "
"Save``). Note, however, that Google Colab is not always able to offer GPU "
"acceleration. If you see an error related to GPU availability in one of the "
"following sections, consider switching back to CPU-based execution by "
"setting ``DEVICE = torch.device(\"cpu\")``. If the runtime has GPU "
"acceleration enabled, you should see the output ``Training on cuda``, "
"otherwise it'll say ``Training on cpu``."
msgstr ""
"可以切换到已启用 GPU 加速的运行时（在 Google Colab 上： 运行时 > 更改运行时类"
"型 > 硬件加速： GPU > 保存``）。但请注意，Google Colab 并非总能提供 GPU 加"
"速。如果在以下部分中看到与 GPU 可用性相关的错误，请考虑通过设置 ``DEVICE = "
"torch.device(\"cpu\")`` 切回基于 CPU 的执行。如果运行时已启用 GPU 加速，你应"
"该会看到输出``Training on cuda``，否则会显示``Training on cpu``。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:114
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:115
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:114
msgid "Data loading"
msgstr "数据加载"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:116
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:116
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into ten "
"smaller datasets (each split into training and validation set), and wrap "
"everything in their own ``DataLoader``. We introduce a new parameter "
"``num_clients`` which allows us to call ``load_datasets`` with different "
"numbers of clients."
msgstr ""
"现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成 10 个较小的数据集（每"
"个数据集又分为训练集和验证集），并将所有数据都封装在各自的 ``DataLoader`` "
"中。我们引入了一个新参数 ``num_clients``，它允许我们使用不同数量的客户端调用 "
"``load_datasets``。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:167
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:168
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:167
msgid "Model training/evaluation"
msgstr "模型培训/评估"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:169
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:170
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:169
msgid ""
"Let's continue with the usual model definition (including ``set_parameters`` "
"and ``get_parameters``), training and test functions:"
msgstr ""
"让我们继续使用常见的模型定义（包括 `set_parameters` 和 `get_parameters`）、训"
"练和测试函数："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:258
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:258
msgid "Flower client"
msgstr "Flower 客户端"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:260
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:260
msgid ""
"To implement the Flower client, we (again) create a subclass of ``flwr."
"client.NumPyClient`` and implement the three methods ``get_parameters``, "
"``fit``, and ``evaluate``. Here, we also pass the ``cid`` to the client and "
"use it log additional details:"
msgstr ""
"为了实现 Flower 客户端，我们（再次）创建了 ``flwr.client.NumPyClient`` 的子"
"类，并实现了 ``get_parameters``、``fit`` 和 ``evaluate``三个方法。在这里，我"
"们还将 ``cid`` 传递给客户端，并使用它记录其他详细信息："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:308
msgid "Let's test what we have so far before we continue:"
msgstr "在继续之前，让我们先测试一下我们目前掌握的情况："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:339
msgid "Build a Strategy from scratch"
msgstr "从零开始构建策略"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:341
msgid ""
"Let’s overwrite the ``configure_fit`` method such that it passes a higher "
"learning rate (potentially also other hyperparameters) to the optimizer of a "
"fraction of the clients. We will keep the sampling of the clients as it is "
"in ``FedAvg`` and then change the configuration dictionary (one of the "
"``FitIns`` attributes)."
msgstr ""
"让我们重写 ``configure_fit`` 方法，使其向一部分客户的优化器传递更高的学习率"
"（可能还有其他超参数）。我们将保持 ``FedAvg`` 中的客户端采样，然后更改配置字"
"典（``FitIns`` 属性之一）。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:507
msgid ""
"The only thing left is to use the newly created custom Strategy "
"``FedCustom`` when starting the experiment:"
msgstr "剩下的唯一工作就是在启动实验时使用新创建的自定义策略 ``FedCustom`` ："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:534
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:932
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:697
msgid "Recap"
msgstr "回顾"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:536
msgid ""
"In this notebook, we’ve seen how to implement a custom strategy. A custom "
"strategy enables granular control over client node configuration, result "
"aggregation, and more. To define a custom strategy, you only have to "
"overwrite the abstract methods of the (abstract) base class ``Strategy``. To "
"make custom strategies even more powerful, you can pass custom functions to "
"the constructor of your new class (``__init__``) and then call these "
"functions whenever needed."
msgstr ""
"在本笔记中，我们了解了如何实施自定义策略。自定义策略可以对客户端节点配置、结"
"果聚合等进行细粒度控制。要定义自定义策略，只需覆盖（抽象）基类 ``Strategy`` "
"的抽象方法即可。为使自定义策略更加强大，您可以将自定义函数传递给新类的构造函"
"数（`__init__``），然后在需要时调用这些函数。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:550
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:948
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:749
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:715
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:369
msgid ""
"Before you continue, make sure to join the Flower community on Slack: `Join "
"Slack <https://flower.dev/join-slack/>`__"
msgstr ""
"在继续之前，请务必加入 Slack 上的 Flower 社区：`Join Slack <https://flower."
"dev/join-slack/>`__"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:552
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:950
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:751
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:717
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:371
msgid ""
"There's a dedicated ``#questions`` channel if you need help, but we'd also "
"love to hear who you are in ``#introductions``!"
msgstr ""
"如果您需要帮助，我们有专门的 ``#questions`` 频道，但我们也很乐意在 "
"``#introductions`` 中了解您是谁！"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:554
msgid ""
"The `Flower Federated Learning Tutorial - Part 4 <https://flower.dev/docs/"
"framework/tutorial-customize-the-client-pytorch.html>`__ introduces "
"``Client``, the flexible API underlying ``NumPyClient``."
msgstr ""
"Flower联邦学习教程 - 第4部分 <https://flower.dev/docs/framework/tutorial-"
"customize-the-client-pytorch.html>`__ 介绍了``Client``，它是``NumPyClient``底"
"层的灵活应用程序接口。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:9
msgid "Customize the client"
msgstr "自定义客户端"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:11
msgid ""
"Welcome to the fourth part of the Flower federated learning tutorial. In the "
"previous parts of this tutorial, we introduced federated learning with "
"PyTorch and Flower (`part 1 <https://flower.dev/docs/framework/tutorial-get-"
"started-with-flower-pytorch.html>`__), we learned how strategies can be used "
"to customize the execution on both the server and the clients (`part 2 "
"<https://flower.dev/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__), and we built our own custom strategy from "
"scratch (`part 3 <https://flower.dev/docs/framework/tutorial-build-a-"
"strategy-from-scratch-pytorch.html>`__)."
msgstr ""
"欢迎来到 Flower 联邦学习教程的第四部分。在本教程的前几部分中，我们介绍了 "
"PyTorch 和 Flower 的联邦学习（`part 1 <https://flower.dev/docs/framework/"
"tutorial-get-started-with-flower-pytorch.html>`__），了解了如何使用策略来定制"
"服务器和客户端的执行（`part 2 <https://flower.dev/docs/framework/tutorial-"
"use-a-federated-learning-strategy-pytorch.html>`__），并从头开始构建了我们自"
"己的定制策略（`part 3 <https://flower.dev/docs/framework/tutorial-build-a-"
"strategy-from-scratch-pytorch.html>`__）。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:14
msgid ""
"In this notebook, we revisit ``NumPyClient`` and introduce a new baseclass "
"for building clients, simply named ``Client``. In previous parts of this "
"tutorial, we've based our client on ``NumPyClient``, a convenience class "
"which makes it easy to work with machine learning libraries that have good "
"NumPy interoperability. With ``Client``, we gain a lot of flexibility that "
"we didn't have before, but we'll also have to do a few things the we didn't "
"have to do before."
msgstr ""
"在本笔记中，我们将重温 ``NumPyClient`` 并引入一个用于构建客户端的新基类，"
"简单命名为 ``Client``。在本教程的前几部分中，我们的客户端基于``NumPyClient``"
"，这是一个便捷类，可以让我们轻松地与具有良好 NumPy "
"互操作性的机器学习库协同工作。有了 ``Client``，我们获得了很多以前没有的灵活性"
"，但我们也必须做一些以前不需要做的事情。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:18
msgid ""
"Let's go deeper and see what it takes to move from ``NumPyClient`` to "
"``Client``!"
msgstr "让我们深入了解一下从 ``NumPyClient`` 到 ``Client`` 的过程！"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:30
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:29
msgid "Step 0: Preparation"
msgstr "步骤 0：准备工作"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:117
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into ten "
"smaller datasets (each split into training and validation set), and wrap "
"everything in their own ``DataLoader``."
msgstr ""
"现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成十个较小的数据集（每个"
"数据集又分为训练集和验证集），并将所有数据都封装在各自的 ``DataLoader`` 中。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:259
msgid "Step 1: Revisiting NumPyClient"
msgstr "步骤 1：重温 NumPyClient"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:261
msgid ""
"So far, we've implemented our client by subclassing ``flwr.client."
"NumPyClient``. The three methods we implemented are ``get_parameters``, "
"``fit``, and ``evaluate``. Finally, we wrap the creation of instances of "
"this class in a function called ``client_fn``:"
msgstr ""
"到目前为止，我们通过子类化 ``flwr.client.NumPyClient`` 实现了我们的客户端。我"
"们实现了三个方法：``get_parameters``, ``fit`, 和``evaluate``。最后，我们用一"
"个名为 ``client_fn`` 的函数来创建该类的实例："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:309
msgid ""
"We've seen this before, there's nothing new so far. The only *tiny* "
"difference compared to the previous notebook is naming, we've changed "
"``FlowerClient`` to ``FlowerNumPyClient`` and ``client_fn`` to "
"``numpyclient_fn``. Let's run it to see the output we get:"
msgstr ""
"我们以前见过这种情况，目前没有什么新东西。与之前的笔记相比，唯一*小*的不同是"
"命名，我们把 ``FlowerClient`` 改成了 ``FlowerNumPyClient``，把 `client_fn` "
"改成了 ``numpyclient_fn``。让我们运行它看看输出结果："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:339
msgid ""
"This works as expected, two clients are training for three rounds of "
"federated learning."
msgstr "结果不出所料，两个客户端正在进行三轮联邦学习训练。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:341
msgid ""
"Let's dive a little bit deeper and discuss how Flower executes this "
"simulation. Whenever a client is selected to do some work, "
"``start_simulation`` calls the function ``numpyclient_fn`` to create an "
"instance of our ``FlowerNumPyClient`` (along with loading the model and the "
"data)."
msgstr ""
"让我们再深入一点，讨论一下 Flower 是如何执行模拟的。每当一个客户端被选中进行"
"工作时，`start_simulation`` 就会调用函数 `numpyclient_fn` 来创建我们的 "
"``FlowerNumPyClient`` 实例（同时加载模型和数据）。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:343
msgid ""
"But here's the perhaps surprising part: Flower doesn't actually use the "
"``FlowerNumPyClient`` object directly. Instead, it wraps the object to makes "
"it look like a subclass of ``flwr.client.Client``, not ``flwr.client."
"NumPyClient``. In fact, the Flower core framework doesn't know how to handle "
"``NumPyClient``'s, it only knows how to handle ``Client``'s. ``NumPyClient`` "
"is just a convenience abstraction built on top of ``Client``."
msgstr ""
"但令人惊讶的部分也许就在这里： Flower 实际上并不直接使用 "
"``FlowerNumPyClient`` 对象。相反，它封装了该对象，使其看起来像 ``flwr.client."
"Client`` 的子类，而不是 ``flwr.client.NumPyClient``。事实上，Flower "
"核心框架不知道如何处理 ``NumPyClient``，它只知道如何处理 "
"``Client``。``NumPyClient`` 只是建立在``Client``之上的便捷抽象类。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:345
msgid ""
"Instead of building on top of ``NumPyClient``, we can directly build on top "
"of ``Client``."
msgstr "与其在 ``NumPyClient`` 上构建，我们可以直接在 ``Client`` 上构建。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:357
msgid "Step 2: Moving from ``NumPyClient`` to ``Client``"
msgstr "步骤 2：从 ``NumPyClient`` 移至 ``Client``"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:359
msgid ""
"Let's try to do the same thing using ``Client`` instead of ``NumPyClient``."
msgstr "让我们尝试使用 ``Client`` 代替 ``NumPyClient`` 做同样的事情。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:465
msgid ""
"Before we discuss the code in more detail, let's try to run it! Gotta make "
"sure our new ``Client``-based client works, right?"
msgstr ""
"在详细讨论代码之前，让我们试着运行它！必须确保我们基于 ``Client`` 的新客户端"
"能正常运行，对吗？"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:490
msgid ""
"That's it, we're now using ``Client``. It probably looks similar to what "
"we've done with ``NumPyClient``. So what's the difference?"
msgstr ""
"就是这样，我们现在开始使用 ``Client``。它看起来可能与我们使用 "
"``NumPyClient`` 所做的类似。那么有什么不同呢？"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:492
msgid ""
"First of all, it's more code. But why? The difference comes from the fact "
"that ``Client`` expects us to take care of parameter serialization and "
"deserialization. For Flower to be able to send parameters over the network, "
"it eventually needs to turn these parameters into ``bytes``. Turning "
"parameters (e.g., NumPy ``ndarray``'s) into raw bytes is called "
"serialization. Turning raw bytes into something more useful (like NumPy "
"``ndarray``'s) is called deserialization. Flower needs to do both: it needs "
"to serialize parameters on the server-side and send them to the client, the "
"client needs to deserialize them to use them for local training, and then "
"serialize the updated parameters again to send them back to the server, "
"which (finally!) deserializes them again in order to aggregate them with the "
"updates received from other clients."
msgstr ""
"首先，它的代码更多。但为什么呢？区别在于 ``Client`` "
"希望我们处理参数的序列化和反序列化。Flower 要想通过网络发送参数，"
"最终需要将这些参数转化为 ``字节``。把参数（例如 NumPy 的 ``ndarray`` "
"参数）变成原始字节叫做序列化。将原始字节转换成更有用的东西（如 NumPy "
"``ndarray`）称为反序列化。Flower 需要同时做这两件事：它需要在服务器端序列化参"
"数并将其发送到客户端，客户端需要反序列化参数以便将其用于本地训练，然后再次序"
"列化更新后的参数并将其发送回服务器，服务器（最后）再次反序列化参数以便将其与"
"从其他客户端接收到的更新汇总在一起。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:495
msgid ""
"The only *real* difference between Client and NumPyClient is that "
"NumPyClient takes care of serialization and deserialization for you. It can "
"do so because it expects you to return parameters as NumPy ndarray's, and it "
"knows how to handle these. This makes working with machine learning "
"libraries that have good NumPy support (most of them) a breeze."
msgstr ""
"Client 与 NumPyClient 之间的唯一**真正区别在于，NumPyClient "
"会为你处理序列化和反序列化。NumPyClient之所以能做到这一点，"
"是因为它预计你会以NumPy ndarray的形式返回参数，而且它知道如何处理这些参数。"
"这使得与具有良好 NumPy 支持的大多数机器学习库一起工作变得轻而易举。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:497
msgid ""
"In terms of API, there's one major difference: all methods in Client take "
"exactly one argument (e.g., ``FitIns`` in ``Client.fit``) and return exactly "
"one value (e.g., ``FitRes`` in ``Client.fit``). The methods in "
"``NumPyClient`` on the other hand have multiple arguments (e.g., "
"``parameters`` and ``config`` in ``NumPyClient.fit``) and multiple return "
"values (e.g., ``parameters``, ``num_example``, and ``metrics`` in "
"``NumPyClient.fit``) if there are multiple things to handle. These ``*Ins`` "
"and ``*Res`` objects in ``Client`` wrap all the individual values you're "
"used to from ``NumPyClient``."
msgstr ""
"在 API 方面，有一个主要区别：Client 中的所有方法都只接受一个参数（例如，"
"``Client.fit`` 中的 ``FitIns``），并只返回一个值（例如，``Client.fit`` 中的 "
"``FitRes``）。另一方面，``NumPyClient``中的方法有多个参数（例如，"
"``NumPyClient.fit``中的``parameters``和``config``）和多个返回值（例如，"
"``NumPyClient.fit``中的``parameters``、``num_example``和``metrics``）。在 "
"``Client`` 中的这些 ``*Ins`` 和 ``*Res`` 对象封装了你在 ``NumPyClient`` 中习"
"惯使用的所有单个值。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:510
msgid "Step 3: Custom serialization"
msgstr "步骤 3：自定义序列化"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:512
msgid ""
"Here we will explore how to implement custom serialization with a simple "
"example."
msgstr "下面我们将通过一个简单的示例来探讨如何实现自定义序列化。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:514
msgid ""
"But first what is serialization? Serialization is just the process of "
"converting an object into raw bytes, and equally as important, "
"deserialization is the process of converting raw bytes back into an object. "
"This is very useful for network communication. Indeed, without "
"serialization, you could not just a Python object through the internet."
msgstr ""
"首先，什么是序列化？序列化只是将对象转换为原始字节的过程，同样重要的是，反序"
"列化是将原始字节转换回对象的过程。这对网络通信非常有用。事实上，如果没有序列"
"化，你就无法通过互联网传输一个 Python 对象。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:516
msgid ""
"Federated Learning relies heavily on internet communication for training by "
"sending Python objects back and forth between the clients and the server. "
"This means that serialization is an essential part of Federated Learning."
msgstr "通过在客户端和服务器之间来回发送 Python 对象，联合学习在很大程度上依赖于互联"
"网通信进行训练。这意味着序列化是联邦学习的重要组成部分。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:518
msgid ""
"In the following section, we will write a basic example where instead of "
"sending a serialized version of our ``ndarray``\\ s containing our "
"parameters, we will first convert the ``ndarray`` into sparse matrices, "
"before sending them. This technique can be used to save bandwidth, as in "
"certain cases where the weights of a model are sparse (containing many 0 "
"entries), converting them to a sparse matrix can greatly improve their "
"bytesize."
msgstr ""
"在下面的章节中，我们将编写一个基本示例，在发送包含参数的 ``ndarray`` 前，"
"我们将首先把 ``ndarray`` 转换为稀疏矩阵，而不是发送序列化版本。这种技术可以用"
"来节省带宽，因为在某些情况下，模型的参数是稀疏的（包含许多 0 "
"条目），将它们转换成稀疏矩阵可以大大提高它们的字节数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:521
msgid "Our custom serialization/deserialization functions"
msgstr "我们的定制序列化/反序列化功能"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:523
msgid ""
"This is where the real serialization/deserialization will happen, especially "
"in ``ndarray_to_sparse_bytes`` for serialization and "
"``sparse_bytes_to_ndarray`` for deserialization."
msgstr ""
"这才是真正的序列化/反序列化，尤其是在用于序列化的 "
"``ndarray_too_sparse_bytes`` 和用于反序列化的 ``sparse_bytes_too_ndarray`` "
"中。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:525
msgid ""
"Note that we imported the ``scipy.sparse`` library in order to convert our "
"arrays."
msgstr "请注意，为了转换数组，我们导入了 ``scipy.sparse`` 库。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:613
msgid "Client-side"
msgstr "客户端"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:615
msgid ""
"To be able to able to serialize our ``ndarray``\\ s into sparse parameters, "
"we will just have to call our custom functions in our ``flwr.client.Client``."
msgstr "为了能够将我们的 ``ndarray`` 序列化为稀疏参数，我们只需在 ``flwr.client."
"Client`` 中调用我们的自定义函数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:617
msgid ""
"Indeed, in ``get_parameters`` we need to serialize the parameters we got "
"from our network using our custom ``ndarrays_to_sparse_parameters`` defined "
"above."
msgstr ""
"事实上，在 `get_parameters` 中，我们需要使用上文定义的自定义 "
"`ndarrays_too_sparse_parameters` 序列化从网络中获取的参数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:619
msgid ""
"In ``fit``, we first need to deserialize the parameters coming from the "
"server using our custom ``sparse_parameters_to_ndarrays`` and then we need "
"to serialize our local results with ``ndarrays_to_sparse_parameters``."
msgstr ""
"在 ``fit`` 中，我们首先需要使用自定义的 ``sparse_parameters_to_ndarrays`` "
"反序列化来自服务器的参数，然后使用 ``ndarrays_to_sparse_parameters`` "
"序列化本地结果。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:621
msgid ""
"In ``evaluate``, we will only need to deserialize the global parameters with "
"our custom function."
msgstr "在 ``evaluate`` 中，我们只需要用自定义函数反序列化全局参数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:725
msgid "Server-side"
msgstr "服务器端"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:727
msgid ""
"For this example, we will just use ``FedAvg`` as a strategy. To change the "
"serialization and deserialization here, we only need to reimplement the "
"``evaluate`` and ``aggregate_fit`` functions of ``FedAvg``. The other "
"functions of the strategy will be inherited from the super class ``FedAvg``."
msgstr ""
"在本例中，我们将只使用 ``FedAvg`` 作为策略。要改变这里的序列化和反序列化，我"
"们只需重新实现 ``FedAvg`` 的 ``evaluate`` 和 ``aggregate_fit`` 函数。策略的其"
"他函数将从超类 ``FedAvg`` 继承。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:729
msgid "As you can see only one line as change in ``evaluate``:"
msgstr "正如你所看到的，``evaluate``中只修改了一行："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:735
msgid ""
"And for ``aggregate_fit``, we will first deserialize every result we "
"received:"
msgstr "而对于 ``aggregate_fit``，我们将首先反序列化收到的每个结果："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:744
msgid "And then serialize the aggregated result:"
msgstr "然后将汇总结果序列化："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:903
msgid "We can now run our custom serialization example!"
msgstr "现在我们可以运行自定义序列化示例！"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:934
msgid ""
"In this part of the tutorial, we've seen how we can build clients by "
"subclassing either ``NumPyClient`` or ``Client``. ``NumPyClient`` is a "
"convenience abstraction that makes it easier to work with machine learning "
"libraries that have good NumPy interoperability. ``Client`` is a more "
"flexible abstraction that allows us to do things that are not possible in "
"``NumPyClient``. In order to do so, it requires us to handle parameter "
"serialization and deserialization ourselves."
msgstr ""
"在本部分教程中，我们已经了解了如何通过子类化 ``NumPyClient`` 或 ``Client`` "
"来构建客户端。NumPyClient \"是一个便捷的抽象类，可以让我们更容易地与具有良好N"
"umPy互操作性的机器学习库一起工作。``Client``是一个更灵活的抽象类，允许我们做"
"一些在`NumPyClient``中做不到的事情。为此，它要求我们自己处理参数序列化和反序"
"列化。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:952
msgid ""
"This is the final part of the Flower tutorial (for now!), congratulations! "
"You're now well equipped to understand the rest of the documentation. There "
"are many topics we didn't cover in the tutorial, we recommend the following "
"resources:"
msgstr "这暂时是 Flower 教程的最后一部分，恭喜您！您现在已经具备了理解其余文档的能力"
"。本教程还有许多内容没有涉及，我们推荐您参考以下资源："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:954
msgid "`Read Flower Docs <https://flower.dev/docs/>`__"
msgstr "阅读Flower文档 <https://flower.dev/docs/>`__"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:955
msgid ""
"`Check out Flower Code Examples <https://github.com/adap/flower/tree/main/"
"examples>`__"
msgstr ""
"查看 Flower 代码示例 <https://github.com/adap/flower/tree/main/examples>`__"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:956
msgid ""
"`Use Flower Baselines for your research <https://flower.dev/docs/baselines/"
">`__"
msgstr "使用 \"Flower Baselines \"进行研究 <https://flower.dev/docs/baselines/>`__"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:957
msgid ""
"`Watch Flower Summit 2023 videos <https://flower.dev/conf/flower-summit-2023/"
">`__"
msgstr ""
"观看 2023 年Flower峰会视频 <https://flower.dev/conf/flower-summit-2023/>`__"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:9
msgid "Get started with Flower"
msgstr "开始使用Flower"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:11
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:11
msgid "Welcome to the Flower federated learning tutorial!"
msgstr "欢迎阅读Flower联邦学习教程！"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:13
msgid ""
"In this notebook, we'll build a federated learning system using Flower and "
"PyTorch. In part 1, we use PyTorch for the model training pipeline and data "
"loading. In part 2, we continue to federate the PyTorch-based pipeline using "
"Flower."
msgstr ""
"在本笔记中，我们将使用 Flower 和 PyTorch 构建一个联邦学习系统。在第一部分中，"
"我们使用 PyTorch 进行模型训练和数据加载。在第二部分中，我们将继续使用 Flower "
"联邦化基于 PyTorch 的框架。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:17
msgid "Let's get stated!"
msgstr "让我们开始吧！"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:31
msgid ""
"Before we begin with any actual code, let's make sure that we have "
"everything we need."
msgstr "在开始编写实际代码之前，让我们先确保我们已经准备好了所需的一切。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:45
msgid ""
"Next, we install the necessary packages for PyTorch (``torch`` and "
"``torchvision``) and Flower (``flwr``):"
msgstr ""
"接下来，我们为 PyTorch（`torch`` 和`torchvision``）和 Flower（`flwr`）安装必"
"要的软件包："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:117
msgid "Loading the data"
msgstr "加载数据"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:119
msgid ""
"Federated learning can be applied to many different types of tasks across "
"different domains. In this tutorial, we introduce federated learning by "
"training a simple convolutional neural network (CNN) on the popular CIFAR-10 "
"dataset. CIFAR-10 can be used to train image classifiers that distinguish "
"between images from ten different classes:"
msgstr ""
"联邦学习可应用于不同领域的多种不同类型任务。在本教程中，我们将通过在流行的 "
"CIFAR-10 数据集上训练一个简单的卷积神经网络 (CNN) 来介绍联合学习。CIFAR-10 可"
"用于训练图像分类器，以区分来自十个不同类别的图像："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:150
msgid ""
"We simulate having multiple datasets from multiple organizations (also "
"called the \"cross-silo\" setting in federated learning) by splitting the "
"original CIFAR-10 dataset into multiple partitions. Each partition will "
"represent the data from a single organization. We're doing this purely for "
"experimentation purposes, in the real world there's no need for data "
"splitting because each organization already has their own data (so the data "
"is naturally partitioned)."
msgstr ""
"我们通过将原始 CIFAR-10 数据集拆分成多个分区来模拟来自多个组织的多个数据集（"
"也称为联邦学习中的 \"跨分区 \"设置）。每个分区代表一个组织的数据。我们这样做"
"纯粹是为了实验目的，在现实世界中不需要拆分数据，因为每个组织都已经有了自己的"
"数据（所以数据是自然分区的）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:152
msgid ""
"Each organization will act as a client in the federated learning system. So "
"having ten organizations participate in a federation means having ten "
"clients connected to the federated learning server:"
msgstr "每个组织都将充当联邦学习系统中的客户端。因此，有十个组织参与联邦学习，就意味"
"着有十个客户端连接到联邦学习服务器："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:172
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into ten "
"smaller datasets (each split into training and validation set), and wrap the "
"resulting partitions by creating a PyTorch ``DataLoader`` for each of them:"
msgstr ""
"现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成 10 个较小的数据集（每"
"个数据集又分为训练集和验证集），并通过为每个数据集创建 PyTorch "
"``DataLoader`` 来包装由此产生的分割集："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:222
msgid ""
"We now have a list of ten training sets and ten validation sets "
"(``trainloaders`` and ``valloaders``) representing the data of ten different "
"organizations. Each ``trainloader``/``valloader`` pair contains 4500 "
"training examples and 500 validation examples. There's also a single "
"``testloader`` (we did not split the test set). Again, this is only "
"necessary for building research or educational systems, actual federated "
"learning systems have their data naturally distributed across multiple "
"partitions."
msgstr ""
"现在，我们有一个包含十个训练集和十个验证集（`trainloaders`` "
"和`valloaders``）的列表，代表十个不同组织的数据。每对 "
"``trainloader``/``valloader`` 都包含 4500 个训练示例和 500 个验证数据。"
"还有一个单独的 ``测试加载器``（我们没有拆分测试集）。同样，这只有在构建研究或"
"教育系统时才有必要，实际的联邦学习系统的数据自然分布在多个分区中。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:225
msgid ""
"Let's take a look at the first batch of images and labels in the first "
"training set (i.e., ``trainloaders[0]``) before we move on:"
msgstr ""
"在继续之前，让我们先看看第一个训练集中的第一批图像和标签（即 "
"``trainloaders[0]``）："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:264
msgid ""
"The output above shows a random batch of images from the first "
"``trainloader`` in our list of ten ``trainloaders``. It also prints the "
"labels associated with each image (i.e., one of the ten possible labels "
"we've seen above). If you run the cell again, you should see another batch "
"of images."
msgstr ""
"上面的输出显示了来自十个 \"trainloader \"列表中第一个 \"trainloader \"的随机"
"图像。它还打印了与每幅图像相关的标签（即我们上面看到的十个可能标签之一）。如"
"果您再次运行该单元，应该会看到另一批图像。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:276
msgid "Step 1: Centralized Training with PyTorch"
msgstr "步骤 1：使用 PyTorch 进行集中训练"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:287
msgid ""
"Next, we're going to use PyTorch to define a simple convolutional neural "
"network. This introduction assumes basic familiarity with PyTorch, so it "
"doesn't cover the PyTorch-related aspects in full detail. If you want to "
"dive deeper into PyTorch, we recommend `DEEP LEARNING WITH PYTORCH: A 60 "
"MINUTE BLITZ <https://pytorch.org/tutorials/beginner/"
"deep_learning_60min_blitz.html>`__."
msgstr ""
"接下来，我们将使用 PyTorch 来定义一个简单的卷积神经网络。本介绍假定您对 "
"PyTorch 有基本的了解，因此不会详细介绍与 PyTorch 相关的内容。"
"如果你想更深入地了解 PyTorch，我们推荐你阅读 `DEEP LEARNING WITH PYTORCH： a "
"60 minute blitz <https://pytorch.org/tutorials/beginner/"
"deep_learning_60min_blitz.html>`__。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:299
msgid "Defining the model"
msgstr "定义模型"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:301
msgid ""
"We use the simple CNN described in the `PyTorch tutorial <https://pytorch."
"org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-"
"neural-network>`__:"
msgstr ""
"我们使用` PyTorch 教程 <https://pytorch.org/tutorials/beginner/blitz/"
"cifar10_tutorial.html#define-a-convolutional-neural-network>`__ 中描述的简单 "
"CNN："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:338
msgid "Let's continue with the usual training and test functions:"
msgstr "让我们继续进行常规的训练和测试功能："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:398
msgid "Training the model"
msgstr "训练模型"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:400
msgid ""
"We now have all the basic building blocks we need: a dataset, a model, a "
"training function, and a test function. Let's put them together to train the "
"model on the dataset of one of our organizations (``trainloaders[0]``). This "
"simulates the reality of most machine learning projects today: each "
"organization has their own data and trains models only on this internal data:"
msgstr ""
"现在我们拥有了所需的所有基本构件：数据集、模型、训练函数和测试函数。让我们把"
"它们放在一起，在我们其中一个组织的数据集（``trainloaders[0]``）上训练模型。这"
"模拟了当今大多数机器学习项目的实际情况：每个组织都有自己的数据，并且只在这些"
"内部数据上训练模型："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:430
msgid ""
"Training the simple CNN on our CIFAR-10 split for 5 epochs should result in "
"a test set accuracy of about 41%, which is not good, but at the same time, "
"it doesn't really matter for the purposes of this tutorial. The intent was "
"just to show a simplistic centralized training pipeline that sets the stage "
"for what comes next - federated learning!"
msgstr ""
"在我们的 CIFAR-10 分片上对简单 CNN 进行 5 个遍历的训练后，测试集的准确率应为 "
"41%，这并不理想，但同时对本教程而言也并不重要。我们只是想展示一个简单的集中式"
"训练流程，为接下来的联邦学习做好铺垫！"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:442
msgid "Step 2: Federated Learning with Flower"
msgstr "步骤 2：使用 Flower 联邦学习"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:444
msgid ""
"Step 1 demonstrated a simple centralized training pipeline. All data was in "
"one place (i.e., a single ``trainloader`` and a single ``valloader``). Next, "
"we'll simulate a situation where we have multiple datasets in multiple "
"organizations and where we train a model over these organizations using "
"federated learning."
msgstr ""
"步骤 1 演示了一个简单的集中式训练流程。所有数据都在一个地方（即一个 "
"\"trainloader \"和一个 \"valloader\"）。接下来，我们将模拟在多个组织中拥有多"
"个数据集的情况，并使用联邦学习在这些组织中训练一个模型。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:456
msgid "Updating model parameters"
msgstr "更新模型参数"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:458
msgid ""
"In federated learning, the server sends the global model parameters to the "
"client, and the client updates the local model with the parameters received "
"from the server. It then trains the model on the local data (which changes "
"the model parameters locally) and sends the updated/changed model parameters "
"back to the server (or, alternatively, it sends just the gradients back to "
"the server, not the full model parameters)."
msgstr ""
"在联邦学习中，服务器将全局模型参数发送给客户端，客户端根据从服务器接收到的参"
"数更新本地模型。然后，客户端根据本地数据对模型进行训练（在本地更改模型参"
"数），并将更新/更改后的模型参数发回服务器（或者，客户端只将梯度参数发回服务"
"器，而不是全部模型参数）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:460
msgid ""
"We need two helper functions to update the local model with parameters "
"received from the server and to get the updated model parameters from the "
"local model: ``set_parameters`` and ``get_parameters``. The following two "
"functions do just that for the PyTorch model above."
msgstr ""
"我们需要两个辅助函数，用从服务器接收到的参数更新本地模型，并从本地模型获取更"
"新后的模型参数：`` set_parameters```和`get_parameters``。"
"下面两个函数就是为上面的 PyTorch 模型做这些工作的。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:462
msgid ""
"The details of how this works are not really important here (feel free to "
"consult the PyTorch documentation if you want to learn more). In essence, we "
"use ``state_dict`` to access PyTorch model parameter tensors. The parameter "
"tensors are then converted to/from a list of NumPy ndarray's (which Flower "
"knows how to serialize/deserialize):"
msgstr ""
"在这里，如何工作的细节并不重要（如果你想了解更多，请随时查阅 PyTorch 文档）。"
"本质上，我们使用 ``state_dict`` 访问 PyTorch 模型参数张量。然后，参数张量会被"
"转换成/转换成 NumPy ndarray 列表（Flower 知道如何序列化/反序列化）："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:490
msgid "Implementing a Flower client"
msgstr "实现 Flower 客户端"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:492
msgid ""
"With that out of the way, let's move on to the interesting part. Federated "
"learning systems consist of a server and multiple clients. In Flower, we "
"create clients by implementing subclasses of ``flwr.client.Client`` or "
"``flwr.client.NumPyClient``. We use ``NumPyClient`` in this tutorial because "
"it is easier to implement and requires us to write less boilerplate."
msgstr ""
"说完这些，让我们进入有趣的部分。联邦学习系统由一个服务器和多个客户端组成。在 "
"Flower 中，我们通过实现 ``flwr.client.Client`` 或 ``flwr.client.NumPyClient``"
" 的子类来创建客户端。在本教程中，我们使用``NumPyClient``，因为它更容易实现，"
"需要我们编写的模板也更少。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:494
msgid ""
"To implement the Flower client, we create a subclass of ``flwr.client."
"NumPyClient`` and implement the three methods ``get_parameters``, ``fit``, "
"and ``evaluate``:"
msgstr ""
"为实现 Flower 客户端，我们创建了 ``flwr.client.NumPyClient`` 的子类，并实现"
"了 ``get_parameters``、``fit`` 和``evaluate`` 三个方法："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:496
msgid "``get_parameters``: Return the current local model parameters"
msgstr "``get_parameters``： 返回当前本地模型参数"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:497
msgid ""
"``fit``: Receive model parameters from the server, train the model "
"parameters on the local data, and return the (updated) model parameters to "
"the server"
msgstr "``fit``： 从服务器接收模型参数，在本地数据上训练模型参数，并将（更新的）模型"
"参数返回服务器"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:498
msgid ""
"``evaluate``: Receive model parameters from the server, evaluate the model "
"parameters on the local data, and return the evaluation result to the server"
msgstr "``evaluate ``： "
"从服务器接收模型参数，在本地数据上评估模型参数，并将评估结果返回服务器"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:500
msgid ""
"We mentioned that our clients will use the previously defined PyTorch "
"components for model training and evaluation. Let's see a simple Flower "
"client implementation that brings everything together:"
msgstr ""
"我们提到，我们的客户端将使用之前定义的 PyTorch 组件进行模型训练和评估。让我们"
"来看看一个简单的 Flower 客户端实现，它将一切都整合在一起："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:537
msgid ""
"Our class ``FlowerClient`` defines how local training/evaluation will be "
"performed and allows Flower to call the local training/evaluation through "
"``fit`` and ``evaluate``. Each instance of ``FlowerClient`` represents a "
"*single client* in our federated learning system. Federated learning systems "
"have multiple clients (otherwise, there's not much to federate), so each "
"client will be represented by its own instance of ``FlowerClient``. If we "
"have, for example, three clients in our workload, then we'd have three "
"instances of ``FlowerClient``. Flower calls ``FlowerClient.fit`` on the "
"respective instance when the server selects a particular client for training "
"(and ``FlowerClient.evaluate`` for evaluation)."
msgstr ""
"我们的类 ``FlowerClient`` 定义了本地训练/评估的执行方式，并允许 Flower 通过 "
"``fit`` 和 ``evaluate`` 调用本地训练/评估。每个 ``FlowerClient`` 实例都代表联"
"邦学习系统中的*单个客户端*。联邦学习系统有多个客户端（否则就没有什么可联邦的"
"），因此每个客户端都将由自己的 ``FlowerClient`` "
"实例来代表。例如，如果我们的工作负载中有三个客户端，那么我们就会有三个 "
"``FlowerClient`` 实例。当服务器选择特定客户端进行训练时，Flower "
"会调用相应实例上的 ``FlowerClient.fit`` （评估时调用 ``FlowerClient."
"evaluate``）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:541
msgid "Using the Virtual Client Engine"
msgstr "使用虚拟客户端引擎"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:543
msgid ""
"In this notebook, we want to simulate a federated learning system with 10 "
"clients on a single machine. This means that the server and all 10 clients "
"will live on a single machine and share resources such as CPU, GPU, and "
"memory. Having 10 clients would mean having 10 instances of ``FlowerClient`` "
"in memory. Doing this on a single machine can quickly exhaust the available "
"memory resources, even if only a subset of these clients participates in a "
"single round of federated learning."
msgstr ""
"在本笔记中，我们要模拟一个联邦学习系统，在一台机器上有 10 个客户端。"
"这意味着服务器和所有 10 个客户端都将位于一台机器上，并共享 CPU、GPU "
"和内存等资源。有 10 个客户端就意味着内存中有 10 个 ``FlowerClient`` 实例。在"
"单台机器上这样做会很快耗尽可用的内存资源，即使这些客户端中只有一个子集参与了"
"一轮联邦学习。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:545
msgid ""
"In addition to the regular capabilities where server and clients run on "
"multiple machines, Flower, therefore, provides special simulation "
"capabilities that create ``FlowerClient`` instances only when they are "
"actually necessary for training or evaluation. To enable the Flower "
"framework to create clients when necessary, we need to implement a function "
"called ``client_fn`` that creates a ``FlowerClient`` instance on demand. "
"Flower calls ``client_fn`` whenever it needs an instance of one particular "
"client to call ``fit`` or ``evaluate`` (those instances are usually "
"discarded after use, so they should not keep any local state). Clients are "
"identified by a client ID, or short ``cid``. The ``cid`` can be used, for "
"example, to load different local data partitions for different clients, as "
"can be seen below:"
msgstr ""
"除了服务器和客户端在多台机器上运行的常规功能外，Flower 还提供了特殊的模拟功"
"能，即只有在训练或评估实际需要时才创建 ``FlowerClient`` 实例。为了让 Flower "
"框架能在必要时创建客户端，我们需要实现一个名为 ``client_fn`` 的函数，它能按需"
"创建一个 ``FlowerClient`` 实例。每当 Flower 需要一个特定的客户端实例来调用 "
"``fit`` 或 ``evaluate`` 时，它就会调用 ``client_fn``（这些实例在使用后通常会"
"被丢弃，因此它们不应保留任何本地状态）。客户端由一个客户端 ID 或简短的 "
"``cid`` 标识。例如，可以使用 ``cid`` 为不同的客户端加载不同的本地数据分区，如"
"下所示："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:580
msgid "Starting the training"
msgstr "开始训练"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:582
msgid ""
"We now have the class ``FlowerClient`` which defines client-side training/"
"evaluation and ``client_fn`` which allows Flower to create ``FlowerClient`` "
"instances whenever it needs to call ``fit`` or ``evaluate`` on one "
"particular client. The last step is to start the actual simulation using "
"``flwr.simulation.start_simulation``."
msgstr ""
"现在我们有了定义客户端训练/评估的类 ``FlowerClient`` 和允许 Flower 在需要调用"
"某个客户端的 ``fit` 或 ``evaluate` 时创建 ``FlowerClient`` 实例的 "
"``client_fn` 类。最后一步是使用 ``flwr.simulation.start_simulation`` 启动实际"
"模拟。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:584
msgid ""
"The function ``start_simulation`` accepts a number of arguments, amongst "
"them the ``client_fn`` used to create ``FlowerClient`` instances, the number "
"of clients to simulate (``num_clients``), the number of federated learning "
"rounds (``num_rounds``), and the strategy. The strategy encapsulates the "
"federated learning approach/algorithm, for example, *Federated Averaging* "
"(FedAvg)."
msgstr ""
"函数 ``start_simulation`` 接受许多参数，其中包括用于创建 ``FlowerClient`` "
"实例的 ``client_fn``、要模拟的客户端数量（``num_clients``）、联邦学习轮数（``"
"num_rounds``）和策略。策略封装了联邦学习方法/算法，例如*联邦平均* (FedAvg)。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:586
msgid ""
"Flower has a number of built-in strategies, but we can also use our own "
"strategy implementations to customize nearly all aspects of the federated "
"learning approach. For this example, we use the built-in ``FedAvg`` "
"implementation and customize it using a few basic parameters. The last step "
"is the actual call to ``start_simulation`` which - you guessed it - starts "
"the simulation:"
msgstr ""
"Flower 有许多内置策略，但我们也可以使用自己的策略实现来定制联邦学习方法的几乎"
"所有方面。在本例中，我们使用内置的 ``FedAvg`` "
"实现，并使用一些基本参数对其进行定制。最后一步是实际调用 "
"``start_simulation``开始模拟："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:628
msgid "Behind the scenes"
msgstr "幕后"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:630
msgid "So how does this work? How does Flower execute this simulation?"
msgstr "那么它是如何工作的呢？Flower 如何进行模拟？"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:632
#, python-format
msgid ""
"When we call ``start_simulation``, we tell Flower that there are 10 clients "
"(``num_clients=10``). Flower then goes ahead an asks the ``FedAvg`` strategy "
"to select clients. ``FedAvg`` knows that it should select 100% of the "
"available clients (``fraction_fit=1.0``), so it goes ahead and selects 10 "
"random clients (i.e., 100% of 10)."
msgstr ""
"当我们调用 ``start_simulation`` 时，我们会告诉 Flower 有 10 个客户"
"（`num_clients=10``）。然后，Flower 会要求 ``FedAvg`` 策略选择客户。"
"``FedAvg`` 知道它应该选择 100%的可用客户（``fraction_fit=1.0``），所以它会随"
"机选择 10 个客户（即 10 的 100%）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:634
msgid ""
"Flower then asks the selected 10 clients to train the model. When the server "
"receives the model parameter updates from the clients, it hands those "
"updates over to the strategy (*FedAvg*) for aggregation. The strategy "
"aggregates those updates and returns the new global model, which then gets "
"used in the next round of federated learning."
msgstr ""
"然后，Flower 会要求选定的 10 个客户端对模型进行训练。服务器收到客户端的模型参"
"数更新后，会将这些更新交给策略（*FedAvg*）进行聚合。策略会聚合这些更新并返回"
"新的全局模型，然后将其用于下一轮联邦学习。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:646
msgid "Where's the accuracy?"
msgstr "准确度在哪里找？"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:648
msgid ""
"You may have noticed that all metrics except for ``losses_distributed`` are "
"empty. Where did the ``{\"accuracy\": float(accuracy)}`` go?"
msgstr ""
"您可能已经注意到，除了 ``losses_distributed`` 以外，所有指标都是空的。{\"准确"
"度\": float(准确度)}``去哪儿了？"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:650
msgid ""
"Flower can automatically aggregate losses returned by individual clients, "
"but it cannot do the same for metrics in the generic metrics dictionary (the "
"one with the ``accuracy`` key). Metrics dictionaries can contain very "
"different kinds of metrics and even key/value pairs that are not metrics at "
"all, so the framework does not (and can not) know how to handle these "
"automatically."
msgstr ""
"Flower 可以自动汇总单个客户端返回的损失值，但无法对通用度量字典中的度量进行同"
"样的处理（即带有 \"准确度 \"键的度量字典）。度量值字典可以包含非常不同种类的"
"度量值，甚至包含根本不是度量值的键/值对，因此框架不知道（也无法知道）如何自动"
"处理这些度量值。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:652
msgid ""
"As users, we need to tell the framework how to handle/aggregate these custom "
"metrics, and we do so by passing metric aggregation functions to the "
"strategy. The strategy will then call these functions whenever it receives "
"fit or evaluate metrics from clients. The two possible functions are "
"``fit_metrics_aggregation_fn`` and ``evaluate_metrics_aggregation_fn``."
msgstr ""
"作为用户，我们需要告诉框架如何处理/聚合这些自定义指标，为此，我们将指标聚合函"
"数传递给策略。然后，只要从客户端接收到拟合或评估指标，策略就会调用这些函数。"
"两个可能的函数是 ``fit_metrics_aggregation_fn`` 和 "
"``evaluate_metrics_aggregation_fn``。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:654
msgid ""
"Let's create a simple weighted averaging function to aggregate the "
"``accuracy`` metric we return from ``evaluate``:"
msgstr ""
"让我们创建一个简单的加权平均函数来汇总从 ``evaluate`` 返回的 ``accuracy`` 指"
"标："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:680
msgid ""
"The only thing left to do is to tell the strategy to call this function "
"whenever it receives evaluation metric dictionaries from the clients:"
msgstr ""
"剩下要做的就是告诉策略，每当它从客户端接收到评估度量字典时，都要调用这个函"
"数："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:717
msgid ""
"We now have a full system that performs federated training and federated "
"evaluation. It uses the ``weighted_average`` function to aggregate custom "
"evaluation metrics and calculates a single ``accuracy`` metric across all "
"clients on the server side."
msgstr ""
"我们现在有了一个完整的系统，可以执行联邦训练和联邦评估。它使用 "
"``weighted_average`` 函数汇总自定义评估指标，"
"并在服务器端计算所有客户端的单一 ``accuracy`` 指标。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:719
msgid ""
"The other two categories of metrics (``losses_centralized`` and "
"``metrics_centralized``) are still empty because they only apply when "
"centralized evaluation is being used. Part two of the Flower tutorial will "
"cover centralized evaluation."
msgstr ""
"其他两类指标（`losses_centralized`` 和 `metrics_centralized`）仍然是空的，因"
"为它们只适用于集中评估。Flower 教程的第二部分将介绍集中式评估。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:731
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:351
msgid "Final remarks"
msgstr "结束语"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:733
msgid ""
"Congratulations, you just trained a convolutional neural network, federated "
"over 10 clients! With that, you understand the basics of federated learning "
"with Flower. The same approach you've seen can be used with other machine "
"learning frameworks (not just PyTorch) and tasks (not just CIFAR-10 images "
"classification), for example NLP with Hugging Face Transformers or speech "
"with SpeechBrain."
msgstr ""
"恭喜您，你刚刚训练了一个由 10 个客户端组成的卷积神经网络！这样，"
"你就了解了使用 Flower "
"进行联邦学习的基础知识。你所看到的方法同样适用于其他机器学习框架（不只是 "
"PyTorch）和任务（不只是 CIFAR-10 图像分类），例如使用 Hugging Face "
"Transformers 的 NLP 或使用 SpeechBrain 的语音。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:735
msgid ""
"In the next notebook, we're going to cover some more advanced concepts. Want "
"to customize your strategy? Initialize parameters on the server side? Or "
"evaluate the aggregated model on the server side? We'll cover all this and "
"more in the next tutorial."
msgstr ""
"在下一个笔记中，我们将介绍一些更先进的概念。想定制你的策略吗？在服务器端初始"
"化参数？或者在服务器端评估聚合模型？我们将在下一个教程中介绍所有这些内容以及"
"更多。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:753
msgid ""
"The `Flower Federated Learning Tutorial - Part 2 <https://flower.dev/docs/"
"framework/tutorial-use-a-federated-learning-strategy-pytorch.html>`__ goes "
"into more depth about strategies and all the advanced things you can build "
"with them."
msgstr ""
"`Flower 联邦学习教程 - 第 2 部分 <https://flower.dev/docs/framework/tutorial-"
"use-a-federated-learning-strategy-pytorch.html>`__ "
"更深入地介绍了策略以及可以使用策略构建的所有高级功能。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:9
msgid "Use a federated learning strategy"
msgstr "使用联邦学习策略"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:11
msgid ""
"Welcome to the next part of the federated learning tutorial. In previous "
"parts of this tutorial, we introduced federated learning with PyTorch and "
"Flower (`part 1 <https://flower.dev/docs/framework/tutorial-get-started-with-"
"flower-pytorch.html>`__)."
msgstr ""
"欢迎来到联邦学习教程的下一部分。在本教程的前几部分，我们介绍了使用 PyTorch "
"和 Flower 进行联邦学习（`第 1 部分 <https://flower.dev/docs/framework/"
"tutorial-get-started-with-flower-pytorch.html>`___）。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:13
msgid ""
"In this notebook, we'll begin to customize the federated learning system we "
"built in the introductory notebook (again, using `Flower <https://flower.dev/"
">`__ and `PyTorch <https://pytorch.org/>`__)."
msgstr ""
"在本笔记中，我们将开始定制在入门笔记中构建的联邦学习系统（再次使用 `Flower "
"<https://flower.dev/>`__ 和 `PyTorch <https://pytorch.org/>`__）。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:17
msgid "Let's move beyond FedAvg with Flower strategies!"
msgstr "让我们超越 FedAvg，采用Flower策略！"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:309
msgid "Strategy customization"
msgstr "策略定制"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:311
msgid ""
"So far, everything should look familiar if you've worked through the "
"introductory notebook. With that, we're ready to introduce a number of new "
"features."
msgstr ""
"到目前为止，如果您已经阅读过入门笔记本，那么一切都应该很熟悉了。接下来，我们"
"将介绍一些新功能。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:323
msgid "Server-side parameter **initialization**"
msgstr "服务器端参数 **初始化**"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:325
msgid ""
"Flower, by default, initializes the global model by asking one random client "
"for the initial parameters. In many cases, we want more control over "
"parameter initialization though. Flower therefore allows you to directly "
"pass the initial parameters to the Strategy:"
msgstr ""
"默认情况下，Flower 会通过向一个随机客户端询问初始参数来初始化全局模型。但在许"
"多情况下，我们需要对参数初始化进行更多控制。因此，Flower 允许您直接将初始参数"
"传递给策略："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:370
msgid ""
"Passing ``initial_parameters`` to the ``FedAvg`` strategy prevents Flower "
"from asking one of the clients for the initial parameters. If we look "
"closely, we can see that the logs do not show any calls to the "
"``FlowerClient.get_parameters`` method."
msgstr ""
"向 ``FedAvg`` 策略传递 ``initial_parameters`` 可以防止 Flower 向其中一个客户"
"端询问初始参数。如果我们仔细观察，就会发现日志中没有显示对 ``FlowerClient."
"get_parameters`` 方法的任何调用。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:382
msgid "Starting with a customized strategy"
msgstr "从定制战略开始"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:384
msgid ""
"We've seen the function ``start_simulation`` before. It accepts a number of "
"arguments, amongst them the ``client_fn`` used to create ``FlowerClient`` "
"instances, the number of clients to simulate ``num_clients``, the number of "
"rounds ``num_rounds``, and the strategy."
msgstr ""
"我们以前见过函数 ``start_simulation``。它接受许多参数，其中包括用于创建 "
"``FlowerClient`` 实例的 ``client_fn``、要模拟的客户数量 ``num_clients``、回合"
"数 ``num_rounds``和策略。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:386
msgid ""
"The strategy encapsulates the federated learning approach/algorithm, for "
"example, ``FedAvg`` or ``FedAdagrad``. Let's try to use a different strategy "
"this time:"
msgstr "该策略封装了联邦学习方法/算法，例如`FedAvg``或`FedAdagrad``。这次让我们尝试使"
"用不同的策略："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:424
msgid "Server-side parameter **evaluation**"
msgstr "服务器端参数**评估**"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:426
msgid ""
"Flower can evaluate the aggregated model on the server-side or on the client-"
"side. Client-side and server-side evaluation are similar in some ways, but "
"different in others."
msgstr ""
"Flower 可以在服务器端或客户端评估聚合模型。客户端和服务器端评估在某些方面相"
"似，但也有不同之处。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:428
msgid ""
"**Centralized Evaluation** (or *server-side evaluation*) is conceptually "
"simple: it works the same way that evaluation in centralized machine "
"learning does. If there is a server-side dataset that can be used for "
"evaluation purposes, then that's great. We can evaluate the newly aggregated "
"model after each round of training without having to send the model to "
"clients. We're also fortunate in the sense that our entire evaluation "
"dataset is available at all times."
msgstr ""
"**集中评估**（或*服务器端评估*）在概念上很简单：它的工作方式与集中式机器学习"
"中的评估方式相同。如果有一个服务器端数据集可用于评估目的，那就太好了。我们可"
"以在每一轮训练后对新聚合的模型进行评估，而无需将模型发送给客户端。我们也很幸"
"运，因为我们的整个评估数据集随时可用。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:430
msgid ""
"**Federated Evaluation** (or *client-side evaluation*) is more complex, but "
"also more powerful: it doesn't require a centralized dataset and allows us "
"to evaluate models over a larger set of data, which often yields more "
"realistic evaluation results. In fact, many scenarios require us to use "
"**Federated Evaluation** if we want to get representative evaluation results "
"at all. But this power comes at a cost: once we start to evaluate on the "
"client side, we should be aware that our evaluation dataset can change over "
"consecutive rounds of learning if those clients are not always available. "
"Moreover, the dataset held by each client can also change over consecutive "
"rounds. This can lead to evaluation results that are not stable, so even if "
"we would not change the model, we'd see our evaluation results fluctuate "
"over consecutive rounds."
msgstr ""
"**联邦评估**（或*客户端评估*）更为复杂，但也更为强大：它不需要集中的数据集，"
"允许我们在更大的数据集上对模型进行评估，这通常会产生更真实的评估结果。事实"
"上，如果我们想得到有代表性的评估结果，很多情况下都需要使用**联邦评估**。但"
"是，这种能力是有代价的：一旦我们开始在客户端进行评估，我们就应该意识到，如果"
"这些客户端并不总是可用，我们的评估数据集可能会在连续几轮学习中发生变化。此"
"外，每个客户端所拥有的数据集也可能在连续几轮学习中发生变化。这可能会导致评估"
"结果不稳定，因此即使我们不改变模型，也会看到评估结果在连续几轮中波动。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:433
msgid ""
"We've seen how federated evaluation works on the client side (i.e., by "
"implementing the ``evaluate`` method in ``FlowerClient``). Now let's see how "
"we can evaluate aggregated model parameters on the server-side:"
msgstr ""
"我们已经了解了联邦评估如何在客户端工作（即通过在 ``FlowerClient`` 中实现 "
"``evaluate`` 方法）。现在让我们看看如何在服务器端评估聚合模型参数："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:490
msgid "Sending/receiving arbitrary values to/from clients"
msgstr "向/从客户端发送/接收任意值"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:492
msgid ""
"In some situations, we want to configure client-side execution (training, "
"evaluation) from the server-side. One example for that is the server asking "
"the clients to train for a certain number of local epochs. Flower provides a "
"way to send configuration values from the server to the clients using a "
"dictionary. Let's look at an example where the clients receive values from "
"the server through the ``config`` parameter in ``fit`` (``config`` is also "
"available in ``evaluate``). The ``fit`` method receives the configuration "
"dictionary through the ``config`` parameter and can then read values from "
"this dictionary. In this example, it reads ``server_round`` and "
"``local_epochs`` and uses those values to improve the logging and configure "
"the number of local training epochs:"
msgstr ""
"在某些情况下，我们希望从服务器端配置客户端的执行（训练、评估）。其中一个例子"
"就是服务器要求客户端训练一定数量的本地遍历。Flower "
"提供了一种使用字典从服务器向客户端发送配置值的方法。让我们来看一个例子："
"客户端通过 ``fit`` 中的 ``config`` 参数从服务器接收配置值（``evaluate`` "
"中也有 ``config`` 参数）。``fit`` 方法通过 ``config`` "
"参数接收配置字典，然后从字典中读取值。在本例中，它读取了 ``server_round`` 和 "
"``local_epochs``，并使用这些值来改进日志记录和配置本地训练遍历的数量："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:546
msgid ""
"So how can we send this config dictionary from server to clients? The built-"
"in Flower Strategies provide way to do this, and it works similarly to the "
"way server-side evaluation works. We provide a function to the strategy, and "
"the strategy calls this function for every round of federated learning:"
msgstr ""
"那么，如何将配置字典从服务器发送到客户端呢？内置的 \"Flower策略\"（Flower Str"
"ategies）提供了这样的方法，其工作原理与服务器端评估的工作原理类似。我们为策略"
"提供一个函数，策略会在每一轮联邦学习中调用这个函数："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:576
msgid ""
"Next, we'll just pass this function to the FedAvg strategy before starting "
"the simulation:"
msgstr "接下来，我们只需在开始模拟前将此函数传递给 FedAvg 策略即可："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:613
msgid ""
"As we can see, the client logs now include the current round of federated "
"learning (which they read from the ``config`` dictionary). We can also "
"configure local training to run for one epoch during the first and second "
"round of federated learning, and then for two epochs during the third round."
msgstr ""
"我们可以看到，客户端日志现在包含了当前一轮的联邦学习（从 ``config`` 字典中读"
"取）。我们还可以将本地训练配置为在第一轮和第二轮联邦学习期间运行一个遍历，然"
"后在第三轮联邦学习期间运行两个遍历。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:615
msgid ""
"Clients can also return arbitrary values to the server. To do so, they "
"return a dictionary from ``fit`` and/or ``evaluate``. We have seen and used "
"this concept throughout this notebook without mentioning it explicitly: our "
"``FlowerClient`` returns a dictionary containing a custom key/value pair as "
"the third return value in ``evaluate``."
msgstr ""
"客户端还可以向服务器返回任意值。为此，它们会从 ``fit`` 和/或 ``evaluate`` "
"返回一个字典。我们在本笔记中看到并使用了这一概念，但并未明确提及：我们的 "
"``FlowerClient`` 返回一个包含自定义键/值对的字典，作为 ``evaluate`` "
"中的第三个返回值。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:627
msgid "Scaling federated learning"
msgstr "扩大联邦学习的规模"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:629
msgid ""
"As a last step in this notebook, let's see how we can use Flower to "
"experiment with a large number of clients."
msgstr "作为本笔记的最后一步，让我们看看如何使用 Flower 对大量客户端进行实验。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:651
#, python-format
msgid ""
"We now have 1000 partitions, each holding 45 training and 5 validation "
"examples. Given that the number of training examples on each client is quite "
"small, we should probably train the model a bit longer, so we configure the "
"clients to perform 3 local training epochs. We should also adjust the "
"fraction of clients selected for training during each round (we don't want "
"all 1000 clients participating in every round), so we adjust "
"``fraction_fit`` to ``0.05``, which means that only 5% of available clients "
"(so 50 clients) will be selected for training each round:"
msgstr ""
"现在我们有 1000 个分区，每个分区有 45 个训练数据和 5 个验证数据。鉴于每个客户"
"端上的训练示例数量较少，我们可能需要对模型进行更长时间的训练，"
"因此我们将客户端配置为执行 3 "
"个本地训练遍历。我们还应该调整每轮训练中被选中的客户端的比例（"
"我们不希望每轮训练都有 1000 个客户端参与），因此我们将 ``fraction_fit`` "
"调整为 ``0.05``，这意味着每轮训练只选中 5%的可用客户端（即 50 个客户端）："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:699
msgid ""
"In this notebook, we've seen how we can gradually enhance our system by "
"customizing the strategy, initializing parameters on the server side, "
"choosing a different strategy, and evaluating models on the server-side. "
"That's quite a bit of flexibility with so little code, right?"
msgstr ""
"在本笔记中，我们看到了如何通过自定义策略、在服务器端初始化参数、选择不同的策"
"略以及在服务器端评估模型来逐步增强我们的系统。用这么少的代码就能实现这么大的"
"灵活性，不是吗？"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:701
msgid ""
"In the later sections, we've seen how we can communicate arbitrary values "
"between server and clients to fully customize client-side execution. With "
"that capability, we built a large-scale Federated Learning simulation using "
"the Flower Virtual Client Engine and ran an experiment involving 1000 "
"clients in the same workload - all in a Jupyter Notebook!"
msgstr ""
"在后面的章节中，我们将看到如何在服务器和客户端之间传递任意值，以完全自定义客"
"户端执行。有了这种能力，我们使用 Flower "
"虚拟客户端引擎构建了一个大规模的联邦学习模拟，并在 Jupyter Notebook "
"中进行了一次实验，在相同的工作负载中运行了 1000 个客户端！"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:719
msgid ""
"The `Flower Federated Learning Tutorial - Part 3 <https://flower.dev/docs/"
"framework/tutorial-build-a-strategy-from-scratch-pytorch.html>`__ shows how "
"to build a fully custom ``Strategy`` from scratch."
msgstr ""
"`Flower 联邦学习教程 - 第 3 部分 <https://flower.dev/docs/framework/tutorial-"
"build-a-strategy-from-scratch-pytorch.html>`__ "
"展示了如何从头开始构建完全自定义的 \"策略\"。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:9
msgid "What is Federated Learning?"
msgstr "什么是联邦学习？"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:13
msgid ""
"In this tutorial, you will learn what federated learning is, build your "
"first system in Flower, and gradually extend it. If you work through all "
"parts of the tutorial, you will be able to build advanced federated learning "
"systems that approach the current state of the art in the field."
msgstr ""
"在本教程中，你将了解什么是联邦学习，用 Flower 搭建第一个系统，并逐步对其进行"
"扩展。如果你能完成本教程的所有部分，你就能构建高级的联邦学习系统，从而接近该"
"领域当前的技术水平。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:15
msgid ""
"🧑‍🏫 This tutorial starts at zero and expects no familiarity with federated "
"learning. Only a basic understanding of data science and Python programming "
"is assumed."
msgstr "🧑‍🏫 本教程从零开始，不要求熟悉联邦学习。仅假定对数据科学和 Python "
"编程有基本了解。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:17
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join the "
"open-source Flower community on Slack to connect, ask questions, and get "
"help: `Join Slack <https://flower.dev/join-slack>`__ 🌼 We'd love to hear "
"from you in the ``#introductions`` channel! And if anything is unclear, head "
"over to the ``#questions`` channel."
msgstr ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ 并加入 Slack 上"
"的开源 Flower 社区，进行交流、提问并获得帮助： 加入 Slack <https://flower."
"dev/join-slack>`__ 🌼 我们希望在 ``#introductions`` 频道听到您的声音！如果有"
"任何不清楚的地方，请访问 ``#questions`` 频道。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:19
msgid "Let's get started!"
msgstr "让我们开始吧！"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:31
msgid "Classic machine learning"
msgstr "经典机器学习"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:33
msgid ""
"Before we begin to discuss federated learning, let us quickly recap how most "
"machine learning works today."
msgstr "在开始讨论联邦学习之前，让我们先快速回顾一下目前大多数机器学习的工作原理。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:35
msgid ""
"In machine learning, we have a model, and we have data. The model could be a "
"neural network (as depicted here), or something else, like classical linear "
"regression."
msgstr ""
"在机器学习中，我们有一个模型和数据。模型可以是一个神经网络（如图所示），也可"
"以是其他东西，比如经典的线性回归。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:41
msgid "|e1dd4b4129b040bea23a894266227080|"
msgstr "|e1dd4b4129b040bea23a894266227080|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:109
msgid "Model and data"
msgstr "模型和数据"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:47
msgid ""
"We train the model using the data to perform a useful task. A task could be "
"to detect objects in images, transcribe an audio recording, or play a game "
"like Go."
msgstr ""
"我们使用数据来训练模型，以完成一项有用的任务。任务可以是检测图像中的物体、转"
"录音频或玩围棋等游戏。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:53
msgid "|c0d4cc6a442948dca8da40d2440068d9|"
msgstr "|c0d4cc6a442948dca8da40d2440068d9|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:111
msgid "Train model using data"
msgstr "使用数据训练模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:59
msgid ""
"Now, in practice, the training data we work with doesn't originate on the "
"machine we train the model on. It gets created somewhere else."
msgstr ""
"实际上，我们使用的训练数据并不来自我们训练模型的机器。它是在其他地方创建的。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:61
msgid ""
"It originates on a smartphone by the user interacting with an app, a car "
"collecting sensor data, a laptop receiving input via the keyboard, or a "
"smart speaker listening to someone trying to sing a song."
msgstr ""
"它源于智能手机上用户与应用程序的交互、汽车上传感器数据的收集、笔记本电脑上键"
"盘输入的接收，或者智能扬声器上某人试着唱的歌。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:67
msgid "|174e1e4fa1f149a19bfbc8bc1126f46a|"
msgstr "|174e1e4fa1f149a19bfbc8bc1126f46a|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:113
msgid "Data on a phone"
msgstr "手机上的数据"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:73
msgid ""
"What's also important to mention, this \"somewhere else\" is usually not "
"just one place, it's many places. It could be several devices all running "
"the same app. But it could also be several organizations, all generating "
"data for the same task."
msgstr ""
"值得一提的是，这个 \"其他地方 \"通常不只是一个地方，而是很多地方。它可能是多"
"个运行同一应用程序的设备。但也可能是多个组织，都在为同一任务生成数据。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:79
msgid "|4e021a3dc08249d2a89daa3ab03c2714|"
msgstr "|4e021a3dc08249d2a89daa3ab03c2714|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:115
msgid "Data is on many devices"
msgstr "数据存在于多种设备中"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:85
msgid ""
"So to use machine learning, or any kind of data analysis, the approach that "
"has been used in the past was to collect all data on a central server. This "
"server can be somewhere in a data center, or somewhere in the cloud."
msgstr ""
"因此，要使用机器学习或任何类型的数据分析，过去使用的方法是在中央服务器上收集"
"所有数据。这个服务器可以在数据中心的某个地方，也可以在云端的某个地方。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:91
msgid "|e74a1d5ce7eb49688651f2167a59065b|"
msgstr "|e74a1d5ce7eb49688651f2167a59065b|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:117
msgid "Central data collection"
msgstr "集中数据收集"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:97
msgid ""
"Once all the data is collected in one place, we can finally use machine "
"learning algorithms to train our model on the data. This is the machine "
"learning approach that we've basically always relied on."
msgstr ""
"一旦所有数据都收集到一处，我们最终就可以使用机器学习算法在数据上训练我们的模"
"型。这就是我们基本上一直依赖的机器学习方法。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:103
msgid "|eb29ec4c7aef4e93976795ed72df647e|"
msgstr "|eb29ec4c7aef4e93976795ed72df647e|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:119
msgid "Central model training"
msgstr "集中模型训练"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:130
msgid "Challenges of classical machine learning"
msgstr "经典机器学习面临的挑战"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:132
msgid ""
"The classic machine learning approach we've just seen can be used in some "
"cases. Great examples include categorizing holiday photos, or analyzing web "
"traffic. Cases, where all the data is naturally available on a centralized "
"server."
msgstr ""
"我们刚刚看到的经典机器学习方法可以在某些情况下使用。很好的例子包括对假日照片"
"进行分类或分析网络流量。在这些案例中，所有数据自然都可以在中央服务器上获得。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:138
msgid "|c2f699d8ac484f5081721a6f1511f70d|"
msgstr "|c2f699d8ac484f5081721a6f1511f70d|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:173
msgid "Centralized possible"
msgstr "可集中管理"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:144
msgid ""
"But the approach can not be used in many other cases. Cases, where the data "
"is not available on a centralized server, or cases where the data available "
"on one server is not enough to train a good model."
msgstr ""
"但这种方法并不适用于许多其他情况。例如，集中服务器上没有数据，或者一台服务器"
"上的数据不足以训练出一个好的模型。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:150
msgid "|cf42accdacbf4e5eb4fa0503108ba7a7|"
msgstr "|cf42accdacbf4e5eb4fa0503108ba7a7|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:175
msgid "Centralized impossible"
msgstr "无法集中"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:156
msgid ""
"There are many reasons why the classic centralized machine learning approach "
"does not work for a large number of highly important real-world use cases. "
"Those reasons include:"
msgstr ""
"传统的集中式机器学习方法无法满足现实世界中大量极为重要的使用案例，原因有很"
"多。这些原因包括："

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:158
msgid ""
"**Regulations**: GDPR (Europe), CCPA (California), PIPEDA (Canada), LGPD "
"(Brazil), PDPL (Argentina), KVKK (Turkey), POPI (South Africa), FSS "
"(Russia), CDPR (China), PDPB (India), PIPA (Korea), APPI (Japan), PDP "
"(Indonesia), PDPA (Singapore), APP (Australia), and other regulations "
"protect sensitive data from being moved. In fact, those regulations "
"sometimes even prevent single organizations from combining their own users' "
"data for artificial intelligence training because those users live in "
"different parts of the world, and their data is governed by different data "
"protection regulations."
msgstr ""
"**法规**： GDPR（欧洲）、CCPA（加利福尼亚）、PIPEDA（加拿大）、LGPD（巴西）、"
"PDPL（阿根廷）、KVKK（土耳其）、POPI（南非）、FSS（俄罗斯）、CDPR（中国）、"
"PDPB（印度）、PIPA（韩国）、APPI（日本）、PDP（印度尼西亚）、PDPA（新加坡）、"
"APP（澳大利亚）等法规保护敏感数据不被移动。事实上，这些法规有时甚至会阻止单个"
"组织将自己的用户数据用于人工智能培训，因为这些用户生活在世界不同地区，他们的"
"数据受不同的数据保护法规管辖。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:160
msgid ""
"**User preference**: In addition to regulation, there are use cases where "
"users just expect that no data leaves their device, ever. If you type your "
"passwords and credit card info into the digital keyboard of your phone, you "
"don't expect those passwords to end up on the server of the company that "
"developed that keyboard, do you? In fact, that use case was the reason "
"federated learning was invented in the first place."
msgstr ""
"**用户偏好**： 除了法规之外，在一些使用案例中，用户只是希望数据永远不会离开他"
"们的设备。如果你在手机的数字键盘上输入密码和信用卡信息，你不会希望这些密码最"
"终出现在开发该键盘的公司的服务器上吧？事实上，这种用例正是联邦学习发明的初衷"
"。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:161
msgid ""
"**Data volume**: Some sensors, like cameras, produce such a high data volume "
"that it is neither feasible nor economic to collect all the data (due to, "
"for example, bandwidth or communication efficiency). Think about a national "
"rail service with hundreds of train stations across the country. If each of "
"these train stations is outfitted with a number of security cameras, the "
"volume of raw on-device data they produce requires incredibly powerful and "
"exceedingly expensive infrastructure to process and store. And most of the "
"data isn't even useful."
msgstr ""
"**数据量**： 有些传感器（如摄像头）产生的数据量很大，收集所有数据既不可行，也"
"不经济（例如，由于带宽或通信效率的原因）。试想一下全国铁路服务，全国有数百个"
"火车站。如果每个火车站都安装了许多安全摄像头，那么它们所产生的大量原始设备数"
"据就需要功能强大且极其昂贵的基础设施来处理和存储。而大部分数据甚至都是无用"
"的。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:164
msgid "Examples where centralized machine learning does not work include:"
msgstr "集中式机器学习不起作用的例子包括："

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:166
msgid ""
"Sensitive healthcare records from multiple hospitals to train cancer "
"detection models"
msgstr "用多家医院的敏感医疗记录训练癌症检测模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:167
msgid ""
"Financial information from different organizations to detect financial fraud"
msgstr "不同组织的财务信息，以侦查财务欺诈行为"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:168
msgid "Location data from your electric car to make better range prediction"
msgstr "通过电动汽车的定位数据更好地预测续航里程"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:169
msgid "End-to-end encrypted messages to train better auto-complete models"
msgstr "端到端加密信息可训练出更好的自动完成模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:171
msgid ""
"The popularity of privacy-enhancing systems like the `Brave <https://brave."
"com/>`__ browser or the `Signal <https://signal.org/>`__ messenger shows "
"that users care about privacy. In fact, they choose the privacy-enhancing "
"version over other alternatives, if such an alernative exists. But what can "
"we do to apply machine learning and data science to these cases to utilize "
"private data? After all, these are all areas that would benefit "
"significantly from recent advances in AI."
msgstr ""
"像 `Brave <https://brave.com/>`__浏览器或 `Signal <https://signal.org/>`__信"
"息管理器这样的隐私增强系统的流行表明，用户关心隐私。事实上，他们会选择隐私性"
"更好的产品。但是，我们能做些什么来将机器学习和数据科学应用到这些情况中，以利"
"用隐私数据呢？毕竟，这些领域都将从人工智能的最新进展中受益匪浅。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:186
msgid "Federated learning"
msgstr "联邦学习"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:188
msgid ""
"Federated learning simply reverses this approach. It enables machine "
"learning on distributed data by moving the training to the data, instead of "
"moving the data to the training. Here's the single-sentence explanation:"
msgstr "联邦学习简单地颠覆了这种方法。它通过将训练转移到数据上，而不是将数据转移到训"
"练上，在分布式数据上实现机器学习。下面是一句话的解释："

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:190
msgid "Central machine learning: move the data to the computation"
msgstr "集中式机器学习：将数据转移到计算中心"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:191
msgid "Federated (machine) learning: move the computation to the data"
msgstr "联邦式（机器）学习：将计算转移到数据上"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:193
msgid ""
"By doing so, it enables us to use machine learning (and other data science "
"approaches) in areas where it wasn't possible before. We can now train "
"excellent medical AI models by enabling different hospitals to work "
"together. We can solve financial fraud by training AI models on the data of "
"different financial institutions. We can build novel privacy-enhancing "
"applications (such as secure messaging) that have better built-in AI than "
"their non-privacy-enhancing alternatives. And those are just a few of the "
"examples that come to mind. As we deploy federated learning, we discover "
"more and more areas that can suddenly be reinvented because they now have "
"access to vast amounts of previously inaccessible data."
msgstr ""
"这样，我们就能在以前不可能的领域使用机器学习（和其他数据科学方法）。现在，我"
"们可以通过让不同的医院协同工作来训练优秀的医疗人工智能模型。我们可以通过在不"
"同金融机构的数据上训练人工智能模型来解决金融欺诈问题。我们可以构建新颖的隐私"
"增强型应用（如安全信息），其内置的人工智能比非隐私增强型应用更好。以上只是我"
"想到的几个例子。随着联邦学习的部署，我们会发现越来越多的领域可以突然重获新生"
"，因为它们现在可以访问大量以前无法访问的数据。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:196
msgid ""
"So how does federated learning work, exactly? Let's start with an intuitive "
"explanation."
msgstr "那么，联邦学习究竟是如何运作的呢？让我们从直观的解释开始。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:199
msgid "Federated learning in five steps"
msgstr "联邦学习的五个步骤"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:202
msgid "Step 0: Initialize global model"
msgstr "步骤 0：初始化全局模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:204
msgid ""
"We start by initializing the model on the server. This is exactly the same "
"in classic centralized learning: we initialize the model parameters, either "
"randomly or from a previously saved checkpoint."
msgstr ""
"我们首先在服务器上初始化模型。这与经典的集中式学习完全相同：我们随机或从先前"
"保存的检查点初始化模型参数。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:210
msgid "|5ec8356bc2564fa09178b1ceed5beccc|"
msgstr "|5ec8356bc2564fa09178b1ceed5beccc|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:307
msgid "Initialize global model"
msgstr "初始化全局模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:217
msgid ""
"Step 1: Send model to a number of connected organizations/devices (client "
"nodes)"
msgstr "第 1 步：将模型发送到多个连接的组织/设备（客户节点）"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:219
msgid ""
"Next, we send the parameters of the global model to the connected client "
"nodes (think: edge devices like smartphones or servers belonging to "
"organizations). This is to ensure that each participating node starts their "
"local training using the same model parameters. We often use only a few of "
"the connected nodes instead of all nodes. The reason for this is that "
"selecting more and more client nodes has diminishing returns."
msgstr ""
"接下来，我们会将全局模型的参数发送到连接的客户端节点（如智能手机等边缘设备或"
"企业的服务器）。这是为了确保每个参与节点都使用相同的模型参数开始本地训练。我"
"们通常只使用几个连接节点，而不是所有节点。这样做的原因是，选择越来越多的客户"
"端节点会导致收益递减。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:225
msgid "|7c9329e97bd0430bad335ab605a897a7|"
msgstr "|7c9329e97bd0430bad335ab605a897a7|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:309
msgid "Send global model"
msgstr "发送全局模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:232
msgid ""
"Step 2: Train model locally on the data of each organization/device (client "
"node)"
msgstr "步骤 2：在本地对每个机构/设备（客户端节点）的数据进行模型训练"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:234
msgid ""
"Now that all (selected) client nodes have the latest version of the global "
"model parameters, they start the local training. They use their own local "
"dataset to train their own local model. They don't train the model until "
"full convergence, but they only train for a little while. This could be as "
"little as one epoch on the local data, or even just a few steps (mini-"
"batches)."
msgstr ""
"现在，所有（选定的）客户端节点都有了最新版本的全局模型参数，它们开始进行本地"
"训练。它们使用自己的本地数据集来训练自己的本地模型。它们不会一直训练到模型完"
"全收敛为止，而只是训练一小段时间。这可能只是本地数据上的一个遍历，甚至只是几"
"个步骤（mini-batches）。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:240
msgid "|88002bbce1094ba1a83c9151df18f707|"
msgstr "|88002bbce1094ba1a83c9151df18f707|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:311
msgid "Train on local data"
msgstr "根据本地数据进行训练"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:247
msgid "Step 3: Return model updates back to the server"
msgstr "步骤 3：将模型参数更新返回服务器"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:249
msgid ""
"After local training, each client node has a slightly different version of "
"the model parameters they originally received. The parameters are all "
"different because each client node has different examples in its local "
"dataset. The client nodes then send those model updates back to the server. "
"The model updates they send can either be the full model parameters or just "
"the gradients that were accumulated during local training."
msgstr ""
"经过本地训练后，每个客户节点最初收到的模型参数都会略有不同。参数之所以不同，"
"是因为每个客户端节点的本地数据集中都有不同的数据。然后，客户端节点将这些模型"
"更新发回服务器。它们发送的模型更新既可以是完整的模型参数，也可以只是本地训练"
"过程中积累的梯度。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:255
msgid "|391766aee87c482c834c93f7c22225e2|"
msgstr "|391766aee87c482c834c93f7c22225e2|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:313
msgid "Send model updates"
msgstr "发送模型参数更新"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:262
msgid "Step 4: Aggregate model updates into a new global model"
msgstr "步骤 4：将模型更新聚合到新的全局模型中"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:264
msgid ""
"The server receives model updates from the selected client nodes. If it "
"selected 100 client nodes, it now has 100 slightly different versions of the "
"original global model, each trained on the local data of one client. But "
"didn't we want to have one model that contains the learnings from the data "
"of all 100 client nodes?"
msgstr ""
"服务器从选定的客户端节点接收模型更新。如果服务器选择了 100 个客户端节点，那么"
"它现在就拥有 100 个略有不同的原始全局模型版本，每个版本都是根据一个客户端的本"
"地数据训练出来的。难道我们不希望有一个包含所有 100 个客户节点数据的模型吗？"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:266
msgid ""
"In order to get one single model, we have to combine all the model updates "
"we received from the client nodes. This process is called *aggregation*, and "
"there are many different ways to do it. The most basic way to do it is "
"called *Federated Averaging* (`McMahan et al., 2016 <https://arxiv.org/"
"abs/1602.05629>`__), often abbreviated as *FedAvg*. *FedAvg* takes the 100 "
"model updates and, as the name suggests, averages them. To be more precise, "
"it takes the *weighted average* of the model updates, weighted by the number "
"of examples each client used for training. The weighting is important to "
"make sure that each data example has the same \"influence\" on the resulting "
"global model. If one client has 10 examples, and another client has 100 "
"examples, then - without weighting - each of the 10 examples would influence "
"the global model ten times as much as each of the 100 examples."
msgstr ""
"为了得到一个单一的模型，我们必须将从客户端节点收到的所有模型更新合并起来。这"
"个过程称为*聚合*，有许多不同的方法。最基本的方法称为 *Federated Averaging* "
"(`McMahan等人，2016 <https://arxiv.org/abs/1602."
"05629>`__)，通常缩写为*FedAvg*。*FedAvg* 可以把100 个模型更新进行平均。更准确"
"地说，它取的是模型更新的*加权平均值*，根据每个客户端用于训练的数据数量进行加"
"权。加权对于确保每个数据示例对生成的全局模型具有相同的 \"影响 \"非常重要。"
"如果一个客户端有 10 个数据点，而另一个客户有 100 "
"个数据点，那么在不加权的情况下，10 个示例对全局模型的影响是 100 个示例的 10 "
"倍。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:273
msgid "|93b9a15bd27f4e91b40f642c253dfaac|"
msgstr "|93b9a15bd27f4e91b40f642c253dfaac|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:315
msgid "Aggregate model updates"
msgstr "聚合模型参数更新"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:280
msgid "Step 5: Repeat steps 1 to 4 until the model converges"
msgstr "步骤 5：重复步骤 1 至 4，直至模型收敛"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:282
msgid ""
"Steps 1 to 4 are what we call a single round of federated learning. The "
"global model parameters get sent to the participating client nodes (step 1), "
"the client nodes train on their local data (step 2), they send their updated "
"models to the server (step 3), and the server then aggregates the model "
"updates to get a new version of the global model (step 4)."
msgstr ""
"步骤 1 至 4 "
"就是我们所说的单轮联邦学习。全局模型参数被发送到参与的客户端节点（第 1 "
"步），客户端节点对其本地数据进行训练（第 2 "
"步），然后将更新后的模型发送到服务器（第 3 "
"步），服务器汇总模型更新，得到新版本的全局模型（第 4 步）。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:284
msgid ""
"During a single round, each client node that participates in that iteration "
"only trains for a little while. This means that after the aggregation step "
"(step 4), we have a model that has been trained on all the data of all "
"participating client nodes, but only for a little while. We then have to "
"repeat this training process over and over again to eventually arrive at a "
"fully trained model that performs well across the data of all client nodes."
msgstr ""
"在一轮迭代中，每个参与迭代的客户节点只训练一小段时间。这意味着，在聚合步骤"
"（步骤 4）之后，我们的模型已经在所有参与的客户节点的所有数据上训练过了，但只"
"训练了一小会儿。然后，我们必须一次又一次地重复这一训练过程，最终得到一个经过"
"全面训练的模型，该模型在所有客户节点的数据中都表现良好。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:289
msgid ""
"Congratulations, you now understand the basics of federated learning. "
"There's a lot more to discuss, of course, but that was federated learning in "
"a nutshell. In later parts of this tutorial, we will go into more detail. "
"Interesting questions include: How can we select the best client nodes that "
"should participate in the next round? What's the best way to aggregate model "
"updates? How can we handle failing client nodes (stragglers)?"
msgstr ""
"恭喜您，现在您已经了解了联邦学习的基础知识。当然，要讨论的内容还有很多，但这"
"只是联邦学习的一个缩影。在本教程的后半部分，我们将进行更详细的介绍。"
"有趣的问题包括 我们如何选择最好的客户端节点参与下一轮学习？聚合模型更新的最佳"
"方法是什么？如何处理失败的客户端节点（落伍者）？"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:294
msgid ""
"Just like we can train a model on the decentralized data of different client "
"nodes, we can also evaluate the model on that data to receive valuable "
"metrics. This is called federated evaluation, sometimes abbreviated as FE. "
"In fact, federated evaluation is an integral part of most federated learning "
"systems."
msgstr ""
"就像我们可以在不同客户节点的分散数据上训练一个模型一样，我们也可以在这些数据"
"上对模型进行评估，以获得有价值的指标。这就是所谓的联邦评估，有时简称为 "
"FE。事实上，联邦评估是大多数联邦学习系统不可或缺的一部分。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:297
msgid "Federated analytics"
msgstr "联邦分析"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:299
msgid ""
"In many cases, machine learning isn't necessary to derive value from data. "
"Data analysis can yield valuable insights, but again, there's often not "
"enough data to get a clear answer. What's the average age at which people "
"develop a certain type of health condition? Federated analytics enables such "
"queries over multiple client nodes. It is usually used in conjunction with "
"other privacy-enhancing technologies like secure aggregation to prevent the "
"server from seeing the results submitted by individual client nodes."
msgstr ""
"在很多情况下，机器学习并不是从数据中获取价值的必要条件。数据分析可以产生有价"
"值的见解，但同样，往往没有足够的数据来获得明确的答案。人们患某种健康疾病的平"
"均年龄是多少？联邦分析可以通过多个客户端节点进行此类查询。它通常与安全聚合等"
"其他隐私增强技术结合使用，以防止服务器看到单个客户端节点提交的结果。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:303
msgid "Differential Privacy"
msgstr "差分隐私"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:305
msgid ""
"Differential privacy (DP) is often mentioned in the context of Federated "
"Learning. It is a privacy-preserving method used when analyzing and sharing "
"statistical data, ensuring the privacy of individual participants. DP "
"achieves this by adding statistical noise to the model updates, ensuring any "
"individual participants’ information cannot be distinguished or re-"
"identified. This technique can be considered an optimization that provides a "
"quantifiable privacy protection measure."
msgstr ""
"差分隐私（DP）经常在联邦学习中被提及。这是一种在分析和共享统计数据时使用的隐"
"私保护方法，可确保单个参与者的隐私。DP 通过在模型更新中添加统计噪声来实现这一"
"目的，确保任何个体参与者的信息都无法被区分或重新识别。这种技术可被视为一种优"
"化，提供了一种可量化的隐私保护措施。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:326
msgid "Flower"
msgstr "Flower"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:328
msgid ""
"Federated learning, federated evaluation, and federated analytics require "
"infrastructure to move machine learning models back and forth, train and "
"evaluate them on local data, and then aggregate the updated models. Flower "
"provides the infrastructure to do exactly that in an easy, scalable, and "
"secure way. In short, Flower presents a unified approach to federated "
"learning, analytics, and evaluation. It allows the user to federate any "
"workload, any ML framework, and any programming language."
msgstr ""
"联邦学习、联邦评估和联邦分析需要基础框架来来回移动机器学习模型，在本地数据上"
"对其进行训练和评估，然后汇总更新的模型。Flower "
"提供的基础架构正是以简单、可扩展和安全的方式实现这些目标的。简而言之，Flower "
"为联邦学习、分析和评估提供了一种统一的方法。它允许用户联邦化任何工作负载、"
"任何 ML 框架和任何编程语言。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:334
msgid "|a23d9638f96342ef9d25209951e2d564|"
msgstr "|a23d9638f96342ef9d25209951e2d564|"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:340
msgid ""
"Flower federated learning server and client nodes (car, scooter, personal "
"computer, roomba, and phone)"
msgstr "Flower联邦学习服务器和客户端节点（汽车、滑板车、个人电脑、roomba 和电话）"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:353
msgid ""
"Congratulations, you just learned the basics of federated learning and how "
"it relates to the classic (centralized) machine learning!"
msgstr "恭喜您，您刚刚了解了联邦学习的基础知识，以及它与传统（集中式）机器学习的关系"
"！"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:355
msgid ""
"In the next part of this tutorial, we are going to build a first federated "
"learning system with Flower."
msgstr "在本教程的下一部分，我们将用 Flower 建立第一个联邦学习系统。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:373
msgid ""
"The `Flower Federated Learning Tutorial - Part 1 <https://flower.dev/docs/"
"framework/tutorial-get-started-with-flower-pytorch.html>`__ shows how to "
"build a simple federated learning system with PyTorch and Flower."
msgstr ""
"`Flower 联邦学习教程 - 第 1 部分 <https://flower.dev/docs/framework/tutorial-"
"get-started-with-flower-pytorch.html>`__ 展示了如何使用 PyTorch 和 Flower "
"构建一个简单的联邦学习系统。"

#: ../../source/contributor-how-to-install-development-versions.rst:62
msgid "Upload the whl (e.g., ``flwr-1.6.0-py3-none-any.whl``)"
msgstr "上传 whl（例如 ``flwr-1.6.0-py3-none-any.whl``)"

#: ../../source/contributor-how-to-install-development-versions.rst:63
msgid ""
"Change ``!pip install -q 'flwr[simulation]' torch torchvision matplotlib`` "
"to ``!pip install -q 'flwr-1.6.0-py3-none-any.whl[simulation]' torch "
"torchvision matplotlib``"
msgstr ""
"将``!pip install -q 'flwr[simulation]' torch torchvision matplotlib``更改为"
"``!pip install -q 'flwr-1.6.0-py3-none-any.whl[simulation]' torch torch "
"torchvision matplotlib``"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:280
msgid ""
"All that's left to do it to define a function that loads both model and "
"data, creates a :code:`CifarClient`, and starts this client. You load your "
"data and model by using :code:`cifar.py`. Start :code:`CifarClient` with the "
"function :code:`fl.client.start_numpy_client()` by pointing it at the same "
"IP adress we used in :code:`server.py`:"
msgstr ""
"剩下要做的就是定义一个加载模型和数据的函数，创建一个 :code:`CifarClient` 并启"
"动该客户端。使用 :code:`cifar.py` 加载数据和模型。使用函数 :code:`fl.client."
"start_numpy_client()` 启动 :code:`CifarClient`，将其指向我们在 :code:`server."
"py` 中使用的相同 IP 地址："

#: ../../source/how-to-run-simulations.rst:10
msgid ""
"The :code:`VirtualClientEngine` schedules, launches and manages `virtual` "
"clients. These clients are identical to `non-virtual` clients (i.e. the ones "
"you launch via the command `flwr.client.start_numpy_client <ref-api-flwr."
"html#start-numpy-client>`_) in the sense that they can be configure by "
"creating a class inheriting, for example, from `flwr.client.NumPyClient <ref-"
"api-flwr.html#flwr.client.NumPyClient>`_ and therefore behave in an "
"identical way. In addition to that, clients managed by the :code:"
"`VirtualClientEngine` are:"
msgstr ""
"代码:`VirtualClientEngine`调度、启动和管理`虚拟`客户端。这些客户端与 \"非虚拟"
" \"客户端（即通过命令 `flwr.client.start_numpy_client <ref-api-flwr.html"
"#start-numpy-client>`_启动的客户端）完全相同，它们可以通过创建一个继承自 "
"\"flwr.client.NumPyClient <ref-api-flwr.html#flwr.client.NumPyClient>`_\" "
"的类来配置，因此行为方式也完全相同。除此之外，由 :code:`VirtualClientEngine` "
"管理的客户端还包括："

#: ../../source/tutorial-quickstart-mxnet.rst:217
#: ../../source/tutorial-quickstart-scikitlearn.rst:150
msgid ""
"That's it for the client. We only have to implement :code:`Client` or :code:"
"`NumPyClient` and call :code:`fl.client.start_client()` or :code:`fl.client."
"start_numpy_client()`. The string :code:`\"0.0.0.0:8080\"` tells the client "
"which server to connect to. In our case we can run the server and the client "
"on the same machine, therefore we use :code:`\"0.0.0.0:8080\"`. If we run a "
"truly federated workload with the server and clients running on different "
"machines, all that needs to change is the :code:`server_address` we pass to "
"the client."
msgstr ""
"这就是客户端。我们只需实现 :code:`Client` 或 :code:`NumPyClient` 并调用 "
":code:`fl.client.start_client()` 或 :code:`fl.client.start_numpy_client()`。"
"字符串 :code:`\"0.0.0.0:8080\"`会告诉客户端要连接的服务器。在本例中，我们可以"
"在同一台机器上运行服务器和客户端，因此我们使用 :code:`\"0.0.0.0:8080\""
"`。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，"
"那么需要改变的只是传递给客户端的 :code:`server_address`。"

#: ../../source/tutorial-quickstart-pytorch.rst:196
#: ../../source/tutorial-quickstart-tensorflow.rst:90
msgid ""
"That's it for the client. We only have to implement :code:`Client` or :code:"
"`NumPyClient` and call :code:`fl.client.start_client()` or :code:`fl.client."
"start_numpy_client()`. The string :code:`\"[::]:8080\"` tells the client "
"which server to connect to. In our case we can run the server and the client "
"on the same machine, therefore we use :code:`\"[::]:8080\"`. If we run a "
"truly federated workload with the server and clients running on different "
"machines, all that needs to change is the :code:`server_address` we point "
"the client at."
msgstr ""
"这就是客户端。我们只需实现 :code:`Client` 或 :code:`NumPyClient` 并调用 "
":code:`fl.client.start_client()` 或 :code:`fl.client.start_numpy_client()`。"
"字符串 :code:`\"[::]:8080\"`会告诉客户端要连接的服务器。在本例中，我们可以在"
"同一台机器上运行服务器和客户端，因此使用 :code:`\"[::]:8080\""
"。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，"
"那么需要改变的只是客户端指向的 :code:`server_address`。"
