
msgid ""
msgstr ""
"Project-Id-Version: Flower Docs\n"
"Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
"POT-Creation-Date: 2023-08-30 18:55+0200\n"
"PO-Revision-Date: 2023-09-05 17:54+0000\n"
"Last-Translator: Charles Beauville <charles@adap.com>\n"
"Language: fr\n"
"Language-Team: French <https://hosted.weblate.org/projects/flower-"
"docs/framework/fr/>\n"
"Plural-Forms: nplurals=2; plural=n > 1;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/contributor-explanation-architecture.rst:2
msgid "Flower Architecture"
msgstr "Architecture florale"

#: ../../source/contributor-explanation-architecture.rst:5
msgid "Edge Client Engine"
msgstr "Moteur client Edge"

#: ../../source/contributor-explanation-architecture.rst:7
msgid ""
"`Flower <https://flower.dev>`_ core framework architecture with Edge "
"Client Engine"
msgstr ""
"`Flower <https://flower.dev>`_ architecture de base avec Edge Client "
"Engine"

#: ../../source/contributor-explanation-architecture.rst:13
msgid "Virtual Client Engine"
msgstr "Moteur de client virtuel"

#: ../../source/contributor-explanation-architecture.rst:15
msgid ""
"`Flower <https://flower.dev>`_ core framework architecture with Virtual "
"Client Engine"
msgstr ""
"`Flower <https://flower.dev>`_ architecture de base avec moteur de client"
" virtuel"

#: ../../source/contributor-explanation-architecture.rst:21
msgid "Virtual Client Engine and Edge Client Engine in the same workload"
msgstr "Moteur client virtuel et moteur client Edge dans la même charge de travail"

#: ../../source/contributor-explanation-architecture.rst:23
msgid ""
"`Flower <https://flower.dev>`_ core framework architecture with both "
"Virtual Client Engine and Edge Client Engine"
msgstr ""
"`Flower <https://flower.dev>`_ architecture de base avec un moteur de "
"client virtuel et un moteur de client périphérique"

#: ../../source/contributor-how-create-new-messages.rst:2
msgid "Creating New Messages"
msgstr "Création de nouveaux messages"

#: ../../source/contributor-how-create-new-messages.rst:4
msgid ""
"This is a simple guide for creating a new type of message between the "
"server and clients in Flower."
msgstr ""
"Voici un guide simple pour créer un nouveau type de message entre le "
"serveur et les clients dans Flower."

#: ../../source/contributor-how-create-new-messages.rst:6
msgid ""
"Let's suppose we have the following example functions in "
":code:`server.py` and :code:`numpy_client.py`..."
msgstr ""
"Supposons que nous ayons les fonctions suivantes dans :code:`server.py` "
"et :code:`numpy_client.py`..."

#: ../../source/contributor-how-create-new-messages.rst:8
msgid "Server's side:"
msgstr "Côté serveur :"

#: ../../source/contributor-how-create-new-messages.rst:17
msgid "Client's side:"
msgstr "Côté client :"

#: ../../source/contributor-how-create-new-messages.rst:26
msgid ""
"Let's now see what we need to implement in order to get this simple "
"function between the server and client to work!"
msgstr ""
"Voyons maintenant ce que nous devons mettre en œuvre pour que cette "
"simple fonction entre le serveur et le client fonctionne !"

#: ../../source/contributor-how-create-new-messages.rst:30
msgid "Message Types for Protocol Buffers"
msgstr "Types de messages pour les tampons de protocole"

#: ../../source/contributor-how-create-new-messages.rst:32
msgid ""
"The first thing we need to do is to define a message type for the RPC "
"system in :code:`transport.proto`. Note that we have to do it for both "
"the request and response messages. For more details on the syntax of "
"proto3, please see the  `official documentation "
"<https://developers.google.com/protocol-buffers/docs/proto3>`_."
msgstr ""
"La première chose à faire est de définir un type de message pour le "
"système RPC dans :code:`transport.proto`. Notez que nous devons le faire "
"à la fois pour les messages de demande et de réponse. Pour plus de "
"détails sur la syntaxe de proto3, veuillez consulter la `documentation "
"officielle <https://developers.google.com/protocol-"
"buffers/docs/proto3>`_."

#: ../../source/contributor-how-create-new-messages.rst:35
msgid "Within the :code:`ServerMessage` block:"
msgstr "Dans le bloc :code:`ServerMessage` :"

#: ../../source/contributor-how-create-new-messages.rst:52
msgid "Within the ClientMessage block:"
msgstr "Dans le bloc ClientMessage :"

#: ../../source/contributor-how-create-new-messages.rst:70
msgid ""
"Make sure to also add a field of the newly created message type in "
":code:`oneof msg`."
msgstr ""
"Veille à ajouter également un champ du type de message nouvellement créé "
"dans :code:`oneof msg`."

#: ../../source/contributor-how-create-new-messages.rst:72
msgid "Once that is done, we will compile the file with:"
msgstr "Une fois que c'est fait, nous compilerons le fichier avec :"

#: ../../source/contributor-how-create-new-messages.rst:78
msgid "If it compiles succesfully, you should see the following message:"
msgstr "S'il se compile avec succès, tu devrais voir le message suivant :"

#: ../../source/contributor-how-create-new-messages.rst:87
msgid "Serialization and Deserialization Functions"
msgstr "Fonctions de sérialisation et de désérialisation"

#: ../../source/contributor-how-create-new-messages.rst:89
msgid ""
"Our next step is to add functions to serialize and deserialize Python "
"datatypes to or from our defined RPC message types. You should add these "
"functions in :code:`serde.py`."
msgstr ""
"La prochaine étape consiste à ajouter des fonctions pour sérialiser et "
"désérialiser les types de données Python vers ou à partir des types de "
"messages RPC définis. Tu dois ajouter ces fonctions dans "
":code:`serde.py`."

#: ../../source/contributor-how-create-new-messages.rst:91
msgid "The four functions:"
msgstr "Les quatre fonctions :"

#: ../../source/contributor-how-create-new-messages.rst:112
msgid "Sending the Message from the Server"
msgstr "Envoi du message à partir du serveur"

#: ../../source/contributor-how-create-new-messages.rst:114
msgid ""
"Now write the request function in your Client Proxy class (e.g., "
":code:`grpc_client_proxy.py`) using the serde functions you just created:"
msgstr ""
"Écris maintenant la fonction de demande dans ta classe Client Proxy (par "
"exemple, :code:`grpc_client_proxy.py`) en utilisant les fonctions serde "
"que tu viens de créer :"

#: ../../source/contributor-how-create-new-messages.rst:128
msgid "Receiving the Message by the Client"
msgstr "Réception du message par le client"

#: ../../source/contributor-how-create-new-messages.rst:130
msgid ""
"Last step! Modify the code in :code:`message_handler.py` to check the "
"field of your message and call the :code:`example_response` function. "
"Remember to use the serde functions!"
msgstr ""
"Dernière étape ! Modifie le code dans :code:`message_handler.py` pour "
"vérifier le champ de ton message et appeler la fonction "
":code:`example_response`. N'oublie pas d'utiliser les fonctions serde !"

#: ../../source/contributor-how-create-new-messages.rst:132
msgid "Within the handle function:"
msgstr "Dans le cadre de la fonction de poignée :"

#: ../../source/contributor-how-create-new-messages.rst:139
msgid "And add a new function:"
msgstr "Et ajoute une nouvelle fonction :"

#: ../../source/contributor-how-create-new-messages.rst:149
msgid "Hopefully, when you run your program you will get the intended result!"
msgstr ""
"Avec un peu de chance, lorsque tu exécuteras ton programme, tu obtiendras"
" le résultat escompté !"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:2
msgid "Develop in VSCode Dev Containers"
msgstr "Utiliser les conteneurs VS Code Remote"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:4
msgid ""
"When working on the Flower framework we want to ensure that all "
"contributors use the same developer environment to format code or run "
"tests. For this purpose we are using the VSCode Remote Containers "
"extension. What is it? Read the following quote:"
msgstr ""
"Lorsque nous travaillons sur Flower, nous voulons nous assurer que tous "
"les contributeurs utilisent le même environnement de développement pour "
"formater le code ou exécuter des tests. À cette fin, nous utilisons "
"l'extension VSCode Remote Containers. Qu'est-ce que c'est ?"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:7
msgid ""
"The Visual Studio Code Remote - Containers extension lets you use a "
"Docker container as a fully-featured development environment. It allows "
"you to open any folder inside (or mounted into) a container and take "
"advantage of Visual Studio Code's full feature set. A "
":code:`devcontainer.json` file in your project tells VS Code how to "
"access (or create) a development container with a well-defined tool and "
"runtime stack. This container can be used to run an application or to "
"separate tools, libraries, or runtimes needed for working with a "
"codebase."
msgstr ""
"L'extension Visual Studio Code Remote - Containers te permet d'utiliser "
"un conteneur Docker comme environnement de développement complet. Elle te"
" permet d'ouvrir n'importe quel dossier à l'intérieur (ou monté dans) "
"d'un conteneur et de profiter de l'ensemble des fonctionnalités de Visual"
" Studio Code. Un fichier :code:`devcontainer.json` dans ton projet "
"indique à VS Code comment accéder à (ou créer) un conteneur de "
"développement avec une pile d'outils et d'exécutions bien définie. Ce "
"conteneur peut être utilisé pour exécuter une application ou pour séparer"
" les outils, les bibliothèques ou les exécutions nécessaires pour "
"travailler avec une base de code."

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:9
msgid ""
"Workspace files are mounted from the local file system or copied or "
"cloned into the container. Extensions are installed and run inside the "
"container, where they have full access to the tools, platform, and file "
"system. This means that you can seamlessly switch your entire development"
" environment just by connecting to a different container."
msgstr ""
"Les fichiers de l'espace de travail sont montés à partir du système de "
"fichiers local ou copiés ou clonés dans le conteneur. Les extensions sont"
" installées et exécutées à l'intérieur du conteneur, où elles ont un "
"accès complet aux outils, à la plateforme et au système de fichiers. Cela"
" signifie que tu peux changer de façon transparente tout ton "
"environnement de développement simplement en te connectant à un autre "
"conteneur."

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:11
msgid ""
"Source: `Official VSCode documentation "
"<https://code.visualstudio.com/docs/remote/containers>`_"
msgstr ""
"Source : `Documentation officielle de VSCode "
"<https://code.visualstudio.com/docs/remote/containers>`_"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:15
msgid "Getting started"
msgstr "Pour commencer"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:17
msgid ""
"Configuring and setting up the :code:`Dockerfile` as well the "
"configuration for the devcontainer can be a bit more involved. The good "
"thing is you want have to do it. Usually it should be enough to install "
"Docker on your system and ensure its available on your command line. "
"Additionally, install the `VSCode Containers Extension <vscode:extension"
"/ms-vscode-remote.remote-containers>`_."
msgstr ""
"La configuration et le paramétrage du :code:`Dockerfile` ainsi que la "
"configuration du devcontainer peuvent être un peu plus complexes. "
"L'avantage, c'est que tu veux avoir à le faire. En général, il devrait "
"suffire d'installer Docker sur ton système et de s'assurer qu'il est "
"disponible sur ta ligne de commande. En outre, installe l'extension "
"`VSCode Containers Extension <vscode:extension/ms-vscode-remote.remote-"
"containers>`_."

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:19
msgid ""
"Now you should be good to go. When starting VSCode, it will ask you to "
"run in the container environment and - if you confirm - automatically "
"build the container and use it. To manually instruct VSCode to use the "
"devcontainer, you can, after installing the extension, click the green "
"area in the bottom left corner of your VSCode window and select the "
"option *(Re)Open Folder in Container*."
msgstr ""
"Maintenant, tu devrais être prêt à partir. Au démarrage de VSCode, il te "
"demandera de fonctionner dans l'environnement du conteneur et - si tu "
"confirmes - construira automatiquement le conteneur et l'utilisera. Pour "
"demander manuellement à VSCode d'utiliser le devcontainer, tu peux, après"
" avoir installé l'extension, cliquer sur la zone verte dans le coin "
"inférieur gauche de ta fenêtre VSCode et sélectionner l'option "
"*(Re)Ouvrir le dossier dans le conteneur*."

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:21
msgid ""
"In some cases your setup might be more involved. For those cases consult "
"the following sources:"
msgstr ""
"Dans certains cas, ton installation peut être plus complexe. Pour ces "
"cas-là, consulte les sources suivantes :"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:23
msgid ""
"`Developing inside a Container "
"<https://code.visualstudio.com/docs/remote/containers#_system-"
"requirements>`_"
msgstr ""
"`Développement à l'intérieur d'un conteneur "
"<https://code.visualstudio.com/docs/remote/containers#_system-"
"requirements>`_"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:24
msgid ""
"`Remote development in Containers "
"<https://code.visualstudio.com/docs/remote/containers-tutorial>`_"
msgstr ""
"`Développement à distance dans les conteneurs "
"<https://code.visualstudio.com/docs/remote/containers-tutorial>`_"

#: ../../source/contributor-how-to-install-development-versions.rst:2
msgid "Install development versions"
msgstr "Installer les versions de développement de Flower"

#: ../../source/contributor-how-to-install-development-versions.rst:5
msgid "Install development versions of Flower"
msgstr "Installe les versions de développement de Flower"

#: ../../source/contributor-how-to-install-development-versions.rst:8
msgid "Using Poetry (recommended)"
msgstr "Utiliser la poésie (recommandé)"

#: ../../source/contributor-how-to-install-development-versions.rst:10
msgid ""
"Install a ``flwr`` pre-release from PyPI: update the ``flwr`` dependency "
"in ``pyproject.toml`` and then reinstall (don't forget to delete "
"``poetry.lock`` (``rm poetry.lock``) before running ``poetry install``)."
msgstr ""
"Installez une pré-version ``flwr`` de PyPI : mettez à jour la dépendance "
"``flwr`` dans ``pyproject.toml`` puis réinstallez (n'oubliez pas de "
"supprimer ``poetry.lock`` (``rm poetry.lock``) avant d'exécuter ``poetry "
"install``)."

#: ../../source/contributor-how-to-install-development-versions.rst:12
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` (without "
"extras)"
msgstr ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` (sans "
"extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:13
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (avec extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:15
msgid ""
"Install ``flwr`` from a local copy of the Flower source code via "
"``pyproject.toml``:"
msgstr ""
"Installez ``flwr`` à partir d'une copie locale du code source de Flower "
"via ``pyproject.toml`` :"

#: ../../source/contributor-how-to-install-development-versions.rst:17
msgid "``flwr = { path = \"../../\", develop = true }`` (without extras)"
msgstr "``flwr = { path = \"../../\", develop = true }`` (sans extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:18
msgid ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] "
"}`` (with extras)"
msgstr ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] "
"}`` (avec extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:20
msgid "Install ``flwr`` from a local wheel file via ``pyproject.toml``:"
msgstr "Installez ``flwr`` à partir d'un fichier local via ``pyproject.toml`` :"

#: ../../source/contributor-how-to-install-development-versions.rst:22
msgid ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\" }`` (without"
" extras)"
msgstr ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\" }`` (sans "
"extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:23
msgid ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (avec extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:25
msgid ""
"Please refer to the Poetry documentation for further details: `Poetry "
"Dependency Specification <https://python-poetry.org/docs/dependency-"
"specification/>`_"
msgstr ""
"Reporte-toi à la documentation de Poetry pour plus de détails : `Poetry "
"Dependency Specification <https://python-poetry.org/docs/dependency-"
"specification/>`_"

#: ../../source/contributor-how-to-install-development-versions.rst:28
msgid "Using pip (recommended on Colab)"
msgstr "Utiliser pip (recommandé sur Colab)"

#: ../../source/contributor-how-to-install-development-versions.rst:30
msgid "Install a ``flwr`` pre-release from PyPI:"
msgstr "Installe une pré-version de ``flwr`` depuis PyPI :"

#: ../../source/contributor-how-to-install-development-versions.rst:32
msgid "``pip install -U --pre flwr`` (without extras)"
msgstr "``pip install -U --pre flwr`` (sans les extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:33
msgid "``pip install -U --pre flwr[simulation]`` (with extras)"
msgstr "``pip install -U --pre flwr[simulation]`` (avec les extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:35
msgid ""
"Python packages can be installed from git repositories. Use one of the "
"following commands to install the Flower directly from GitHub."
msgstr ""
"Les paquets Python peuvent être installés à partir des dépôts git. "
"Utilise l'une des commandes suivantes pour installer Flower directement à"
" partir de GitHub."

#: ../../source/contributor-how-to-install-development-versions.rst:37
msgid "Install ``flwr`` from the default GitHub branch (``main``):"
msgstr "Installez ``flwr`` à partir de la branche GitHub par défaut (``main``) :"

#: ../../source/contributor-how-to-install-development-versions.rst:39
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git`` (without "
"extras)"
msgstr ""
"``pip install flwr@git+https://github.com/adap/flower.git`` (sans les "
"extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:40
msgid ""
"``pip install flwr[simulation]@git+https://github.com/adap/flower.git`` "
"(with extras)"
msgstr ""
"``pip install flwr[simulation]@git+https://github.com/adap/flower.git`` "
"(avec les extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:42
msgid "Install ``flwr`` from a specific GitHub branch (``branch-name``):"
msgstr ""
"Installez ``flwr`` à partir d'une branche GitHub spécifique (``nom-"
"branche``) :"

#: ../../source/contributor-how-to-install-development-versions.rst:44
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git@branch-name`` "
"(without extras)"
msgstr ""
"``pip install flwr@git+https://github.com/adap/flower.git@nom-branche`` "
"(sans les extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:45
msgid ""
"``pip install flwr[simulation]@git+https://github.com/adap/flower.git"
"@branch-name`` (with extras)"
msgstr ""
"``pip install flwr[simulation]@git+https://github.com/adap/flower.git"
"@nom-de-branche`` (avec des extras)"

#: ../../source/contributor-how-to-install-development-versions.rst:49
msgid "Open Jupyter Notebooks on Google Colab"
msgstr "Ouvre les carnets Jupyter sur Google Colab"

#: ../../source/contributor-how-to-install-development-versions.rst:51
msgid ""
"Open the notebook ``doc/source/tutorial-get-started-with-flower-"
"pytorch.ipynb``:"
msgstr ""
"Ouvrir le notebook ``doc/source/tutorial/Flower-1-Intro-to-FL-"
"PyTorch.ipynb`` :"

#: ../../source/contributor-how-to-install-development-versions.rst:53
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-get-started-with-flower-pytorch.ipynb"
msgstr ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-get-started-with-flower-pytorch.ipynb"

#: ../../source/contributor-how-to-install-development-versions.rst:55
msgid ""
"Open a development version of the same notebook from branch `branch-name`"
" by changing ``main`` to ``branch-name`` (right after ``blob``):"
msgstr ""
"Ouvre une version de développement du même carnet à partir de la branche "
"`nom-branche` en remplaçant `main` par `nom-branche` (juste après `blob`)"
" :"

#: ../../source/contributor-how-to-install-development-versions.rst:57
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/branch-"
"name/doc/source/tutorial-get-started-with-flower-pytorch.ipynb"
msgstr ""
"https://colab.research.google.com/github/adap/flower/blob/branch-"
"name/doc/source/tutorial-get-started-with-flower-pytorch.ipynb"

#: ../../source/contributor-how-to-release-flower.rst:2
msgid "Release Flower"
msgstr "Publier Flower"

#: ../../source/contributor-how-to-release-flower.rst:4
msgid ""
"This document describes the current release process. It may or may not "
"change in the future."
msgstr ""
"Ce document décrit le processus de diffusion actuel, qui peut ou non "
"changer à l'avenir."

#: ../../source/contributor-how-to-release-flower.rst:7
msgid "Before the release"
msgstr "Avant la sortie"

#: ../../source/contributor-how-to-release-flower.rst:9
msgid ""
"Update the changelog (``changelog.md``) with all relevant changes that "
"happened after the last release. If the last release was tagged "
"``v1.2.0``, you can use the following URL to see all commits that got "
"merged into ``main`` since then:"
msgstr ""
"Mettez à jour le journal des modifications (``changelog.md``) avec tous "
"les changements pertinents qui se sont produits après la dernière "
"version. Si la dernière version a été étiquetée ``v1.2.0``, vous pouvez "
"utiliser l'URL suivante pour voir tous les commits qui ont été fusionnés "
"dans ``main`` depuis lors :"

#: ../../source/contributor-how-to-release-flower.rst:11
msgid ""
"`GitHub: Compare v1.2.0...main "
"<https://github.com/adap/flower/compare/v1.2.0...main>`_"
msgstr ""
"`GitHub : Compare v1.2.0...main "
"<https://github.com/adap/flower/compare/v1.2.0...main>`_"

#: ../../source/contributor-how-to-release-flower.rst:13
msgid ""
"Thank the authors who contributed since the last release. This command "
"helps extract them: ``git log --format='%aN' v1.1.0..HEAD | sort -u``. "
"The command has the same order as ``git shortlog``."
msgstr ""
"Remerciez les auteurs qui ont contribué depuis la dernière version. Cette"
" commande permet de les extraire : ``git log --format='%aN' v1.1.0..HEAD "
"| sort -u``. La commande a le même ordre que ``git shortlog``."

#: ../../source/contributor-how-to-release-flower.rst:17
msgid "During the release"
msgstr "Lors de la sortie"

#: ../../source/contributor-how-to-release-flower.rst:19
msgid ""
"The version number of a release is stated in ``pyproject.toml``. To "
"release a new version of Flower, the following things need to happen (in "
"that order):"
msgstr ""
"Le numéro de version d'une version est indiqué dans ``pyproject.toml``. "
"Pour publier une nouvelle version de Flower, les choses suivantes doivent"
" se produire (dans cet ordre) :"

#: ../../source/contributor-how-to-release-flower.rst:21
msgid ""
"Update the ``changelog.md`` section header ``Unreleased`` to contain the "
"version number and date for the release you are building. Create a pull "
"request with the change."
msgstr ""
"Mettez à jour l'en-tête de section ``changelog.md`` ``Unreleased`` pour "
"qu'il contienne le numéro de version et la date de la version que vous "
"construisez. Créez une demande de traction avec le changement."

#: ../../source/contributor-how-to-release-flower.rst:22
msgid ""
"Tag the release commit with the version number as soon as the PR is "
"merged: ``git tag v0.12.3``, then ``git push --tags``"
msgstr ""
"Marquez le commit de la version avec le numéro de version dès que le PR "
"est fusionné : ``git tag v0.12.3``, puis ``git push --tags``"

#: ../../source/contributor-how-to-release-flower.rst:23
msgid ""
"Build the release with ``./dev/build.sh``, then publish it with "
"``./dev/publish.sh``"
msgstr ""
"Construisez la version avec ``./dev/build.sh``, puis publiez-la avec "
"``./dev/publish.sh``"

#: ../../source/contributor-how-to-release-flower.rst:24
msgid ""
"Create an entry in GitHub releases with the release notes for the "
"previously tagged commit and attach the build artifacts (:code:`.whl` and"
" :code:`.tar.gz`)."
msgstr ""
"Crée une entrée dans GitHub releases avec les notes de version pour le "
"commit précédemment étiqueté et attache les artefacts de construction "
"(:code:`.whl` et :code:`.tar.gz`)."

#: ../../source/contributor-how-to-release-flower.rst:27
msgid "After the release"
msgstr "Après la publication"

#: ../../source/contributor-how-to-release-flower.rst:29
msgid "Create a pull request which contains the following changes:"
msgstr "Crée une demande de pull qui contient les modifications suivantes :"

#: ../../source/contributor-how-to-release-flower.rst:31
msgid "Increase the minor version in ``pyproject.toml`` by one."
msgstr "Augmente la version mineure de ``pyproject.toml`` d'une unité."

#: ../../source/contributor-how-to-release-flower.rst:32
msgid "Update all files which contain the current version number if necessary."
msgstr ""
"Mets à jour tous les fichiers qui contiennent le numéro de version actuel"
" si nécessaire."

#: ../../source/contributor-how-to-release-flower.rst:33
msgid "Add a new ``Unreleased`` section in ``changelog.md``."
msgstr "Ajoute une nouvelle section ``Unreleased`` dans ``changelog.md``."

#: ../../source/contributor-how-to-release-flower.rst:35
msgid ""
"Merge the pull request on the same day (i.e., before a new nighly release"
" gets published to PyPI)."
msgstr ""
"Fusionne la pull request le jour même (c'est-à-dire avant qu'une nouvelle"
" version nighly ne soit publiée sur PyPI)."

#: ../../source/contributor-how-to-release-flower.rst:38
msgid "Publishing a pre-release"
msgstr "Publier une pré-version"

#: ../../source/contributor-how-to-release-flower.rst:41
msgid "Pre-release naming"
msgstr "Nom de la pré-version"

#: ../../source/contributor-how-to-release-flower.rst:43
msgid ""
"PyPI supports pre-releases (alpha, beta, release candiate). Pre-releases "
"MUST use one of the following naming patterns:"
msgstr ""
"PyPI prend en charge les préversions (alpha, bêta, version candiate). Les"
" préversions DOIVENT utiliser l'un des modèles de dénomination suivants :"

#: ../../source/contributor-how-to-release-flower.rst:45
msgid "Alpha: ``MAJOR.MINOR.PATCHaN``"
msgstr "Alpha : ``MAJOR.MINOR.PATCHaN``"

#: ../../source/contributor-how-to-release-flower.rst:46
msgid "Beta: ``MAJOR.MINOR.PATCHbN``"
msgstr "Bêta : ``MAJOR.MINOR.PATCHbN``"

#: ../../source/contributor-how-to-release-flower.rst:47
msgid "Release candiate (RC): ``MAJOR.MINOR.PATCHrcN``"
msgstr "Candidat à la publication (RC) : ``MAJOR.MINOR.PATCHrcN``"

#: ../../source/contributor-how-to-release-flower.rst:49
msgid "Examples include:"
msgstr "Voici quelques exemples :"

#: ../../source/contributor-how-to-release-flower.rst:51
msgid "``1.0.0a0``"
msgstr "``1.0.0a0``"

#: ../../source/contributor-how-to-release-flower.rst:52
msgid "``1.0.0b0``"
msgstr "``1.0.0b0``"

#: ../../source/contributor-how-to-release-flower.rst:53
msgid "``1.0.0rc0``"
msgstr "``1.0.0rc0``"

#: ../../source/contributor-how-to-release-flower.rst:54
msgid "``1.0.0rc1``"
msgstr "1.0.0rc1"

#: ../../source/contributor-how-to-release-flower.rst:56
msgid ""
"This is in line with PEP-440 and the recommendations from the Python "
"Packaging Authority (PyPA):"
msgstr ""
"Ceci est conforme au PEP-440 et aux recommandations de l'Autorité de "
"l'emballage Python (PyPA) :"

#: ../../source/contributor-how-to-release-flower.rst:59
msgid "`PEP-440 <https://peps.python.org/pep-0440/>`_"
msgstr "`PEP-440 <https://peps.python.org/pep-0440/>`_"

#: ../../source/contributor-how-to-release-flower.rst:60
msgid ""
"`PyPA Choosing a versioning scheme "
"<https://packaging.python.org/en/latest/guides/distributing-packages-"
"using-setuptools/#choosing-a-versioning-scheme>`_"
msgstr ""
"`PyPA Choisir un schéma de version "
"<https://packaging.python.org/en/latest/guides/distributing-packages-"
"using-setuptools/#choosing-a-versioning-scheme>`_"

#: ../../source/contributor-how-to-release-flower.rst:62
msgid ""
"Note that the approach defined by PyPA is not compatible with SemVer "
"2.0.0 spec, for details consult the `Semantic Versioning Specification "
"<https://semver.org/spec/v2.0.0.html#spec-item-11>`_ (specifically item "
"11 on precedence)."
msgstr ""
"Note que l'approche définie par PyPA n'est pas compatible avec la "
"spécification SemVer 2.0.0, pour plus de détails, consulte la `Semantic "
"Versioning Specification <https://semver.org/spec/v2.0.0.html#spec-"
"item-11>`_ (en particulier le point 11 sur la préséance)."

#: ../../source/contributor-how-to-release-flower.rst:65
msgid "Pre-release classification"
msgstr "Classification avant publication"

#: ../../source/contributor-how-to-release-flower.rst:67
msgid "Should the next pre-release be called alpha, beta, or release candidate?"
msgstr ""
"La prochaine préversion doit-elle être appelée alpha, bêta ou release "
"candidate ?"

#: ../../source/contributor-how-to-release-flower.rst:69
msgid ""
"RC: feature complete, no known issues (apart from issues that are "
"classified as \"won't fix\" for the next stable release) - if no issues "
"surface this will become the next stable release"
msgstr ""
"RC : fonctionnalités complètes, pas de problèmes connus (à l'exception "
"des problèmes classés comme \"à ne pas corriger\" pour la prochaine "
"version stable) - si aucun problème n'apparaît, cette version deviendra "
"la prochaine version stable"

#: ../../source/contributor-how-to-release-flower.rst:70
msgid "Beta: feature complete, allowed to have known issues"
msgstr "Bêta : fonctionnalité complète, autorisée à avoir des problèmes connus"

#: ../../source/contributor-how-to-release-flower.rst:71
msgid "Alpha: not feature complete, allowed to have known issues"
msgstr ""
"Alpha : les fonctionnalités ne sont pas complètes, les problèmes connus "
"sont autorisés"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:2
msgid "Set up a virtual env"
msgstr "Mettre un environment virtuel en place"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:4
msgid ""
"It is recommended to run your Python setup within a virtual environment. "
"This guide shows three different examples how to create a virtual "
"environment with pyenv virtualenv, poetry, or Anaconda. You can follow "
"the instructions or choose your preferred setup."
msgstr ""
"Il est recommandé d'exécuter ton installation Python dans un "
"environnement virtuel. Ce guide montre trois exemples différents de "
"création d'un environnement virtuel avec pyenv virtualenv, poetry ou "
"Anaconda. Tu peux suivre les instructions ou choisir la configuration que"
" tu préfères."

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:9
msgid "Python Version"
msgstr "Version Python"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:11
#: ../../source/how-to-install-flower.rst:8
#, fuzzy
msgid ""
"Flower requires at least `Python 3.8 <https://docs.python.org/3.8/>`_, "
"but `Python 3.10 <https://docs.python.org/3.10/>`_ or above is "
"recommended."
msgstr ""
"Flower nécessite `Python 3.7 <https://docs.python.org/3.7/>`_ ou plus, "
"nous recommandons `Python 3.8 <https://docs.python.org/3.8/>`_."

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:14
msgid "Virutualenv with Pyenv/Virtualenv"
msgstr "Virutualenv avec Pyenv/Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:16
msgid ""
"One of the recommended virtual environment is `pyenv "
"<https://github.com/pyenv/pyenv>`_/`virtualenv <https://github.com/pyenv"
"/pyenv-virtualenv>`_. Please see `Flower examples "
"<https://github.com/adap/flower/tree/main/examples/>`_ for details."
msgstr ""
"L'un des environnements virtuels recommandés est `pyenv "
"<https://github.com/pyenv/pyenv>`_/`virtualenv <https://github.com/pyenv"
"/pyenv-virtualenv>`_. Voir `Flower examples "
"<https://github.com/adap/flower/tree/main/examples/>`_ pour plus de "
"détails."

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:18
#, fuzzy
msgid ""
"Once Pyenv is set up, you can use it to install `Python Version 3.10 "
"<https://docs.python.org/3.10/>`_ or above:"
msgstr ""
"Une fois Pyenv mis en place, tu peux l'utiliser pour installer `Python "
"Version 3.7 <https://docs.python.org/3.7/>`_ ou supérieure :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:24
msgid "Create the virtualenv with:"
msgstr "Crée le virtualenv avec :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:31
msgid "Activate the virtualenv by running the following command:"
msgstr "Active la virtualenv en exécutant la commande suivante :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:39
msgid "Virtualenv with Poetry"
msgstr "Virtualenv et la poésie"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:41
msgid ""
"The Flower examples are based on `Poetry <https://python-"
"poetry.org/docs/>`_ to manage dependencies. After installing Poetry you "
"simply create a virtual environment with:"
msgstr ""
"Les exemples de Flower sont basés sur `Poetry <https://python-"
"poetry.org/docs/>`_ pour gérer les dépendances. Après l'installation de "
"Poetry, il te suffit de créer un environnement virtuel avec :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:47
msgid ""
"If you open a new terminal you can activate the previously created "
"virtual environment with the following command:"
msgstr ""
"Si tu ouvres un nouveau terminal, tu peux activer l'environnement virtuel"
" précédemment créé avec la commande suivante :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:55
msgid "Virtualenv with Anaconda"
msgstr "Virtualenv avec Anaconda"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:57
msgid ""
"If you prefer to use Anaconda for your virtual environment then install "
"and setup the `conda <https://docs.conda.io/projects/conda/en/latest"
"/user-guide/install/index.html>`_  package. After setting it up you can "
"create a virtual environment with:"
msgstr ""
"Si tu préfères utiliser Anaconda pour ton environnement virtuel, installe"
" et configure le paquet `conda "
"<https://docs.conda.io/projects/conda/en/latest/user-"
"guide/install/index.html>`_. Après l'avoir configuré, tu peux créer un "
"environnement virtuel avec :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:63
msgid "and activate the virtual environment with:"
msgstr "et active l'environnement virtuel avec :"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:71
msgid "And then?"
msgstr "Et ensuite ?"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:73
msgid ""
"As soon as you created your virtual environment you clone one of the "
"`Flower examples <https://github.com/adap/flower/tree/main/examples/>`_."
msgstr ""
"Dès que tu as créé ton environnement virtuel, tu clones l'un des exemples"
" de `Flower <https://github.com/adap/flower/tree/main/examples/>`_."

#: ../../source/contributor-how-to-write-documentation.rst:2
msgid "Write documentation"
msgstr "Rédiger de la documentation"

#: ../../source/contributor-how-to-write-documentation.rst:6
msgid "Project layout"
msgstr "Schéma du projet"

#: ../../source/contributor-how-to-write-documentation.rst:8
msgid ""
"The Flower documentation lives in the ``doc`` directory. The Sphinx-based"
" documentation system supports both reStructuredText (``.rst`` files) and"
" Markdown (``.md`` files)."
msgstr ""
"La documentation de Flower se trouve dans le répertoire `doc``. Le "
"système de documentation basé sur Sphinx supporte à la fois "
"reStructuredText (fichiers `.rst`) et Markdown (fichiers `.md`)."

#: ../../source/contributor-how-to-write-documentation.rst:10
#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:119
msgid ""
"Note that, in order to build the documentation locally (with ``poetry run"
" make html``, like described below), `Pandoc "
"<https://pandoc.org/installing.html>_` needs to be installed on the "
"system."
msgstr ""
"Noter que, pour compiler la documentation localement (avec ``poetry run "
"make html``, comme décrit plus bas), `Pandoc "
"<https://pandoc.org/installing.html>_` doit être installé sur le système."

#: ../../source/contributor-how-to-write-documentation.rst:14
msgid "Edit an existing page"
msgstr "Modifier une page existante"

#: ../../source/contributor-how-to-write-documentation.rst:16
msgid "Edit an existing ``.rst`` (or ``.md``) file under ``doc/source/``"
msgstr "Modifier un fichier ``.rst`` (ou ``.md``) existant sous ``doc/source/``"

#: ../../source/contributor-how-to-write-documentation.rst:17
#: ../../source/contributor-how-to-write-documentation.rst:27
msgid "Compile the docs: ``cd doc``, then ``poetry run make html``"
msgstr "Compilez les documents : ``cd doc``, puis ``poetry run make html``"

#: ../../source/contributor-how-to-write-documentation.rst:18
#: ../../source/contributor-how-to-write-documentation.rst:28
msgid "Open ``doc/build/html/index.html`` in the browser to check the result"
msgstr ""
"Ouvre ``doc/build/html/index.html`` dans le navigateur pour vérifier le "
"résultat"

#: ../../source/contributor-how-to-write-documentation.rst:22
msgid "Create a new page"
msgstr "Créer une nouvelle page"

#: ../../source/contributor-how-to-write-documentation.rst:24
msgid "Add new ``.rst`` file under ``doc/source/``"
msgstr "Ajouter un nouveau fichier ``.rst`` sous ``doc/source/``"

#: ../../source/contributor-how-to-write-documentation.rst:25
msgid "Add content to the new ``.rst`` file"
msgstr "Ajoute du contenu au nouveau fichier ``.rst``"

#: ../../source/contributor-how-to-write-documentation.rst:26
msgid "Link to the new rst from ``index.rst``"
msgstr "Lien vers le nouveau rst depuis ``index.rst``"

#: ../../source/contributor-ref-good-first-contributions.rst:2
msgid "Good first contributions"
msgstr "Bonnes premières contributions"

#: ../../source/contributor-ref-good-first-contributions.rst:4
msgid ""
"We welcome contributions to Flower! However, it is not always easy to "
"know where to start. We therefore put together a few recommendations on "
"where to start to increase your chances of getting your PR accepted into "
"the Flower codebase."
msgstr ""
"Les contributions à Flower sont les bienvenues ! Cependant, il n'est pas "
"toujours facile de savoir par où commencer. Nous avons donc rassemblé "
"quelques recommandations sur les points de départ pour augmenter tes "
"chances de voir ton PR accepté dans la base de code de Flower."

#: ../../source/contributor-ref-good-first-contributions.rst:11
msgid "Where to start"
msgstr "Par où commencer"

#: ../../source/contributor-ref-good-first-contributions.rst:13
msgid ""
"Until the Flower core library matures it will be easier to get PR's "
"accepted if they only touch non-core areas of the codebase. Good "
"candidates to get started are:"
msgstr ""
"Jusqu'à ce que la bibliothèque centrale de Flower arrive à maturité, il "
"sera plus facile de faire accepter les RP s'ils ne touchent que des zones"
" non essentielles de la base de code. Les bons candidats pour commencer "
"sont :"

#: ../../source/contributor-ref-good-first-contributions.rst:17
msgid "Documentation: What's missing? What could be expressed more clearly?"
msgstr ""
"Documentation : Qu'est-ce qui manque ? Qu'est-ce qui pourrait être "
"exprimé plus clairement ?"

#: ../../source/contributor-ref-good-first-contributions.rst:18
msgid "Baselines: See below."
msgstr "Références : voir ci-dessous."

#: ../../source/contributor-ref-good-first-contributions.rst:19
msgid "Examples: See below."
msgstr "Exemples : voir ci-dessous."

#: ../../source/contributor-ref-good-first-contributions.rst:23
msgid "Request for Flower Baselines"
msgstr "Demande pour une nouvelle Flower Baseline"

#: ../../source/contributor-ref-good-first-contributions.rst:25
msgid ""
"If you are not familiar with Flower Baselines, you should probably check-"
"out our `contributing guide for baselines <https://flower.dev/docs"
"/contributing-baselines.html>`_."
msgstr ""
"Si tu n'es pas familier avec les Flower Baselines, tu devrais "
"probablement consulter notre `guide de contribution pour les baselines "
"<https://flower.dev/docs/contributing-baselines.html>`_."

#: ../../source/contributor-ref-good-first-contributions.rst:27
msgid ""
"You should then check out the open `issues "
"<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
" for baseline requests. If you find a baseline that you'd like to work on"
" and that has no assignes, feel free to assign it to yourself and start "
"working on it!"
msgstr ""
"Tu devrais ensuite consulter les `issues ouvertes "
"<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
" pour les demandes de lignes de base. Si tu trouves une ligne de base sur"
" laquelle tu aimerais travailler et qui n'a pas d'assignés, n'hésite pas "
"à te l'attribuer et à commencer à travailler dessus !"

#: ../../source/contributor-ref-good-first-contributions.rst:31
msgid ""
"Otherwise, if you don't find a baseline you'd like to work on, be sure to"
" open a new issue with the baseline request template!"
msgstr ""
"Sinon, si tu ne trouves pas de ligne de base sur laquelle tu aimerais "
"travailler, n'oublie pas d'ouvrir un nouveau problème à l'aide du modèle "
"de demande de ligne de base !"

#: ../../source/contributor-ref-good-first-contributions.rst:34
msgid "Request for examples"
msgstr "Demande pour un nouveau Flower Example"

#: ../../source/contributor-ref-good-first-contributions.rst:36
msgid ""
"We wish we had more time to write usage examples because we believe they "
"help users to get started with building what they want to build. Here are"
" a few ideas where we'd be happy to accept a PR:"
msgstr ""
"Nous aimerions avoir plus de temps pour écrire des exemples d'utilisation"
" car nous pensons qu'ils aident les utilisateurs à commencer à construire"
" ce qu'ils veulent construire. Voici quelques idées pour lesquelles nous "
"serions heureux d'accepter un RP :"

#: ../../source/contributor-ref-good-first-contributions.rst:40
msgid "Llama 2 fine-tuning, with Hugging Face Transformers and PyTorch"
msgstr "LLaMA 2 fine-tuning avec Hugging Face et PyTorch"

#: ../../source/contributor-ref-good-first-contributions.rst:41
msgid "XGBoost"
msgstr "XGBoost"

#: ../../source/contributor-ref-good-first-contributions.rst:42
msgid "Android ONNX on-device training"
msgstr "Training sur téléphone à l'aide d'Android ONNX"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:2
msgid "Secure Aggregation Protocols"
msgstr "Protocoles d'agrégation sécurisés"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:4
msgid ""
"Include SecAgg, SecAgg+, and LightSecAgg protocol. The LightSecAgg "
"protocol has not been implemented yet, so its diagram and abstraction may"
" not be accurate in practice. The SecAgg protocol can be considered as a "
"special case of the SecAgg+ protocol."
msgstr ""
"Inclut les protocoles SecAgg, SecAgg+ et LightSecAgg. Le protocole "
"LightSecAgg n'a pas encore été mis en œuvre, de sorte que son diagramme "
"et son abstraction peuvent ne pas être exacts dans la pratique. Le "
"protocole SecAgg peut être considéré comme un cas particulier du "
"protocole SecAgg+."

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:8
msgid "The :code:`SecAgg+` abstraction"
msgstr "L'abstraction :code:`SecAgg+`"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:10
#: ../../source/contributor-ref-secure-aggregation-protocols.rst:161
msgid ""
"In this implementation, each client will be assigned with a unique index "
"(int) for secure aggregation, and thus many python dictionaries used have"
" keys of int type rather than ClientProxy type."
msgstr ""
"Dans cette implémentation, chaque client se verra attribuer un index "
"unique (int) pour une agrégation sécurisée, et donc de nombreux "
"dictionnaires python utilisés ont des clés de type int plutôt que de type"
" ClientProxy."

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:65
#: ../../source/contributor-ref-secure-aggregation-protocols.rst:198
msgid ""
"The Flower server will execute and process received results in the "
"following order:"
msgstr ""
"Le serveur Flower exécutera et traitera les résultats reçus dans l'ordre "
"suivant :"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:159
msgid "The :code:`LightSecAgg` abstraction"
msgstr "L'abstraction :code:`LightSecAgg`"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:271
msgid "Types"
msgstr "Types"

#: ../../source/contributor-tutorial-contribute-on-github.rst:2
msgid "Contribute on GitHub"
msgstr "Contribuer sur GitHub"

#: ../../source/contributor-tutorial-contribute-on-github.rst:4
msgid ""
"This guide is for people who want to get involved with Flower, but who "
"are not used to contributing to GitHub projects."
msgstr ""
"Ce guide s'adresse aux personnes qui veulent participer au développement "
"de Flower mais qui n'ont pas l'habitude de contribuer à des projets "
"GitHub."

#: ../../source/contributor-tutorial-contribute-on-github.rst:6
msgid ""
"If you're familiar with how contributing on GitHub works, you can "
"directly checkout our `getting started guide for contributors "
"<https://flower.dev/docs/getting-started-for-contributors.html>`_ and "
"examples of `good first contributions <https://flower.dev/docs/good-"
"first-contributions.html>`_."
msgstr ""
"Si tu es familier avec le fonctionnement des contributions sur GitHub, tu"
" peux directement consulter notre `guide de démarrage pour les "
"contributeurs <https://flower.dev/docs/getting-started-for-"
"contributors.html>`_ et des exemples de `bonnes premières contributions "
"<https://flower.dev/docs/good-first-contributions.html>`_."

#: ../../source/contributor-tutorial-contribute-on-github.rst:12
msgid "Setting up the repository"
msgstr "Mise en place du référentiel"

#: ../../source/contributor-tutorial-contribute-on-github.rst:23
msgid "**Create a GitHub account and setup Git**"
msgstr "**Créer un compte GitHub et configurer Git**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:15
msgid ""
"Git is a distributed version control tool. This allows for an entire "
"codebase's history to be stored and every developer's machine. It is a "
"software that will need to be installed on your local machine, you can "
"follow this `guide <https://docs.github.com/en/get-started/quickstart"
"/set-up-git>`_ to set it up."
msgstr ""
"Git est un outil de contrôle de version distribué. Il permet de stocker "
"l'historique d'une base de code entière sur la machine de chaque "
"développeur. C'est un logiciel qui devra être installé sur ta machine "
"locale, tu peux suivre ce `guide <https://docs.github.com/en/get-"
"started/quickstart/set-up-git>`_ pour le mettre en place."

#: ../../source/contributor-tutorial-contribute-on-github.rst:18
msgid ""
"GitHub, itself, is a code hosting platform for version control and "
"collaboration. It allows for everyone to collaborate and work from "
"anywhere on remote repositories."
msgstr ""
"GitHub, lui-même, est une plateforme d'hébergement de code pour le "
"contrôle des versions et la collaboration. Il permet à chacun de "
"collaborer et de travailler de n'importe où sur des dépôts à distance."

#: ../../source/contributor-tutorial-contribute-on-github.rst:20
msgid ""
"If you haven't already, you will need to create an account on `GitHub "
"<https://github.com/signup>`_."
msgstr ""
"Si ce n'est pas déjà fait, tu devras créer un compte sur `GitHub "
"<https://github.com/signup>`_."

#: ../../source/contributor-tutorial-contribute-on-github.rst:22
msgid ""
"The idea behind the generic Git and GitHub workflow boils down to this: "
"you download code from a remote repository on GitHub, make changes "
"locally and keep track of them using Git and then you upload your new "
"history back to GitHub."
msgstr ""
"L'idée derrière le flux de travail générique de Git et GitHub se résume à"
" ceci : tu télécharges le code d'un dépôt distant sur GitHub, tu apportes"
" des modifications localement et tu en gardes une trace à l'aide de Git, "
"puis tu télécharges ton nouvel historique à nouveau sur GitHub."

#: ../../source/contributor-tutorial-contribute-on-github.rst:34
msgid "**Forking the Flower repository**"
msgstr "**Fourche le dépôt de Flower**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:26
msgid ""
"A fork is a personal copy of a GitHub repository. To create one for "
"Flower, you must navigate to https://github.com/adap/flower (while "
"connected to your GitHub account) and click the ``Fork`` button situated "
"on the top right of the page."
msgstr ""
"Un fork est une copie personnelle d'un dépôt GitHub. Pour en créer un "
"pour Flower, tu dois naviguer sur https://github.com/adap/flower (en "
"étant connecté à ton compte GitHub) et cliquer sur le bouton ``Fork`` "
"situé en haut à droite de la page."

#: ../../source/contributor-tutorial-contribute-on-github.rst:31
msgid ""
"You can change the name if you want, but this is not necessary as this "
"version of Flower will be yours and will sit inside your own account "
"(i.e., in your own list of repositories). Once created, you should see on"
" the top left corner that you are looking at your own version of Flower."
msgstr ""
"Tu peux changer le nom si tu le souhaites, mais ce n'est pas nécessaire "
"car cette version de Flower sera la tienne et se trouvera dans ton propre"
" compte (c'est-à-dire dans ta propre liste de dépôts). Une fois créée, tu"
" devrais voir dans le coin supérieur gauche que tu es en train de "
"regarder ta propre version de Flower."

#: ../../source/contributor-tutorial-contribute-on-github.rst:49
msgid "**Cloning your forked repository**"
msgstr "**Clonage de ton dépôt forké**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:37
msgid ""
"The next step is to download the forked repository on your machine to be "
"able to make changes to it. On your forked repository page, you should "
"first click on the ``Code`` button on the right, this will give you the "
"ability to copy the HTTPS link of the repository."
msgstr ""
"L'étape suivante consiste à télécharger le dépôt forké sur ta machine "
"pour pouvoir y apporter des modifications. Sur la page de ton dépôt "
"forké, tu dois d'abord cliquer sur le bouton ``Code`` à droite, ce qui te"
" permettra de copier le lien HTTPS du dépôt."

#: ../../source/contributor-tutorial-contribute-on-github.rst:43
msgid ""
"Once you copied the \\<URL\\>, you can open a terminal on your machine, "
"navigate to the place you want to download the repository to and type:"
msgstr ""
"Une fois que tu as copié le \\<URL\\>, tu peux ouvrir un terminal sur ta "
"machine, naviguer jusqu'à l'endroit où tu veux télécharger le référentiel"
" et taper :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:49
msgid ""
"This will create a `flower/` (or the name of your fork if you renamed it)"
" folder in the current working directory."
msgstr ""
"Cela créera un dossier `flower/` (ou le nom de ta fourche si tu l'as "
"renommée) dans le répertoire de travail actuel."

#: ../../source/contributor-tutorial-contribute-on-github.rst:68
msgid "**Add origin**"
msgstr "**Ajouter l'origine**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:52
msgid "You can then go into the repository folder:"
msgstr "Tu peux ensuite aller dans le dossier du référentiel :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:58
msgid ""
"And here we will need to add an origin to our repository. The origin is "
"the \\<URL\\> of the remote fork repository. To obtain it, we can do as "
"previously mentioned by going to our fork repository on our GitHub "
"account and copying the link."
msgstr ""
"Et ici, nous devrons ajouter une origine à notre dépôt.L'origine est le "
"\\<URL\\> du dépôt fork distant.Pour l'obtenir, nous pouvons faire comme "
"indiqué précédemment en allant sur notre dépôt fork sur notre compte "
"GitHub et en copiant le lien."

#: ../../source/contributor-tutorial-contribute-on-github.rst:63
msgid ""
"Once the \\<URL\\> is copied, we can type the following command in our "
"terminal:"
msgstr ""
"Une fois que le \\<URL\\> est copié, nous pouvons taper la commande "
"suivante dans notre terminal :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:92
msgid "**Add upstream**"
msgstr "**Ajouter en amont**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:71
msgid ""
"Now we will add an upstream address to our repository. Still in the same "
"directroy, we must run the following command:"
msgstr ""
"Nous allons maintenant ajouter une adresse en amont à notre dépôt. "
"Toujours dans le même directroy, nous devons exécuter la commande "
"suivante :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:78
msgid "The following diagram visually explains what we did in the previous steps:"
msgstr ""
"Le schéma suivant explique visuellement ce que nous avons fait dans les "
"étapes précédentes :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:82
msgid ""
"The upstream is the GitHub remote address of the parent repository (in "
"this case Flower), i.e. the one we eventually want to contribute to and "
"therefore need an up-to-date history of. The origin is just the GitHub "
"remote address of the forked repository we created, i.e. the copy (fork) "
"in our own account."
msgstr ""
"L'amont est l'adresse distante GitHub du dépôt parent (dans ce cas "
"Flower), c'est-à-dire celui auquel nous voulons éventuellement contribuer"
" et dont nous avons donc besoin d'un historique à jour. L'origine est "
"simplement l'adresse distante GitHub du dépôt forké que nous avons créé, "
"c'est-à-dire la copie (fork) dans notre propre compte."

#: ../../source/contributor-tutorial-contribute-on-github.rst:86
msgid ""
"To make sure our local version of the fork is up-to-date with the latest "
"changes from the Flower repository, we can execute the following command:"
msgstr ""
"Pour nous assurer que notre version locale du fork est à jour avec les "
"dernières modifications du dépôt Flower, nous pouvons exécuter la "
"commande suivante :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:95
msgid "Setting up the coding environment"
msgstr "Mise en place de l'environnement de codage"

#: ../../source/contributor-tutorial-contribute-on-github.rst:97
msgid ""
"This can be achieved by following this `getting started guide for "
"contributors`_ (note that you won't need to clone the repository). Once "
"you are able to write code and test it, you can finally start making "
"changes!"
msgstr ""
"Pour ce faire, tu peux suivre ce `guide de démarrage pour les "
"contributeurs`_ (note que tu n'auras pas besoin de cloner le dépôt). Une "
"fois que tu es capable d'écrire du code et de le tester, tu peux enfin "
"commencer à faire des changements !"

#: ../../source/contributor-tutorial-contribute-on-github.rst:102
msgid "Making changes"
msgstr "Apporter des changements"

#: ../../source/contributor-tutorial-contribute-on-github.rst:104
msgid ""
"Before making any changes make sure you are up-to-date with your "
"repository:"
msgstr ""
"Avant de faire des changements, assure-toi que tu es à jour avec ton "
"référentiel :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:110
msgid "And with Flower's repository:"
msgstr "Et avec le référentiel de Flower :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:124
msgid "**Create a new branch**"
msgstr "**Créer une nouvelle branche**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:117
msgid ""
"To make the history cleaner and easier to work with, it is good practice "
"to create a new branch for each feature/project that needs to be "
"implemented."
msgstr ""
"Pour rendre l'historique plus propre et plus facile à travailler, c'est "
"une bonne pratique de créer une nouvelle branche pour chaque "
"fonctionnalité/projet qui doit être mis en œuvre."

#: ../../source/contributor-tutorial-contribute-on-github.rst:120
msgid ""
"To do so, just run the following command inside the repository's "
"directory:"
msgstr ""
"Pour ce faire, il suffit d'exécuter la commande suivante dans le "
"répertoire du référentiel :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:127
msgid "**Make changes**"
msgstr "**Apporter des modifications**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:127
msgid "Write great code and create wonderful changes using your favorite editor!"
msgstr ""
"Écris du bon code et crée de merveilleuses modifications à l'aide de ton "
"éditeur préféré !"

#: ../../source/contributor-tutorial-contribute-on-github.rst:140
msgid "**Test and format your code**"
msgstr "**Teste et mets en forme ton code**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:130
msgid ""
"Don't forget to test and format your code! Otherwise your code won't be "
"able to be merged into the Flower repository. This is done so the "
"codebase stays consistent and easy to understand."
msgstr ""
"N'oublie pas de tester et de formater ton code ! Sinon, ton code ne "
"pourra pas être fusionné dans le dépôt Flower, et ce, afin que la base de"
" code reste cohérente et facile à comprendre."

#: ../../source/contributor-tutorial-contribute-on-github.rst:133
msgid "To do so, we have written a few scripts that you can execute:"
msgstr "Pour ce faire, nous avons écrit quelques scripts que tu peux exécuter :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:152
msgid "**Stage changes**"
msgstr "**Changements de scène**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:143
msgid ""
"Before creating a commit that will update your history, you must specify "
"to Git which files it needs to take into account."
msgstr ""
"Avant de créer un commit qui mettra à jour ton historique, tu dois "
"spécifier à Git les fichiers qu'il doit prendre en compte."

#: ../../source/contributor-tutorial-contribute-on-github.rst:145
msgid "This can be done with:"
msgstr "Cela peut se faire avec :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:151
msgid ""
"To check which files have been modified compared to the last version "
"(last commit) and to see which files are staged for commit, you can use "
"the :code:`git status` command."
msgstr ""
"Pour vérifier quels fichiers ont été modifiés par rapport à la dernière "
"version (last commit) et pour voir quels fichiers sont mis à disposition "
"pour le commit, tu peux utiliser la commande :code:`git status`."

#: ../../source/contributor-tutorial-contribute-on-github.rst:162
msgid "**Commit changes**"
msgstr "**Commit changes**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:155
msgid ""
"Once you have added all the files you wanted to commit using :code:`git "
"add`, you can finally create your commit using this command:"
msgstr ""
"Une fois que tu as ajouté tous les fichiers que tu voulais livrer à "
"l'aide de :code:`git add`, tu peux enfin créer ta livraison à l'aide de "
"cette commande :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:161
msgid ""
"The \\<commit_message\\> is there to explain to others what the commit "
"does. It should be written in an imperative style and be concise. An "
"example would be :code:`git commit -m \"Add images to README\"`."
msgstr ""
"Le ``commit_message`` est là pour expliquer aux autres ce que fait le "
"commit. Il doit être écrit dans un style impératif et être concis. Un "
"exemple serait :code:`git commit -m \"Ajouter des images au README\"`."

#: ../../source/contributor-tutorial-contribute-on-github.rst:173
msgid "**Push the changes to the fork**"
msgstr "**Pousser les changements vers la fourche**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:165
msgid ""
"Once we have committed our changes, we have effectively updated our local"
" history, but GitHub has no way of knowing this unless we push our "
"changes to our origin's remote address:"
msgstr ""
"Une fois que nous avons validé nos modifications, nous avons "
"effectivement mis à jour notre historique local, mais GitHub n'a aucun "
"moyen de le savoir à moins que nous ne poussions nos modifications vers "
"l'adresse distante de notre origine :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:172
msgid ""
"Once this is done, you will see on the GitHub that your forked repo was "
"updated with the changes you have made."
msgstr ""
"Une fois que c'est fait, tu verras sur GitHub que ton repo forké a été "
"mis à jour avec les modifications que tu as apportées."

#: ../../source/contributor-tutorial-contribute-on-github.rst:176
msgid "Creating and merging a pull request (PR)"
msgstr "Créer et fusionner une pull request (PR)"

#: ../../source/contributor-tutorial-contribute-on-github.rst:203
msgid "**Create the PR**"
msgstr "**Créer le PR**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:179
msgid ""
"Once you have pushed changes, on the GitHub webpage of your repository "
"you should see the following message:"
msgstr ""
"Une fois que tu as poussé les modifications, sur la page web GitHub de "
"ton dépôt, tu devrais voir le message suivant :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:183
msgid "Otherwise you can always find this option in the `Branches` page."
msgstr "Sinon, tu peux toujours trouver cette option dans la page `Branches`."

#: ../../source/contributor-tutorial-contribute-on-github.rst:185
msgid ""
"Once you click the `Compare & pull request` button, you should see "
"something similar to this:"
msgstr ""
"Une fois que tu as cliqué sur le bouton `Compare & pull request`, tu "
"devrais voir quelque chose de similaire à ceci :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:189
msgid "At the top you have an explanation of which branch will be merged where:"
msgstr ""
"En haut, tu as une explication de quelle branche sera fusionnée à quel "
"endroit :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:193
msgid ""
"In this example you can see that the request is to merge the branch "
"``doc-fixes`` from my forked repository to branch ``main`` from the "
"Flower repository."
msgstr ""
"Dans cet exemple, tu peux voir que la demande consiste à fusionner la "
"branche ``doc-fixes`` de mon dépôt forké à la branche ``main`` du dépôt "
"Flower."

#: ../../source/contributor-tutorial-contribute-on-github.rst:195
msgid ""
"The input box in the middle is there for you to describe what your PR "
"does and to link it to existing issues. We have placed comments (that "
"won't be rendered once the PR is opened) to guide you through the "
"process."
msgstr ""
"La zone de saisie au milieu est là pour que tu décrives ce que fait ton "
"PR et que tu le relies aux questions existantes. Nous avons placé des "
"commentaires (qui ne seront pas rendus une fois le PR ouvert) pour te "
"guider tout au long du processus."

#: ../../source/contributor-tutorial-contribute-on-github.rst:198
msgid ""
"At the bottom you will find the button to open the PR. This will notify "
"reviewers that a new PR has been opened and that they should look over it"
" to merge or to request changes."
msgstr ""
"En bas de l'écran, tu trouveras le bouton permettant d'ouvrir le PR, ce "
"qui informera les réviseurs qu'un nouveau PR a été ouvert et qu'ils "
"doivent le consulter pour le fusionner ou demander des modifications."

#: ../../source/contributor-tutorial-contribute-on-github.rst:201
msgid ""
"If your PR is not yet ready for review, and you don't want to notify "
"anyone, you have the option to create a draft pull request:"
msgstr ""
"Si ton RP n'est pas encore prêt à être examiné, et que tu ne veux avertir"
" personne, tu as la possibilité de créer un brouillon de demande de "
"traction :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:206
msgid "**Making new changes**"
msgstr "**Faire de nouveaux changements**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:206
msgid ""
"Once the PR has been opened (as draft or not), you can still push new "
"commits to it the same way we did before, by making changes to the branch"
" associated with the PR."
msgstr ""
"Une fois que le PR a été ouvert (en tant que brouillon ou non), tu peux "
"toujours y pousser de nouveaux commits de la même manière qu'auparavant, "
"en apportant des modifications à la branche associée au PR."

#: ../../source/contributor-tutorial-contribute-on-github.rst:228
msgid "**Review the PR**"
msgstr "**Review the PR**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:209
msgid ""
"Once the PR has been opened or once the draft PR has been marked as "
"ready, a review from code owners will be automatically requested:"
msgstr ""
"Une fois que le PR a été ouvert ou que le projet de PR a été marqué comme"
" étant prêt, une révision des propriétaires de code sera automatiquement "
"demandée :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:213
msgid ""
"Code owners will then look into the code, ask questions, request changes "
"or validate the PR."
msgstr ""
"Les propriétaires du code vont alors se pencher sur le code, poser des "
"questions, demander des modifications ou valider le RP."

#: ../../source/contributor-tutorial-contribute-on-github.rst:215
msgid "Merging will be blocked if there are ongoing requested changes."
msgstr "La fusion sera bloquée s'il y a des changements demandés en cours."

#: ../../source/contributor-tutorial-contribute-on-github.rst:219
msgid ""
"To resolve them, just push the necessary changes to the branch associated"
" with the PR:"
msgstr ""
"Pour les résoudre, il suffit de pousser les changements nécessaires vers "
"la branche associée au PR :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:223
msgid "And resolve the conversation:"
msgstr "Et résous la conversation :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:227
msgid ""
"Once all the conversations have been resolved, you can re-request a "
"review."
msgstr ""
"Une fois que toutes les conversations ont été résolues, tu peux "
"redemander un examen."

#: ../../source/contributor-tutorial-contribute-on-github.rst:248
msgid "**Once the PR is merged**"
msgstr "**Une fois que le PR est fusionné**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:231
msgid ""
"If all the automatic tests have passed and reviewers have no more changes"
" to request, they can approve the PR and merge it."
msgstr ""
"Si tous les tests automatiques ont réussi et que les réviseurs n'ont plus"
" de modifications à demander, ils peuvent approuver le PR et le "
"fusionner."

#: ../../source/contributor-tutorial-contribute-on-github.rst:235
msgid ""
"Once it is merged, you can delete the branch on GitHub (a button should "
"appear to do so) and also delete it locally by doing:"
msgstr ""
"Une fois qu'elle est fusionnée, tu peux supprimer la branche sur GitHub "
"(un bouton devrait apparaître pour le faire) et aussi la supprimer "
"localement en faisant :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:242
msgid "Then you should update your forked repository by doing:"
msgstr "Ensuite, tu dois mettre à jour ton dépôt forké en faisant :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:251
msgid "Example of first contribution"
msgstr "Exemple de première contribution"

#: ../../source/contributor-tutorial-contribute-on-github.rst:254
msgid "Problem"
msgstr "Problème"

#: ../../source/contributor-tutorial-contribute-on-github.rst:256
msgid ""
"For our documentation, we’ve started to use the `Diàtaxis framework "
"<https://diataxis.fr/>`_."
msgstr ""
"Pour notre documentation, nous avons commencé à utiliser le cadre "
"`Diàtaxis <https://diataxis.fr/>`_."

#: ../../source/contributor-tutorial-contribute-on-github.rst:258
msgid ""
"Our “How to” guides should have titles that continue the sencence “How to"
" …”, for example, “How to upgrade to Flower 1.0”."
msgstr ""
"Nos guides \"Comment faire\" devraient avoir des titres qui poursuivent "
"la phrase \"Comment faire pour...\", par exemple, \"Comment passer à "
"Flower 1.0\"."

#: ../../source/contributor-tutorial-contribute-on-github.rst:260
msgid ""
"Most of our guides do not follow this new format yet, and changing their "
"title is (unfortunately) more involved than one might think."
msgstr ""
"La plupart de nos guides ne suivent pas encore ce nouveau format, et "
"changer leur titre est (malheureusement) plus compliqué qu'on ne le "
"pense."

#: ../../source/contributor-tutorial-contribute-on-github.rst:262
msgid ""
"This issue is about changing the title of a doc from present continious "
"to present simple."
msgstr ""
"Cette question porte sur le changement du titre d'un document du présent "
"continu au présent simple."

#: ../../source/contributor-tutorial-contribute-on-github.rst:264
msgid ""
"Let's take the example of “Saving Progress” which we changed to “Save "
"Progress”. Does this pass our check?"
msgstr ""
"Prenons l'exemple de \"Sauvegarder la progression\" que nous avons "
"remplacé par \"Sauvegarder la progression\". Est-ce que cela passe notre "
"contrôle ?"

#: ../../source/contributor-tutorial-contribute-on-github.rst:266
msgid "Before: ”How to saving progress” ❌"
msgstr "Avant : \"Comment sauvegarder les progrès\" ❌"

#: ../../source/contributor-tutorial-contribute-on-github.rst:268
msgid "After: ”How to save progress” ✅"
msgstr "Après : \"Comment sauvegarder la progression\" ✅"

#: ../../source/contributor-tutorial-contribute-on-github.rst:271
msgid "Solution"
msgstr "Solution"

#: ../../source/contributor-tutorial-contribute-on-github.rst:273
msgid ""
"This is a tiny change, but it’ll allow us to test your end-to-end setup. "
"After cloning and setting up the Flower repo, here’s what you should do:"
msgstr ""
"C'est un tout petit changement, mais il nous permettra de tester ta "
"configuration de bout en bout. Après avoir cloné et configuré le repo "
"Flower, voici ce que tu dois faire :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:275
msgid "Find the source file in `doc/source`"
msgstr "Trouve le fichier source dans `doc/source`"

#: ../../source/contributor-tutorial-contribute-on-github.rst:276
msgid ""
"Make the change in the `.rst` file (beware, the dashes under the title "
"should be the same length as the title itself)"
msgstr ""
"Effectue la modification dans le fichier `.rst` (attention, les tirets "
"sous le titre doivent être de la même longueur que le titre lui-même)"

#: ../../source/contributor-tutorial-contribute-on-github.rst:277
msgid ""
"Build the docs and check the result: `<https://flower.dev/docs/writing-"
"documentation.html#edit-an-existing-page>`_"
msgstr ""
"Construis les documents et vérifie le résultat : "
"`<https://flower.dev/docs/writing-documentation.html#edit-an-existing-"
"page>`_"

#: ../../source/contributor-tutorial-contribute-on-github.rst:280
msgid "Rename file"
msgstr "Renommer le fichier"

#: ../../source/contributor-tutorial-contribute-on-github.rst:282
msgid ""
"You might have noticed that the file name still reflects the old wording."
" If we just change the file, then we break all existing links to it - it "
"is **very important** to avoid that, breaking links can harm our search "
"engine ranking."
msgstr ""
"Tu as peut-être remarqué que le nom du fichier reflète toujours "
"l'ancienne formulation. Si nous changeons simplement le fichier, nous "
"brisons tous les liens existants vers celui-ci - il est **très "
"important** d'éviter cela, car briser des liens peut nuire à notre "
"classement dans les moteurs de recherche."

#: ../../source/contributor-tutorial-contribute-on-github.rst:285
msgid "Here’s how to change the file name:"
msgstr "Voici comment changer le nom du fichier :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:287
msgid "Change the file name to `save-progress.rst`"
msgstr "Change le nom du fichier en `save-progress.rst`"

#: ../../source/contributor-tutorial-contribute-on-github.rst:288
msgid "Add a redirect rule to `doc/source/conf.py`"
msgstr "Ajouter une règle de redirection à `doc/source/conf.py`"

#: ../../source/contributor-tutorial-contribute-on-github.rst:290
msgid ""
"This will cause a redirect from `saving-progress.html` to `save-"
"progress.html`, old links will continue to work."
msgstr ""
"Cela entraînera une redirection de `saving-progress.html` vers `save-"
"progress.html`, les anciens liens continueront à fonctionner."

#: ../../source/contributor-tutorial-contribute-on-github.rst:293
msgid "Apply changes in the index file"
msgstr "Applique les changements dans le fichier d'index"

#: ../../source/contributor-tutorial-contribute-on-github.rst:295
msgid ""
"For the lateral navigation bar to work properly, it is very important to "
"update the `index.rst` file as well. This is where we define the whole "
"arborescence of the navbar."
msgstr ""
"Pour que la barre de navigation latérale fonctionne correctement, il est "
"très important de mettre également à jour le fichier `index.rst`. C'est "
"là que nous définissons toute l'arborescence de la barre de navigation."

#: ../../source/contributor-tutorial-contribute-on-github.rst:298
msgid "Find and modify the file name in `index.rst`"
msgstr "Trouve et modifie le nom du fichier dans `index.rst`"

#: ../../source/contributor-tutorial-contribute-on-github.rst:301
msgid "Open PR"
msgstr "Open PR"

#: ../../source/contributor-tutorial-contribute-on-github.rst:303
msgid ""
"Commit the changes (commit messages are always imperative: “Do "
"something”, in this case “Change …”)"
msgstr ""
"Valide les modifications (les messages de validation sont toujours "
"impératifs : \"Fais quelque chose\", dans ce cas \"Modifie...\")"

#: ../../source/contributor-tutorial-contribute-on-github.rst:304
msgid "Push the changes to your fork"
msgstr "Transmets les changements à ta fourchette"

#: ../../source/contributor-tutorial-contribute-on-github.rst:305
msgid "Open a PR (as shown above)"
msgstr "Ouvre un RP (comme indiqué ci-dessus)"

#: ../../source/contributor-tutorial-contribute-on-github.rst:306
msgid "Wait for it to be approved!"
msgstr "Attends qu'elle soit approuvée !"

#: ../../source/contributor-tutorial-contribute-on-github.rst:307
msgid "Congrats! 🥳 You're now officially a Flower contributor!"
msgstr ""
"Félicitations 🥳 Tu es désormais officiellement une contributrice de "
"Flower !"

#: ../../source/contributor-tutorial-contribute-on-github.rst:311
msgid "How to write a good PR title"
msgstr "Comment écrire un bon titre de PR"

#: ../../source/contributor-tutorial-contribute-on-github.rst:313
msgid ""
"A well-crafted PR title helps team members quickly understand the purpose"
" and scope of the changes being proposed. Here's a guide to help you "
"write a good GitHub PR title:"
msgstr ""
"Un titre de PR bien choisi permet aux autres développeurs de rapidement "
"comprendre l'intérêt et le scope des changements proposés. Voici un guide"
" pour vous aider à écrire des bons titres de PR :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:315
msgid ""
"1. Be Clear and Concise: Provide a clear summary of the changes in a "
"concise manner. 1. Use Actionable Verbs: Start with verbs like \"Add,\" "
"\"Update,\" or \"Fix\" to indicate the purpose. 1. Include Relevant "
"Information: Mention the affected feature or module for context. 1. Keep "
"it Short: Avoid lengthy titles for easy readability. 1. Use Proper "
"Capitalization and Punctuation: Follow grammar rules for clarity."
msgstr ""
"1. Soyez clair et concis : Donnez un résumé clair des changements de "
"manière concise. 1. Utilisez des verbes actionnables : Commencez par des "
"verbes comme \"Add\", \"Update\", ou \"Fix\" pour indiquer le but. 1. "
"Inclure des renseignements pertinents : Mentionner la caractéristique ou "
"le module concerné pour le contexte. 1. Gardez le court : Évitez les "
"longs titres pour une lisibilité facile. 1. Utiliser une bonne "
"capitalisation et une ponctuation : Suivre les règles de grammaire pour "
"la clarté."

#: ../../source/contributor-tutorial-contribute-on-github.rst:321
msgid ""
"Let's start with a few examples for titles that should be avoided because"
" they do not provide meaningful information:"
msgstr ""
"Commençons par quelques exemples de titres qui devraient être évités "
"parce qu'ils ne fournissent pas d'information significative :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:323
msgid "Implement Algorithm"
msgstr "Implement Algorithm"

#: ../../source/contributor-tutorial-contribute-on-github.rst:324
msgid "Database"
msgstr "Database"

#: ../../source/contributor-tutorial-contribute-on-github.rst:325
msgid "Add my_new_file.py to codebase"
msgstr "Add my_new_file.py to codebase"

#: ../../source/contributor-tutorial-contribute-on-github.rst:326
msgid "Improve code in module"
msgstr "Improve code in module"

#: ../../source/contributor-tutorial-contribute-on-github.rst:327
msgid "Change SomeModule"
msgstr "Change SomeModule"

#: ../../source/contributor-tutorial-contribute-on-github.rst:329
msgid ""
"Here are a few positive examples which provide helpful information "
"without repeating how they do it, as that is already visible in the "
"\"Files changed\" section of the PR:"
msgstr ""
"Voici quelques bons exemples qui fournissent de l'information utile sans "
"répéter comment ils le font, comme cela est déjà visible dans la section "
"\"Files changed\" de la PR :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:331
msgid "Update docs banner to mention Flower Summit 2023"
msgstr "Update docs banner to mention Flower Summit 2023"

#: ../../source/contributor-tutorial-contribute-on-github.rst:332
msgid "Remove unnecessary XGBoost dependency"
msgstr "Remove unnecessary XGBoost dependency"

#: ../../source/contributor-tutorial-contribute-on-github.rst:333
msgid "Remove redundant attributes in strategies subclassing FedAvg"
msgstr "Remove redundant attributes in strategies subclassing FedAvg"

#: ../../source/contributor-tutorial-contribute-on-github.rst:334
msgid "Add CI job to deploy the staging system when the `main` branch changes"
msgstr "Add CI job to deploy the staging system when the `main` branch changes"

#: ../../source/contributor-tutorial-contribute-on-github.rst:335
msgid ""
"Add new amazing library which will be used to improve the simulation "
"engine"
msgstr ""
"Add new amazing library which will be used to improve the simulation "
"engine"

#: ../../source/contributor-tutorial-contribute-on-github.rst:339
#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:548
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:946
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:747
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:713
#: ../../source/tutorial-what-is-federated-learning.ipynb:367
msgid "Next steps"
msgstr "Prochaines étapes"

#: ../../source/contributor-tutorial-contribute-on-github.rst:341
msgid ""
"Once you have made your first PR, and want to contribute more, be sure to"
" check out the following :"
msgstr ""
"Une fois que tu auras fait ton premier RP, et que tu voudras contribuer "
"davantage, ne manque pas de consulter les sites suivants :"

#: ../../source/contributor-tutorial-contribute-on-github.rst:343
msgid ""
"`Good first contributions <https://flower.dev/docs/framework/contributor-"
"ref-good-first-contributions.html>`_, where you should particularly look "
"into the :code:`baselines` contributions."
msgstr ""
"`Bonnes premières contributions <https://flower.dev/docs/framework"
"/contributor-ref-good-first-contributions.html>`_, où vous devriez "
"particulièrement regarder les contributions :code:`baselines`."

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:2
msgid "Get started as a contributor"
msgstr "Devenez un·e contributeur·ice"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:5
msgid "Prerequisites"
msgstr "Prérequis"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:7
msgid "`Python 3.7 <https://docs.python.org/3.7/>`_ or above"
msgstr "`Python 3.7 <https://docs.python.org/3.7/>`_ ou plus"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:8
msgid "`Poetry 1.3 <https://python-poetry.org/>`_ or above"
msgstr "`Poetry 1.3 <https://python-poetry.org/>`_ ou plus"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:9
msgid "(Optional) `pyenv <https://github.com/pyenv/pyenv>`_"
msgstr "(Optionnel) `pyenv <https://github.com/pyenv/pyenv>`_"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:10
msgid "(Optional) `pyenv-virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_"
msgstr ""
"(Optionnel) `pyenv-virtualenv <https://github.com/pyenv/pyenv-"
"virtualenv>`_"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:12
msgid ""
"Flower uses :code:`pyproject.toml` to manage dependencies and configure "
"development tools (the ones which support it). Poetry is a build tool "
"which supports `PEP 517 <https://www.python.org/dev/peps/pep-0517/>`_."
msgstr ""
"Flower utilise un fichier :code:`pyproject.toml` pour gérer les "
"dependences et configurer les outils de développement (du moins ceux qui "
"le supportent). Poetry est un outil qui support `PEP 517 "
"<https://www.python.org/dev/peps/pep-0517/>`_."

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:18
msgid "Developer Machine Setup"
msgstr "Setup de la machine"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:20
msgid ""
"First, clone the `Flower repository <https://github.com/adap/flower>`_ "
"from GitHub::"
msgstr ""
"Pour commencer, cloner la `repo Flower <https://github.com/adap/flower>`_"
" depuis GitHub::"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:26
msgid ""
"Second, create a virtual environment (and activate it). If you chose to "
"use :code:`pyenv` (with the :code:`pyenv-virtualenv` plugin) and already "
"have it installed , you can use the following convenience script (by "
"default it will use :code:`Python 3.8.17`, but you can change it by "
"providing a specific :code:`<version>`)::"
msgstr ""
"Deuxièmement, créer un environnement virtuel (et l'activer). Si vous "
"choisissez d'utiliser :code:`pyenv` (avec le plugin :code:`pyenv-"
"virtualenv`) et que vous l'avez déjà installé, vous pouvez utiliser le "
"script suivant (par défaut il utilisera :code:`Python 3.8.17`, mais vous "
"pouvez le changer en fournissant une :code:`<version>` spécifique)::"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:33
msgid ""
"If you don't have :code:`pyenv` installed, you can use the following "
"script that will install pyenv, set it up and create the virtual "
"environment (with :code:`Python 3.8.17` by default)::"
msgstr ""
"Si vous n'avez pas :code:`pyenv` installé, vous pouvez utiliser le script"
" suivant qui l'installera, le configurera et créera l'environnement "
"virtuel (avec :code:`Python 3.8.17` par défaut)::"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:39
msgid ""
"Third, install the Flower package in development mode (think :code:`pip "
"install -e`) along with all necessary dependencies::"
msgstr ""
"Troisièmement, installez le paquet Flower en mode de développement ( "
":code :`pip install -e`) avec toutes les dépendances nécessaires :"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:46
msgid "Convenience Scripts"
msgstr "Scripts pratiques"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:48
msgid ""
"The Flower repository contains a number of convenience scripts to make "
"recurring development tasks easier and less error-prone. See the "
":code:`/dev` subdirectory for a full list. The following scripts are "
"amonst the most important ones:"
msgstr ""
"La repo de Flower contient un certain nombre de scripts de commodité pour"
" rendre les tâches de développement récurrentes plus faciles et moins "
"problématiques. Voir le sous-répertoire :code :`/dev` pour une liste "
"complète. Les scripts suivants sont parmis les plus importants :"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:54
msgid "Create/Delete Virtual Environment"
msgstr "Créer/Supprimer l'environment virtuel"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:62
msgid "Compile ProtoBuf Definitions"
msgstr "Compiler les définitions ProtoBuf"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:69
msgid "Auto-Format Code"
msgstr "Formatter le code"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:76
msgid "Run Linters and Tests"
msgstr "Vérifier le format et tester le code"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:83
msgid "Run Github Actions (CI) locally"
msgstr "Exécuter les GitHub Actions (CI) localement"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:85
msgid ""
"Developers could run the full set of Github Actions workflows under their"
" local environment by using `Act <https://github.com/nektos/act>_`. "
"Please refer to the installation instructions under the linked repository"
" and run the next command under Flower main cloned repository folder::"
msgstr ""
"Il est possible d'exécuter l'ensemble des Github Actions sous leur "
"environnement local en utilisant `Act <https ://github.com/nektos/act>_`. En "
"suivant le lien vous trouverez les instructions d'installation. Une fois "
"installé, exécuter la commande suivante dans le dossier principale de Flower "
":"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:92
msgid ""
"The Flower default workflow would run by setting up the required Docker "
"machines underneath."
msgstr ""
"Le workflow par défaut de Flower sera exécuté en configurant les machines "
"Docker requises en arrière plan."

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:97
#, fuzzy
msgid "Build Release"
msgstr "Inédit"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:99
msgid ""
"Flower uses Poetry to build releases. The necessary command is wrapped in"
" a simple script::"
msgstr ""
"Flower utilise Poetry pour construire les nouvelles versions. La commande "
"nécessaire est comprise dans un script simple ::"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:104
msgid ""
"The resulting :code:`.whl` and :code:`.tar.gz` releases will be stored in"
" the :code:`/dist` subdirectory."
msgstr ""
"Les versions résultantes :code:`.whl` et :code:`.tar.gz` seront stockées "
"dans le sous-répertoire:code:`/dist`."

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:109
#, fuzzy
msgid "Build Documentation"
msgstr "Amélioration de la documentation"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:111
msgid ""
"Flower's documentation uses `Sphinx <https://www.sphinx-doc.org/>`_. "
"There's no convenience script to re-build the documentation yet, but it's"
" pretty easy::"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:117
msgid "This will generate HTML documentation in ``doc/build/html``."
msgstr ""

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:2
msgid "Example: FedBN in PyTorch - From Centralized To Federated"
msgstr "Exemple : FedBN dans PyTorch - De la centralisation à la fédération"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:4
msgid ""
"This tutorial will show you how to use Flower to build a federated "
"version of an existing machine learning workload with `FedBN "
"<https://github.com/med-air/FedBN>`_, a federated training strategy "
"designed for non-iid data. We are using PyTorch to train a Convolutional "
"Neural Network(with Batch Normalization layers) on the CIFAR-10 dataset. "
"When applying FedBN, only few changes needed compared to `Example: "
"PyTorch - From Centralized To Federated <https://flower.dev/docs/example-"
"pytorch-from-centralized-to-federated.html>`_."
msgstr ""
"Ce tutoriel te montrera comment utiliser Flower pour construire une "
"version fédérée d'une charge de travail d'apprentissage automatique "
"existante avec `FedBN <https://github.com/med-air/FedBN>`_, une stratégie"
" de formation fédérée conçue pour les données non-identifiées. Nous "
"utilisons PyTorch pour former un réseau neuronal convolutif (avec des "
"couches de normalisation par lots) sur l'ensemble de données CIFAR-10. "
"Lors de l'application de FedBN, seules quelques modifications sont "
"nécessaires par rapport à `Exemple : PyTorch - De la centralisation à la "
"fédération <https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`_."

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:9
#: ../../source/example-pytorch-from-centralized-to-federated.rst:10
msgid "Centralized Training"
msgstr "Formation centralisée"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:10
msgid ""
"All files are revised based on `Example: PyTorch - From Centralized To "
"Federated <https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`_. The only thing to do is modifying the file called "
":code:`cifar.py`, revised part is shown below:"
msgstr ""
"Tous les fichiers sont révisés sur la base de `Exemple : PyTorch - From "
"Centralized To Federated <https://flower.dev/docs/example-pytorch-from-"
"centralized-to-federated.html>`_. La seule chose à faire est de modifier "
"le fichier appelé :code:`cifar.py`, la partie révisée est montrée ci-"
"dessous :"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:13
msgid ""
"The model architecture defined in class Net() is added with Batch "
"Normalization layers accordingly."
msgstr ""
"L'architecture du modèle définie dans la classe Net() est ajoutée avec "
"les couches de normalisation par lots en conséquence."

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:41
#: ../../source/example-pytorch-from-centralized-to-federated.rst:157
msgid "You can now run your machine learning workload:"
msgstr ""
"Tu peux maintenant exécuter ta charge de travail d'apprentissage "
"automatique :"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:47
msgid ""
"So far this should all look fairly familiar if you've used PyTorch "
"before. Let's take the next step and use what we've built to create a "
"federated learning system within FedBN, the sytstem consists of one "
"server and two clients."
msgstr ""
"Jusqu'à présent, tout ceci devrait te sembler assez familier si tu as "
"déjà utilisé PyTorch. Passons à l'étape suivante et utilisons ce que nous"
" avons construit pour créer un système d'apprentissage fédéré au sein de "
"FedBN, le système se compose d'un serveur et de deux clients."

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:51
#: ../../source/example-pytorch-from-centralized-to-federated.rst:167
msgid "Federated Training"
msgstr "Formation fédérée"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:53
msgid ""
"If you have read `Example: PyTorch - From Centralized To Federated "
"<https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`_, the following parts are easy to follow, onyl "
":code:`get_parameters` and :code:`set_parameters` function in "
":code:`client.py` needed to revise. If not, please read the `Example: "
"PyTorch - From Centralized To Federated <https://flower.dev/docs/example-"
"pytorch-from-centralized-to-federated.html>`_. first."
msgstr ""
"Si vous avez lu `Exemple : PyTorch - From Centralized To Federated "
"<https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`_, les parties suivantes sont faciles à suivre, seules "
"les fonctions :code:`get_parameters` et :code:`set_parameters` dans "
":code:`client.py` ont besoin d'être révisées. Si ce n'est pas le cas, "
"veuillez lire `Exemple : PyTorch - From Centralized To Federated "
"<https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`. d'abord."

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:56
msgid ""
"Our example consists of one *server* and two *clients*. In FedBN, "
":code:`server.py` keeps unchanged, we can start the server directly."
msgstr ""
"Notre exemple consiste en un *serveur* et deux *clients*. Dans FedBN, "
":code:`server.py` reste inchangé, nous pouvons démarrer le serveur "
"directement."

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:62
msgid ""
"Finally, we will revise our *client* logic by changing "
":code:`get_parameters` and :code:`set_parameters` in :code:`client.py`, "
"we will exclude batch normalization parameters from model parameter list "
"when sending to or receiving from the server."
msgstr ""
"Enfin, nous allons réviser notre logique *client* en modifiant "
":code:`get_parameters` et :code:`set_parameters` dans :code:`client.py`, "
"nous allons exclure les paramètres de normalisation des lots de la liste "
"des paramètres du modèle lors de l'envoi ou de la réception depuis le "
"serveur."

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:85
msgid "Now, you can now open two additional terminal windows and run"
msgstr "Tu peux maintenant ouvrir deux autres fenêtres de terminal et lancer"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:91
msgid ""
"in each window (make sure that the server is still running before you do "
"so) and see your (previously centralized) PyTorch project run federated "
"learning with FedBN strategy across two clients. Congratulations!"
msgstr ""
"dans chaque fenêtre (assure-toi que le serveur est toujours en cours "
"d'exécution avant de le faire) et tu verras ton projet PyTorch "
"(auparavant centralisé) exécuter l'apprentissage fédéré avec la stratégie"
" FedBN sur deux clients. Félicitations !"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:94
#: ../../source/example-jax-from-centralized-to-federated.rst:277
#: ../../source/example-mxnet-walk-through.rst:356
#: ../../source/example-pytorch-from-centralized-to-federated.rst:310
#: ../../source/tutorial-quickstart-jax.rst:280
msgid "Next Steps"
msgstr "Prochaines étapes"

#: ../../source/example-fedbn-pytorch-from-centralized-to-federated.rst:96
#, fuzzy
msgid ""
"The full source code for this example can be found `here "
"<https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_. Our example is of course somewhat over-"
"simplified because both clients load the exact same dataset, which isn't "
"realistic. You're now prepared to explore this topic further. How about "
"using different subsets of CIFAR-10 on each client? How about adding more"
" clients?"
msgstr ""
"Le code source complet de cet exemple se trouve ici "
"<https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_. Notre exemple est bien sûr un peu trop "
"simplifié parce que les deux clients chargent exactement le même ensemble"
" de données, ce qui n'est pas réaliste. Tu es maintenant prêt à "
"approfondir ce sujet. Pourquoi ne pas utiliser différents sous-ensembles "
"de CIFAR-10 sur chaque client ? Pourquoi ne pas ajouter d'autres clients "
"?"

#: ../../source/example-jax-from-centralized-to-federated.rst:2
msgid "Example: JAX - Run JAX Federated"
msgstr "Exemple : JAX - Exécuter JAX Federated"

#: ../../source/example-jax-from-centralized-to-federated.rst:4
#: ../../source/tutorial-quickstart-jax.rst:7
#, fuzzy
msgid ""
"This tutorial will show you how to use Flower to build a federated "
"version of an existing JAX workload. We are using JAX to train a linear "
"regression model on a scikit-learn dataset. We will structure the example"
" similar to our `PyTorch - From Centralized To Federated "
"<https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_ walkthrough. First, we build a centralized "
"training approach based on the `Linear Regression with JAX "
"<https://coax.readthedocs.io/en/latest/examples/linear_regression/jax.html>`_"
" tutorial`. Then, we build upon the centralized training code to run the "
"training in a federated fashion."
msgstr ""
"Ce tutoriel te montrera comment utiliser Flower pour construire une "
"version fédérée d'une charge de travail JAX existante. Nous utilisons JAX"
" pour entraîner un modèle de régression linéaire sur un ensemble de "
"données scikit-learn. Nous structurerons l'exemple de la même manière que"
" notre présentation `PyTorch - De la centralisation à la fédération "
"<https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_. Tout d'abord, nous construisons une approche"
" d'entraînement centralisée basée sur le tutoriel `Régression linéaire "
"avec JAX "
"<https://coax.readthedocs.io/en/latest/examples/linear_regression/jax.html>`_."
" Ensuite, nous nous appuyons sur le code d'entraînement centralisé pour "
"exécuter l'entraînement de manière fédérée."

#: ../../source/example-jax-from-centralized-to-federated.rst:10
#: ../../source/tutorial-quickstart-jax.rst:13
msgid ""
"Before we start building our JAX example, we need install the packages "
":code:`jax`, :code:`jaxlib`, :code:`scikit-learn`, and :code:`flwr`:"
msgstr ""
"Avant de commencer à construire notre exemple JAX, nous devons installer "
"les paquets :code:`jax`, :code:`jaxlib`, :code:`scikit-learn`, et "
":code:`flwr` :"

#: ../../source/example-jax-from-centralized-to-federated.rst:18
#: ../../source/tutorial-quickstart-jax.rst:21
msgid "Linear Regression with JAX"
msgstr "Régression linéaire avec JAX"

#: ../../source/example-jax-from-centralized-to-federated.rst:20
#: ../../source/tutorial-quickstart-jax.rst:23
msgid ""
"We begin with a brief description of the centralized training code based "
"on a :code:`Linear Regression` model. If you want a more in-depth "
"explanation of what's going on then have a look at the official `JAX "
"documentation <https://jax.readthedocs.io/>`_."
msgstr ""
"Nous commençons par une brève description du code d'entraînement "
"centralisé basé sur un modèle :code:`Régression linéaire`. Si tu veux une"
" explication plus approfondie de ce qui se passe, jette un coup d'œil à "
"la documentation officielle `JAX <https://jax.readthedocs.io/>`_."

#: ../../source/example-jax-from-centralized-to-federated.rst:23
#: ../../source/tutorial-quickstart-jax.rst:26
msgid ""
"Let's create a new file called :code:`jax_training.py` with all the "
"components required for a traditional (centralized) linear regression "
"training. First, the JAX packages :code:`jax` and :code:`jaxlib` need to "
"be imported. In addition, we need to import :code:`sklearn` since we use "
":code:`make_regression` for the dataset and :code:`train_test_split` to "
"split the dataset into a training and test set. You can see that we do "
"not yet import the :code:`flwr` package for federated learning. This will"
" be done later."
msgstr ""
"Créons un nouveau fichier appelé :code:`jax_training.py` avec tous les "
"composants nécessaires pour un apprentissage traditionnel (centralisé) de"
" la régression linéaire. Tout d'abord, les paquets JAX :code:`jax` et "
":code:`jaxlib` doivent être importés. En outre, nous devons importer "
":code:`sklearn` puisque nous utilisons :code:`make_regression` pour le "
"jeu de données et :code:`train_test_split` pour diviser le jeu de données"
" en un jeu d'entraînement et un jeu de test. Tu peux voir que nous "
"n'avons pas encore importé le paquet :code:`flwr` pour l'apprentissage "
"fédéré, ce qui sera fait plus tard."

#: ../../source/example-jax-from-centralized-to-federated.rst:37
#: ../../source/tutorial-quickstart-jax.rst:40
msgid ""
"The :code:`load_data()` function loads the mentioned training and test "
"sets."
msgstr ""
"La fonction :code:`load_data()` charge les ensembles d'entraînement et de"
" test mentionnés."

#: ../../source/example-jax-from-centralized-to-federated.rst:47
#: ../../source/tutorial-quickstart-jax.rst:50
msgid ""
"The model architecture (a very simple :code:`Linear Regression` model) is"
" defined in :code:`load_model()`."
msgstr ""
"L'architecture du modèle (un modèle :code:`Régression linéaire` très "
"simple) est définie dans :code:`load_model()`."

#: ../../source/example-jax-from-centralized-to-federated.rst:59
#: ../../source/tutorial-quickstart-jax.rst:62
msgid ""
"We now need to define the training (function :code:`train()`), which "
"loops over the training set and measures the loss (function "
":code:`loss_fn()`) for each batch of training examples. The loss function"
" is separate since JAX takes derivatives with a :code:`grad()` function "
"(defined in the :code:`main()` function and called in :code:`train()`)."
msgstr ""
"Nous devons maintenant définir l'entraînement (fonction :code:`train()`),"
" qui boucle sur l'ensemble d'entraînement et mesure la perte (fonction "
":code:`loss_fn()`) pour chaque lot d'exemples d'entraînement. La fonction"
" de perte est séparée puisque JAX prend des dérivés avec une fonction "
":code:`grad()` (définie dans la fonction :code:`main()` et appelée dans "
":code:`train()`)."

#: ../../source/example-jax-from-centralized-to-federated.rst:77
#: ../../source/tutorial-quickstart-jax.rst:80
msgid ""
"The evaluation of the model is defined in the function "
":code:`evaluation()`. The function takes all test examples and measures "
"the loss of the linear regression model."
msgstr ""
"L'évaluation du modèle est définie dans la fonction :code:`evaluation()`."
" La fonction prend tous les exemples de test et mesure la perte du modèle"
" de régression linéaire."

#: ../../source/example-jax-from-centralized-to-federated.rst:88
#: ../../source/tutorial-quickstart-jax.rst:91
msgid ""
"Having defined the data loading, model architecture, training, and "
"evaluation we can put everything together and train our model using JAX. "
"As already mentioned, the :code:`jax.grad()` function is defined in "
":code:`main()` and passed to :code:`train()`."
msgstr ""
"Après avoir défini le chargement des données, l'architecture du modèle, "
"l'entraînement et l'évaluation, nous pouvons tout assembler et entraîner "
"notre modèle à l'aide de JAX. Comme nous l'avons déjà mentionné, la "
"fonction :code:`jax.grad()` est définie dans :code:`main()` et transmise "
"à :code:`train()`."

#: ../../source/example-jax-from-centralized-to-federated.rst:105
#: ../../source/tutorial-quickstart-jax.rst:108
msgid "You can now run your (centralized) JAX linear regression workload:"
msgstr ""
"Tu peux maintenant exécuter ta charge de travail (centralisée) de "
"régression linéaire JAX :"

#: ../../source/example-jax-from-centralized-to-federated.rst:111
#: ../../source/tutorial-quickstart-jax.rst:114
msgid ""
"So far this should all look fairly familiar if you've used JAX before. "
"Let's take the next step and use what we've built to create a simple "
"federated learning system consisting of one server and two clients."
msgstr ""
"Jusqu'à présent, tout cela devrait te sembler assez familier si tu as "
"déjà utilisé JAX. Passons à l'étape suivante et utilisons ce que nous "
"avons construit pour créer un simple système d'apprentissage fédéré "
"composé d'un serveur et de deux clients."

#: ../../source/example-jax-from-centralized-to-federated.rst:115
#: ../../source/tutorial-quickstart-jax.rst:118
msgid "JAX meets Flower"
msgstr "JAX rencontre Flower"

#: ../../source/example-jax-from-centralized-to-federated.rst:117
#: ../../source/tutorial-quickstart-jax.rst:120
msgid ""
"The concept of federating an existing workload is always the same and "
"easy to understand. We have to start a *server* and then use the code in "
":code:`jax_training.py` for the *clients* that are connected to the "
"*server*. The *server* sends model parameters to the clients. The "
"*clients* run the training and update the parameters. The updated "
"parameters are sent back to the *server*, which averages all received "
"parameter updates. This describes one round of the federated learning "
"process, and we repeat this for multiple rounds."
msgstr ""
"Le concept de fédération d'une charge de travail existante est toujours "
"le même et facile à comprendre. Nous devons démarrer un *serveur*, puis "
"utiliser le code dans :code:`jax_training.py` pour les *clients* qui sont"
" connectés au *serveur*.Le *serveur* envoie les paramètres du modèle aux "
"clients.Les *clients* exécutent la formation et mettent à jour les "
"paramètres.Les paramètres mis à jour sont renvoyés au *serveur*, qui fait"
" la moyenne de toutes les mises à jour de paramètres reçues.Ceci décrit "
"un tour du processus d'apprentissage fédéré, et nous répétons cette "
"opération pour plusieurs tours."

#: ../../source/example-jax-from-centralized-to-federated.rst:123
#: ../../source/example-mxnet-walk-through.rst:204
#: ../../source/example-pytorch-from-centralized-to-federated.rst:181
#: ../../source/tutorial-quickstart-jax.rst:126
msgid ""
"Our example consists of one *server* and two *clients*. Let's set up "
":code:`server.py` first. The *server* needs to import the Flower package "
":code:`flwr`. Next, we use the :code:`start_server` function to start a "
"server and tell it to perform three rounds of federated learning."
msgstr ""
"Notre exemple consiste en un *serveur* et deux *clients*. Commençons par "
"configurer :code:`server.py`. Le *serveur* doit importer le paquet Flower"
" :code:`flwr`. Ensuite, nous utilisons la fonction :code:`start_server` "
"pour démarrer un serveur et lui demander d'effectuer trois cycles "
"d'apprentissage fédéré."

#: ../../source/example-jax-from-centralized-to-federated.rst:133
#: ../../source/example-mxnet-walk-through.rst:214
#: ../../source/example-pytorch-from-centralized-to-federated.rst:191
#: ../../source/tutorial-quickstart-jax.rst:136
msgid "We can already start the *server*:"
msgstr "Nous pouvons déjà démarrer le *serveur* :"

#: ../../source/example-jax-from-centralized-to-federated.rst:139
#: ../../source/tutorial-quickstart-jax.rst:142
msgid ""
"Finally, we will define our *client* logic in :code:`client.py` and build"
" upon the previously defined JAX training in :code:`jax_training.py`. Our"
" *client* needs to import :code:`flwr`, but also :code:`jax` and "
":code:`jaxlib` to update the parameters on our JAX model:"
msgstr ""
"Enfin, nous allons définir la logique de notre *client* dans "
":code:`client.py` et nous appuyer sur la formation JAX définie "
"précédemment dans :code:`jax_training.py`. Notre *client* doit importer "
":code:`flwr`, mais aussi :code:`jax` et :code:`jaxlib` pour mettre à jour"
" les paramètres de notre modèle JAX :"

#: ../../source/example-jax-from-centralized-to-federated.rst:154
#: ../../source/tutorial-quickstart-jax.rst:157
msgid ""
"Implementing a Flower *client* basically means implementing a subclass of"
" either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. "
"Our implementation will be based on :code:`flwr.client.NumPyClient` and "
"we'll call it :code:`FlowerClient`. :code:`NumPyClient` is slightly "
"easier to implement than :code:`Client` if you use a framework with good "
"NumPy interoperability (like JAX) because it avoids some of the "
"boilerplate that would otherwise be necessary. :code:`FlowerClient` needs"
" to implement four methods, two methods for getting/setting model "
"parameters, one method for training the model, and one method for testing"
" the model:"
msgstr ""
"L'implémentation d'un *client* Flower signifie essentiellement "
"l'implémentation d'une sous-classe de :code:`flwr.client.Client` ou "
":code:`flwr.client.NumPyClient`. Notre implémentation sera basée sur "
":code:`flwr.client.NumPyClient` et nous l'appellerons "
":code:`FlowerClient`. :code:`NumPyClient` est légèrement plus facile à "
"implémenter que :code:`Client` si vous utilisez un framework avec une "
"bonne interopérabilité NumPy (comme JAX) parce qu'il évite une partie du "
"boilerplate qui serait autrement nécessaire. :code:`FlowerClient` doit "
"implémenter quatre méthodes, deux méthodes pour obtenir/régler les "
"paramètres du modèle, une méthode pour former le modèle, et une méthode "
"pour tester le modèle :"

#: ../../source/example-jax-from-centralized-to-federated.rst:161
#: ../../source/example-mxnet-walk-through.rst:242
#: ../../source/tutorial-quickstart-jax.rst:164
msgid ":code:`set_parameters (optional)`"
msgstr ":code:`set_parameters (optional)`"

#: ../../source/example-jax-from-centralized-to-federated.rst:160
#: ../../source/example-mxnet-walk-through.rst:241
#: ../../source/example-pytorch-from-centralized-to-federated.rst:219
#: ../../source/tutorial-quickstart-jax.rst:163
msgid ""
"set the model parameters on the local model that are received from the "
"server"
msgstr "règle les paramètres du modèle local reçus du serveur"

#: ../../source/example-jax-from-centralized-to-federated.rst:161
#: ../../source/tutorial-quickstart-jax.rst:164
msgid "transform parameters to NumPy :code:`ndarray`'s"
msgstr "transforme les paramètres en NumPy :code:`ndarray`'s"

#: ../../source/example-jax-from-centralized-to-federated.rst:162
#: ../../source/example-mxnet-walk-through.rst:243
#: ../../source/example-pytorch-from-centralized-to-federated.rst:220
#: ../../source/tutorial-quickstart-jax.rst:165
msgid ""
"loop over the list of model parameters received as NumPy "
":code:`ndarray`'s (think list of neural network layers)"
msgstr ""
"boucle sur la liste des paramètres du modèle reçus sous forme de NumPy "
":code:`ndarray`'s (pensez à la liste des couches du réseau neuronal)"

#: ../../source/example-jax-from-centralized-to-federated.rst:163
#: ../../source/example-mxnet-walk-through.rst:244
#: ../../source/example-pytorch-from-centralized-to-federated.rst:221
#: ../../source/tutorial-quickstart-jax.rst:166
#: ../../source/tutorial-quickstart-mxnet.rst:166
#: ../../source/tutorial-quickstart-pytorch.rst:152
#: ../../source/tutorial-quickstart-scikitlearn.rst:105
msgid ":code:`get_parameters`"
msgstr ":code:`get_parameters`"

#: ../../source/example-jax-from-centralized-to-federated.rst:164
#: ../../source/example-mxnet-walk-through.rst:245
#: ../../source/example-pytorch-from-centralized-to-federated.rst:222
#: ../../source/tutorial-quickstart-jax.rst:167
msgid ""
"get the model parameters and return them as a list of NumPy "
":code:`ndarray`'s (which is what :code:`flwr.client.NumPyClient` expects)"
msgstr ""
"récupère les paramètres du modèle et les renvoie sous forme de liste de "
":code:`ndarray` NumPy (ce qui correspond à ce que "
":code:`flwr.client.NumPyClient` attend)"

#: ../../source/example-jax-from-centralized-to-federated.rst:167
#: ../../source/example-mxnet-walk-through.rst:248
#: ../../source/example-pytorch-from-centralized-to-federated.rst:225
#: ../../source/tutorial-quickstart-jax.rst:170
#: ../../source/tutorial-quickstart-mxnet.rst:172
#: ../../source/tutorial-quickstart-pytorch.rst:158
#: ../../source/tutorial-quickstart-scikitlearn.rst:112
msgid ":code:`fit`"
msgstr ":code:`fit`"

#: ../../source/example-jax-from-centralized-to-federated.rst:166
#: ../../source/example-jax-from-centralized-to-federated.rst:170
#: ../../source/example-mxnet-walk-through.rst:247
#: ../../source/example-mxnet-walk-through.rst:251
#: ../../source/example-pytorch-from-centralized-to-federated.rst:224
#: ../../source/example-pytorch-from-centralized-to-federated.rst:228
#: ../../source/tutorial-quickstart-jax.rst:169
#: ../../source/tutorial-quickstart-jax.rst:173
msgid ""
"update the parameters of the local model with the parameters received "
"from the server"
msgstr ""
"mettre à jour les paramètres du modèle local avec les paramètres reçus du"
" serveur"

#: ../../source/example-jax-from-centralized-to-federated.rst:167
#: ../../source/example-mxnet-walk-through.rst:248
#: ../../source/example-pytorch-from-centralized-to-federated.rst:225
#: ../../source/tutorial-quickstart-jax.rst:170
msgid "train the model on the local training set"
msgstr "entraîne le modèle sur l'ensemble d'apprentissage local"

#: ../../source/example-jax-from-centralized-to-federated.rst:168
#: ../../source/tutorial-quickstart-jax.rst:171
msgid "get the updated local model parameters and return them to the server"
msgstr ""
"récupère les paramètres du modèle local mis à jour et les renvoie au "
"serveur"

#: ../../source/example-jax-from-centralized-to-federated.rst:172
#: ../../source/example-mxnet-walk-through.rst:253
#: ../../source/example-pytorch-from-centralized-to-federated.rst:230
#: ../../source/tutorial-quickstart-jax.rst:175
#: ../../source/tutorial-quickstart-mxnet.rst:175
#: ../../source/tutorial-quickstart-pytorch.rst:161
#: ../../source/tutorial-quickstart-scikitlearn.rst:115
msgid ":code:`evaluate`"
msgstr ":code:`évaluer`"

#: ../../source/example-jax-from-centralized-to-federated.rst:171
#: ../../source/example-mxnet-walk-through.rst:252
#: ../../source/example-pytorch-from-centralized-to-federated.rst:229
#: ../../source/tutorial-quickstart-jax.rst:174
msgid "evaluate the updated model on the local test set"
msgstr "évaluer le modèle mis à jour sur l'ensemble de test local"

#: ../../source/example-jax-from-centralized-to-federated.rst:172
#: ../../source/tutorial-quickstart-jax.rst:175
msgid "return the local loss to the server"
msgstr "renvoie la perte locale au serveur"

#: ../../source/example-jax-from-centralized-to-federated.rst:174
#: ../../source/tutorial-quickstart-jax.rst:177
msgid ""
"The challenging part is to transform the JAX model parameters from "
":code:`DeviceArray` to :code:`NumPy ndarray` to make them compatible with"
" `NumPyClient`."
msgstr ""
"La partie la plus difficile consiste à transformer les paramètres du "
"modèle JAX de :code:`DeviceArray` en :code:`NumPy ndarray` pour les "
"rendre compatibles avec `NumPyClient`."

#: ../../source/example-jax-from-centralized-to-federated.rst:176
#: ../../source/tutorial-quickstart-jax.rst:179
msgid ""
"The two :code:`NumPyClient` methods :code:`fit` and :code:`evaluate` make"
" use of the functions :code:`train()` and :code:`evaluate()` previously "
"defined in :code:`jax_training.py`. So what we really do here is we tell "
"Flower through our :code:`NumPyClient` subclass which of our already "
"defined functions to call for training and evaluation. We included type "
"annotations to give you a better understanding of the data types that get"
" passed around."
msgstr ""
"Les deux méthodes :code:`NumPyClient` :code:`fit` et :code:`evaluate` "
"utilisent les fonctions :code:`train()` et :code:`evaluate()` définies "
"précédemment dans :code:`jax_training.py`. Ce que nous faisons vraiment "
"ici, c'est que nous indiquons à Flower, par le biais de notre sous-classe"
" :code:`NumPyClient`, laquelle de nos fonctions déjà définies doit être "
"appelée pour l'entraînement et l'évaluation. Nous avons inclus des "
"annotations de type pour te donner une meilleure compréhension des types "
"de données qui sont transmis."

#: ../../source/example-jax-from-centralized-to-federated.rst:245
#: ../../source/tutorial-quickstart-jax.rst:248
msgid "Having defined the federation process, we can run it."
msgstr "Après avoir défini le processus de fédération, nous pouvons l'exécuter."

#: ../../source/example-jax-from-centralized-to-federated.rst:268
#: ../../source/example-mxnet-walk-through.rst:347
#: ../../source/example-pytorch-from-centralized-to-federated.rst:301
#: ../../source/tutorial-quickstart-jax.rst:271
msgid "And that's it. You can now open two additional terminal windows and run"
msgstr ""
"Tu peux maintenant ouvrir deux autres fenêtres de terminal et exécuter "
"les commandes suivantes"

#: ../../source/example-jax-from-centralized-to-federated.rst:274
#: ../../source/tutorial-quickstart-jax.rst:277
msgid ""
"in each window (make sure that the server is still running before you do "
"so) and see your JAX project run federated learning across two clients. "
"Congratulations!"
msgstr ""
"dans chaque fenêtre (assure-toi que le serveur est toujours en cours "
"d'exécution avant de le faire) et tu verras que ton projet JAX exécute "
"l'apprentissage fédéré sur deux clients. Félicitations !"

#: ../../source/example-jax-from-centralized-to-federated.rst:279
#: ../../source/tutorial-quickstart-jax.rst:282
#, fuzzy
msgid ""
"The source code of this example was improved over time and can be found "
"here: `Quickstart JAX <https://github.com/adap/flower/blob/main/examples"
"/quickstart-jax>`_. Our example is somewhat over-simplified because both "
"clients load the same dataset."
msgstr ""
"Le code source de cet exemple a été amélioré au fil du temps et peut être"
" trouvé ici : `Quickstart JAX "
"<https://github.com/adap/flower/blob/main/examples/quickstart-jax>`_. "
"Notre exemple est quelque peu simplifié à l'extrême car les deux clients "
"chargent le même jeu de données."

#: ../../source/example-jax-from-centralized-to-federated.rst:282
#: ../../source/tutorial-quickstart-jax.rst:285
msgid ""
"You're now prepared to explore this topic further. How about using a more"
" sophisticated model or using a different dataset? How about adding more "
"clients?"
msgstr ""
"Tu es maintenant prêt à approfondir ce sujet. Pourquoi ne pas utiliser un"
" modèle plus sophistiqué ou un ensemble de données différent ? Pourquoi "
"ne pas ajouter d'autres clients ?"

#: ../../source/example-mxnet-walk-through.rst:2
msgid "Example: MXNet - Run MXNet Federated"
msgstr "Exemple : MXNet - Exécuter MXNet Federated"

#: ../../source/example-mxnet-walk-through.rst:4
#, fuzzy
msgid ""
"This tutorial will show you how to use Flower to build a federated "
"version of an existing MXNet workload. We are using MXNet to train a "
"Sequential model on the MNIST dataset. We will structure the example "
"similar to our `PyTorch - From Centralized To Federated "
"<https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_ walkthrough. MXNet and PyTorch are very "
"similar and a very good comparison between MXNet and PyTorch is given "
"`here <https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials"
"/getting-started/to-mxnet/pytorch.html>`_. First, we build a centralized "
"training approach based on the `Handwritten Digit Recognition "
"<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_"
" tutorial. Then, we build upon the centralized training code to run the "
"training in a federated fashion."
msgstr ""
"Ce tutoriel te montrera comment utiliser Flower pour construire une "
"version fédérée d'une charge de travail MXNet existante. Nous utilisons "
"MXNet pour former un modèle séquentiel sur l'ensemble de données MNIST. "
"Nous structurerons l'exemple de la même manière que notre présentation "
"`PyTorch - De la centralisation à la fédération "
"<https://github.com/adap/flower/blob/main/examples/pytorch-from-"
"centralized-to-federated>`_. MXNet et PyTorch sont très similaires et une"
" très bonne comparaison entre MXNet et PyTorch est donnée ici "
"<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials"
"/getting-started/to-mxnet/pytorch.html>`_. Tout d'abord, nous "
"construisons une approche de formation centralisée basée sur le tutoriel "
"`Handandwritten Digit Recognition "
"<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_."
" Ensuite, nous nous basons sur le code de formation centralisé pour "
"exécuter la formation de manière fédérée."

#: ../../source/example-mxnet-walk-through.rst:10
msgid ""
"Before we start setting up our MXNet example, we install the "
":code:`mxnet` and :code:`flwr` packages:"
msgstr ""
"Avant de commencer à configurer notre exemple MXNet, nous installons les "
"paquets :code:`mxnet` et :code:`flwr` :"

#: ../../source/example-mxnet-walk-through.rst:19
msgid "MNIST Training with MXNet"
msgstr "Formation MNIST avec MXNet"

#: ../../source/example-mxnet-walk-through.rst:21
msgid ""
"We begin with a brief description of the centralized training code based "
"on a :code:`Sequential` model. If you want a more in-depth explanation of"
" what's going on then have a look at the official `MXNet tutorial "
"<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/>`_."
msgstr ""
"Nous commençons par une brève description du code d'entraînement "
"centralisé basé sur un modèle :code:`Sequential`. Si tu veux une "
"explication plus approfondie de ce qui se passe, jette un coup d'œil au "
"tutoriel officiel `MXNet "
"<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/>`_."

#: ../../source/example-mxnet-walk-through.rst:24
msgid ""
"Let's create a new file called:code:`mxnet_mnist.py` with all the "
"components required for a traditional (centralized) MNIST training. "
"First, the MXNet package :code:`mxnet` needs to be imported. You can see "
"that we do not yet import the :code:`flwr` package for federated "
"learning. This will be done later."
msgstr ""
"Créons un nouveau fichier appelé :code:`mxnet_mnist.py` avec tous les "
"composants requis pour un apprentissage MNIST traditionnel (centralisé). "
"Tout d'abord, le package MXNet :code:`mxnet` doit être importé. Tu peux "
"voir que nous n'avons pas encore importé le package :code:`flwr` pour "
"l'apprentissage fédéré. Cela sera fait plus tard."

#: ../../source/example-mxnet-walk-through.rst:42
msgid "The :code:`load_data()` function loads the MNIST training and test sets."
msgstr ""
"La fonction :code:`load_data()` charge les ensembles d'entraînement et de"
" test MNIST."

#: ../../source/example-mxnet-walk-through.rst:57
msgid ""
"As already mentioned, we will use the MNIST dataset for this machine "
"learning workload. The model architecture (a very simple "
":code:`Sequential` model) is defined in :code:`model()`."
msgstr ""
"Comme nous l'avons déjà mentionné, nous utiliserons l'ensemble de données"
" MNIST pour cette charge de travail d'apprentissage automatique. "
"L'architecture du modèle (un modèle :code:`Séquentiel` très simple) est "
"définie dans :code:`model()`."

#: ../../source/example-mxnet-walk-through.rst:70
msgid ""
"We now need to define the training (function :code:`train()`) which loops"
" over the training set and measures the loss for each batch of training "
"examples."
msgstr ""
"Nous devons maintenant définir la formation (fonction :code:`train()`) "
"qui passe en boucle sur l'ensemble de la formation et mesure la perte "
"pour chaque lot d'exemples de formation."

#: ../../source/example-mxnet-walk-through.rst:123
msgid ""
"The evaluation of the model is defined in function :code:`test()`. The "
"function loops over all test samples and measures the loss and accuracy "
"of the model based on the test dataset."
msgstr ""
"L'évaluation du modèle est définie dans la fonction :code:`test()`. Cette"
" fonction passe en boucle sur tous les échantillons de test et mesure la "
"perte et la précision du modèle en fonction de l'ensemble des données de "
"test."

#: ../../source/example-mxnet-walk-through.rst:158
msgid ""
"Having defined the data loading, model architecture, training, and "
"evaluation we can put everything together and train our model on MNIST. "
"Note that the GPU/CPU device for the training and testing is defined "
"within the :code:`ctx` (context)."
msgstr ""
"Après avoir défini le chargement des données, l'architecture du modèle, "
"l'entraînement et l'évaluation, nous pouvons tout assembler et entraîner "
"notre modèle sur MNIST. Note que le dispositif GPU/CPU pour "
"l'entraînement et le test est défini dans le :code:`ctx` (contexte)."

#: ../../source/example-mxnet-walk-through.rst:184
msgid "You can now run your (centralized) MXNet machine learning workload:"
msgstr ""
"Tu peux maintenant exécuter ta charge de travail (centralisée) "
"d'apprentissage automatique MXNet :"

#: ../../source/example-mxnet-walk-through.rst:190
msgid ""
"So far this should all look fairly familiar if you've used MXNet (or even"
" PyTorch) before. Let's take the next step and use what we've built to "
"create a simple federated learning system consisting of one server and "
"two clients."
msgstr ""
"Jusqu'à présent, tout cela devrait te sembler assez familier si tu as "
"déjà utilisé MXNet (ou même PyTorch). Passons à l'étape suivante et "
"utilisons ce que nous avons construit pour créer un simple système "
"d'apprentissage fédéré composé d'un serveur et de deux clients."

#: ../../source/example-mxnet-walk-through.rst:194
msgid "MXNet meets Flower"
msgstr "MXNet rencontre Flower"

#: ../../source/example-mxnet-walk-through.rst:196
msgid ""
"So far, it was not easily possible to use MXNet workloads for federated "
"learning because federated learning is not supported in MXNet. Since "
"Flower is fully agnostic towards the underlying machine learning "
"framework, it can be used to federated arbitrary machine learning "
"workloads. This section will show you how Flower can be used to federate "
"our centralized MXNet workload."
msgstr ""
"Jusqu'à présent, il n'était pas facile d'utiliser les charges de travail "
"MXNet pour l'apprentissage fédéré car l'apprentissage fédéré n'est pas "
"pris en charge dans MXNet. Comme Flower est totalement agnostique "
"vis-à-vis du cadre d'apprentissage automatique sous-jacent, il peut être "
"utilisé pour fédérer des charges de travail d'apprentissage automatique "
"arbitraires. Cette section te montrera comment Flower peut être utilisé "
"pour fédérer notre charge de travail MXNet centralisée."

#: ../../source/example-mxnet-walk-through.rst:198
msgid ""
"The concept to federate an existing workload is always the same and easy "
"to understand. We have to start a *server* and then use the code in "
":code:`mxnet_mnist.py` for the *clients* that are connected to the "
"*server*. The *server* sends model parameters to the clients. The "
"*clients* run the training and update the parameters. The updated "
"parameters are sent back to the *server* which averages all received "
"parameter updates. This describes one round of the federated learning "
"process and we repeat this for multiple rounds."
msgstr ""
"Le concept pour fédérer une charge de travail existante est toujours le "
"même et facile à comprendre. Nous devons démarrer un *serveur* et ensuite"
" utiliser le code dans :code:`mxnet_mnist.py` pour les *clients* qui sont"
" connectés au *serveur*. Le *serveur* envoie les paramètres du modèle aux"
" clients. Les *clients* exécutent la formation et mettent à jour les "
"paramètres. Les paramètres mis à jour sont renvoyés au *serveur* qui fait"
" la moyenne de toutes les mises à jour de paramètres reçues. Ceci décrit "
"un tour du processus d'apprentissage fédéré et nous répétons cette "
"opération pour plusieurs tours."

#: ../../source/example-mxnet-walk-through.rst:220
msgid ""
"Finally, we will define our *client* logic in :code:`client.py` and build"
" upon the previously defined MXNet training in :code:`mxnet_mnist.py`. "
"Our *client* needs to import :code:`flwr`, but also :code:`mxnet` to "
"update the parameters on our MXNet model:"
msgstr ""
"Enfin, nous allons définir la logique de notre *client* dans "
":code:`client.py` et nous appuyer sur l'entraînement MXNet défini "
"précédemment dans :code:`mxnet_mnist.py`. Notre *client* doit importer "
":code:`flwr`, mais aussi :code:`mxnet` pour mettre à jour les paramètres "
"de notre modèle MXNet :"

#: ../../source/example-mxnet-walk-through.rst:235
msgid ""
"Implementing a Flower *client* basically means implementing a subclass of"
" either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. "
"Our implementation will be based on :code:`flwr.client.NumPyClient` and "
"we'll call it :code:`MNISTClient`. :code:`NumPyClient` is slighly easier "
"to implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like PyTorch or MXNet) because it avoids some of the "
"boilerplate that would otherwise be necessary. :code:`MNISTClient` needs "
"to implement four methods, two methods for getting/setting model "
"parameters, one method for training the model, and one method for testing"
" the model:"
msgstr ""
"Implementing a Flower *client* basically means implementing a subclass of"
" either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. "
"Our implementation will be based on :code:`flwr.client.NumPyClient` and "
"we'll call it :code:`MNISTClient`. :code:`NumPyClient` is slighly easier "
"to implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like PyTorch or MXNet) because it avoids some of the "
"boilerplate that would otherwise be necessary. :code:`MNISTClient` needs "
"to implement four methods, two methods for getting/setting model "
"parameters, one method for training the model, and one method for testing"
" the model:"

#: ../../source/example-mxnet-walk-through.rst:242
msgid "transform MXNet :code:`NDArray`'s to NumPy :code:`ndarray`'s"
msgstr "transforme les :code:`NDArray` du MXNet en :code:`ndarray` de NumPy"

#: ../../source/example-mxnet-walk-through.rst:249
#: ../../source/example-pytorch-from-centralized-to-federated.rst:226
msgid "get the updated local model weights and return them to the server"
msgstr "récupère les poids du modèle local mis à jour et les renvoie au serveur"

#: ../../source/example-mxnet-walk-through.rst:253
#: ../../source/example-pytorch-from-centralized-to-federated.rst:230
msgid "return the local loss and accuracy to the server"
msgstr "renvoie la perte locale et la précision au serveur"

#: ../../source/example-mxnet-walk-through.rst:255
msgid ""
"The challenging part is to transform the MXNet parameters from "
":code:`NDArray` to :code:`NumPy Arrays` to make it readable for Flower."
msgstr ""
"La partie la plus difficile est de transformer les paramètres MXNet de "
":code:`NDArray` en :code:`NumPy Arrays` pour les rendre lisibles pour "
"Flower."

#: ../../source/example-mxnet-walk-through.rst:257
msgid ""
"The two :code:`NumPyClient` methods :code:`fit` and :code:`evaluate` make"
" use of the functions :code:`train()` and :code:`test()` previously "
"defined in :code:`mxnet_mnist.py`. So what we really do here is we tell "
"Flower through our :code:`NumPyClient` subclass which of our already "
"defined functions to call for training and evaluation. We included type "
"annotations to give you a better understanding of the data types that get"
" passed around."
msgstr ""
"Les deux méthodes :code:`NumPyClient` :code:`fit` et :code:`evaluate` "
"utilisent les fonctions :code:`train()` et :code:`test()` définies "
"précédemment dans :code:`mxnet_mnist.py`. Ce que nous faisons vraiment "
"ici, c'est que nous indiquons à Flower, par le biais de notre sous-classe"
" :code:`NumPyClient`, laquelle de nos fonctions déjà définies doit être "
"appelée pour l'entraînement et l'évaluation. Nous avons inclus des "
"annotations de type pour te donner une meilleure compréhension des types "
"de données qui sont transmis."

#: ../../source/example-mxnet-walk-through.rst:319
msgid ""
"Having defined data loading, model architecture, training, and evaluation"
" we can put everything together and train our :code:`Sequential` model on"
" MNIST."
msgstr ""
"Après avoir défini le chargement des données, l'architecture du modèle, "
"la formation et l'évaluation, nous pouvons tout rassembler et former "
"notre modèle :code:`Sequential` sur MNIST."

#: ../../source/example-mxnet-walk-through.rst:353
msgid ""
"in each window (make sure that the server is still running before you do "
"so) and see your MXNet project run federated learning across two clients."
" Congratulations!"
msgstr ""
"dans chaque fenêtre (assure-toi que le serveur est toujours en cours "
"d'exécution avant de le faire) et tu verras ton projet MXNet exécuter "
"l'apprentissage fédéré sur deux clients. Félicitations !"

#: ../../source/example-mxnet-walk-through.rst:358
#, fuzzy
msgid ""
"The full source code for this example: `MXNet: From Centralized To "
"Federated (Code) <https://github.com/adap/flower/blob/main/examples"
"/mxnet-from-centralized-to-federated>`_. Our example is of course "
"somewhat over-simplified because both clients load the exact same "
"dataset, which isn't realistic. You're now prepared to explore this topic"
" further. How about using a CNN or using a different dataset? How about "
"adding more clients?"
msgstr ""
"Le code source complet de cet exemple : `MXNet : From Centralized To "
"Federated (Code) <https://github.com/adap/flower/blob/main/examples"
"/mxnet-from-centralized-to-federated>`_. Notre exemple est bien sûr un "
"peu trop simplifié parce que les deux clients chargent exactement le même"
" ensemble de données, ce qui n'est pas réaliste. Tu es maintenant prêt à "
"explorer ce sujet plus en profondeur. Pourquoi ne pas utiliser un CNN ou "
"un ensemble de données différent ? Pourquoi ne pas ajouter d'autres "
"clients ?"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:2
msgid "Example: PyTorch - From Centralized To Federated"
msgstr "Exemple : PyTorch - De la centralisation à la fédération"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:4
msgid ""
"This tutorial will show you how to use Flower to build a federated "
"version of an existing machine learning workload. We are using PyTorch to"
" train a Convolutional Neural Network on the CIFAR-10 dataset. First, we "
"introduce this machine learning task with a centralized training approach"
" based on the `Deep Learning with PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ "
"tutorial. Then, we build upon the centralized training code to run the "
"training in a federated fashion."
msgstr ""
"Ce tutoriel te montrera comment utiliser Flower pour construire une "
"version fédérée d'une charge de travail d'apprentissage automatique "
"existante. Nous utilisons PyTorch pour entraîner un réseau neuronal "
"convolutif sur l'ensemble de données CIFAR-10. Tout d'abord, nous "
"présentons cette tâche d'apprentissage automatique avec une approche "
"d'entraînement centralisée basée sur le tutoriel `Deep Learning with "
"PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_. "
"Ensuite, nous nous appuyons sur le code d'entraînement centralisé pour "
"exécuter l'entraînement de manière fédérée."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:12
msgid ""
"We begin with a brief description of the centralized CNN training code. "
"If you want a more in-depth explanation of what's going on then have a "
"look at the official `PyTorch tutorial "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
msgstr ""
"Nous commençons par une brève description du code d'entraînement CNN "
"centralisé. Si tu veux une explication plus approfondie de ce qui se "
"passe, jette un coup d'œil au tutoriel officiel `PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:15
msgid ""
"Let's create a new file called :code:`cifar.py` with all the components "
"required for a traditional (centralized) training on CIFAR-10. First, all"
" required packages (such as :code:`torch` and :code:`torchvision`) need "
"to be imported. You can see that we do not import any package for "
"federated learning. You can keep all these imports as they are even when "
"we add the federated learning components at a later point."
msgstr ""
"Créons un nouveau fichier appelé :code:`cifar.py` avec tous les "
"composants requis pour une formation traditionnelle (centralisée) sur le "
"CIFAR-10. Tout d'abord, tous les paquets requis (tels que :code:`torch` "
"et :code:`torchvision`) doivent être importés. Tu peux voir que nous "
"n'importons aucun paquet pour l'apprentissage fédéré. Tu peux conserver "
"toutes ces importations telles quelles même lorsque nous ajouterons les "
"composants d'apprentissage fédéré à un moment ultérieur."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:32
msgid ""
"As already mentioned we will use the CIFAR-10 dataset for this machine "
"learning workload. The model architecture (a very simple Convolutional "
"Neural Network) is defined in :code:`class Net()`."
msgstr ""
"Comme nous l'avons déjà mentionné, nous utiliserons l'ensemble de données"
" CIFAR-10 pour cette charge de travail d'apprentissage automatique. "
"L'architecture du modèle (un réseau neuronal convolutif très simple) est "
"définie dans :code:`class Net()`."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:56
msgid ""
"The :code:`load_data()` function loads the CIFAR-10 training and test "
"sets. The :code:`transform` normalized the data after loading."
msgstr ""
"La fonction :code:`load_data()` charge les ensembles d'entraînement et de"
" test CIFAR-10. La fonction :code:`transform` normalise les données après"
" leur chargement."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:74
msgid ""
"We now need to define the training (function :code:`train()`) which loops"
" over the training set, measures the loss, backpropagates it, and then "
"takes one optimizer step for each batch of training examples."
msgstr ""
"Nous devons maintenant définir la formation (fonction :code:`train()`) "
"qui passe en boucle sur l'ensemble de la formation, mesure la perte, la "
"rétropropage, puis effectue une étape d'optimisation pour chaque lot "
"d'exemples de formation."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:76
msgid ""
"The evaluation of the model is defined in the function :code:`test()`. "
"The function loops over all test samples and measures the loss of the "
"model based on the test dataset."
msgstr ""
"L'évaluation du modèle est définie dans la fonction :code:`test()`. La "
"fonction boucle sur tous les échantillons de test et mesure la perte du "
"modèle en fonction de l'ensemble des données de test."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:136
msgid ""
"Having defined the data loading, model architecture, training, and "
"evaluation we can put everything together and train our CNN on CIFAR-10."
msgstr ""
"Après avoir défini le chargement des données, l'architecture du modèle, "
"la formation et l'évaluation, nous pouvons tout mettre ensemble et former"
" notre CNN sur CIFAR-10."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:163
msgid ""
"So far, this should all look fairly familiar if you've used PyTorch "
"before. Let's take the next step and use what we've built to create a "
"simple federated learning system consisting of one server and two "
"clients."
msgstr ""
"Jusqu'à présent, tout cela devrait te sembler assez familier si tu as "
"déjà utilisé PyTorch. Passons à l'étape suivante et utilisons ce que nous"
" avons construit pour créer un simple système d'apprentissage fédéré "
"composé d'un serveur et de deux clients."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:169
msgid ""
"The simple machine learning project discussed in the previous section "
"trains the model on a single dataset (CIFAR-10), we call this centralized"
" learning. This concept of centralized learning, as shown in the previous"
" section, is probably known to most of you, and many of you have used it "
"previously. Normally, if you'd want to run machine learning workloads in "
"a federated fashion, then you'd have to change most of your code and set "
"everything up from scratch. This can be a considerable effort."
msgstr ""
"Le projet simple d'apprentissage automatique discuté dans la section "
"précédente entraîne le modèle sur un seul ensemble de données (CIFAR-10),"
" nous appelons cela l'apprentissage centralisé. Ce concept "
"d'apprentissage centralisé, comme le montre la section précédente, est "
"probablement connu de la plupart d'entre vous, et beaucoup d'entre vous "
"l'ont déjà utilisé. Normalement, si tu veux exécuter des charges de "
"travail d'apprentissage automatique de manière fédérée, tu dois alors "
"changer la plupart de ton code et tout mettre en place à partir de zéro, "
"ce qui peut représenter un effort considérable."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:173
msgid ""
"However, with Flower you can evolve your pre-existing code into a "
"federated learning setup without the need for a major rewrite."
msgstr ""
"Cependant, avec Flower, tu peux faire évoluer ton code préexistant vers "
"une configuration d'apprentissage fédéré sans avoir besoin d'une "
"réécriture majeure."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:175
msgid ""
"The concept is easy to understand. We have to start a *server* and then "
"use the code in :code:`cifar.py` for the *clients* that are connected to "
"the *server*. The *server* sends model parameters to the clients. The "
"*clients* run the training and update the paramters. The updated "
"parameters are sent back to the *server* which averages all received "
"parameter updates. This describes one round of the federated learning "
"process and we repeat this for multiple rounds."
msgstr ""
"Le concept est facile à comprendre. Nous devons démarrer un *serveur* et "
"utiliser le code dans :code:`cifar.py` pour les *clients* qui sont "
"connectés au *serveur*. Le *serveur* envoie les paramètres du modèle aux "
"clients. Les *clients* exécutent la formation et mettent à jour les "
"paramètres. Les paramètres mis à jour sont renvoyés au *serveur* qui fait"
" la moyenne de toutes les mises à jour de paramètres reçues. Ceci décrit "
"un tour du processus d'apprentissage fédéré et nous répétons cette "
"opération pour plusieurs tours."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:197
msgid ""
"Finally, we will define our *client* logic in :code:`client.py` and build"
" upon the previously defined centralized training in :code:`cifar.py`. "
"Our *client* needs to import :code:`flwr`, but also :code:`torch` to "
"update the paramters on our PyTorch model:"
msgstr ""
"Enfin, nous allons définir notre logique *client* dans :code:`client.py` "
"et nous appuyer sur la formation centralisée définie précédemment dans "
":code:`cifar.py`. Notre *client* doit importer :code:`flwr`, mais aussi "
":code:`torch` pour mettre à jour les paramètres de notre modèle PyTorch :"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:213
msgid ""
"Implementing a Flower *client* basically means implementing a subclass of"
" either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. "
"Our implementation will be based on :code:`flwr.client.NumPyClient` and "
"we'll call it :code:`CifarClient`. :code:`NumPyClient` is slighly easier "
"to implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like PyTorch or TensorFlow/Keras) because it avoids "
"some of the boilerplate that would otherwise be necessary. "
":code:`CifarClient` needs to implement four methods, two methods for "
"getting/setting model parameters, one method for training the model, and "
"one method for testing the model:"
msgstr ""
"Implementing a Flower *client* basically means implementing a subclass of"
" either :code:`flwr.client.Client` or :code:`flwr.client.NumPyClient`. "
"Our implementation will be based on :code:`flwr.client.NumPyClient` and "
"we'll call it :code:`CifarClient`. :code:`NumPyClient` is slighly easier "
"to implement than :code:`Client` if you use a framework with good NumPy "
"interoperability (like PyTorch or TensorFlow/Keras) because it avoids "
"some of the boilerplate that would otherwise be necessary. "
":code:`CifarClient` needs to implement four methods, two methods for "
"getting/setting model parameters, one method for training the model, and "
"one method for testing the model:"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:219
msgid ":code:`set_parameters`"
msgstr ":code:`set_parameters`"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:232
msgid ""
"The two :code:`NumPyClient` methods :code:`fit` and :code:`evaluate` make"
" use of the functions :code:`train()` and :code:`test()` previously "
"defined in :code:`cifar.py`. So what we really do here is we tell Flower "
"through our :code:`NumPyClient` subclass which of our already defined "
"functions to call for training and evaluation. We included type "
"annotations to give you a better understanding of the data types that get"
" passed around."
msgstr ""
"Les deux méthodes :code:`NumPyClient` :code:`fit` et :code:`evaluate` "
"utilisent les fonctions :code:`train()` et :code:`test()` définies "
"précédemment dans :code:`cifar.py`. Ce que nous faisons vraiment ici, "
"c'est que nous indiquons à Flower, par le biais de notre sous-classe "
":code:`NumPyClient`, laquelle de nos fonctions déjà définies doit être "
"appelée pour l'entraînement et l'évaluation. Nous avons inclus des "
"annotations de type pour te donner une meilleure compréhension des types "
"de données qui sont transmis."

#: ../../source/example-pytorch-from-centralized-to-federated.rst:280
msgid ""
"All that's left to do it to define a function that loads both model and "
"data, creates a :code:`CifarClient`, and starts this client. You load "
"your data and model by using :code:`cifar.py`. Start :code:`CifarClient` "
"with the function :code:`fl.client.start_client()` by pointing it "
"at the same IP adress we used in :code:`server.py`:"
msgstr ""
"Il ne reste plus qu'à définir une fonction qui charge le modèle et les "
"données, crée un :code:`CifarClient` et démarre ce client. Tu charges tes"
" données et ton modèle en utilisant :code:`cifar.py`. Démarre "
":code:`CifarClient` avec la fonction "
":code:`fl.client.start_client()` en la faisant pointer sur la même "
"adresse IP que celle que nous avons utilisée dans :code:`server.py` :"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:307
msgid ""
"in each window (make sure that the server is running before you do so) "
"and see your (previously centralized) PyTorch project run federated "
"learning across two clients. Congratulations!"
msgstr ""
"dans chaque fenêtre (assure-toi que le serveur fonctionne avant de le "
"faire) et tu verras ton projet PyTorch (auparavant centralisé) exécuter "
"l'apprentissage fédéré sur deux clients. Félicitations !"

#: ../../source/example-pytorch-from-centralized-to-federated.rst:312
#, fuzzy
msgid ""
"The full source code for this example: `PyTorch: From Centralized To "
"Federated (Code) <https://github.com/adap/flower/blob/main/examples"
"/pytorch-from-centralized-to-federated>`_. Our example is, of course, "
"somewhat over-simplified because both clients load the exact same "
"dataset, which isn't realistic. You're now prepared to explore this topic"
" further. How about using different subsets of CIFAR-10 on each client? "
"How about adding more clients?"
msgstr ""
"Le code source complet de cet exemple : `PyTorch : From Centralized To "
"Federated (Code) <https://github.com/adap/flower/blob/main/examples"
"/pytorch-from-centralized-to-federated>`_. Notre exemple est, bien sûr, "
"un peu trop simplifié parce que les deux clients chargent exactement le "
"même ensemble de données, ce qui n'est pas réaliste. Tu es maintenant "
"prêt à explorer davantage ce sujet. Pourquoi ne pas utiliser différents "
"sous-ensembles de CIFAR-10 sur chaque client ? Pourquoi ne pas ajouter "
"d'autres clients ?"

#: ../../source/example-walkthrough-pytorch-mnist.rst:2
msgid "Example: Walk-Through PyTorch & MNIST"
msgstr "Exemple : PyTorch et MNIST"

#: ../../source/example-walkthrough-pytorch-mnist.rst:4
msgid ""
"In this tutorial we will learn, how to train a Convolutional Neural "
"Network on MNIST using Flower and PyTorch."
msgstr ""
"Dans ce tutoriel, nous allons apprendre, comment former un réseau "
"neuronal convolutif sur MNIST en utilisant Flower et PyTorch."

#: ../../source/example-walkthrough-pytorch-mnist.rst:6
#: ../../source/tutorial-quickstart-mxnet.rst:11
#: ../../source/tutorial-quickstart-pytorch.rst:14
#: ../../source/tutorial-quickstart-scikitlearn.rst:11
msgid ""
"Our example consists of one *server* and two *clients* all having the "
"same model."
msgstr ""
"Notre exemple consiste en un *serveur* et deux *clients* ayant tous le "
"même modèle."

#: ../../source/example-walkthrough-pytorch-mnist.rst:8
#: ../../source/tutorial-quickstart-pytorch.rst:16
msgid ""
"*Clients* are responsible for generating individual weight-updates for "
"the model based on their local datasets. These updates are then sent to "
"the *server* which will aggregate them to produce a better model. "
"Finally, the *server* sends this improved version of the model back to "
"each *client*. A complete cycle of weight updates is called a *round*."
msgstr ""
"*Les clients* sont chargés de générer des mises à jour de poids "
"individuelles pour le modèle en fonction de leurs ensembles de données "
"locales. Ces mises à jour sont ensuite envoyées au *serveur* qui les "
"agrège pour produire un meilleur modèle. Enfin, le *serveur* renvoie "
"cette version améliorée du modèle à chaque *client*. Un cycle complet de "
"mises à jour de poids s'appelle un *round*."

#: ../../source/example-walkthrough-pytorch-mnist.rst:12
#: ../../source/tutorial-quickstart-pytorch.rst:20
msgid ""
"Now that we have a rough idea of what is going on, let's get started. We "
"first need to install Flower. You can do this by running :"
msgstr ""
"Maintenant que nous avons une idée générale de ce qui se passe, "
"commençons. Nous devons d'abord installer Flower. Tu peux le faire en "
"exécutant :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:18
msgid ""
"Since we want to use PyTorch to solve a computer vision task, let's go "
"ahead an install PyTorch and the **torchvision** library:"
msgstr ""
"Puisque nous voulons utiliser PyTorch pour résoudre une tâche de vision "
"par ordinateur, installons PyTorch et la bibliothèque **torchvision** :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:26
msgid "Ready... Set... Train!"
msgstr "Prêts... prêts... entraînez-vous !"

#: ../../source/example-walkthrough-pytorch-mnist.rst:28
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training "
"procedure and network architecture are based on PyTorch's `Basic MNIST "
"Example <https://github.com/pytorch/examples/tree/master/mnist>`_. This "
"will allow you see how easy it is to wrap your code with Flower and begin"
" training in a federated way. We provide you with two helper scripts, "
"namely *run-server.sh*, and *run-clients.sh*. Don't be afraid to look "
"inside, they are simple enough =)."
msgstr ""
"Maintenant que nous avons installé toutes nos dépendances, lançons un "
"simple entraînement distribué avec deux clients et un serveur. Notre "
"procédure d'entraînement et l'architecture de notre réseau sont basées "
"sur l'exemple MNIST de base de PyTorch "
"<https://github.com/pytorch/examples/tree/master/mnist>`_. Cela te "
"permettra de voir à quel point il est facile d'envelopper ton code avec "
"Flower et de commencer l'entraînement de manière fédérée. Nous te "
"fournissons deux scripts d'aide, à savoir *run-server.sh*, et *run-"
"clients.sh*. N'aie pas peur de regarder à l'intérieur, ils sont assez "
"simples =)."

#: ../../source/example-walkthrough-pytorch-mnist.rst:31
msgid ""
"Go ahead and launch on a terminal the *run-server.sh* script first as "
"follows:"
msgstr "Lance sur un terminal le script *run-server.sh* d'abord comme suit :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:38
msgid "Now that the server is up and running, go ahead and launch the clients."
msgstr "Maintenant que le serveur est opérationnel, vas-y et lance les clients."

#: ../../source/example-walkthrough-pytorch-mnist.rst:45
msgid ""
"Et voilà! You should be seeing the training procedure and, after a few "
"iterations, the test accuracy for each client."
msgstr ""
"Et voilà ! Tu devrais voir la procédure d'entraînement et, après quelques"
" itérations, la précision du test pour chaque client."

#: ../../source/example-walkthrough-pytorch-mnist.rst:66
msgid "Now, let's see what is really happening inside."
msgstr "Maintenant, voyons ce qui se passe réellement à l'intérieur."

#: ../../source/example-walkthrough-pytorch-mnist.rst:69
#: ../../source/tutorial-quickstart-ios.rst:126
#: ../../source/tutorial-quickstart-mxnet.rst:221
#: ../../source/tutorial-quickstart-pytorch.rst:200
#: ../../source/tutorial-quickstart-scikitlearn.rst:154
#: ../../source/tutorial-quickstart-tensorflow.rst:95
msgid "Flower Server"
msgstr "Serveur de Flower"

#: ../../source/example-walkthrough-pytorch-mnist.rst:71
msgid ""
"Inside the server helper script *run-server.sh* you will find the "
"following code that basically runs the :code:`server.py`"
msgstr ""
"Dans le script d'aide au serveur *run-server.sh*, tu trouveras le code "
"suivant qui exécute le fichier :code:`server.py`"

#: ../../source/example-walkthrough-pytorch-mnist.rst:78
msgid ""
"We can go a bit deeper and see that :code:`server.py` simply launches a "
"server that will coordinate three rounds of training. Flower Servers are "
"very customizable, but for simple workloads, we can start a server using "
"the :ref:`start_server <flwr-server-start_server-apiref>` function and "
"leave all the configuration possibilities at their default values, as "
"seen below."
msgstr ""
"Nous pouvons aller un peu plus loin et voir que :code:`server.py` lance "
"simplement un serveur qui coordonnera trois tours de formation. Flower "
"Les serveurs sont très personnalisables, mais pour les charges de travail"
" simples, nous pouvons démarrer un serveur à l'aide de la fonction "
":ref:`start_server <flwr-server-start_server-apiref>` et laisser toutes "
"les possibilités de configuration à leurs valeurs par défaut, comme on "
"peut le voir ci-dessous."

#: ../../source/example-walkthrough-pytorch-mnist.rst:89
#: ../../source/tutorial-quickstart-ios.rst:31
#: ../../source/tutorial-quickstart-mxnet.rst:31
#: ../../source/tutorial-quickstart-pytorch.rst:34
#: ../../source/tutorial-quickstart-scikitlearn.rst:37
#: ../../source/tutorial-quickstart-tensorflow.rst:26
msgid "Flower Client"
msgstr "Client de la fleur"

#: ../../source/example-walkthrough-pytorch-mnist.rst:91
msgid ""
"Next, let's take a look at the *run-clients.sh* file. You will see that "
"it contains the main loop that starts a set of *clients*."
msgstr ""
"Ensuite, jetons un coup d'œil au fichier *run-clients.sh*. Tu verras "
"qu'il contient la boucle principale qui démarre un ensemble de *clients*."

#: ../../source/example-walkthrough-pytorch-mnist.rst:100
msgid ""
"**cid**: is the client ID. It is an integer that uniquely identifies "
"client identifier."
msgstr ""
"**cid** : c'est l'identifiant du client. C'est un nombre entier qui "
"identifie de façon unique l'identifiant du client."

#: ../../source/example-walkthrough-pytorch-mnist.rst:101
msgid "**sever_address**: String that identifies IP and port of the server."
msgstr "**sever_address** : Chaîne qui identifie l'IP et le port du serveur."

#: ../../source/example-walkthrough-pytorch-mnist.rst:102
msgid ""
"**nb_clients**: This defines the number of clients being created. This "
"piece of information is not required by the client, but it helps us "
"partition the original MNIST dataset to make sure that every client is "
"working on unique subsets of both *training* and *test* sets."
msgstr ""
"**Cette information n'est pas requise par le client, mais elle nous aide "
"à partitionner l'ensemble de données MNIST original pour nous assurer que"
" chaque client travaille sur des sous-ensembles uniques des ensembles "
"*formation* et *test*."

#: ../../source/example-walkthrough-pytorch-mnist.rst:104
#, fuzzy
msgid ""
"Again, we can go deeper and look inside :code:`flwr_example/quickstart-"
"pytorch/client.py`. After going through the argument parsing code at the "
"beginning of our :code:`main` function, you will find a call to "
":code:`mnist.load_data`. This function is responsible for partitioning "
"the original MNIST datasets (*training* and *test*) and returning a "
":code:`torch.utils.data.DataLoader` s for each of them. We then "
"instantiate a :code:`PytorchMNISTClient` object with our client ID, our "
"DataLoaders, the number of epochs in each round, and which device we want"
" to use for training (CPU or GPU)."
msgstr ""
"Encore une fois, nous pouvons aller plus loin et regarder dans "
":code:`flwr_example/quickstart-pytorch/client.py`. Après avoir parcouru "
"le code d'analyse des arguments au début de notre fonction :code:`main`, "
"tu trouveras un appel à :code:`mnist.load_data`. Cette fonction est "
"responsable du partitionnement des ensembles de données MNIST originaux "
"(*training* et *test*) et renvoie un :code:`torch.utils.data.DataLoader` "
"s pour chacun d'entre eux. Nous instancions ensuite un objet "
":code:`PytorchMNISTClient` avec notre ID client, nos DataLoaders, le "
"nombre d'époques dans chaque tour et le périphérique que nous voulons "
"utiliser pour l'entraînement (CPU ou GPU)."

#: ../../source/example-walkthrough-pytorch-mnist.rst:119
msgid ""
"The :code:`PytorchMNISTClient` object when finally passed to "
":code:`fl.client.start_client` along with the server's address as the "
"training process begins."
msgstr ""
"L'objet :code:`PytorchMNISTClient` est finalement transmis à "
":code:`fl.client.start_client` avec l'adresse du serveur lorsque le "
"processus de formation commence."

#: ../../source/example-walkthrough-pytorch-mnist.rst:123
msgid "A Closer Look"
msgstr "Regarder de plus près"

#: ../../source/example-walkthrough-pytorch-mnist.rst:125
#, fuzzy
msgid ""
"Now, let's look closely into the :code:`PytorchMNISTClient` inside "
":code:`flwr_example.quickstart-pytorch.mnist` and see what it is doing:"
msgstr ""
"Maintenant, examinons de près le :code:`PytorchMNISTClient` à l'intérieur"
" du :code:`flwr_example.quickstart-pytorch.mnist` et voyons ce qu'il fait"
" :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:226
msgid ""
"The first thing to notice is that :code:`PytorchMNISTClient` instantiates"
" a CNN model inside its constructor"
msgstr ""
"La première chose à remarquer est que :code:`PytorchMNISTClient` "
"instancie un modèle CNN dans son constructeur"

#: ../../source/example-walkthrough-pytorch-mnist.rst:244
#, fuzzy
msgid ""
"The code for the CNN is available under :code:`quickstart-pytorch.mnist` "
"and it is reproduced below. It is the same network found in `Basic MNIST "
"Example <https://github.com/pytorch/examples/tree/master/mnist>`_."
msgstr ""
"Le code du CNN est disponible sous :code:`quickstart-pytorch.mnist` et il"
" est reproduit ci-dessous. Il s'agit du même réseau que celui que l'on "
"trouve dans `Exemple basique de MNIST "
"<https://github.com/pytorch/examples/tree/master/mnist>`_."

#: ../../source/example-walkthrough-pytorch-mnist.rst:290
msgid ""
"The second thing to notice is that :code:`PytorchMNISTClient` class "
"inherits from the :code:`fl.client.Client`, and hence it must implement "
"the following methods:"
msgstr ""
"La deuxième chose à noter est que la classe :code:`PytorchMNISTClient` "
"hérite de :code:`fl.client.Client`, et qu'elle doit donc implémenter les "
"méthodes suivantes :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:315
msgid ""
"When comparing the abstract class to its derived class "
":code:`PytorchMNISTClient` you will notice that :code:`fit` calls a "
":code:`train` function and that :code:`evaluate` calls a :code:`test`: "
"function."
msgstr ""
"En comparant la classe abstraite à sa classe dérivée "
":code:`PytorchMNISTClient`, tu remarqueras que :code:`fit` appelle une "
"fonction :code:`train` et que :code:`evaluate` appelle une fonction "
":code:`test` :."

#: ../../source/example-walkthrough-pytorch-mnist.rst:317
#, fuzzy
msgid ""
"These functions can both be found inside the same :code:`quickstart-"
"pytorch.mnist` module:"
msgstr ""
"Ces fonctions se trouvent toutes deux dans le même module :code"
":`quickstart-pytorch.mnist` :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:437
msgid ""
"Observe that these functions encapsulate regular training and test loops "
"and provide :code:`fit` and :code:`evaluate` with final statistics for "
"each round. You could substitute them with your custom train and test "
"loops and change the network architecture, and the entire example would "
"still work flawlessly. As a matter of fact, why not try and modify the "
"code to an example of your liking?"
msgstr ""
"Observe que ces fonctions encapsulent les boucles d'entraînement et de "
"test habituelles et fournissent à :code:`fit` et :code:`evaluate` les "
"statistiques finales pour chaque tour. Tu pourrais les remplacer par tes "
"boucles d'entraînement et de test personnalisées et changer "
"l'architecture du réseau, et l'ensemble de l'exemple fonctionnerait "
"toujours parfaitement. En fait, pourquoi ne pas essayer de modifier le "
"code pour en faire un exemple qui te plairait ?"

#: ../../source/example-walkthrough-pytorch-mnist.rst:444
msgid "Give It a Try"
msgstr "Fais un essai"

#: ../../source/example-walkthrough-pytorch-mnist.rst:445
msgid ""
"Looking through the quickstart code description above will have given a "
"good understanding of how *clients* and *servers* work in Flower, how to "
"run a simple experiment, and the internals of a client wrapper. Here are "
"a few things you could try on your own and get more experience with "
"Flower:"
msgstr ""
"En parcourant la description du code de démarrage rapide ci-dessus, tu "
"auras acquis une bonne compréhension du fonctionnement des *clients* et "
"des *serveurs* dans Flower, de l'exécution d'une expérience simple et de "
"la structure interne d'un wrapper client. Voici quelques exemples que tu "
"peux essayer par toi-même pour acquérir plus d'expérience avec Flower :"

#: ../../source/example-walkthrough-pytorch-mnist.rst:448
msgid ""
"Try and change :code:`PytorchMNISTClient` so it can accept different "
"architectures."
msgstr ""
"Essaie de modifier :code:`PytorchMNISTClient` pour qu'il puisse accepter "
"différentes architectures."

#: ../../source/example-walkthrough-pytorch-mnist.rst:449
msgid "Modify the :code:`train` function so that it accepts different optimizers"
msgstr ""
"Modifie la fonction :code:`train` pour qu'elle accepte différents "
"optimiseurs"

#: ../../source/example-walkthrough-pytorch-mnist.rst:450
msgid ""
"Modify the :code:`test` function so that it proves not only the top-1 "
"(regular accuracy) but also the top-5 accuracy?"
msgstr ""
"Modifie la fonction :code:`test` pour qu'elle prouve non seulement le "
"top-1 (précision normale) mais aussi le top-5 ?"

#: ../../source/example-walkthrough-pytorch-mnist.rst:451
msgid ""
"Go larger! Try to adapt the code to larger images and datasets. Why not "
"try training on ImageNet with a ResNet-50?"
msgstr ""
"Essaie d'adapter le code à des images et à des ensembles de données plus "
"grands. Pourquoi ne pas essayer de s'entraîner sur ImageNet avec un "
"ResNet-50 ?"

#: ../../source/example-walkthrough-pytorch-mnist.rst:453
msgid "You are ready now. Enjoy learning in a federated way!"
msgstr "Tu es prêt maintenant. Profite de l'apprentissage de manière fédérée !"

#: ../../source/explanation-differential-privacy.rst:2
#, fuzzy
msgid "Differential privacy"
msgstr "Confidentialité différentielle"

#: ../../source/explanation-differential-privacy.rst:4
msgid ""
"Flower provides differential privacy (DP) wrapper classes for the easy "
"integration of the central DP guarantees provided by DP-FedAvg into "
"training pipelines defined in any of the various ML frameworks that "
"Flower is compatible with."
msgstr ""
"Flower fournit des classes d'enveloppe de confidentialité différentielle "
"(DP) pour l'intégration facile des garanties centrales de DP fournies par"
" DP-FedAvg dans les pipelines de formation définis dans n'importe lequel "
"des divers cadres de ML avec lesquels Flower est compatible."

#: ../../source/explanation-differential-privacy.rst:7
msgid ""
"Please note that these components are still experimental, the correct "
"configuration of DP for a specific task is still an unsolved problem."
msgstr ""
"Note que ces composants sont encore expérimentaux, la configuration "
"correcte du DP pour une tâche spécifique est encore un problème non "
"résolu."

#: ../../source/explanation-differential-privacy.rst:10
msgid ""
"The name DP-FedAvg is misleading since it can be applied on top of any FL"
" algorithm that conforms to the general structure prescribed by the "
"FedOpt family of algorithms."
msgstr ""
"Le nom DP-FedAvg est trompeur car il peut être appliqué à n'importe quel "
"algorithme FL qui se conforme à la structure générale prescrite par la "
"famille d'algorithmes FedOpt."

#: ../../source/explanation-differential-privacy.rst:13
msgid "DP-FedAvg"
msgstr "DP-FedAvg"

#: ../../source/explanation-differential-privacy.rst:15
msgid ""
"DP-FedAvg, originally proposed by McMahan et al. [mcmahan]_ and extended "
"by Andrew et al. [andrew]_, is essentially FedAvg with the following "
"modifications."
msgstr ""
"DP-FedAvg, proposé à l'origine par McMahan et al. [mcmahan]_ et étendu "
"par Andrew et al. [andrew]_, est essentiellement FedAvg avec les "
"modifications suivantes."

#: ../../source/explanation-differential-privacy.rst:17
msgid ""
"**Clipping** : The influence of each client's update is bounded by "
"clipping it. This is achieved by enforcing a cap on the L2 norm of the "
"update, scaling it down if needed."
msgstr ""
"**Clipping** : L'influence de la mise à jour de chaque client est limitée"
" en l'écrêtant. Ceci est réalisé en imposant un plafond à la norme L2 de "
"la mise à jour, en la réduisant si nécessaire."

#: ../../source/explanation-differential-privacy.rst:18
msgid ""
"**Noising** :  Gaussian noise, calibrated to the clipping threshold, is "
"added to the average computed at the server."
msgstr ""
"**Bruit** : un bruit gaussien, calibré sur le seuil d'écrêtage, est "
"ajouté à la moyenne calculée au niveau du serveur."

#: ../../source/explanation-differential-privacy.rst:20
msgid ""
"The distribution of the update norm has been shown to vary from task-to-"
"task and to evolve as training progresses. Therefore, we use an adaptive "
"approach [andrew]_ that continuously adjusts the clipping threshold to "
"track a prespecified quantile of the update norm distribution."
msgstr ""
"Il a été démontré que la distribution de la norme de mise à jour varie "
"d'une tâche à l'autre et évolue au fur et à mesure de la formation. C'est"
" pourquoi nous utilisons une approche adaptative [andrew]_ qui ajuste "
"continuellement le seuil d'écrêtage pour suivre un quantile prédéfini de "
"la distribution de la norme de mise à jour."

#: ../../source/explanation-differential-privacy.rst:23
msgid "Simplifying Assumptions"
msgstr "Simplifier les hypothèses"

#: ../../source/explanation-differential-privacy.rst:25
msgid ""
"We make (and attempt to enforce) a number of assumptions that must be "
"satisfied to ensure that the training process actually realises the "
":math:`(\\epsilon, \\delta)` guarantees the user has in mind when "
"configuring the setup."
msgstr ""
"Nous formulons (et tentons d'appliquer) un certain nombre d'hypothèses "
"qui doivent être satisfaites pour que le processus de formation réalise "
"réellement les garanties :math:`(\\epsilon, \\delta)` que l'utilisateur a"
" à l'esprit lorsqu'il configure l'installation."

#: ../../source/explanation-differential-privacy.rst:27
msgid ""
"**Fixed-size subsampling** :Fixed-size subsamples of the clients must be "
"taken at each round, as opposed to variable-sized Poisson subsamples."
msgstr ""
"**Sous-échantillonnage de taille fixe** :Des sous-échantillons de taille "
"fixe des clients doivent être prélevés à chaque tour, par opposition aux "
"sous-échantillons de Poisson de taille variable."

#: ../../source/explanation-differential-privacy.rst:28
msgid ""
"**Unweighted averaging** : The contributions from all the clients must "
"weighted equally in the aggregate to eliminate the requirement for the "
"server to know in advance the sum of the weights of all clients available"
" for selection."
msgstr ""
"**Moyenne non pondérée** : Les contributions de tous les clients doivent "
"être pondérées de façon égale dans l'ensemble afin que le serveur n'ait "
"pas à connaître à l'avance la somme des poids de tous les clients "
"disponibles pour la sélection."

#: ../../source/explanation-differential-privacy.rst:29
msgid ""
"**No client failures** : The set of available clients must stay constant "
"across all rounds of training. In other words, clients cannot drop out or"
" fail."
msgstr ""
"**Aucune défaillance de client** : L'ensemble des clients disponibles "
"doit rester constant pendant toutes les séries de formation. En d'autres "
"termes, les clients ne peuvent pas abandonner ou échouer."

#: ../../source/explanation-differential-privacy.rst:31
msgid ""
"The first two are useful for eliminating a multitude of complications "
"associated with calibrating the noise to the clipping threshold while the"
" third one is required to comply with the assumptions of the privacy "
"analysis."
msgstr ""
"Les deux premiers sont utiles pour éliminer une multitude de "
"complications liées au calibrage du bruit en fonction du seuil "
"d'écrêtage, tandis que le troisième est nécessaire pour se conformer aux "
"hypothèses de l'analyse de la vie privée."

#: ../../source/explanation-differential-privacy.rst:34
msgid ""
"These restrictions are in line with constraints imposed by Andrew et al. "
"[andrew]_."
msgstr ""
"Ces restrictions sont conformes aux contraintes imposées par Andrew et "
"al. [andrew]_."

#: ../../source/explanation-differential-privacy.rst:37
msgid "Customizable Responsibility for Noise injection"
msgstr "Responsabilité personnalisable pour l'injection de bruit"

#: ../../source/explanation-differential-privacy.rst:38
msgid ""
"In contrast to other implementations where the addition of noise is "
"performed at the server, you can configure the site of noise injection to"
" better match your threat model. We provide users with the flexibility to"
" set up the training such that each client independently adds a small "
"amount of noise to the clipped update, with the result that simply "
"aggregating the noisy updates is equivalent to the explicit addition of "
"noise to the non-noisy aggregate at the server."
msgstr ""
"Contrairement à d'autres implémentations où l'ajout de bruit est effectué"
" au niveau du serveur, tu peux configurer le site d'injection de bruit "
"pour qu'il corresponde mieux à ton modèle de menace. Nous offrons aux "
"utilisateurs la possibilité de configurer l'entraînement de telle sorte "
"que chaque client ajoute indépendamment une petite quantité de bruit à la"
" mise à jour écrêtée, ce qui fait que le simple fait d'agréger les mises "
"à jour bruyantes équivaut à l'ajout explicite de bruit à l'agrégat non "
"bruyant au niveau du serveur."

#: ../../source/explanation-differential-privacy.rst:41
msgid ""
"To be precise, if we let :math:`m` be the number of clients sampled each "
"round and :math:`\\sigma_\\Delta` be the scale of the total Gaussian "
"noise that needs to be added to the sum of the model updates, we can use "
"simple maths to show that this is equivalent to each client adding noise "
"with scale :math:`\\sigma_\\Delta/\\sqrt{m}`."
msgstr ""
"Pour être précis, si nous laissons :math:`m` être le nombre de clients "
"échantillonnés à chaque tour et :math:\\sigma_\\Delta` être l'échelle du "
"bruit gaussien total qui doit être ajouté à la somme des mises à jour du "
"modèle, nous pouvons utiliser des mathématiques simples pour montrer que "
"cela équivaut à ce que chaque client ajoute du bruit avec l'échelle "
":math:\\sigma_\\Delta/\\sqrt{m}`."

#: ../../source/explanation-differential-privacy.rst:44
msgid "Wrapper-based approach"
msgstr "Approche basée sur l'enveloppe"

#: ../../source/explanation-differential-privacy.rst:46
msgid ""
"Introducing DP to an existing workload can be thought of as adding an "
"extra layer of security around it. This inspired us to provide the "
"additional server and client-side logic needed to make the training "
"process differentially private as wrappers for instances of the "
":code:`Strategy` and :code:`NumPyClient` abstract classes respectively. "
"This wrapper-based approach has the advantage of being easily composable "
"with other wrappers that someone might contribute to the Flower library "
"in the future, e.g., for secure aggregation. Using Inheritance instead "
"can be tedious because that would require the creation of new sub- "
"classes every time a new class implementing :code:`Strategy` or "
":code:`NumPyClient` is defined."
msgstr ""
"L'introduction du DP dans une charge de travail existante peut être "
"considérée comme l'ajout d'une couche de sécurité supplémentaire autour "
"d'elle. Cela nous a incités à fournir la logique supplémentaire côté "
"serveur et côté client nécessaire pour rendre le processus de formation "
"différentiellement privé en tant qu'enveloppes pour les instances des "
"classes abstraites :code:`Strategy` et :code:`NumPyClient` "
"respectivement. Cette approche basée sur l'enveloppe a l'avantage d'être "
"facilement composable avec d'autres enveloppes que quelqu'un pourrait "
"contribuer à la bibliothèque Flower à l'avenir, par exemple, pour "
"l'agrégation sécurisée. L'utilisation de l'héritage à la place peut être "
"fastidieuse car cela nécessiterait la création de nouvelles sous-classes "
"chaque fois qu'une nouvelle classe mettant en œuvre :code:`Strategy` ou "
":code:`NumPyClient` est définie."

#: ../../source/explanation-differential-privacy.rst:49
msgid "Server-side logic"
msgstr "Logique côté serveur"

#: ../../source/explanation-differential-privacy.rst:51
msgid ""
"The first version of our solution was to define a decorator whose "
"constructor accepted, among other things, a boolean valued variable "
"indicating whether adaptive clipping was to be enabled or not. We quickly"
" realized that this would clutter its :code:`__init__()` function with "
"variables corresponding to hyperparameters of adaptive clipping that "
"would remain unused when it was disabled. A cleaner implementation could "
"be achieved by splitting the functionality into two decorators, "
":code:`DPFedAvgFixed` and :code:`DPFedAvgAdaptive`, with the latter sub- "
"classing the former. The constructors for both classes accept a boolean "
"parameter :code:`server_side_noising`, which, as the name suggests, "
"determines where noising is to be performed."
msgstr ""
"La première version de notre solution consistait à définir un décorateur "
"dont le constructeur acceptait, entre autres, une variable à valeur "
"booléenne indiquant si l'écrêtage adaptatif devait être activé ou non. "
"Nous nous sommes rapidement rendu compte que cela encombrerait sa "
"fonction :code:`__init__()` avec des variables correspondant aux "
"hyperparamètres de l'écrêtage adaptatif qui resteraient inutilisées "
"lorsque celui-ci était désactivé. Une implémentation plus propre pourrait"
" être obtenue en divisant la fonctionnalité en deux décorateurs, "
":code:`DPFedAvgFixed` et :code:`DPFedAvgAdaptive`, le second sous-"
"classant le premier. Les constructeurs des deux classes acceptent un "
"paramètre booléen :code:`server_side_noising` qui, comme son nom "
"l'indique, détermine l'endroit où le noising doit être effectué."

#: ../../source/explanation-differential-privacy.rst:54
msgid "DPFedAvgFixed"
msgstr "DPFedAvgFixed"

#: ../../source/explanation-differential-privacy.rst:56
msgid ""
"The server-side capabilities required for the original version of DP-"
"FedAvg, i.e., the one which performed fixed clipping, can be completely "
"captured with the help of wrapper logic for just the following two "
"methods of the :code:`Strategy` abstract class."
msgstr ""
"Les capacités côté serveur requises pour la version originale de DP-"
"FedAvg, c'est-à-dire celle qui effectue un écrêtage fixe, peuvent être "
"entièrement capturées à l'aide d'une logique d'enveloppement pour les "
"deux méthodes suivantes de la classe abstraite :code:`Strategy`."

#: ../../source/explanation-differential-privacy.rst:58
msgid ""
":code:`configure_fit()` : The config dictionary being sent by the wrapped"
" :code:`Strategy` to each client needs to be augmented with an additional"
" value equal to the clipping threshold (keyed under "
":code:`dpfedavg_clip_norm`) and, if :code:`server_side_noising=true`, "
"another one equal to the scale of the Gaussian noise that needs to be "
"added at the client (keyed under :code:`dpfedavg_noise_stddev`). This "
"entails *post*-processing of the results returned by the wrappee's "
"implementation of :code:`configure_fit()`."
msgstr ""
":code:`configure_fit()` : Le dictionnaire de configuration envoyé par la "
":code:`Strategy` enveloppée à chaque client doit être augmenté d'une "
"valeur supplémentaire égale au seuil d'écrêtage (indiqué sous "
":code:`dpfedavg_clip_norm`) et, si :code:`server_side_noising=true`, "
"d'une autre égale à l'échelle du bruit gaussien qui doit être ajouté au "
"client (indiqué sous :code:`dpfedavg_noise_stddev`)."

#: ../../source/explanation-differential-privacy.rst:59
msgid ""
":code:`aggregate_fit()`: We check whether any of the sampled clients "
"dropped out or failed to upload an update before the round timed out. In "
"that case, we need to abort the current round, discarding any successful "
"updates that were received, and move on to the next one. On the other "
"hand, if all clients responded successfully, we must force the averaging "
"of the updates to happen in an unweighted manner by intercepting the "
":code:`parameters` field of :code:`FitRes` for each received update and "
"setting it to 1. Furthermore, if :code:`server_side_noising=true`, each "
"update is perturbed with an amount of noise equal to what it would have "
"been subjected to had client-side noising being enabled.  This entails "
"*pre*-processing of the arguments to this method before passing them on "
"to the wrappee's implementation of :code:`aggregate_fit()`."
msgstr ""
":code:`aggregate_fit()`: We check whether any of the sampled clients "
"dropped out or failed to upload an update before the round timed out. In "
"that case, we need to abort the current round, discarding any successful "
"updates that were received, and move on to the next one. On the other "
"hand, if all clients responded successfully, we must force the averaging "
"of the updates to happen in an unweighted manner by intercepting the "
":code:`parameters` field of :code:`FitRes` for each received update and "
"setting it to 1. Furthermore, if :code:`server_side_noising=true`, each "
"update is perturbed with an amount of noise equal to what it would have "
"been subjected to had client-side noising being enabled. This entails "
"*pre*-processing of the arguments to this method before passing them on "
"to the wrappee's implementation of :code:`aggregate_fit()`."

#: ../../source/explanation-differential-privacy.rst:62
msgid ""
"We can't directly change the aggregation function of the wrapped strategy"
" to force it to add noise to the aggregate, hence we simulate client-side"
" noising to implement server-side noising."
msgstr ""
"Nous ne pouvons pas modifier directement la fonction d'agrégation de la "
"stratégie enveloppée pour la forcer à ajouter du bruit à l'agrégat, c'est"
" pourquoi nous simulons le bruit côté client pour mettre en œuvre le "
"bruit côté serveur."

#: ../../source/explanation-differential-privacy.rst:64
msgid ""
"These changes have been put together into a class called "
":code:`DPFedAvgFixed`, whose constructor accepts the strategy being "
"decorated, the clipping threshold and the number of clients sampled every"
" round as compulsory arguments. The user is expected to specify the "
"clipping threshold since the order of magnitude of the update norms is "
"highly dependent on the model being trained and providing a default value"
" would be misleading. The number of clients sampled at every round is "
"required to calculate the amount of noise that must be added to each "
"individual update, either by the server or the clients."
msgstr ""
"Ces modifications ont été regroupées dans une classe appelée "
":code:`DPFedAvgFixed`, dont le constructeur accepte la stratégie décorée,"
" le seuil d'écrêtage et le nombre de clients échantillonnés à chaque tour"
" comme arguments obligatoires. L'utilisateur est censé spécifier le seuil"
" d'écrêtage car l'ordre de grandeur des normes de mise à jour dépend "
"fortement du modèle formé et fournir une valeur par défaut serait "
"trompeur. Le nombre de clients échantillonnés à chaque tour est "
"nécessaire pour calculer la quantité de bruit qui doit être ajoutée à "
"chaque mise à jour individuelle, que ce soit par le serveur ou par les "
"clients."

#: ../../source/explanation-differential-privacy.rst:67
msgid "DPFedAvgAdaptive"
msgstr "DPFedAvgAdaptive"

#: ../../source/explanation-differential-privacy.rst:69
msgid ""
"The additional functionality required to facilitate adaptive clipping has"
" been provided in :code:`DPFedAvgAdaptive`, a subclass of "
":code:`DPFedAvgFixed`. It overrides the above-mentioned methods to do the"
" following."
msgstr ""
"La fonctionnalité supplémentaire nécessaire pour faciliter l'écrêtage "
"adaptatif a été fournie dans :code:`DPFedAvgAdaptive`, une sous-classe de"
" :code:`DPFedAvgFixed`. Elle remplace les méthodes mentionnées ci-dessus "
"pour effectuer les opérations suivantes."

#: ../../source/explanation-differential-privacy.rst:71
msgid ""
":code:`configure_fit()` : It intercepts the config dict returned by "
":code:`super.configure_fit()` to add the key-value pair "
":code:`dpfedavg_adaptive_clip_enabled:True` to it, which the client "
"interprets as an instruction to include an indicator bit (1 if update "
"norm <= clipping threshold, 0 otherwise) in the results returned by it."
msgstr ""
":code:`configure_fit()` : Il intercepte le dict de configuration renvoyé "
"par :code:`super.configure_fit()` pour y ajouter la paire clé-valeur "
":code:`dpfedavg_adaptive_clip_enabled:True`, que le client interprète "
"comme une instruction d'inclure un bit indicateur (1 si la norme de mise "
"à jour <= seuil d'écrêtage, 0 sinon) dans les résultats qu'il renvoie."

#: ../../source/explanation-differential-privacy.rst:73
msgid ""
":code:`aggregate_fit()` : It follows a call to "
":code:`super.aggregate_fit()` with one to :code:`__update_clip_norm__()`,"
" a procedure which adjusts the clipping threshold on the basis of the "
"indicator bits received from the sampled clients."
msgstr ""
":code:`aggregate_fit()` : Il fait suivre un appel à "
":code:`super.aggregate_fit()` d'un appel à "
":code:`__update_clip_norm__()`, une procédure qui ajuste le seuil "
"d'écrêtage sur la base des bits indicateurs reçus des clients "
"échantillonnés."

#: ../../source/explanation-differential-privacy.rst:77
msgid "Client-side logic"
msgstr "Logique côté client"

#: ../../source/explanation-differential-privacy.rst:79
msgid ""
"The client-side capabilities required can be completely captured through "
"wrapper logic for just the :code:`fit()` method of the "
":code:`NumPyClient` abstract class. To be precise, we need to *post-"
"process* the update computed by the wrapped client to clip it, if "
"necessary, to the threshold value supplied by the server as part of the "
"config dictionary. In addition to this, it may need to perform some extra"
" work if either (or both) of the following keys are also present in the "
"dict."
msgstr ""
"Les capacités requises côté client peuvent être entièrement capturées par"
" une logique de wrapper pour la seule méthode :code:`fit()` de la classe "
"abstraite :code:`NumPyClient`. Pour être précis, nous devons *post-"
"traiter* la mise à jour calculée par le client wrapped pour l'écrêter, si"
" nécessaire, à la valeur seuil fournie par le serveur dans le cadre du "
"dictionnaire de configuration. En plus de cela, il peut avoir besoin "
"d'effectuer un travail supplémentaire si l'une des clés suivantes (ou les"
" deux) est également présente dans le dict."

#: ../../source/explanation-differential-privacy.rst:81
msgid ""
":code:`dpfedavg_noise_stddev` : Generate and add the specified amount of "
"noise to the clipped update."
msgstr ""
":code:`dpfedavg_noise_stddev` : Génère et ajoute la quantité de bruit "
"spécifiée à la mise à jour de l'écrêtage."

#: ../../source/explanation-differential-privacy.rst:82
msgid ""
":code:`dpfedavg_adaptive_clip_enabled` : Augment the metrics dict in the "
":code:`FitRes` object being returned to the server with an indicator bit,"
" calculated as described earlier."
msgstr ""
":code:`dpfedavg_adaptive_clip_enabled` : Complète les métriques dict dans"
" l'objet :code:`FitRes` renvoyé au serveur avec un bit indicateur, "
"calculé comme décrit précédemment."

#: ../../source/explanation-differential-privacy.rst:86
msgid "Performing the :math:`(\\epsilon, \\delta)` analysis"
msgstr "Effectuer l'analyse :math:`(\\epsilon, \\delta)`"

#: ../../source/explanation-differential-privacy.rst:88
msgid ""
"Assume you have trained for :math:`n` rounds with sampling fraction "
":math:`q` and noise multiplier :math:`z`. In order to calculate the "
":math:`\\epsilon` value this would result in for a particular "
":math:`\\delta`, the following script may be used."
msgstr ""
"Supposons que tu te sois entraîné pendant :math:`n` tours avec la "
"fraction d'échantillonnage :math:`q` et le multiplicateur de bruit "
":math:`z`. Afin de calculer la valeur :math:`epsilon` qui en résulterait "
"pour un :math:`\\delta` particulier, le script suivant peut être utilisé."

#: ../../source/explanation-differential-privacy.rst:98
msgid ""
"McMahan, H. Brendan, et al. \"Learning differentially private recurrent "
"language models.\" arXiv preprint arXiv:1710.06963 (2017)."
msgstr ""
"McMahan, H. Brendan, et al. \"Learning differentially private recurrent "
"language models\", arXiv preprint arXiv:1710.06963 (2017)."

#: ../../source/explanation-differential-privacy.rst:100
msgid ""
"Andrew, Galen, et al. \"Differentially private learning with adaptive "
"clipping.\" Advances in Neural Information Processing Systems 34 (2021): "
"17455-17466."
msgstr ""
"Andrew, Galen, et al. \"Differentially private learning with adaptive "
"clipping\" Advances in Neural Information Processing Systems 34 (2021) : "
"17455-17466."

#: ../../source/explanation-federated-evaluation.rst:2
#: ../../source/tutorial-what-is-federated-learning.ipynb:292
msgid "Federated evaluation"
msgstr "Évaluation fédérée"

#: ../../source/explanation-federated-evaluation.rst:4
msgid ""
"There are two main approaches to evaluating models in federated learning "
"systems: centralized (or server-side) evaluation and federated (or "
"client-side) evaluation."
msgstr ""
"Il existe deux approches principales pour évaluer les modèles dans les "
"systèmes d'apprentissage fédérés : l'évaluation centralisée (ou côté "
"serveur) et l'évaluation fédérée (ou côté client)."

#: ../../source/explanation-federated-evaluation.rst:8
msgid "Centralized Evaluation"
msgstr "Évaluation centralisée"

#: ../../source/explanation-federated-evaluation.rst:11
msgid "Built-In Strategies"
msgstr "Stratégies intégrées"

#: ../../source/explanation-federated-evaluation.rst:13
msgid ""
"All built-in strategies support centralized evaluation by providing an "
"evaluation function during initialization. An evaluation function is any "
"function that can take the current global model parameters as input and "
"return evaluation results:"
msgstr ""
"Toutes les stratégies intégrées prennent en charge l'évaluation "
"centralisée en fournissant une fonction d'évaluation lors de "
"l'initialisation. Une fonction d'évaluation est une fonction qui peut "
"prendre les paramètres du modèle global actuel comme entrée et renvoyer "
"les résultats de l'évaluation :"

#: ../../source/explanation-federated-evaluation.rst:58
msgid "Custom Strategies"
msgstr "Stratégies personnalisées"

#: ../../source/explanation-federated-evaluation.rst:60
msgid ""
"The :code:`Strategy` abstraction provides a method called "
":code:`evaluate` that can directly be used to evaluate the current global"
" model parameters. The current server implementation calls "
":code:`evaluate` after parameter aggregation and before federated "
"evaluation (see next paragraph)."
msgstr ""
"L'abstraction :code:`Strategy` fournit une méthode appelée "
":code:`evaluate` qui peut être directement utilisée pour évaluer les "
"paramètres du modèle global actuel. L'implémentation actuelle du serveur "
"appelle :code:`evaluate` après l'agrégation des paramètres et avant "
"l'évaluation fédérée (voir le paragraphe suivant)."

#: ../../source/explanation-federated-evaluation.rst:65
msgid "Federated Evaluation"
msgstr "Évaluation fédérée"

#: ../../source/explanation-federated-evaluation.rst:68
msgid "Implementing Federated Evaluation"
msgstr "Mise en œuvre de l'évaluation fédérée"

#: ../../source/explanation-federated-evaluation.rst:70
msgid ""
"Client-side evaluation happens in the :code:`Client.evaluate` method and "
"can be configured from the server side."
msgstr ""
"L'évaluation côté client se fait dans la méthode :code:`Client.evaluate` "
"et peut être configurée côté serveur."

#: ../../source/explanation-federated-evaluation.rst:101
msgid "Configuring Federated Evaluation"
msgstr "Configuration de l'évaluation fédérée"

#: ../../source/explanation-federated-evaluation.rst:103
msgid ""
"Federated evaluation can be configured from the server side. Built-in "
"strategies support the following arguments:"
msgstr ""
"L'évaluation fédérée peut être configurée du côté du serveur. Les "
"stratégies intégrées prennent en charge les arguments suivants :"

#: ../../source/explanation-federated-evaluation.rst:105
msgid ""
":code:`fraction_evaluate`: a :code:`float` defining the fraction of "
"clients that will be selected for evaluation. If "
":code:`fraction_evaluate` is set to :code:`0.1` and :code:`100` clients "
"are connected to the server, then :code:`10` will be randomly selected "
"for evaluation. If :code:`fraction_evaluate` is set to :code:`0.0`, "
"federated evaluation will be disabled."
msgstr ""
":code:`fraction_evaluate` : un :code:`float` définissant la fraction de "
"clients qui sera sélectionnée pour l'évaluation. Si "
":code:`fraction_evaluate` est défini à :code:`0.1` et que :code:`100` "
"clients sont connectés au serveur, alors :code:`10` sera sélectionné "
"aléatoirement pour l'évaluation. Si :code:`fraction_evaluate` est défini "
"à :code:`0.0`, l'évaluation fédérée sera désactivée."

#: ../../source/explanation-federated-evaluation.rst:106
msgid ""
":code:`min_evaluate_clients`: an :code:`int`: the minimum number of "
"clients to be selected for evaluation. If :code:`fraction_evaluate` is "
"set to :code:`0.1`, :code:`min_evaluate_clients` is set to 20, and "
":code:`100` clients are connected to the server, then :code:`20` clients "
"will be selected for evaluation."
msgstr ""
"si :code:`fraction_evaluate` est réglé sur :code:`0.1`, "
":code:`min_evaluate_clients` est réglé sur 20, et que :code:`100` clients"
" sont connectés au serveur, alors :code:`20` clients seront sélectionnés "
"pour l'évaluation."

#: ../../source/explanation-federated-evaluation.rst:107
msgid ""
":code:`min_available_clients`: an :code:`int` that defines the minimum "
"number of clients which need to be connected to the server before a round"
" of federated evaluation can start. If fewer than "
":code:`min_available_clients` are connected to the server, the server "
"will wait until more clients are connected before it continues to sample "
"clients for evaluation."
msgstr ""
":code:`min_available_clients` : un :code:`int` qui définit le nombre "
"minimum de clients qui doivent être connectés au serveur avant qu'un "
"cycle d'évaluation fédérée puisse commencer. Si moins de "
":code:`min_available_clients` sont connectés au serveur, le serveur "
"attendra que d'autres clients soient connectés avant de continuer à "
"échantillonner des clients pour l'évaluation."

#: ../../source/explanation-federated-evaluation.rst:108
msgid ""
":code:`on_evaluate_config_fn`: a function that returns a configuration "
"dictionary which will be sent to the selected clients. The function will "
"be called during each round and provides a convenient way to customize "
"client-side evaluation from the server side, for example, to configure "
"the number of validation steps performed."
msgstr ""
":code:`on_evaluate_config_fn` : une fonction qui renvoie un dictionnaire "
"de configuration qui sera envoyé aux clients sélectionnés. Cette fonction"
" sera appelée à chaque tour et offre un moyen pratique de personnaliser "
"l'évaluation côté client depuis le côté serveur, par exemple pour "
"configurer le nombre d'étapes de validation effectuées."

#: ../../source/explanation-federated-evaluation.rst:135
msgid "Evaluating Local Model Updates During Training"
msgstr "Évaluer les mises à jour du modèle local pendant la formation"

#: ../../source/explanation-federated-evaluation.rst:137
msgid ""
"Model parameters can also be evaluated during training. "
":code:`Client.fit` can return arbitrary evaluation results as a "
"dictionary:"
msgstr ""
"Les paramètres du modèle peuvent également être évalués pendant la "
"formation. :code:`Client.fit` peut renvoyer des résultats d'évaluation "
"arbitraires sous forme de dictionnaire :"

#: ../../source/explanation-federated-evaluation.rst:177
msgid "Full Code Example"
msgstr "Exemple de code complet"

#: ../../source/explanation-federated-evaluation.rst:179
#, fuzzy
msgid ""
"For a full code example that uses both centralized and federated "
"evaluation, see the *Advanced TensorFlow Example* (the same approach can "
"be applied to workloads implemented in any other framework): "
"https://github.com/adap/flower/tree/main/examples/advanced-tensorflow"
msgstr ""
"Pour un exemple de code complet qui utilise à la fois l'évaluation "
"centralisée et fédérée, voir l'*Exemple TensorFlow avancé* (la même "
"approche peut être appliquée aux charges de travail mises en œuvre dans "
"n'importe quel autre framework) : "
"https://github.com/adap/flower/tree/main/examples/advanced-tensorflow"

#: ../../source/fed/0000-20200102-fed-template.md:10
msgid "FED Template"
msgstr "Modèle FED"

#: ../../source/fed/0000-20200102-fed-template.md:12
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:12
msgid "Table of Contents"
msgstr "Table des matières"

#: ../../source/fed/0000-20200102-fed-template.md:14
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:14
msgid "[Table of Contents](#table-of-contents)"
msgstr "[Table des matières](#table-of-contents)"

#: ../../source/fed/0000-20200102-fed-template.md:15
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:15
msgid "[Summary](#summary)"
msgstr "[Résumé](#résumé)"

#: ../../source/fed/0000-20200102-fed-template.md:16
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:16
msgid "[Motivation](#motivation)"
msgstr "[Motivation](#motivation)"

#: ../../source/fed/0000-20200102-fed-template.md:17
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:17
msgid "[Goals](#goals)"
msgstr "[Buts](#buts)"

#: ../../source/fed/0000-20200102-fed-template.md:18
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:18
msgid "[Non-Goals](#non-goals)"
msgstr "[Non-objectifs](#non-objectifs)"

#: ../../source/fed/0000-20200102-fed-template.md:19
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:19
msgid "[Proposal](#proposal)"
msgstr "[Proposition](#proposition)"

#: ../../source/fed/0000-20200102-fed-template.md:20
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:23
msgid "[Drawbacks](#drawbacks)"
msgstr "[Inconvénients](#inconvénients)"

#: ../../source/fed/0000-20200102-fed-template.md:21
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:24
msgid "[Alternatives Considered](#alternatives-considered)"
msgstr "[Alternatives envisagées](#alternatives-considered)"

#: ../../source/fed/0000-20200102-fed-template.md:22
msgid "[Appendix](#appendix)"
msgstr "[Annexe](#appendix)"

#: ../../source/fed/0000-20200102-fed-template.md:24
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:28
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:76
msgid "Summary"
msgstr "Résumé"

#: ../../source/fed/0000-20200102-fed-template.md:26
#, fuzzy
msgid "\\[TODO - sentence 1: summary of the problem\\]"
msgstr "[TODO - phrase 1 : résumé du problème]"

#: ../../source/fed/0000-20200102-fed-template.md:28
#, fuzzy
msgid "\\[TODO - sentence 2: summary of the solution\\]"
msgstr "[TODO - phrase 2 : résumé de la solution]"

#: ../../source/fed/0000-20200102-fed-template.md:30
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:47
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:77
msgid "Motivation"
msgstr "Motivation"

#: ../../source/fed/0000-20200102-fed-template.md:32
#: ../../source/fed/0000-20200102-fed-template.md:36
#: ../../source/fed/0000-20200102-fed-template.md:40
#: ../../source/fed/0000-20200102-fed-template.md:44
#: ../../source/fed/0000-20200102-fed-template.md:48
#: ../../source/fed/0000-20200102-fed-template.md:54
#: ../../source/fed/0000-20200102-fed-template.md:58
#, fuzzy
msgid "\\[TODO\\]"
msgstr "[TODO]"

#: ../../source/fed/0000-20200102-fed-template.md:34
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:53
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:78
msgid "Goals"
msgstr "Objectifs"

#: ../../source/fed/0000-20200102-fed-template.md:38
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:59
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:79
msgid "Non-Goals"
msgstr "Non-objectifs"

#: ../../source/fed/0000-20200102-fed-template.md:42
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:65
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:80
msgid "Proposal"
msgstr "Proposition"

#: ../../source/fed/0000-20200102-fed-template.md:46
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:85
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:129
msgid "Drawbacks"
msgstr "Inconvénients"

#: ../../source/fed/0000-20200102-fed-template.md:50
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:86
#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:135
msgid "Alternatives Considered"
msgstr "Alternatives envisagées"

#: ../../source/fed/0000-20200102-fed-template.md:52
#, fuzzy
msgid "\\[Alternative 1\\]"
msgstr "[Alternative 1]"

#: ../../source/fed/0000-20200102-fed-template.md:56
#, fuzzy
msgid "\\[Alternative 2\\]"
msgstr "[Alternative 2]"

#: ../../source/fed/0000-20200102-fed-template.md:60
msgid "Appendix"
msgstr "Annexe"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:10
msgid "Flower Enhancement Doc"
msgstr "Doc sur l'amélioration des fleurs"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:20
msgid "[Enhancement Doc Template](#enhancement-doc-template)"
msgstr "[Modèle de document d'amélioration](#enhancement-doc-template)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:21
msgid "[Metadata](#metadata)"
msgstr "[Métadonnées](#métadonnées)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:22
msgid "[Workflow](#workflow)"
msgstr "[Workflow](#workflow)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:25
msgid "[GitHub Issues](#github-issues)"
msgstr "[GitHub Issues](#github-issues)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:26
msgid "[Google Docs](#google-docs)"
msgstr "[Google Docs](#google-docs)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:30
msgid "A Flower Enhancement is a standardized development process to"
msgstr ""
"Une amélioration de la fleur est un processus de développement "
"standardisé pour"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:32
msgid "provide a common structure for proposing larger changes"
msgstr ""
"fournir une structure commune pour proposer des changements plus "
"importants"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:33
msgid "ensure that the motivation for a change is clear"
msgstr "s'assurer que la motivation du changement est claire"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:34
msgid "persist project information in a version control system"
msgstr ""
"conserver les informations sur le projet dans un système de contrôle des "
"versions"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:35
msgid "document the motivation for impactful user-facing changes"
msgstr ""
"documenter la motivation des changements qui ont un impact sur "
"l'utilisateur"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:36
msgid "reserve GitHub issues for tracking work in flight"
msgstr "réserve les problèmes GitHub pour le suivi du travail en vol"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:37
msgid ""
"ensure community participants can successfully drive changes to "
"completion across one or more releases while stakeholders are adequately "
"represented throughout the process"
msgstr ""
"s'assurer que les participants de la communauté peuvent mener à bien les "
"changements dans le cadre d'une ou plusieurs versions et que les parties "
"prenantes sont représentées de manière adéquate tout au long du processus"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:39
msgid "Hence, an Enhancement Doc combines aspects of"
msgstr "Par conséquent, un document d'amélioration combine des aspects de"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:41
msgid "a feature, and effort-tracking document"
msgstr "une caractéristique, et un document de suivi des efforts"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:42
msgid "a product requirements document"
msgstr "un document sur les exigences du produit"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:43
msgid "a design document"
msgstr "un document de conception"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:45
msgid ""
"into one file, which is created incrementally in collaboration with the "
"community."
msgstr ""
"en un seul fichier, qui est créé progressivement en collaboration avec la"
" communauté."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:49
msgid ""
"For far-fetching changes or features proposed to Flower, an abstraction "
"beyond a single GitHub issue or pull request is required to understand "
"and communicate upcoming changes to the project."
msgstr ""
"Pour les changements lointains ou les fonctionnalités proposées à Flower,"
" une abstraction au-delà d'une simple question GitHub ou d'une demande de"
" tirage est nécessaire pour comprendre et communiquer les changements à "
"venir dans le projet."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:51
msgid ""
"The purpose of this process is to reduce the amount of \"tribal "
"knowledge\" in our community. By moving decisions from Slack threads, "
"video calls, and hallway conversations into a well-tracked artifact, this"
" process aims to enhance communication and discoverability."
msgstr ""
"L'objectif de ce processus est de réduire la quantité de \"connaissances "
"tribales\" dans notre communauté. En déplaçant les décisions des fils de "
"discussion Slack, des appels vidéo et des conversations de couloir vers "
"un artefact bien suivi, ce processus vise à améliorer la communication et"
" la découvrabilité."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:55
msgid ""
"Roughly any larger, user-facing enhancement should follow the Enhancement"
" process. If an enhancement would be described in either written or "
"verbal communication to anyone besides the author or developer, then "
"consider creating an Enhancement Doc."
msgstr ""
"Si une amélioration doit être décrite par écrit ou verbalement à "
"quelqu'un d'autre que l'auteur ou le développeur, il faut envisager de "
"créer un document d'amélioration."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:57
msgid ""
"Similarly, any technical effort (refactoring, major architectural change)"
" that will impact a large section of the development community should "
"also be communicated widely. The Enhancement process is suited for this "
"even if it will have zero impact on the typical user or operator."
msgstr ""
"De même, tout effort technique (refactorisation, changement architectural"
" majeur) qui aura un impact sur une grande partie de la communauté de "
"développement doit également être communiqué à grande échelle. Le "
"processus d'amélioration est adapté à cela, même s'il n'aura aucun impact"
" sur l'utilisateur ou l'opérateur type."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:61
msgid ""
"For small changes and additions, going through the Enhancement process "
"would be time-consuming and unnecessary. This includes, for example, "
"adding new Federated Learning algorithms, as these only add features "
"without changing how Flower works or is used."
msgstr ""
"Pour les petits changements et ajouts, passer par le processus "
"d'amélioration prendrait beaucoup de temps et serait inutile. Cela "
"inclut, par exemple, l'ajout de nouveaux algorithmes d'apprentissage "
"fédéré, car ceux-ci ne font qu'ajouter des fonctionnalités sans changer "
"le fonctionnement ou l'utilisation de Flower."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:63
msgid ""
"Enhancements are different from feature requests, as they are already "
"providing a laid-out path for implementation and are championed by "
"members of the community."
msgstr ""
"Les améliorations sont différentes des demandes de fonctionnalités, car "
"elles fournissent déjà un chemin tracé pour la mise en œuvre et sont "
"défendues par les membres de la communauté."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:67
msgid ""
"An Enhancement is captured in a Markdown file that follows a defined "
"template and a workflow to review and store enhancement docs for "
"reference — the Enhancement Doc."
msgstr ""
"Une amélioration est capturée dans un fichier Markdown qui suit un modèle"
" défini et un flux de travail pour examiner et stocker les documents "
"d'amélioration pour référence - le Doc d'amélioration."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:69
msgid "Enhancement Doc Template"
msgstr "Modèle de document d'amélioration"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:71
msgid ""
"Each enhancement doc is provided as a Markdown file having the following "
"structure"
msgstr ""
"Chaque document d'amélioration est fourni sous la forme d'un fichier "
"Markdown ayant la structure suivante"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:73
msgid "Metadata (as [described below](#metadata) in form of a YAML preamble)"
msgstr ""
"Métadonnées (comme [décrit ci-dessous](#metadata) sous la forme d'un "
"préambule YAML)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:74
msgid "Title (same as in metadata)"
msgstr "Titre (le même que dans les métadonnées)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:75
msgid "Table of Contents (if needed)"
msgstr "Table des matières (si nécessaire)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:81
msgid "Notes/Constraints/Caveats (optional)"
msgstr "Notes/Contraintes/Cavats (facultatif)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:82
msgid "Design Details (optional)"
msgstr "Détails de la conception (facultatif)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:83
msgid "Graduation Criteria"
msgstr "Critères d'obtention du diplôme"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:84
msgid "Upgrade/Downgrade Strategy (if applicable)"
msgstr "Stratégie de mise à niveau/rétrogradation (le cas échéant)"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:88
msgid "As a reference, this document follows the above structure."
msgstr "À titre de référence, ce document suit la structure ci-dessus."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:90
msgid "Metadata"
msgstr "Métadonnées"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:92
msgid ""
"**fed-number** (Required) The `fed-number` of the last Flower Enhancement"
" Doc + 1. With this number, it becomes easy to reference other proposals."
msgstr ""
"**numérofed** (Obligatoire) Le `numérofed` du dernier document "
"d'amélioration de la fleur + 1. Avec ce numéro, il devient facile de "
"faire référence à d'autres propositions."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:94
msgid "**title** (Required) The title of the proposal in plain language."
msgstr "**titre** (obligatoire) Le titre de la proposition en langage clair."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:96
msgid ""
"**status** (Required) The current status of the proposal. See "
"[workflow](#workflow) for the possible states."
msgstr ""
"**status** (obligatoire) L'état actuel de la proposition. Voir "
"[workflow](#workflow) pour les états possibles."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:98
msgid ""
"**authors** (Required) A list of authors of the proposal. This is simply "
"the GitHub ID."
msgstr ""
"**authors** (Obligatoire) Une liste des auteurs de la proposition, il "
"s'agit simplement de l'identifiant GitHub."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:100
msgid ""
"**creation-date** (Required) The date that the proposal was first "
"submitted in a PR."
msgstr ""
"**creation-date** (Obligatoire) Date à laquelle la proposition a été "
"soumise pour la première fois dans un RP."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:102
msgid ""
"**last-updated** (Optional) The date that the proposal was last changed "
"significantly."
msgstr ""
"**dernière mise à jour** (Facultatif) La date à laquelle la proposition a"
" été modifiée de manière significative pour la dernière fois."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:104
msgid ""
"**see-also** (Optional) A list of other proposals that are relevant to "
"this one."
msgstr ""
"**see-also** (Facultatif) Une liste d'autres propositions qui sont "
"pertinentes par rapport à celle-ci."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:106
msgid "**replaces** (Optional) A list of proposals that this one replaces."
msgstr "**replaces** (Facultatif) Une liste de propositions que celle-ci remplace."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:108
msgid "**superseded-by** (Optional) A list of proposals that this one supersedes."
msgstr ""
"**superseded-by** (Facultatif) Une liste de propositions que celle-ci "
"remplace."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:111
msgid "Workflow"
msgstr "Flux de travail"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:113
msgid ""
"The idea forming the enhancement should already have been discussed or "
"pitched in the community. As such, it needs a champion, usually the "
"author, who shepherds the enhancement. This person also has to find "
"committers to Flower willing to review the proposal."
msgstr ""
"L'idée à l'origine de l'amélioration doit déjà avoir fait l'objet d'une "
"discussion ou d'une présentation au sein de la communauté. À ce titre, "
"elle a besoin d'un champion, généralement l'auteur, qui se charge de "
"l'amélioration. Cette personne doit également trouver des committers to "
"Flower prêts à examiner la proposition."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:115
msgid ""
"New enhancements are checked in with a file name in the form of `NNNN-"
"YYYYMMDD-enhancement-title.md`, with `NNNN` being the Flower Enhancement "
"Doc number, to `enhancements`. All enhancements start in `provisional` "
"state as part of a pull request. Discussions are done as part of the pull"
" request review."
msgstr ""
"Les nouvelles améliorations sont enregistrées avec un nom de fichier de "
"la forme `NNN-YYYMMDD-enhancement-title.md`, `NNNN` étant le numéro du "
"document d'amélioration de la fleur, dans `enhancements`. Toutes les "
"améliorations commencent à l'état `provisionnel` dans le cadre d'une "
"demande d'extraction. Les discussions sont effectuées dans le cadre de "
"l'examen de la demande d'extraction."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:117
msgid ""
"Once an enhancement has been reviewed and approved, its status is changed"
" to `implementable`. The actual implementation is then done in separate "
"pull requests. These pull requests should mention the respective "
"enhancement as part of their description. After the implementation is "
"done, the proposal status is changed to `implemented`."
msgstr ""
"Une fois qu'une amélioration a été examinée et approuvée, son statut "
"passe à `implémentable`. L'implémentation réelle est alors réalisée dans "
"des demandes d'extension séparées. Ces demandes d'extension doivent "
"mentionner l'amélioration concernée dans leur description. Une fois "
"l'implémentation réalisée, le statut de la proposition passe à "
"`implémented`."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:119
msgid ""
"Under certain conditions, other states are possible. An Enhancement has "
"the following states:"
msgstr ""
"Sous certaines conditions, d'autres états sont possibles. Une "
"amélioration a les états suivants :"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:121
msgid ""
"`provisional`: The enhancement has been proposed and is actively being "
"defined. This is the starting state while the proposal is being fleshed "
"out and actively defined and discussed."
msgstr ""
"`provisoire` : L'amélioration a été proposée et est en cours de "
"définition. C'est l'état de départ pendant que la proposition est étoffée"
" et activement définie et discutée."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:122
msgid "`implementable`: The enhancement has been reviewed and approved."
msgstr "`implementable` : L'amélioration a été examinée et approuvée."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:123
msgid ""
"`implemented`: The enhancement has been implemented and is no longer "
"actively changed."
msgstr ""
"`implemented` : L'amélioration a été mise en œuvre et n'est plus "
"activement modifiée."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:124
msgid "`deferred`: The enhancement is proposed but not actively being worked on."
msgstr ""
"`deferred` : L'amélioration est proposée mais n'est pas activement "
"travaillée."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:125
msgid ""
"`rejected`: The authors and reviewers have decided that this enhancement "
"is not moving forward."
msgstr ""
"`rejeté` : Les auteurs et les réviseurs ont décidé que cette amélioration"
" n'allait pas de l'avant."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:126
msgid "`withdrawn`: The authors have withdrawn the enhancement."
msgstr "`withdrawn` : Les auteurs ont retiré l'amélioration."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:127
msgid "`replaced`: The enhancement has been replaced by a new enhancement."
msgstr "`replaced` : L'amélioration a été remplacée par une nouvelle amélioration."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:131
msgid ""
"Adding an additional process to the ones already provided by GitHub "
"(Issues and Pull Requests) adds more complexity and can be a barrier for "
"potential first-time contributors."
msgstr ""
"L'ajout d'un processus supplémentaire à ceux déjà fournis par GitHub "
"(Issues et Pull Requests) ajoute plus de complexité et peut constituer un"
" obstacle pour les éventuels nouveaux contributeurs."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:133
msgid ""
"Expanding the proposal template beyond the single-sentence description "
"currently required in the features issue template may be a heavy burden "
"for non-native English speakers."
msgstr ""
"Élargir le modèle de proposition au-delà de la description d'une seule "
"phrase actuellement requise dans le modèle de questions sur les "
"caractéristiques peut constituer une lourde charge pour les personnes "
"dont l'anglais n'est pas la langue maternelle."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:137
msgid "GitHub Issues"
msgstr "Questions sur GitHub"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:139
msgid ""
"Using GitHub Issues for these kinds of enhancements is doable. One could "
"use, for example, tags, to differentiate and filter them from other "
"issues. The main issue is in discussing and reviewing an enhancement: "
"GitHub issues only have a single thread for comments. Enhancements "
"usually have multiple threads of discussion at the same time for various "
"parts of the doc. Managing these multiple discussions can be confusing "
"when using GitHub Issues."
msgstr ""
"Il est possible d'utiliser GitHub Issues pour ce type d'améliorations. On"
" pourrait utiliser, par exemple, des balises pour les différencier et les"
" filtrer par rapport aux autres problèmes. Le principal problème concerne"
" la discussion et la révision d'une amélioration : les GitHub Issues "
"n'ont qu'un seul fil de discussion pour les commentaires. Les "
"améliorations ont généralement plusieurs fils de discussion en même temps"
" pour différentes parties de la documentation. La gestion de ces "
"multiples discussions peut être déroutante lorsque l'on utilise GitHub "
"Issues."

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:141
msgid "Google Docs"
msgstr "Google Docs"

#: ../../source/fed/0001-20220311-flower-enhancement-doc.md:143
msgid ""
"Google Docs allow for multiple threads of discussions. But as Google Docs"
" are hosted outside the project, their discoverability by the community "
"needs to be taken care of. A list of links to all proposals has to be "
"managed and made available for the community. Compared to shipping "
"proposals as part of Flower's repository, the potential for missing links"
" is much higher."
msgstr ""
"Les Google Docs permettent de multiplier les fils de discussion. Mais "
"comme les Google Docs sont hébergés en dehors du projet, il faut veiller "
"à ce que la communauté puisse les découvrir. Une liste de liens vers "
"toutes les propositions doit être gérée et mise à la disposition de la "
"communauté. Par rapport à l'envoi de propositions dans le cadre du "
"référentiel de Flower, le risque de liens manquants est beaucoup plus "
"élevé."

#: ../../source/fed/index.md:1
msgid "FED - Flower Enhancement Doc"
msgstr "FED - Doc pour l'amélioration des fleurs"

#: ../../source/how-to-aggregate-evaluation-results.rst:2
#, fuzzy
msgid "Aggregate evaluation results"
msgstr "Résultats globaux de l'évaluation."

#: ../../source/how-to-aggregate-evaluation-results.rst:4
msgid ""
"The Flower server does not prescribe a way to aggregate evaluation "
"results, but it enables the user to fully customize result aggregation."
msgstr ""

#: ../../source/how-to-aggregate-evaluation-results.rst:8
msgid "Aggregate Custom Evaluation Results"
msgstr "Agréger les résultats de l'évaluation personnalisée"

#: ../../source/how-to-aggregate-evaluation-results.rst:10
msgid ""
"The same :code:`Strategy`-customization approach can be used to aggregate"
" custom evaluation results coming from individual clients. Clients can "
"return custom metrics to the server by returning a dictionary:"
msgstr ""
"La même approche de personnalisation :code:`Stratégie` peut être utilisée"
" pour agréger les résultats d'évaluation personnalisés provenant de "
"clients individuels. Les clients peuvent renvoyer des mesures "
"personnalisées au serveur en renvoyant un dictionnaire :"

#: ../../source/how-to-aggregate-evaluation-results.rst:36
msgid ""
"The server can then use a customized strategy to aggregate the metrics "
"provided in these dictionaries:"
msgstr ""
"Le serveur peut alors utiliser une stratégie personnalisée pour agréger "
"les mesures fournies dans ces dictionnaires :"

#: ../../source/how-to-configure-clients.rst:2
#, fuzzy
msgid "Configure clients"
msgstr "Configurer les clients"

#: ../../source/how-to-configure-clients.rst:4
msgid ""
"Along with model parameters, Flower can send configuration values to "
"clients. Configuration values can be used for various purposes. They are,"
" for example, a popular way to control client-side hyperparameters from "
"the server."
msgstr ""
"En plus des paramètres du modèle, Flower peut envoyer des valeurs de "
"configuration aux clients. Les valeurs de configuration peuvent être "
"utilisées à diverses fins. Elles constituent, par exemple, un moyen "
"populaire de contrôler les hyperparamètres côté client à partir du "
"serveur."

#: ../../source/how-to-configure-clients.rst:7
msgid "Configuration values"
msgstr "Valeurs de configuration"

#: ../../source/how-to-configure-clients.rst:9
msgid ""
"Configuration values are represented as a dictionary with ``str`` keys "
"and values of type ``bool``, ``bytes``, ``double`` (64-bit precision "
"float), ``int``, or ``str`` (or equivalent types in different languages)."
" Here is an example of a configuration dictionary in Python:"
msgstr ""
"Les valeurs de configuration sont représentées sous forme de dictionnaire"
" avec des clés `str`` et des valeurs de type `bool`, `bytes`, `double` "
"(float de précision 64 bits), `int`, ou `str` (ou des types équivalents "
"dans d'autres langages). Voici un exemple de dictionnaire de "
"configuration en Python :"

#: ../../source/how-to-configure-clients.rst:20
msgid ""
"Flower serializes these configuration dictionaries (or *config dict* for "
"short) to their ProtoBuf representation, transports them to the client "
"using gRPC, and then deserializes them back to Python dictionaries."
msgstr ""
"Flower sérialise ces dictionnaires de configuration (ou *config dict* en "
"abrégé) dans leur représentation ProtoBuf, les transporte vers le client "
"à l'aide de gRPC, puis les désérialise à nouveau en dictionnaires Python."

#: ../../source/how-to-configure-clients.rst:24
msgid ""
"Currently, there is no support for directly sending collection types "
"(e.g., ``Set``, ``List``, ``Map``) as values in configuration "
"dictionaries. There are several workarounds to send collections as values"
" by converting them to one of the supported value types (and converting "
"them back on the client-side)."
msgstr ""
"Actuellement, il n'est pas possible d'envoyer directement des types de "
"collections (par exemple, ``Set``, ``List``, ``Map``) en tant que valeurs"
" dans les dictionnaires de configuration. Il existe plusieurs solutions "
"pour envoyer des collections en tant que valeurs en les convertissant en "
"l'un des types de valeurs pris en charge (et en les reconvertissant du "
"côté client)."

#: ../../source/how-to-configure-clients.rst:26
msgid ""
"One can, for example, convert a list of floating-point numbers to a JSON "
"string, then send the JSON string using the configuration dictionary, and"
" then convert the JSON string back to a list of floating-point numbers on"
" the client."
msgstr ""
"On peut, par exemple, convertir une liste de nombres à virgule flottante "
"en une chaîne JSON, puis envoyer la chaîne JSON à l'aide du dictionnaire "
"de configuration, et enfin reconvertir la chaîne JSON en une liste de "
"nombres à virgule flottante sur le client."

#: ../../source/how-to-configure-clients.rst:30
msgid "Configuration through built-in strategies"
msgstr "Configuration par le biais de stratégies intégrées"

#: ../../source/how-to-configure-clients.rst:32
msgid ""
"The easiest way to send configuration values to clients is to use a "
"built-in strategy like :code:`FedAvg`. Built-in strategies support so-"
"called configuration functions. A configuration function is a function "
"that the built-in strategy calls to get the configuration dictionary for "
"the current round. It then forwards the configuration dictionary to all "
"the clients selected during that round."
msgstr ""
"La façon la plus simple d'envoyer des valeurs de configuration aux "
"clients est d'utiliser une stratégie intégrée comme :code:`FedAvg`. Les "
"stratégies intégrées prennent en charge ce que l'on appelle les fonctions"
" de configuration. Une fonction de configuration est une fonction que la "
"stratégie intégrée appelle pour obtenir le dictionnaire de configuration "
"pour le tour en cours. Elle transmet ensuite le dictionnaire de "
"configuration à tous les clients sélectionnés au cours de ce tour."

#: ../../source/how-to-configure-clients.rst:34
msgid ""
"Let's start with a simple example. Imagine we want to send (a) the batch "
"size that the client should use, (b) the current global round of "
"federated learning, and (c) the number of epochs to train on the client-"
"side. Our configuration function could look like this:"
msgstr ""
"Commençons par un exemple simple. Imaginons que nous voulions envoyer (a)"
" la taille du lot que le client doit utiliser, (b) le cycle global actuel"
" de l'apprentissage fédéré et (c) le nombre d'époques à former du côté "
"client. Notre fonction de configuration pourrait ressembler à ceci :"

#: ../../source/how-to-configure-clients.rst:47
msgid ""
"To make the built-in strategies use this function, we can pass it to "
"``FedAvg`` during initialization using the parameter "
":code:`on_fit_config_fn`:"
msgstr ""
"Pour que les stratégies intégrées utilisent cette fonction, nous pouvons "
"la passer à ``FedAvg`` lors de l'initialisation en utilisant le paramètre"
" :code:`on_fit_config_fn` :"

#: ../../source/how-to-configure-clients.rst:56
msgid "One the client side, we receive the configuration dictionary in ``fit``:"
msgstr "Côté client, nous recevons le dictionnaire de configuration dans ``fit`` :"

#: ../../source/how-to-configure-clients.rst:67
msgid ""
"There is also an `on_evaluate_config_fn` to configure evaluation, which "
"works the same way. They are separate functions because one might want to"
" send different configuration values to `evaluate` (for example, to use a"
" different batch size)."
msgstr ""
"Il existe également une fonction `on_evaluate_config_fn` pour configurer "
"l'évaluation, qui fonctionne de la même manière. Ce sont des fonctions "
"séparées car on peut vouloir envoyer différentes valeurs de configuration"
" à `evaluate` (par exemple, pour utiliser une taille de lot différente)."

#: ../../source/how-to-configure-clients.rst:69
msgid ""
"The built-in strategies call this function every round (that is, every "
"time `Strategy.configure_fit` or `Strategy.configure_evaluate` runs). "
"Calling `on_evaluate_config_fn` every round allows us to vary/change the "
"config dict over consecutive rounds. If we wanted to implement a "
"hyperparameter schedule, for example, to increase the number of local "
"epochs during later rounds, we could do the following:"
msgstr ""
"Les stratégies intégrées appellent cette fonction à chaque tour "
"(c'est-à-dire à chaque fois que `Strategy.configure_fit` ou "
"`Strategy.configure_evaluate` s'exécute). Appeler `on_evaluate_config_fn`"
" à chaque tour nous permet de varier/changer le dict de config au cours "
"de tours consécutifs. Si nous voulions mettre en place un calendrier "
"d'hyperparamètres, par exemple, pour augmenter le nombre d'époques "
"locales au cours des derniers tours, nous pourrions faire ce qui suit :"

#: ../../source/how-to-configure-clients.rst:82
msgid "The :code:`FedAvg` strategy will call this function *every round*."
msgstr "La stratégie :code:`FedAvg` appellera cette fonction *à chaque tour*."

#: ../../source/how-to-configure-clients.rst:85
msgid "Configuring individual clients"
msgstr "Configuration des clients individuels"

#: ../../source/how-to-configure-clients.rst:87
msgid ""
"In some cases, it is necessary to send different configuration values to "
"different clients."
msgstr ""
"Dans certains cas, il est nécessaire d'envoyer des valeurs de "
"configuration différentes à des clients différents."

#: ../../source/how-to-configure-clients.rst:89
msgid ""
"This can be achieved by customizing an existing strategy or by "
"`implementing a custom strategy from scratch <https://flower.dev/docs"
"/how-to-implement-strategies.html>`_. Here's a nonsensical example that "
"customizes :code:`FedAvg` by adding a custom ``\"hello\": \"world\"`` "
"configuration key/value pair to the config dict of a *single client* "
"(only the first client in the list, the other clients in this round to "
"not receive this \"special\" config value):"
msgstr ""
"Ceci peut être réalisé en personnalisant une stratégie existante ou en "
"`mettant en œuvre une stratégie personnalisée à partir de zéro "
"<https://flower.dev/docs/framework/how-to-implement-strategies.html>`_. Voici un "
"exemple absurde qui personnalise :code:`FedAvg` en ajoutant une paire "
"clé/valeur de configuration personnalisée ``\"hello\" : \"world\"`` au "
"config dict d'un *seul client* (uniquement le premier client de la liste,"
" les autres clients de cette série ne recevant pas cette valeur de "
"configuration \"spéciale\") :"

#: ../../source/how-to-configure-logging.rst:2
#, fuzzy
msgid "Configure logging"
msgstr "Configurer les clients"

#: ../../source/how-to-configure-logging.rst:4
msgid ""
"The Flower logger keeps track of all core events that take place in "
"federated learning workloads. It presents information by default "
"following a standard message format:"
msgstr ""

#: ../../source/how-to-configure-logging.rst:13
msgid ""
"containing relevant information including: log message level (e.g. "
":code:`INFO`, :code:`DEBUG`), a timestamp, the line where the logging "
"took place from, as well as the log message itself. In this way, the "
"logger would typically display information on your terminal as follows:"
msgstr ""

#: ../../source/how-to-configure-logging.rst:34
msgid "Saving log to file"
msgstr ""

#: ../../source/how-to-configure-logging.rst:36
msgid ""
"By default, the Flower log is outputted to the terminal where you launch "
"your Federated Learning workload from. This applies for both gRPC-based "
"federation (i.e. when you do :code:`fl.server.start_server`) and when "
"using the :code:`VirtualClientEngine` (i.e. when you do "
":code:`fl.simulation.start_simulation`). In some situations you might "
"want to save this log to disk. You can do so by calling the "
"`fl.common.logger.configure() "
"<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_"
" function. For example:"
msgstr ""

#: ../../source/how-to-configure-logging.rst:53
msgid ""
"With the above, Flower will record the log you see on your terminal to "
":code:`log.txt`. This file will be created in the same directory as were "
"you are running the code from. If we inspect we see the log above is also"
" recorded but prefixing with :code:`identifier` each line:"
msgstr ""
"Avec ce qui précède, Flower enregistrera le log que vous voyez sur votre "
"terminal dans :code:`log.txt`. Ce fichier sera créé dans le répertoire "
"depuis lequel le code est exécuté. Si nous inspectons nous voyons que le log "
"ci-dessous est également enregistré mais préfixé avec :code:`identifier` sur "
"chaque ligne :"

#: ../../source/how-to-configure-logging.rst:74
msgid "Log your own messages"
msgstr "Loggez vos propres messages"

#: ../../source/how-to-configure-logging.rst:76
msgid ""
"You might expand the information shown by default with the Flower logger "
"by adding more messages relevant to your application. You can achieve "
"this easily as follows."
msgstr ""

#: ../../source/how-to-configure-logging.rst:102
msgid ""
"In this way your logger will show, in addition to the default messages, "
"the ones introduced by the clients as specified above."
msgstr ""

#: ../../source/how-to-configure-logging.rst:128
msgid "Log to a remote service"
msgstr ""

#: ../../source/how-to-configure-logging.rst:130
msgid ""
"The :code:`fl.common.logger.configure` function, also allows specifying a"
" host to which logs can be pushed (via :code:`POST`) through a native "
"Python :code:`logging.handler.HTTPHandler`. This is a particularly useful"
" feature in :code:`gRPC`-based Federated Learning workloads where "
"otherwise gathering logs from all entities (i.e. the server and the "
"clients) might be cumbersome. Note that in Flower simulation, the server "
"automatically displays all logs. You can still specify a "
":code:`HTTPHandler` should you whish to backup or analyze the logs "
"somewhere else."
msgstr ""

#: ../../source/how-to-enable-ssl-connections.rst:2
#, fuzzy
msgid "Enable SSL connections"
msgstr "Collecte centralisée des données"

#: ../../source/how-to-enable-ssl-connections.rst:4
msgid ""
"This guide describes how to a SSL-enabled secure Flower server can be "
"started and how a Flower client can establish a secure connections to it."
msgstr ""
"Ce guide décrit comment démarrer un serveur Flower sécurisé par SSL et "
"comment un client Flower peut établir une connexion sécurisée avec lui."

#: ../../source/how-to-enable-ssl-connections.rst:7
#, fuzzy
msgid ""
"A complete code example demonstrating a secure connection can be found "
"`here <https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_."
msgstr ""
"Un exemple de code complet démontrant une connexion sécurisée peut être "
"trouvé ici <https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_."

#: ../../source/how-to-enable-ssl-connections.rst:10
msgid ""
"The code example comes with a README.md file which will explain how to "
"start it. Although it is already SSL-enabled, it might be less "
"descriptive on how. Stick to this guide for a deeper introduction to the "
"topic."
msgstr ""
"L'exemple de code est accompagné d'un fichier README.md qui t'expliquera "
"comment le démarrer. Bien qu'il soit déjà activé par SSL, il peut être "
"moins descriptif sur la façon de procéder. Tiens-toi en à ce guide pour "
"une introduction plus approfondie sur le sujet."

#: ../../source/how-to-enable-ssl-connections.rst:16
msgid "Certificates"
msgstr "Certificats"

#: ../../source/how-to-enable-ssl-connections.rst:18
#, fuzzy
msgid ""
"Using SSL-enabled connections requires certificates to be passed to the "
"server and client. For the purpose of this guide we are going to generate"
" self-signed certificates. As this can become quite complex we are going "
"to ask you to run the script in :code:`examples/advanced-"
"tensorflow/certificates/generate.sh`"
msgstr ""
"L'utilisation de connexions compatibles avec le protocole SSL nécessite "
"que des certificats soient transmis au serveur et au client. Pour les "
"besoins de ce guide, nous allons générer des certificats auto-signés. "
"Comme cela peut devenir assez complexe, nous allons te demander "
"d'exécuter le script dans :code:`examples/advanced-"
"tensorflow/certificates/generate.sh`"

#: ../../source/how-to-enable-ssl-connections.rst:23
msgid "with the following command sequence:"
msgstr "avec la séquence de commandes suivante :"

#: ../../source/how-to-enable-ssl-connections.rst:30
#, fuzzy
msgid ""
"This will generate the certificates in :code:`examples/advanced-"
"tensorflow/.cache/certificates`."
msgstr ""
"Cela générera les certificats dans :code:`examples/advanced-"
"tensorflow/.cache/certificates`."

#: ../../source/how-to-enable-ssl-connections.rst:32
msgid ""
"The approach how the SSL certificates are generated in this example can "
"serve as an inspiration and starting point but should not be taken as "
"complete for production environments. Please refer to other sources "
"regarding the issue of correctly generating certificates for production "
"environments."
msgstr ""
"L'approche de la génération des certificats SSL dans cet exemple peut "
"servir d'inspiration et de point de départ, mais ne doit pas être "
"considérée comme complète pour les environnements de production."

#: ../../source/how-to-enable-ssl-connections.rst:36
msgid ""
"In case you are a researcher you might be just fine using the self-signed"
" certificates generated using the scripts which are part of this guide."
msgstr ""
"Si tu es un chercheur, tu peux très bien utiliser les certificats auto-"
"signés générés à l'aide des scripts qui font partie de ce guide."

#: ../../source/how-to-enable-ssl-connections.rst:41
msgid "Server"
msgstr "Serveur"

#: ../../source/how-to-enable-ssl-connections.rst:43
msgid ""
"We are now going to show how to write a sever which uses the previously "
"generated scripts."
msgstr ""
"Nous allons maintenant montrer comment écrire un serveur qui utilise les "
"scripts générés précédemment."

#: ../../source/how-to-enable-ssl-connections.rst:61
msgid ""
"When providing certificates, the server expects a tuple of three "
"certificates. :code:`Path` can be used to easily read the contents of "
"those files into byte strings, which is the data type "
":code:`start_server` expects."
msgstr ""
"Lorsqu'il fournit des certificats, le serveur attend un tuple de trois "
"certificats. :code:`Path` peut être utilisé pour lire facilement le "
"contenu de ces fichiers en chaînes d'octets, ce qui est le type de "
"données attendu par :code:`start_server`."

#: ../../source/how-to-enable-ssl-connections.rst:65
#: ../../source/how-to-upgrade-to-flower-1.0.rst:37
#: ../../source/ref-api-flwr.rst:15
msgid "Client"
msgstr "Client"

#: ../../source/how-to-enable-ssl-connections.rst:67
msgid ""
"We are now going to show how to write a client which uses the previously "
"generated scripts:"
msgstr ""
"Nous allons maintenant montrer comment écrire un client qui utilise les "
"scripts générés précédemment :"

#: ../../source/how-to-enable-ssl-connections.rst:84
msgid ""
"When setting :code:`root_certificates`, the client expects the PEM-"
"encoded root certificates as a byte string. We are again using "
":code:`Path` to simplify reading those as byte strings."
msgstr ""
"En définissant :code:`root_certificates`, le client s'attend à recevoir "
"les certificats racine codés en PEM sous forme de chaîne d'octets. Nous "
"utilisons à nouveau :code:`Path` pour simplifier la lecture de ces "
"certificats sous forme de chaînes d'octets."

#: ../../source/how-to-enable-ssl-connections.rst:89
#: ../../source/tutorial-what-is-federated-learning.ipynb:287
msgid "Conclusion"
msgstr "Conclusion"

#: ../../source/how-to-enable-ssl-connections.rst:91
msgid ""
"You should now have learned how to generate self-signed certificates "
"using the given script, start a SSL-enabled server, and have a client "
"establish a secure connection to it."
msgstr ""
"Tu devrais maintenant avoir appris à générer des certificats auto-signés "
"à l'aide du script donné, à démarrer un serveur compatible SSL et à "
"demander à un client d'établir une connexion sécurisée avec lui."

#: ../../source/how-to-enable-ssl-connections.rst:96
#, fuzzy
msgid "Additional resources"
msgstr "Ressources supplémentaires"

#: ../../source/how-to-enable-ssl-connections.rst:98
msgid ""
"These additional sources might be relevant if you would like to dive "
"deeper into the topic of certificates:"
msgstr ""
"Ces sources supplémentaires peuvent être pertinentes si tu souhaites "
"approfondir le sujet des certificats :"

#: ../../source/how-to-enable-ssl-connections.rst:100
msgid "`Let's Encrypt <https://letsencrypt.org/docs/>`_"
msgstr "`Let's Encrypt <https://letsencrypt.org/docs/>`_"

#: ../../source/how-to-enable-ssl-connections.rst:101
msgid "`certbot <https://certbot.eff.org/>`_"
msgstr "`certbot <https://certbot.eff.org/>`_"

#: ../../source/how-to-implement-strategies.rst:2
#, fuzzy
msgid "Implement strategies"
msgstr "Mettre en place des stratégies"

#: ../../source/how-to-implement-strategies.rst:4
msgid ""
"The strategy abstraction enables implementation of fully custom "
"strategies. A strategy is basically the federated learning algorithm that"
" runs on the server. Strategies decide how to sample clients, how to "
"configure clients for training, how to aggregate updates, and how to "
"evaluate models. Flower provides a few built-in strategies which are "
"based on the same API described below."
msgstr ""
"L'abstraction de la stratégie permet de mettre en œuvre des stratégies "
"entièrement personnalisées. Une stratégie est essentiellement "
"l'algorithme d'apprentissage fédéré qui s'exécute sur le serveur. Les "
"stratégies décident comment échantillonner les clients, comment "
"configurer les clients pour la formation, comment agréger les mises à "
"jour et comment évaluer les modèles. Flower fournit quelques stratégies "
"intégrées qui sont basées sur la même API que celle décrite ci-dessous."

#: ../../source/how-to-implement-strategies.rst:11
msgid "The :code:`Strategy` abstraction"
msgstr "L'abstraction :code:`Stratégie`"

#: ../../source/how-to-implement-strategies.rst:13
msgid ""
"All strategy implementation are derived from the abstract base class "
":code:`flwr.server.strategy.Strategy`, both built-in implementations and "
"third party implementations. This means that custom strategy "
"implementations have the exact same capabilities at their disposal as "
"built-in ones."
msgstr ""
"Toutes les implémentations de stratégies sont dérivées de la classe de "
"base abstraite :code:`flwr.server.strategy.Strategy`, qu'il s'agisse "
"d'implémentations intégrées ou d'implémentations tierces. Cela signifie "
"que les implémentations de stratégies personnalisées ont exactement les "
"mêmes capacités à leur disposition que les implémentations intégrées."

#: ../../source/how-to-implement-strategies.rst:18
msgid ""
"The strategy abstraction defines a few abstract methods that need to be "
"implemented:"
msgstr ""
"L'abstraction de la stratégie définit quelques méthodes abstraites qui "
"doivent être mises en œuvre :"

#: ../../source/how-to-implement-strategies.rst:75
msgid ""
"Creating a new strategy means implementing a new :code:`class` (derived "
"from the abstract base class :code:`Strategy`) that implements for the "
"previously shown abstract methods:"
msgstr ""
"La création d'une nouvelle stratégie implique la mise en œuvre d'une "
"nouvelle :code:`classe` (dérivée de la classe de base abstraite "
":code:`Stratégie`) qui met en œuvre les méthodes abstraites présentées "
"précédemment :"

#: ../../source/how-to-implement-strategies.rst:100
msgid "The Flower server calls these methods in the following order:"
msgstr "Le serveur Flower appelle ces méthodes dans l'ordre suivant :"

#: ../../source/how-to-implement-strategies.rst:177
msgid "The following sections describe each of those methods in more detail."
msgstr "Les sections suivantes décrivent chacune de ces méthodes plus en détail."

#: ../../source/how-to-implement-strategies.rst:180
msgid "The :code:`initialize_parameters` method"
msgstr "La méthode :code:`initialize_parameters` (initialisation des paramètres)"

#: ../../source/how-to-implement-strategies.rst:182
msgid ""
":code:`initialize_parameters` is called only once, at the very beginning "
"of an execution. It is responsible for providing the initial global model"
" parameters in a serialized form (i.e., as a :code:`Parameters` object)."
msgstr ""
":code:`initialize_parameters` n'est appelé qu'une seule fois, au tout "
"début d'une exécution. Il est chargé de fournir les paramètres initiaux "
"du modèle global sous une forme sérialisée (c'est-à-dire sous la forme "
"d'un objet :code:`Parameters`)."

#: ../../source/how-to-implement-strategies.rst:184
msgid ""
"Built-in strategies return user-provided initial parameters. The "
"following example shows how initial parameters can be passed to "
":code:`FedAvg`:"
msgstr ""
"Les stratégies intégrées renvoient les paramètres initiaux fournis par "
"l'utilisateur. L'exemple suivant montre comment les paramètres initiaux "
"peuvent être transmis à :code:`FedAvg` :"

#: ../../source/how-to-implement-strategies.rst:209
msgid ""
"The Flower server will call :code:`initialize_parameters`, which either "
"returns the parameters that were passed to :code:`initial_parameters`, or"
" :code:`None`. If no parameters are returned from "
":code:`initialize_parameters` (i.e., :code:`None`), the server will "
"randomly select one client and ask it to provide its parameters. This is "
"a convenience feature and not recommended in practice, but it can be "
"useful for prototyping. In practice, it is recommended to always use "
"server-side parameter initialization."
msgstr ""
"Le serveur Flower appelle :code:`initialize_parameters`, qui renvoie les "
"paramètres passés à :code:`initial_parameters`, ou :code:`None`. Si aucun"
" paramètre n'est renvoyé par :code:`initialize_parameters` (c'est-à-dire "
":code:`None`), le serveur sélectionne au hasard un client et lui demande "
"de fournir ses paramètres. Il s'agit d'une fonction de commodité qui "
"n'est pas recommandée dans la pratique, mais qui peut être utile pour le "
"prototypage. Dans la pratique, il est recommandé de toujours utiliser "
"l'initialisation des paramètres du côté du serveur."

#: ../../source/how-to-implement-strategies.rst:213
msgid ""
"Server-side parameter initialization is a powerful mechanism. It can be "
"used, for example, to resume training from a previously saved checkpoint."
" It is also the fundamental capability needed to implement hybrid "
"approaches, for example, to fine-tune a pre-trained model using federated"
" learning."
msgstr ""
"L'initialisation des paramètres côté serveur est un mécanisme puissant. "
"Elle peut être utilisée, par exemple, pour reprendre l'entraînement à "
"partir d'un point de contrôle précédemment sauvegardé. C'est également la"
" capacité fondamentale nécessaire pour mettre en œuvre des approches "
"hybrides, par exemple, pour affiner un modèle pré-entraîné à l'aide de "
"l'apprentissage fédéré."

#: ../../source/how-to-implement-strategies.rst:216
msgid "The :code:`configure_fit` method"
msgstr "La méthode :code:`configure_fit`"

#: ../../source/how-to-implement-strategies.rst:218
msgid ""
":code:`configure_fit` is responsible for configuring the upcoming round "
"of training. What does *configure* mean in this context? Configuring a "
"round means selecting clients and deciding what instructions to send to "
"these clients. The signature of :code:`configure_fit` makes this clear:"
msgstr ""
":code:`configure_fit` est chargé de configurer le prochain tour de "
"formation. Que signifie *configurer* dans ce contexte ? Configurer un "
"tour signifie sélectionner des clients et décider des instructions à leur"
" envoyer. La signature de :code:`configure_fit` l'indique clairement :"

#: ../../source/how-to-implement-strategies.rst:231
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations "
"usually perform the following steps in :code:`configure_fit`:"
msgstr ""
"La valeur de retour est une liste de tuples, chacun représentant les "
"instructions qui seront envoyées à un client particulier. Les "
"implémentations de stratégies effectuent généralement les étapes "
"suivantes dans :code:`configure_fit` :"

#: ../../source/how-to-implement-strategies.rst:233
#: ../../source/how-to-implement-strategies.rst:280
msgid ""
"Use the :code:`client_manager` to randomly sample all (or a subset of) "
"available clients (each represented as a :code:`ClientProxy` object)"
msgstr ""
"Utilise le :code:`client_manager` pour échantillonner au hasard tous les "
"clients disponibles (ou un sous-ensemble d'entre eux) (chacun représenté "
"par un objet :code:`ClientProxy`)"

#: ../../source/how-to-implement-strategies.rst:234
msgid ""
"Pair each :code:`ClientProxy` with the same :code:`FitIns` holding the "
"current global model :code:`parameters` and :code:`config` dict"
msgstr ""
"Associe chaque :code:`ClientProxy` au même :code:`FitIns` contenant le "
"modèle global actuel :code:`parameters` et :code:`config` dict"

#: ../../source/how-to-implement-strategies.rst:236
msgid ""
"More sophisticated implementations can use :code:`configure_fit` to "
"implement custom client selection logic. A client will only participate "
"in a round if the corresponding :code:`ClientProxy` is included in the "
"the list returned from :code:`configure_fit`."
msgstr ""
"Les implémentations plus sophistiquées peuvent utiliser "
":code:`configure_fit` pour mettre en œuvre une logique de sélection des "
"clients personnalisée. Un client ne participera à un tour que si le "
":code:`ClientProxy` correspondant est inclus dans la liste renvoyée par "
":code:`configure_fit`."

#: ../../source/how-to-implement-strategies.rst:240
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies "
"to train, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the :code:`config` "
"dict)."
msgstr ""
"La structure de cette valeur de retour offre beaucoup de souplesse à "
"l'utilisateur. Comme les instructions sont définies par client, des "
"instructions différentes peuvent être envoyées à chaque client, ce qui "
"permet d'élaborer des stratégies personnalisées pour former, par exemple,"
" différents modèles sur différents clients, ou utiliser différents "
"hyperparamètres sur différents clients (via le dict :code:`config`)."

#: ../../source/how-to-implement-strategies.rst:243
msgid "The :code:`aggregate_fit` method"
msgstr "La méthode :code:`aggregate_fit` (agrégation)"

#: ../../source/how-to-implement-strategies.rst:245
msgid ""
":code:`aggregate_fit` is responsible for aggregating the results returned"
" by the clients that were selected and asked to train in "
":code:`configure_fit`."
msgstr ""
":code:`aggregate_fit` est chargé d'agréger les résultats renvoyés par les"
" clients qui ont été sélectionnés et à qui on a demandé de s'entraîner "
"dans :code:`configure_fit`."

#: ../../source/how-to-implement-strategies.rst:258
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via "
":code:`configure_fit`). :code:`aggregate_fit` therefore receives a list "
"of :code:`results`, but also a list of :code:`failures`."
msgstr ""
"Bien sûr, des échecs peuvent se produire, il n'y a donc aucune garantie "
"que le serveur obtienne des résultats de tous les clients auxquels il a "
"envoyé des instructions (via :code:`configure_fit`). "
":code:`aggregate_fit` reçoit donc une liste de :code:`résultats`, mais "
"aussi une liste de :code:`échecs`."

#: ../../source/how-to-implement-strategies.rst:260
msgid ""
":code:`aggregate_fit` returns an optional :code:`Parameters` object and a"
" dictionary of aggregated metrics. The :code:`Parameters` return value is"
" optional because :code:`aggregate_fit` might decide that the results "
"provided are not sufficient for aggregation (e.g., too many failures)."
msgstr ""
":code:`aggregate_fit` renvoie un objet :code:`Parameters` facultatif et "
"un dictionnaire de métriques agrégées. La valeur de retour "
":code:`Parameters` est facultative car :code:`aggregate_fit` peut décider"
" que les résultats fournis ne sont pas suffisants pour l'agrégation (par "
"exemple, trop d'échecs)."

#: ../../source/how-to-implement-strategies.rst:263
msgid "The :code:`configure_evaluate` method"
msgstr "La méthode :code:`configure_evaluate` (en anglais)"

#: ../../source/how-to-implement-strategies.rst:265
msgid ""
":code:`configure_evaluate` is responsible for configuring the upcoming "
"round of evaluation. What does *configure* mean in this context? "
"Configuring a round means selecting clients and deciding what "
"instructions to send to these clients. The signature of "
":code:`configure_evaluate` makes this clear:"
msgstr ""
":code:`configure_evaluate` est chargé de configurer le prochain tour "
"d'évaluation. Que signifie *configurer* dans ce contexte ? Configurer un "
"tour signifie sélectionner des clients et décider des instructions à leur"
" envoyer. La signature de :code:`configure_evaluate` l'indique clairement"
" :"

#: ../../source/how-to-implement-strategies.rst:278
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations "
"usually perform the following steps in :code:`configure_evaluate`:"
msgstr ""
"La valeur de retour est une liste de tuples, chacun représentant les "
"instructions qui seront envoyées à un client particulier. Les "
"implémentations de stratégies effectuent généralement les étapes "
"suivantes dans :code:`configure_evaluate` :"

#: ../../source/how-to-implement-strategies.rst:281
msgid ""
"Pair each :code:`ClientProxy` with the same :code:`EvaluateIns` holding "
"the current global model :code:`parameters` and :code:`config` dict"
msgstr ""
"Associe chaque :code:`ClientProxy` au même :code:`EvaluateIns` contenant "
"le modèle global actuel :code:`parameters` et :code:`config` dict"

#: ../../source/how-to-implement-strategies.rst:283
msgid ""
"More sophisticated implementations can use :code:`configure_evaluate` to "
"implement custom client selection logic. A client will only participate "
"in a round if the corresponding :code:`ClientProxy` is included in the "
"the list returned from :code:`configure_evaluate`."
msgstr ""
"Les implémentations plus sophistiquées peuvent utiliser "
":code:`configure_evaluate` pour mettre en œuvre une logique de sélection "
"des clients personnalisée. Un client ne participera à un tour que si le "
":code:`ClientProxy` correspondant est inclus dans la liste renvoyée par "
":code:`configure_evaluate`."

#: ../../source/how-to-implement-strategies.rst:287
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies "
"to evaluate, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the :code:`config` "
"dict)."
msgstr ""
"La structure de cette valeur de retour offre beaucoup de souplesse à "
"l'utilisateur. Comme les instructions sont définies par client, des "
"instructions différentes peuvent être envoyées à chaque client. Cela "
"permet aux stratégies personnalisées d'évaluer, par exemple, différents "
"modèles sur différents clients, ou d'utiliser différents hyperparamètres "
"sur différents clients (via le dict :code:`config`)."

#: ../../source/how-to-implement-strategies.rst:291
msgid "The :code:`aggregate_evaluate` method"
msgstr "La méthode :code:`aggregate_evaluate` (agréger_évaluer)"

#: ../../source/how-to-implement-strategies.rst:293
msgid ""
":code:`aggregate_evaluate` is responsible for aggregating the results "
"returned by the clients that were selected and asked to evaluate in "
":code:`configure_evaluate`."
msgstr ""
":code:`aggregate_evaluate` est chargé d'agréger les résultats renvoyés "
"par les clients qui ont été sélectionnés et à qui l'on a demandé "
"d'évaluer dans :code:`configure_evaluate`."

#: ../../source/how-to-implement-strategies.rst:306
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via "
":code:`configure_evaluate`). :code:`aggregate_evaluate` therefore "
"receives a list of :code:`results`, but also a list of :code:`failures`."
msgstr ""
"Bien sûr, des échecs peuvent se produire, il n'y a donc aucune garantie "
"que le serveur obtienne des résultats de tous les clients auxquels il a "
"envoyé des instructions (via :code:`configure_evaluate`). "
":code:`aggregate_evaluate` reçoit donc une liste de :code:`résultats`, "
"mais aussi une liste d' :code:`échecs`."

#: ../../source/how-to-implement-strategies.rst:308
msgid ""
":code:`aggregate_evaluate` returns an optional :code:`float` (loss) and a"
" dictionary of aggregated metrics. The :code:`float` return value is "
"optional because :code:`aggregate_evaluate` might decide that the results"
" provided are not sufficient for aggregation (e.g., too many failures)."
msgstr ""
":code:`aggregate_evaluate` renvoie un :code:`float` facultatif (perte) et"
" un dictionnaire de mesures agrégées. La valeur de retour :code:`float` "
"est facultative car :code:`aggregate_evaluate` peut décider que les "
"résultats fournis ne sont pas suffisants pour l'agrégation (par exemple, "
"trop d'échecs)."

#: ../../source/how-to-implement-strategies.rst:311
msgid "The :code:`evaluate` method"
msgstr "La méthode :code:`évaluer`"

#: ../../source/how-to-implement-strategies.rst:313
msgid ""
":code:`evaluate` is responsible for evaluating model parameters on the "
"server-side. Having :code:`evaluate` in addition to "
":code:`configure_evaluate`/:code:`aggregate_evaluate` enables strategies "
"to perform both servers-side and client-side (federated) evaluation."
msgstr ""
"le fait d'avoir :code:`evaluate` en plus de "
":code:`configure_evaluate`/:code:`aggregate_evaluate` permet aux "
"stratégies d'effectuer des évaluations à la fois côté serveur et côté "
"client (fédéré)."

#: ../../source/how-to-implement-strategies.rst:323
msgid ""
"The return value is again optional because the strategy might not need to"
" implement server-side evaluation or because the user-defined "
":code:`evaluate` method might not complete successfully (e.g., it might "
"fail to load the server-side evaluation data)."
msgstr ""
"La valeur de retour est à nouveau facultative parce que la stratégie peut"
" ne pas avoir besoin de mettre en œuvre l'évaluation côté serveur ou "
"parce que la méthode :code:`evaluate` définie par l'utilisateur peut ne "
"pas se terminer avec succès (par exemple, elle peut échouer à charger les"
" données de l'évaluation côté serveur)."

#: ../../source/how-to-install-flower.rst:2
#, fuzzy
msgid "Install Flower"
msgstr "Installer Flower"

#: ../../source/how-to-install-flower.rst:6
#, fuzzy
msgid "Python version"
msgstr "Version Python"

#: ../../source/how-to-install-flower.rst:12
msgid "Install stable release"
msgstr "Installe la version stable"

#: ../../source/how-to-install-flower.rst:14
msgid ""
"Stable releases are available on `PyPI "
"<https://pypi.org/project/flwr/>`_::"
msgstr ""
"Les versions stables sont disponibles sur `PyPI "
"<https://pypi.org/project/flwr/>`_: :"

#: ../../source/how-to-install-flower.rst:18
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` should be "
"installed with the ``simulation`` extra::"
msgstr ""
"Pour les simulations qui utilisent le moteur de client virtuel, ``flwr`` "
"doit être installé avec l'option ``simulation``: :"

#: ../../source/how-to-install-flower.rst:24
msgid "Verify installation"
msgstr "Vérifie l'installation"

#: ../../source/how-to-install-flower.rst:26
msgid ""
"The following command can be used to verfiy if Flower was successfully "
"installed. If everything worked, it should print the version of Flower to"
" the command line::"
msgstr ""
"La commande suivante peut être utilisée pour vérifier si Flower a été "
"installé avec succès. Si tout a fonctionné, la version de Flower devrait "
"être imprimée sur la ligne de commande: :"

#: ../../source/how-to-install-flower.rst:33
msgid "Advanced installation options"
msgstr "Options d'installation avancées"

#: ../../source/how-to-install-flower.rst:36
msgid "Install pre-release"
msgstr "Installer la version pre-release"

#: ../../source/how-to-install-flower.rst:38
msgid ""
"New (possibly unstable) versions of Flower are sometimes available as "
"pre-release versions (alpha, beta, release candidate) before the stable "
"release happens::"
msgstr ""
"Les nouvelles versions (éventuellement instables) de Flower sont parfois "
"disponibles en tant que versions préliminaires (alpha, bêta, release "
"candidate) avant que la version stable n'arrive : :"

#: ../../source/how-to-install-flower.rst:42
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` pre-releases"
" should be installed with the ``simulation`` extra::"
msgstr ""
"Pour les simulations qui utilisent le moteur de client virtuel, les "
"versions de ``flwr`` doivent être installées avec l'option "
"``simulation``: :"

#: ../../source/how-to-install-flower.rst:47
msgid "Install nightly release"
msgstr "Installer la version nightly"

#: ../../source/how-to-install-flower.rst:49
msgid ""
"The latest (potentially unstable) changes in Flower are available as "
"nightly releases::"
msgstr ""
"Les dernières modifications (potentiellement instables) de Flower sont "
"disponibles sous forme de versions nocturnes: :"

#: ../../source/how-to-install-flower.rst:53
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr-nightly`` "
"should be installed with the ``simulation`` extra::"
msgstr ""
"Pour les simulations qui utilisent le moteur de client virtuel, ``flwr-"
"nightly`` doit être installé avec l'option ``simulation``: :"

#: ../../source/how-to-monitor-simulation.rst:2
#, fuzzy
msgid "Monitor simulation"
msgstr "Simulation de moniteur"

#: ../../source/how-to-monitor-simulation.rst:4
msgid ""
"Flower allows you to monitor system resources while running your "
"simulation. Moreover, the Flower simulation engine is powerful and "
"enables you to decide how to allocate resources per client manner and "
"constrain the total usage. Insights from resource consumption can help "
"you make smarter decisions and speed up the execution time."
msgstr ""
"Flower te permet de surveiller les ressources du système pendant "
"l'exécution de ta simulation. De plus, le moteur de simulation de Flower "
"est puissant et te permet de décider comment allouer les ressources par "
"manière de client et de limiter l'utilisation totale. Les informations "
"sur la consommation des ressources peuvent t'aider à prendre des "
"décisions plus intelligentes et à accélérer le temps d'exécution."

#: ../../source/how-to-monitor-simulation.rst:6
msgid ""
"The specific instructions assume you are using macOS and have the "
"`Homebrew <https://brew.sh/>`_ package manager installed."
msgstr ""
"Les instructions spécifiques supposent que tu utilises macOS et que le "
"gestionnaire de paquets `Homebrew <https://brew.sh/>`_ est installé."

#: ../../source/how-to-monitor-simulation.rst:10
msgid "Downloads"
msgstr "Téléchargements"

#: ../../source/how-to-monitor-simulation.rst:16
msgid ""
"`Prometheus <https://prometheus.io/>`_ is used for data collection, while"
" `Grafana <https://grafana.com/>`_ will enable you to visualize the "
"collected data. They are both well integrated with `Ray "
"<https://www.ray.io/>`_ which Flower uses under the hood."
msgstr ""
"`Prometheus <https://prometheus.io/>`_ est utilisé pour la collecte de "
"données, tandis que `Grafana <https://grafana.com/>`_ te permettra de "
"visualiser les données collectées. Ils sont tous deux bien intégrés à "
"`Ray <https://www.ray.io/>`_ que Flower utilise sous le capot."

#: ../../source/how-to-monitor-simulation.rst:18
msgid ""
"Overwrite the configuration files (depending on your device, it might be "
"installed on a different path)."
msgstr ""
"Écrase les fichiers de configuration (selon ton appareil, il se peut "
"qu'il soit installé sur un chemin différent)."

#: ../../source/how-to-monitor-simulation.rst:20
msgid "If you are on an M1 Mac, it should be:"
msgstr "Si tu es sur un Mac M1, il devrait l'être :"

#: ../../source/how-to-monitor-simulation.rst:27
msgid "On the previous generation Intel Mac devices, it should be:"
msgstr ""
"Sur les appareils Mac Intel de la génération précédente, ce devrait être "
"le cas :"

#: ../../source/how-to-monitor-simulation.rst:34
msgid ""
"Open the respective configuration files and change them. Depending on "
"your device, use one of the two following commands:"
msgstr ""
"Ouvre les fichiers de configuration respectifs et modifie-les. Selon ton "
"appareil, utilise l'une des deux commandes suivantes :"

#: ../../source/how-to-monitor-simulation.rst:44
msgid ""
"and then delete all the text in the file and paste a new Prometheus "
"config you see below. You may adjust the time intervals to your "
"requirements:"
msgstr ""
"puis supprime tout le texte du fichier et colle une nouvelle "
"configuration Prometheus que tu vois ci-dessous. Tu peux adapter les "
"intervalles de temps à tes besoins :"

#: ../../source/how-to-monitor-simulation.rst:59
msgid ""
"Now after you have edited the Prometheus configuration, do the same with "
"the Grafana configuration files. Open those using one of the following "
"commands as before:"
msgstr ""
"Maintenant, après avoir édité la configuration de Prometheus, fais de "
"même avec les fichiers de configuration de Grafana. Ouvre ces derniers à "
"l'aide de l'une des commandes suivantes, comme précédemment :"

#: ../../source/how-to-monitor-simulation.rst:69
msgid ""
"Your terminal editor should open and allow you to apply the following "
"configuration as before."
msgstr ""
"Ton éditeur de terminal devrait s'ouvrir et te permettre d'appliquer la "
"configuration suivante comme précédemment."

#: ../../source/how-to-monitor-simulation.rst:84
msgid ""
"Congratulations, you just downloaded all the necessary software needed "
"for metrics tracking. Now, let’s start it."
msgstr ""
"Félicitations, tu viens de télécharger tous les logiciels nécessaires au "
"suivi des métriques, maintenant, démarrons-le."

#: ../../source/how-to-monitor-simulation.rst:88
msgid "Tracking metrics"
msgstr "Suivi des mesures"

#: ../../source/how-to-monitor-simulation.rst:90
msgid ""
"Before running your Flower simulation, you have to start the monitoring "
"tools you have just installed and configured."
msgstr ""
"Avant de lancer ta simulation Flower, tu dois démarrer les outils de "
"surveillance que tu viens d'installer et de configurer."

#: ../../source/how-to-monitor-simulation.rst:97
msgid ""
"Please include the following argument in your Python code when starting a"
" simulation."
msgstr ""
"Tu dois inclure l'argument suivant dans ton code Python lorsque tu "
"démarres une simulation."

#: ../../source/how-to-monitor-simulation.rst:108
msgid "Now, you are ready to start your workload."
msgstr "Maintenant, tu es prêt à commencer ta charge de travail."

#: ../../source/how-to-monitor-simulation.rst:110
msgid ""
"Shortly after the simulation starts, you should see the following logs in"
" your terminal:"
msgstr ""
"Peu de temps après le début de la simulation, tu devrais voir les "
"journaux suivants dans ton terminal :"

#: ../../source/how-to-monitor-simulation.rst:117
msgid "You can look at everything at `<http://127.0.0.1:8265>`_ ."
msgstr "Tu peux tout regarder sur `<http://127.0.0.1:8265>`_ ."

#: ../../source/how-to-monitor-simulation.rst:119
msgid ""
"It's a Ray Dashboard. You can navigate to Metrics (on the left panel, the"
" lowest option)."
msgstr ""
"Il s'agit d'un tableau de bord Ray. Tu peux naviguer vers Metrics (sur le"
" panneau de gauche, l'option la plus basse)."

#: ../../source/how-to-monitor-simulation.rst:121
msgid ""
"Or alternatively, you can just see them in Grafana by clicking on the "
"right-up corner, “View in Grafana”. Please note that the Ray dashboard is"
" only accessible during the simulation. After the simulation ends, you "
"can only use Grafana to explore the metrics. You can start Grafana by "
"going to ``http://localhost:3000/``."
msgstr ""
"Ou alors, tu peux simplement les voir dans Grafana en cliquant sur le "
"coin supérieur droit, \"View in Grafana\". Sache que le tableau de bord "
"Ray n'est accessible que pendant la simulation. Une fois la simulation "
"terminée, tu ne peux utiliser Grafana que pour explorer les métriques. Tu"
" peux démarrer Grafana en te rendant sur `http://localhost:3000/``."

#: ../../source/how-to-monitor-simulation.rst:123
msgid ""
"After you finish the visualization, stop Prometheus and Grafana. This is "
"important as they will otherwise block, for example port :code:`3000` on "
"your machine as long as they are running."
msgstr ""
"Après avoir terminé la visualisation, arrête Prometheus et Grafana. C'est"
" important car sinon ils bloqueront, par exemple, le port :code:`3000` "
"sur ta machine tant qu'ils seront en cours d'exécution."

#: ../../source/how-to-monitor-simulation.rst:132
msgid "Resource allocation"
msgstr "Allocation des ressources"

#: ../../source/how-to-monitor-simulation.rst:134
msgid ""
"You must understand how the Ray library works to efficiently allocate "
"system resources to simulation clients on your own."
msgstr ""
"Tu dois comprendre le fonctionnement de la bibliothèque Ray pour allouer "
"efficacement les ressources du système aux clients de simulation de ton "
"côté."

#: ../../source/how-to-monitor-simulation.rst:136
msgid ""
"Initially, the simulation (which Ray handles under the hood) starts by "
"default with all the available resources on the system, which it shares "
"among the clients. It doesn't mean it divides it equally among all of "
"them, nor that the model training happens at all of them simultaneously. "
"You will learn more about that in the later part of this blog. You can "
"check the system resources by running the following:"
msgstr ""
"Au départ, la simulation (que Ray gère sous le capot) démarre par défaut "
"avec toutes les ressources disponibles sur le système, qu'elle partage "
"entre les clients. Cela ne signifie pas qu'elle les divise de manière "
"égale entre tous, ni que l'apprentissage du modèle se fait sur tous les "
"clients simultanément. Tu en apprendras plus à ce sujet dans la suite de "
"ce blog. Tu peux vérifier les ressources du système en exécutant ce qui "
"suit :"

#: ../../source/how-to-monitor-simulation.rst:143
msgid "In Google Colab, the result you see might be similar to this:"
msgstr "Dans Google Colab, le résultat que tu obtiens peut ressembler à ceci :"

#: ../../source/how-to-monitor-simulation.rst:155
msgid ""
"However, you can overwrite the defaults. When starting a simulation, do "
"the following (you don't need to overwrite all of them):"
msgstr ""
"Cependant, tu peux écraser les valeurs par défaut. Lorsque tu démarres "
"une simulation, fais ce qui suit (tu n'as pas besoin de les écraser "
"toutes) :"

#: ../../source/how-to-monitor-simulation.rst:175
msgid "Let’s also specify the resource for a single client."
msgstr "Spécifions également la ressource pour un seul client."

#: ../../source/how-to-monitor-simulation.rst:205
msgid ""
"Now comes the crucial part. Ray will start a new client only when it has "
"all the required resources (such that they run in parallel) when the "
"resources allow."
msgstr ""
"Ray ne démarrera un nouveau client que lorsqu'il disposera de toutes les "
"ressources nécessaires (de manière à ce qu'ils fonctionnent en parallèle)"
" lorsque les ressources le permettront."

#: ../../source/how-to-monitor-simulation.rst:207
msgid ""
"In the example above, only one client will be run, so your clients won't "
"run concurrently. Setting :code:`client_num_gpus = 0.5` would allow "
"running two clients and therefore enable them to run concurrently. Be "
"careful not to require more resources than available. If you specified "
":code:`client_num_gpus = 2`, the simulation wouldn't start (even if you "
"had 2 GPUs but decided to set 1 in :code:`ray_init_args`)."
msgstr ""
"Dans l'exemple ci-dessus, un seul client sera exécuté, donc tes clients "
"ne fonctionneront pas simultanément. En définissant "
":code:`client_num_gpus = 0.5`, tu pourras exécuter deux clients et donc "
"les faire fonctionner simultanément. Fais attention à ne pas demander "
"plus de ressources que celles disponibles. Si tu as spécifié "
":code:`client_num_gpus = 2`, la simulation ne démarrera pas (même si tu "
"as 2 GPU mais que tu as décidé d'en définir 1 dans "
":code:`ray_init_args`)."

#: ../../source/how-to-monitor-simulation.rst:212 ../../source/ref-faq.rst:2
msgid "FAQ"
msgstr "FAQ"

#: ../../source/how-to-monitor-simulation.rst:214
msgid "Q: I don't see any metrics logged."
msgstr "Q : Je ne vois aucune mesure enregistrée."

#: ../../source/how-to-monitor-simulation.rst:216
msgid ""
"A: The timeframe might not be properly set. The setting is in the top "
"right corner (\"Last 30 minutes\" by default). Please change the "
"timeframe to reflect the period when the simulation was running."
msgstr ""
"R : Il se peut que le délai ne soit pas correctement défini. Le paramètre"
" se trouve dans le coin supérieur droit (\"Dernières 30 minutes\" par "
"défaut). Modifie le délai pour qu'il corresponde à la période pendant "
"laquelle la simulation s'est déroulée."

#: ../../source/how-to-monitor-simulation.rst:218
msgid ""
"Q: I see “Grafana server not detected. Please make sure the Grafana "
"server is running and refresh this page” after going to the Metrics tab "
"in Ray Dashboard."
msgstr ""
"Q : Je vois s'afficher \"Serveur Grafana non détecté. Vérifie que le "
"serveur Grafana fonctionne et actualise cette page\" après avoir accédé à"
" l'onglet Métriques dans Ray Dashboard."

#: ../../source/how-to-monitor-simulation.rst:220
msgid ""
"A: You probably don't have Grafana running. Please check the running "
"services"
msgstr ""
"R : Grafana n'est probablement pas en cours d'exécution. Vérifie les "
"services en cours d'exécution"

#: ../../source/how-to-monitor-simulation.rst:226
msgid ""
"Q: I see \"This site can't be reached\" when going to "
"`<http://127.0.0.1:8265>`_."
msgstr ""
"Q : Je vois \"This site can't be reached\" quand je vais sur "
"`<http://127.0.0.1:8265>`_."

#: ../../source/how-to-monitor-simulation.rst:228
msgid ""
"A: Either the simulation has already finished, or you still need to start"
" Prometheus."
msgstr ""
"R : Soit la simulation est déjà terminée, soit tu dois encore démarrer "
"Prometheus."

#: ../../source/how-to-monitor-simulation.rst:232
msgid "Resources"
msgstr "Ressources"

#: ../../source/how-to-monitor-simulation.rst:234
msgid ""
"Ray Dashboard: `<https://docs.ray.io/en/latest/ray-core/ray-"
"dashboard.html>`_"
msgstr ""
"Tableau de bord Ray : `<https://docs.ray.io/en/latest/ray-core/ray-"
"dashboard.html>`_"

#: ../../source/how-to-monitor-simulation.rst:236
msgid ""
"Ray Metrics: `<https://docs.ray.io/en/latest/ray-observability/ray-"
"metrics.html>`_"
msgstr ""
"Ray Metrics : `<https://docs.ray.io/en/latest/ray-observability/ray-"
"metrics.html>`_"

#: ../../source/how-to-run-simulations.rst:2
#, fuzzy
msgid "Run simulations"
msgstr "Simulation de moniteur"

#: ../../source/how-to-run-simulations.rst:8
msgid ""
"Simulating Federated Learning workloads is useful for a multitude of use-"
"cases: you might want to run your workload on a large cohort of clients "
"but without having to source, configure and mange a large number of "
"physical devices; you might want to run your FL workloads as fast as "
"possible on the compute systems you have access to without having to go "
"through a complex setup process; you might want to validate your "
"algorithm on different scenarios at varying levels of data and system "
"heterogeneity, client availability, privacy budgets, etc. These are among"
" some of the use-cases where simulating FL workloads makes sense. Flower "
"can accommodate these scenarios by means of its `VirtualClientEngine "
"<contributor-explanation-architecture.html#virtual-client-engine>`_ or "
"VCE."
msgstr ""

#: ../../source/how-to-run-simulations.rst:10
msgid ""
"The :code:`VirtualClientEngine` schedules, launches and manages `virtual`"
" clients. These clients are identical to `non-virtual` clients (i.e. the "
"ones you launch via the command `flwr.client.start_client <ref-api-"
"flwr.html#start-client>`_) in the sense that they can be configure "
"by creating a class inheriting, for example, from "
"`flwr.client.NumPyClient <ref-api-flwr.html#flwr.client.NumPyClient>`_ "
"and therefore behave in an identical way. In addition to that, clients "
"managed by the :code:`VirtualClientEngine` are:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:12
msgid ""
"resource-aware: this means that each client gets assigned a portion of "
"the compute and memory on your system. You as a user can control this at "
"the beginning of the simulation and allows you to control the degree of "
"parallelism of your Flower FL simulation. The fewer the resources per "
"client, the more clients can run concurrently on the same hardware."
msgstr ""

#: ../../source/how-to-run-simulations.rst:13
msgid ""
"self-managed: this means that you as a user do not need to launch clients"
" manually, instead this gets delegated to :code:`VirtualClientEngine`'s "
"internals."
msgstr ""

#: ../../source/how-to-run-simulations.rst:14
msgid ""
"ephemeral: this means that a client is only materialized when it is "
"required in the FL process (e.g. to do `fit() <ref-api-"
"flwr.html#flwr.client.Client.fit>`_). The object is destroyed afterwards,"
" releasing the resources it was assigned and allowing in this way other "
"clients to participate."
msgstr ""

#: ../../source/how-to-run-simulations.rst:16
msgid ""
"The :code:`VirtualClientEngine` implements `virtual` clients using `Ray "
"<https://www.ray.io/>`_, an open-source framework for scalable Python "
"workloads. In particular, Flower's :code:`VirtualClientEngine` makes use "
"of `Actors <https://docs.ray.io/en/latest/ray-core/actors.html>`_ to "
"spawn `virtual` clients and run their workload."
msgstr ""

#: ../../source/how-to-run-simulations.rst:20
msgid "Launch your Flower simulation"
msgstr ""

#: ../../source/how-to-run-simulations.rst:22
msgid ""
"Running Flower simulations still require you to define your client class,"
" a strategy, and utility functions to download and load (and potentially "
"partition) your dataset. With that out of the way, launching your "
"simulation is done with `start_simulation <ref-api-"
"flwr.html#flwr.simulation.start_simulation>`_ and a minimal example looks"
" as follows:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:44
#, fuzzy
msgid "VirtualClientEngine resources"
msgstr "Moteur de client virtuel"

#: ../../source/how-to-run-simulations.rst:45
msgid ""
"By default the VCE has access to all system resources (i.e. all CPUs, all"
" GPUs, etc) since that is also the default behavior when starting Ray. "
"However, in some settings you might want to limit how many of your system"
" resources are used for simulation. You can do this via the "
":code:`ray_init_args` input argument to :code:`start_simulation` which "
"the VCE internally passes to Ray's :code:`ray.init` command. For a "
"complete list of settings you can configure check the `ray.init "
"<https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html#ray-init>`_"
" documentation. Do not set :code:`ray_init_args` if you want the VCE to "
"use all your system's CPUs and GPUs."
msgstr ""

#: ../../source/how-to-run-simulations.rst:62
msgid "Assigning client resources"
msgstr ""

#: ../../source/how-to-run-simulations.rst:63
msgid ""
"By default the :code:`VirtualClientEngine` assigns a single CPU core (and"
" nothing else) to each virtual client. This means that if your system has"
" 10 cores, that many virtual clients can be concurrently running."
msgstr ""

#: ../../source/how-to-run-simulations.rst:65
msgid ""
"More often than not, you would probably like to adjust the resources your"
" clients get assigned based on the complexity (i.e. compute and memory "
"footprint) of your FL workload. You can do so when starting your "
"simulation by setting the argument `client_resources` to "
"`start_simulation <ref-api-flwr.html#flwr.simulation.start_simulation>`_."
" Two keys are internally used by Ray to schedule and spawn workloads (in "
"our case Flower clients):"
msgstr ""

#: ../../source/how-to-run-simulations.rst:67
msgid ":code:`num_cpus` indicates the number of CPU cores a client would get."
msgstr ""

#: ../../source/how-to-run-simulations.rst:68
msgid ""
":code:`num_gpus` indicates the **ratio** of GPU memory a client gets "
"assigned."
msgstr ""

#: ../../source/how-to-run-simulations.rst:70
msgid "Let's see a few examples:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:89
msgid ""
"While the :code:`client_resources` can be used to control the degree of "
"concurrency in your FL simulation, this does not stop you from running "
"dozens, hundreds or even thousands of clients in the same round and "
"having orders of magnitude more `dormant` (i.e. not participating in a "
"round) clients. Let's say you want to have 100 clients per round but your"
" system can only accommodate 8 clients concurrently. The "
":code:`VirtualClientEngine` will schedule 100 jobs to run (each "
"simulating a client sampled by the strategy) and then will execute them "
"in a resource-aware manner in batches of 8."
msgstr ""

#: ../../source/how-to-run-simulations.rst:91
msgid ""
"To understand all the intricate details on how resources are used to "
"schedule FL clients and how to define custom resources, please take a "
"look at the `Ray documentation <https://docs.ray.io/en/latest/ray-"
"core/scheduling/resources.html>`_."
msgstr ""

#: ../../source/how-to-run-simulations.rst:94
#, fuzzy
msgid "Simulation examples"
msgstr "Exemples de PyTorch"

#: ../../source/how-to-run-simulations.rst:96
msgid ""
"A few ready-to-run complete examples for Flower simulation in "
"Tensorflow/Keras and PyTorch are provided in the `Flower repository "
"<https://github.com/adap/flower>`_. You can run them on Google Colab too:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:98
#, fuzzy
msgid ""
"`Tensorflow/Keras Simulation "
"<https://github.com/adap/flower/tree/main/examples/simulation-"
"tensorflow>`_: 100 clients collaboratively train a MLP model on MNIST."
msgstr ""
"`Quickstart TensorFlow (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_"

#: ../../source/how-to-run-simulations.rst:99
msgid ""
"`PyTorch Simulation <https://github.com/adap/flower/tree/main/examples"
"/simulation-pytorch>`_: 100 clients collaboratively train a CNN model on "
"MNIST."
msgstr ""

#: ../../source/how-to-run-simulations.rst:104
#, fuzzy
msgid "Multi-node Flower simulations"
msgstr "Simulation de moniteur"

#: ../../source/how-to-run-simulations.rst:106
msgid ""
"Flower's :code:`VirtualClientEngine` allows you to run FL simulations "
"across multiple compute nodes. Before starting your multi-node simulation"
" ensure that you:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:108
msgid "Have the same Python environment in all nodes."
msgstr ""

#: ../../source/how-to-run-simulations.rst:109
msgid "Have a copy of your code (e.g. your entire repo) in all nodes."
msgstr ""

#: ../../source/how-to-run-simulations.rst:110
msgid ""
"Have a copy of your dataset in all nodes (more about this in "
":ref:`simulation considerations <considerations-for-simulations>`)"
msgstr ""

#: ../../source/how-to-run-simulations.rst:111
msgid ""
"Pass :code:`ray_init_args={\"address\"=\"auto\"}` to `start_simulation "
"<ref-api-flwr.html#flwr.simulation.start_simulation>`_ so the "
":code:`VirtualClientEngine` attaches to a running Ray instance."
msgstr ""

#: ../../source/how-to-run-simulations.rst:112
msgid ""
"Start Ray on you head node: on the terminal type :code:`ray start "
"--head`. This command will print a few lines, one of which indicates how "
"to attach other nodes to the head node."
msgstr ""

#: ../../source/how-to-run-simulations.rst:113
msgid ""
"Attach other nodes to the head node: copy the command shown after "
"starting the head and execute it on terminal of a new node: for example "
":code:`ray start --address='192.168.1.132:6379'`"
msgstr ""

#: ../../source/how-to-run-simulations.rst:115
msgid ""
"With all the above done, you can run your code from the head node as you "
"would if the simulation was running on a single node."
msgstr ""

#: ../../source/how-to-run-simulations.rst:117
msgid ""
"Once your simulation is finished, if you'd like to dismantle your cluster"
" you simply need to run the command :code:`ray stop` in each node's "
"terminal (including the head node)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:120
msgid "Multi-node simulation good-to-know"
msgstr ""

#: ../../source/how-to-run-simulations.rst:122
msgid ""
"Here we list a few interesting functionality when running multi-node FL "
"simulations:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:124
msgid ""
"User :code:`ray status` to check all nodes connected to your head node as"
" well as the total resources available to the "
":code:`VirtualClientEngine`."
msgstr ""

#: ../../source/how-to-run-simulations.rst:126
msgid ""
"When attaching a new node to the head, all its resources (i.e. all CPUs, "
"all GPUs) will be visible by the head node. This means that the "
":code:`VirtualClientEngine` can schedule as many `virtual` clients as "
"that node can possible run. In some settings you might want to exclude "
"certain resources from the simulation. You can do this by appending "
"`--num-cpus=<NUM_CPUS_FROM_NODE>` and/or `--num-"
"gpus=<NUM_GPUS_FROM_NODE>` in any :code:`ray start` command (including "
"when starting the head)"
msgstr ""

#: ../../source/how-to-run-simulations.rst:132
#, fuzzy
msgid "Considerations for simulations"
msgstr "Simulation de moniteur"

#: ../../source/how-to-run-simulations.rst:135
msgid ""
"We are actively working on these fronts so to make it trivial to run any "
"FL workload with Flower simulation."
msgstr ""

#: ../../source/how-to-run-simulations.rst:138
msgid ""
"The current VCE allows you to run Federated Learning workloads in "
"simulation mode whether you are prototyping simple scenarios on your "
"personal laptop or you want to train a complex FL pipeline across "
"multiple high-performance GPU nodes. While we add more capabilities to "
"the VCE, the points below highlight some of the considerations to keep in"
" mind when designing your FL pipeline with Flower. We also highlight a "
"couple of current limitations in our implementation."
msgstr ""

#: ../../source/how-to-run-simulations.rst:141
#, fuzzy
msgid "GPU resources"
msgstr "Ressources"

#: ../../source/how-to-run-simulations.rst:143
msgid ""
"The VCE assigns a share of GPU memory to a client that specifies the key "
":code:`num_gpus` in :code:`client_resources`. This being said, Ray (used "
"internally by the VCE) is by default:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:146
msgid ""
"not aware of the total VRAM available on the GPUs. This means that if you"
" set :code:`num_gpus=0.5` and you have two GPUs in your system with "
"different (e.g. 32GB and 8GB) VRAM amounts, they both would run 2 clients"
" concurrently."
msgstr ""

#: ../../source/how-to-run-simulations.rst:147
msgid ""
"not aware of other unrelated (i.e. not created by the VCE) workloads are "
"running on the GPU. Two takeaways from this are:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:149
msgid ""
"Your Flower server might need a GPU to evaluate the `global model` after "
"aggregation (by instance when making use of the `evaluate method <how-to-"
"implement-strategies.html#the-evaluate-method>`_)"
msgstr ""

#: ../../source/how-to-run-simulations.rst:150
msgid ""
"If you want to run several independent Flower simulations on the same "
"machine you need to mask-out your GPUs with "
":code:`CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"` when launching your "
"experiment."
msgstr ""

#: ../../source/how-to-run-simulations.rst:153
msgid ""
"In addition, the GPU resource limits passed to :code:`client_resources` "
"are not `enforced` (i.e. they can be exceeded) which can result in the "
"situation of client using more VRAM than the ratio specified when "
"starting the simulation."
msgstr ""

#: ../../source/how-to-run-simulations.rst:156
#, fuzzy
msgid "TensorFlow with GPUs"
msgstr "Exemples de TensorFlow"

#: ../../source/how-to-run-simulations.rst:158
msgid ""
"When `using a GPU with TensorFlow "
"<https://www.tensorflow.org/guide/gpu>`_ nearly your entire GPU memory of"
" all your GPUs visible to the process will be mapped. This is done by "
"TensorFlow for optimization purposes. However, in settings such as FL "
"simulations where we want to split the GPU into multiple `virtual` "
"clients, this is not a desirable mechanism. Luckily we can disable this "
"default behavior by `enabling memory growth "
"<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_."
msgstr ""

#: ../../source/how-to-run-simulations.rst:160
msgid ""
"This would need to be done in the main process (which is where the server"
" would run) and in each Actor created by the VCE. By means of "
":code:`actor_kwargs` we can pass the reserved key `\"on_actor_init_fn\"` "
"in order to specify a function to be executed upon actor initialization. "
"In this case, to enable GPU growth for TF workloads. It would look as "
"follows:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:179
#, fuzzy
msgid ""
"This is precisely the mechanism used in `Tensorflow/Keras Simulation "
"<https://github.com/adap/flower/tree/main/examples/simulation-"
"tensorflow>`_ example."
msgstr ""
"`Quickstart TensorFlow (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_"

#: ../../source/how-to-run-simulations.rst:183
msgid "Multi-node setups"
msgstr ""

#: ../../source/how-to-run-simulations.rst:185
msgid ""
"The VCE does not currently offer a way to control on which node a "
"particular `virtual` client is executed. In other words, if more than a "
"single node have the resources needed by a client to run, then any of "
"those nodes could get the client workload scheduled onto. Later in the FL"
" process (i.e. in a different round) the same client could be executed by"
" a different node. Depending on how your clients access their datasets, "
"this might require either having a copy of all dataset partitions on all "
"nodes or a dataset serving mechanism (e.g. using nfs, a database) to "
"circumvent data duplication."
msgstr ""

#: ../../source/how-to-run-simulations.rst:187
msgid ""
"By definition virtual clients are `stateless` due to their ephemeral "
"nature. A client state can be implemented as part of the Flower client "
"class but users need to ensure this saved to persistent storage (e.g. a "
"database, disk) and that can be retrieve later by the same client "
"regardless on which node it is running from. This is related to the point"
" above also since, in some way, the client's dataset could be seen as a "
"type of `state`."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:2
#, fuzzy
msgid "Save and load model checkpoints"
msgstr "Sauvegarde et chargement des points de contrôle PyTorch"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:4
msgid ""
"Flower does not automatically save model updates on the server-side. This"
" how-to guide describes the steps to save (and load) model checkpoints in"
" Flower."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:8
#, fuzzy
msgid "Model checkpointing"
msgstr "Point de contrôle du modèle"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:10
msgid ""
"Model updates can be persisted on the server-side by customizing "
":code:`Strategy` methods. Implementing custom strategies is always an "
"option, but for many cases it may be more convenient to simply customize "
"an existing strategy. The following code example defines a new "
":code:`SaveModelStrategy` which customized the existing built-in "
":code:`FedAvg` strategy. In particular, it customizes "
":code:`aggregate_fit` by calling :code:`aggregate_fit` in the base class "
"(:code:`FedAvg`). It then continues to save returned (aggregated) weights"
" before it returns those aggregated weights to the caller (i.e., the "
"server):"
msgstr ""
"Les mises à jour du modèle peuvent être conservées côté serveur en "
"personnalisant les méthodes :code:`Strategy`. L'implémentation de "
"stratégies personnalisées est toujours possible, mais dans de nombreux "
"cas, il peut être plus pratique de simplement personnaliser une stratégie"
" existante. L'exemple de code suivant définit une nouvelle "
":code:`SaveModelStrategy` qui personnalise la stratégie intégrée "
":code:`FedAvg` existante. En particulier, il personnalise "
":code:`aggregate_fit` en appelant :code:`aggregate_fit` dans la classe de"
" base (:code:`FedAvg`). Il continue ensuite à sauvegarder les poids "
"retournés (agrégés) avant de renvoyer ces poids agrégés à l'appelant "
"(c'est-à-dire le serveur) :"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:47
#, fuzzy
msgid "Save and load PyTorch checkpoints"
msgstr "Sauvegarde et chargement des points de contrôle PyTorch"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:49
#, fuzzy
msgid ""
"Similar to the previous example but with a few extra steps, we'll show "
"how to store a PyTorch checkpoint we'll use the ``torch.save`` function. "
"Firstly, ``aggregate_fit`` returns a ``Parameters`` object that has to be"
" transformed into a list of NumPy ``ndarray``'s, then those are "
"transformed into the PyTorch ``state_dict`` following the ``OrderedDict``"
" class structure."
msgstr ""
"Comme dans l'exemple précédent, mais avec quelques étapes "
"supplémentaires, nous allons montrer comment stocker un point de contrôle"
" PyTorch en utilisant la fonction ``torch.save``. Tout d'abord, "
"``aggregate_fit`` renvoie un objet ``Parameters`` qui doit être "
"transformé en une liste de `ndarray`` NumPy, puis ceux-ci sont "
"transformés en ``state_dict`` PyTorch en suivant la structure de la "
"classe ``OrderedDict``."

#: ../../source/how-to-save-and-load-model-checkpoints.rst:85
msgid ""
"To load your progress, you simply append the following lines to your "
"code. Note that this will iterate over all saved checkpoints and load the"
" latest one:"
msgstr ""
"Pour charger ta progression, il te suffit d'ajouter les lignes suivantes "
"à ton code. Note que cela va itérer sur tous les points de contrôle "
"sauvegardés et charger le plus récent :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:2
msgid "Upgrade to Flower 1.0"
msgstr "Passe à Flower 1.0"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:4
msgid ""
"Flower 1.0 is here. Along with new features, Flower 1.0 provides a stable"
" foundation for future growth. Compared to Flower 0.19 (and other 0.x "
"series releases), there are a few breaking changes that make it necessary"
" to change the code of existing 0.x-series projects."
msgstr ""
"Flower 1.0 est arrivé. En plus de nouvelles fonctionnalités, Flower 1.0 "
"fournit une base stable pour la croissance future. Par rapport à Flower "
"0.19 (et aux autres versions de la série 0.x), il y a quelques "
"changements qui nécessitent de modifier le code des projets de la série "
"0.x existants."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:8
msgid "Install update"
msgstr "Installer la mise à jour"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:10
msgid ""
"Here's how to update an existing installation to Flower 1.0 using either "
"pip or Poetry:"
msgstr ""
"Voici comment mettre à jour une installation existante vers Flower 1.0 en"
" utilisant soit pip soit Poetry :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:12
msgid "pip: add ``-U`` when installing."
msgstr "pip : ajoute ``-U`` lors de l'installation."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:14
msgid ""
"``python -m pip install -U flwr`` (when using ``start_server`` and "
"``start_client``)"
msgstr ""
"``python -m pip install -U flwr`` (lors de l'utilisation de "
"``start_server`` et ``start_client``)"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:15
msgid ""
"``python -m pip install -U flwr[simulation]`` (when using "
"``start_simulation``)"
msgstr ""
"``python -m pip install -U flwr[simulation]`` (lors de l'utilisation de "
"``start_simulation``)"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:17
msgid ""
"Poetry: update the ``flwr`` dependency in ``pyproject.toml`` and then "
"reinstall (don't forget to delete ``poetry.lock`` via ``rm poetry.lock`` "
"before running ``poetry install``)."
msgstr ""
"Poetry : mettez à jour la dépendance ``flwr`` dans ``pyproject.toml`` "
"puis réinstallez (n'oubliez pas de supprimer ``poetry.lock`` via ``rm "
"poetry.lock`` avant d'exécuter ``poetry install``)."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:19
msgid "``flwr = \"^1.0.0\"`` (when using ``start_server`` and ``start_client``)"
msgstr ""
"``flwr = \"^1.0.0\"`` (lors de l'utilisation de ``start_server`` et "
"``start_client``)"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:20
msgid ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] }`` (when "
"using ``start_simulation``)"
msgstr ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] }`` (lors de "
"l'utilisation de ``start_simulation``)"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:24
msgid "Required changes"
msgstr "Changements nécessaires"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:26
msgid "The following breaking changes require manual updates."
msgstr ""
"Les changements de rupture suivants nécessitent des mises à jour "
"manuelles."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:29
msgid "General"
msgstr "Généralités"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:31
msgid ""
"Pass all arguments as keyword arguments (not as positional arguments). "
"Here's an example:"
msgstr ""
"Passe tous les arguments comme des arguments de mots-clés (et non comme "
"des arguments de position). Voici un exemple :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:33
msgid ""
"Flower 0.19 (positional arguments): ``start_client(\"127.0.0.1:8080\", "
"FlowerClient())``"
msgstr ""
"Flower 0.19 (arguments positionnels) : ``start_client(\"127.0.0.1:8080\","
" FlowerClient())``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:34
msgid ""
"Flower 1.0 (keyword arguments): "
"``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())``"
msgstr ""
"Fleur 1.0 (arguments de mots-clés) : "
"``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:39
msgid ""
"Subclasses of ``NumPyClient``: change ``def get_parameters(self):``` to "
"``def get_parameters(self, config):``"
msgstr ""
"Sous-classes de ``NumPyClient`` : changez ``def get_parameters(self):`` "
"en ``def get_parameters(self, config):``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:40
msgid ""
"Subclasses of ``Client``: change ``def get_parameters(self):``` to ``def "
"get_parameters(self, ins: GetParametersIns):``"
msgstr ""
"Sous-classes de ``Client`` : changez ``def get_parameters(self):`` en "
"``def get_parameters(self, ins : GetParametersIns):``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:43
msgid "Strategies / ``start_server`` / ``start_simulation``"
msgstr "Stratégies / ``démarrer_serveur`` / ``démarrer_simulation``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:45
msgid ""
"Pass ``ServerConfig`` (instead of a dictionary) to ``start_server`` and "
"``start_simulation``. Here's an example:"
msgstr ""
"Passez ``ServerConfig`` (au lieu d'un dictionnaire) à ``start_server`` et"
" ``start_simulation``. Voici un exemple :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:47
msgid ""
"Flower 0.19: ``start_server(..., config={\"num_rounds\": 3, "
"\"round_timeout\": 600.0}, ...)``"
msgstr ""
"Flower 0.19 : ``start_server(..., config={\"num_rounds\" : 3, "
"\"round_timeout\" : 600.0}, ...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:48
msgid ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"
msgstr ""
"Flower 1.0 : ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:50
msgid ""
"Replace ``num_rounds=1`` in ``start_simulation`` with the new "
"``config=ServerConfig(...)`` (see previous item)"
msgstr ""
"Remplacer ``num_rounds=1`` dans ``start_simulation`` par le nouveau "
"``config=ServerConfig(...)`` (voir point précédent)"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:51
msgid ""
"Remove ``force_final_distributed_eval`` parameter from calls to "
"``start_server``. Distributed evaluation on all clients can be enabled by"
" configuring the strategy to sample all clients for evaluation after the "
"last round of training."
msgstr ""
"Supprime le paramètre ``force_final_distributed_eval`` des appels à "
"``start_server``. L'évaluation distribuée sur tous les clients peut être "
"activée en configurant la stratégie pour échantillonner tous les clients "
"pour l'évaluation après le dernier tour de formation."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:52
msgid "Rename parameter/ndarray conversion functions:"
msgstr "Renomme les fonctions de conversion des paramètres et des tableaux :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:54
msgid "``parameters_to_weights`` --> ``parameters_to_ndarrays``"
msgstr "``parameters_to_weights`` --> ``parameters_to_ndarrays``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:55
msgid "``weights_to_parameters`` --> ``ndarrays_to_parameters``"
msgstr "``Poids_à_paramètres`` --> ``Réseaux_à_paramètres``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:57
msgid ""
"Strategy initialization: if the strategy relies on the default values for"
" ``fraction_fit`` and ``fraction_evaluate``, set ``fraction_fit`` and "
"``fraction_evaluate`` manually to ``0.1``. Projects that do not manually "
"create a strategy (by calling ``start_server`` or ``start_simulation`` "
"without passing a strategy instance) should now manually initialize "
"FedAvg with ``fraction_fit`` and ``fraction_evaluate`` set to ``0.1``."
msgstr ""
"Initialisation de la stratégie : si la stratégie repose sur les valeurs "
"par défaut de ``fraction_fit`` et ``fraction_evaluate``, fixer "
"manuellement ``fraction_fit`` et ``fraction_evaluate`` à `0.1``. Les "
"projets qui ne créent pas manuellement une stratégie (en appelant "
"``start_server` ou ``start_simulation`` sans passer une instance de "
"stratégie) doivent maintenant initialiser manuellement FedAvg avec "
"``fraction_fit`` et ``fraction_evaluate`` fixés à ``0.1``."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:58
msgid "Rename built-in strategy parameters (e.g., ``FedAvg``):"
msgstr "Renommer les paramètres de stratégie intégrés (par exemple, ``FedAvg``) :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:60
msgid "``fraction_eval`` --> ``fraction_evaluate``"
msgstr "``fraction_eval`` --> ``fraction_evaluate``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:61
msgid "``min_eval_clients`` --> ``min_evaluate_clients``"
msgstr "``min_eval_clients` --> ``min_evaluate_clients``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:62
msgid "``eval_fn`` --> ``evaluate_fn``"
msgstr "``eval_fn`` --> ``evaluate_fn``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:64
msgid ""
"Rename ``rnd`` to ``server_round``. This impacts multiple methods and "
"functions, for example, ``configure_fit``, ``aggregate_fit``, "
"``configure_evaluate``, ``aggregate_evaluate``, and ``evaluate_fn``."
msgstr ""
"Renommez ``rnd`` en ``server_round``. Cela a un impact sur plusieurs "
"méthodes et fonctions, par exemple, ``configure_fit``, ``aggregate_fit``,"
" ``configure_evaluate``, ``aggregate_evaluate``, et ``evaluate_fn``."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:65
msgid "Add ``server_round`` and ``config`` to ``evaluate_fn``:"
msgstr "Ajoute ``server_round`` et ``config`` à `evaluate_fn`` :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:67
msgid ""
"Flower 0.19: ``def evaluate(parameters: NDArrays) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 0.19 : ``def evaluate(parameters : NDArrays) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:68
msgid ""
"Flower 1.0: ``def evaluate(server_round: int, parameters: NDArrays, "
"config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, "
"Scalar]]]:``"
msgstr ""
"Flower 1.0 : ``def evaluate(server_round : int, parameters : NDArrays, "
"config : Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, "
"Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:71
msgid "Custom strategies"
msgstr "Stratégies personnalisées"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:73
msgid ""
"The type of parameter ``failures`` has changed from "
"``List[BaseException]`` to ``List[Union[Tuple[ClientProxy, FitRes], "
"BaseException]]`` (in ``aggregate_fit``) and "
"``List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]`` (in "
"``aggregate_evaluate``)"
msgstr ""
"Le type du paramètre ``failures`` a changé de ``List[BaseException]`` à "
"``List[Union[Tuple[ClientProxy, FitRes], BaseException]]`` (dans "
"``aggregate_fit``) et ``List[Union[Tuple[ClientProxy, EvaluateRes], "
"BaseException]]`` (dans ``aggregate_evaluate``)"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:74
msgid ""
"The ``Strategy`` method ``evaluate`` now receives the current round of "
"federated learning/evaluation as the first parameter:"
msgstr ""
"La méthode ``Stratégie`` `évaluer`` reçoit maintenant le cycle actuel "
"d'apprentissage/évaluation fédéré comme premier paramètre :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:76
msgid ""
"Flower 0.19: ``def evaluate(self, parameters: Parameters) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 0.19 : ``def evaluate(self, parameters : Parameters) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:77
msgid ""
"Flower 1.0: ``def evaluate(self, server_round: int, parameters: "
"Parameters) -> Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 1.0 : ``def evaluate(self, server_round : int, parameters : "
"Parameters) -> Optional[Tuple[float, Dict[str, Scalar]]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:80
msgid "Optional improvements"
msgstr "Améliorations facultatives"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:82
msgid ""
"Along with the necessary changes above, there are a number of potential "
"improvements that just became possible:"
msgstr ""
"En plus des changements nécessaires mentionnés ci-dessus, il existe un "
"certain nombre d'améliorations potentielles qui viennent d'être rendues "
"possibles :"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:84
msgid ""
"Remove \"placeholder\" methods from subclasses of ``Client`` or "
"``NumPyClient``. If you, for example, use server-side evaluation, then "
"empy placeholder implementations of ``evaluate`` are no longer necessary."
msgstr ""
"Supprime les méthodes \"placeholder\" des sous-classes de ``Client`` ou "
"de ``NumPyClient``. Si tu utilises, par exemple, l'évaluation côté "
"serveur, alors les implémentations \"placeholder\" de ``evaluate`` ne "
"sont plus nécessaires."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:85
msgid ""
"Configure the round timeout via ``start_simulation``: "
"``start_simulation(..., config=flwr.server.ServerConfig(num_rounds=3, "
"round_timeout=600.0), ...)``"
msgstr ""
"Configurez le délai d'attente de la ronde via ``start_simulation`` : "
"``start_simulation(..., config=flwr.server.ServerConfig(num_rounds=3, "
"round_timeout=600.0), ...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:89
msgid "Further help"
msgstr "Aide supplémentaire"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:91
msgid ""
"Most official `Flower code examples "
"<https://github.com/adap/flower/tree/main/examples>`_ are already updated"
" to Flower 1.0, they can serve as a reference for using the Flower 1.0 "
"API. If there are further questionsm, `join the Flower Slack "
"<https://flower.dev/join-slack/>`_ and use the channgel ``#questions``."
msgstr ""
"La plupart des `exemples de code Flower officiels "
"<https://github.com/adap/flower/tree/main/examples>`_ sont déjà mis à "
"jour vers Flower 1.0, ils peuvent servir de référence pour l'utilisation "
"de l'API Flower 1.0. Si vous avez d'autres questions, `joins le Slack "
"Flower <https://flower.dev/join-slack/>`_ et utilise le canal "
"``#questions``."

#: ../../source/how-to-use-strategies.rst:2
#, fuzzy
msgid "Use strategies"
msgstr "Stratégies personnalisées"

#: ../../source/how-to-use-strategies.rst:4
msgid ""
"Flower allows full customization of the learning process through the "
":code:`Strategy` abstraction. A number of built-in strategies are "
"provided in the core framework."
msgstr ""
"Flower permet une personnalisation complète du processus d'apprentissage "
"grâce à l'abstraction :code:`Stratégie`. Un certain nombre de stratégies "
"intégrées sont fournies dans le cadre principal."

#: ../../source/how-to-use-strategies.rst:6
msgid ""
"There are three ways to customize the way Flower orchestrates the "
"learning process on the server side:"
msgstr ""
"Il y a trois façons de personnaliser la manière dont Flower orchestre le "
"processus d'apprentissage du côté du serveur :"

#: ../../source/how-to-use-strategies.rst:8
msgid "Use an existing strategy, for example, :code:`FedAvg`"
msgstr "Utilise une stratégie existante, par exemple :code:`FedAvg`"

#: ../../source/how-to-use-strategies.rst:9
#: ../../source/how-to-use-strategies.rst:40
msgid "Customize an existing strategy with callback functions"
msgstr "Personnalise une stratégie existante avec des fonctions de rappel"

#: ../../source/how-to-use-strategies.rst:10
#: ../../source/how-to-use-strategies.rst:87
msgid "Implement a novel strategy"
msgstr "Mets en place une nouvelle stratégie"

#: ../../source/how-to-use-strategies.rst:14
msgid "Use an existing strategy"
msgstr "Utilise une stratégie existante"

#: ../../source/how-to-use-strategies.rst:16
msgid ""
"Flower comes with a number of popular federated learning strategies "
"built-in. A built-in strategy can be instantiated as follows:"
msgstr ""
"Flower intègre un certain nombre de stratégies d'apprentissage fédéré "
"populaires. Une stratégie intégrée peut être instanciée comme suit :"

#: ../../source/how-to-use-strategies.rst:25
msgid ""
"This creates a strategy with all parameters left at their default values "
"and passes it to the :code:`start_server` function. It is usually "
"recommended to adjust a few parameters during instantiation:"
msgstr ""
"Cela crée une stratégie dont tous les paramètres sont laissés à leur "
"valeur par défaut et la transmet à la fonction :code:`start_server`. Il "
"est généralement recommandé d'ajuster quelques paramètres lors de "
"l'instanciation :"

#: ../../source/how-to-use-strategies.rst:42
msgid ""
"Existing strategies provide several ways to customize their behaviour. "
"Callback functions allow strategies to call user-provided code during "
"execution."
msgstr ""
"Les stratégies existantes offrent plusieurs façons de personnaliser leur "
"comportement. Les fonctions de rappel permettent aux stratégies d'appeler"
" le code fourni par l'utilisateur pendant l'exécution."

#: ../../source/how-to-use-strategies.rst:45
msgid "Configuring client fit and client evaluate"
msgstr "Configurer l'adaptation et l'évaluation du client"

#: ../../source/how-to-use-strategies.rst:47
msgid ""
"The server can pass new configuration values to the client each round by "
"providing a function to :code:`on_fit_config_fn`. The provided function "
"will be called by the strategy and must return a dictionary of "
"configuration key values pairs that will be sent to the client. It must "
"return a dictionary of arbitraty configuration values  :code:`client.fit`"
" and :code:`client.evaluate` functions during each round of federated "
"learning."
msgstr ""
"Le serveur peut transmettre de nouvelles valeurs de configuration au "
"client à chaque tour en fournissant une fonction à "
":code:`on_fit_config_fn`. La fonction fournie sera appelée par la "
"stratégie et doit renvoyer un dictionnaire de paires de valeurs de clés "
"de configuration qui seront envoyées au client. Elle doit renvoyer un "
"dictionnaire de valeurs de configuration arbitraires :code:`client.fit` "
"et :code:`client.evaluate` au cours de chaque tour d'apprentissage "
"fédéré."

#: ../../source/how-to-use-strategies.rst:75
msgid ""
"The :code:`on_fit_config_fn` can be used to pass arbitrary configuration "
"values from server to client, and poetentially change these values each "
"round, for example, to adjust the learning rate. The client will receive "
"the dictionary returned by the :code:`on_fit_config_fn` in its own "
":code:`client.fit()` function."
msgstr ""
"Le :code:`on_fit_config_fn` peut être utilisé pour passer des valeurs de "
"configuration arbitraires du serveur au client, et changer poétiquement "
"ces valeurs à chaque tour, par exemple pour ajuster le taux "
"d'apprentissage. Le client recevra le dictionnaire renvoyé par le "
":code:`on_fit_config_fn` dans sa propre fonction :code:`client.fit()`."

#: ../../source/how-to-use-strategies.rst:78
msgid ""
"Similar to :code:`on_fit_config_fn`, there is also "
":code:`on_evaluate_config_fn` to customize the configuration sent to "
":code:`client.evaluate()`"
msgstr ""
"Comme pour :code:`on_fit_config_fn`, il existe aussi "
":code:`on_evaluate_config_fn` pour personnaliser la configuration envoyée"
" à :code:`client.evaluate()`"

#: ../../source/how-to-use-strategies.rst:81
msgid "Configuring server-side evaluation"
msgstr "Configuration de l'évaluation côté serveur"

#: ../../source/how-to-use-strategies.rst:83
msgid ""
"Server-side evaluation can be enabled by passing an evaluation function "
"to :code:`evaluate_fn`."
msgstr ""
"L'évaluation côté serveur peut être activée en passant une fonction "
"d'évaluation à :code:`evaluate_fn`."

#: ../../source/how-to-use-strategies.rst:89
msgid ""
"Writing a fully custom strategy is a bit more involved, but it provides "
"the most flexibility. Read the `Implementing Strategies <implementing-"
"strategies.html>`_ guide to learn more."
msgstr ""
"L'écriture d'une stratégie entièrement personnalisée est un peu plus "
"complexe, mais c'est celle qui offre le plus de souplesse. Lis le guide "
"`Implémentation des stratégies <how-to-implement-strategies.html>`_ pour en "
"savoir plus."

#: ../../source/index.rst:31
msgid "Tutorial"
msgstr "Tutoriel"

#: ../../source/index.rst:41
msgid "Quickstart tutorials"
msgstr "Quickstart tutorials"

#: ../../source/index.rst:74 ../../source/index.rst:78
msgid "How-to guides"
msgstr "Guides"

#: ../../source/index.rst:94
msgid "Legacy example guides"
msgstr ""

#: ../../source/index.rst:105 ../../source/index.rst:109
msgid "Explanations"
msgstr "Explications"

#: ../../source/index.rst:121
msgid "API reference"
msgstr "Référence pour l'API"

#: ../../source/index.rst:128
msgid "Reference docs"
msgstr "Référence pour la documentation"

#: ../../source/index.rst:144
#, fuzzy
msgid "Contributor tutorials"
msgstr "Configuration du contributeur"

#: ../../source/index.rst:151
#, fuzzy
msgid "Contributor how-to guides"
msgstr "Guide pour les contributeurs"

#: ../../source/index.rst:162
#, fuzzy
msgid "Contributor explanations"
msgstr "Explications"

#: ../../source/index.rst:168
#, fuzzy
msgid "Contributor references"
msgstr "Configuration du contributeur"

#: ../../source/index.rst:2
#, fuzzy
msgid "Flower Framework Documentation"
msgstr "Rédiger de la documentation"

#: ../../source/index.rst:4
msgid ""
"Welcome to Flower's documentation. `Flower <https://flower.dev>`_ is a "
"friendly federated learning framework."
msgstr ""
"Bienvenue sur la documentation de Flower. `Flower <https://flower.dev>`_ "
"est un framework de federated learning convivial et facile à utiliser."

#: ../../source/index.rst:8
msgid "Join the Flower Community"
msgstr "Rejoignez la communauté de Flower"

#: ../../source/index.rst:10
msgid ""
"The Flower Community is growing quickly - we're a friendly group of "
"researchers, engineers, students, professionals, academics, and other "
"enthusiasts."
msgstr ""
"Le communauté de Flower s'agrandit rapidement - on est un super groupe de"
" chercheurs, ingénieurs, étudiants, professionnels, académiques, et "
"autres hobbyistes."

#: ../../source/index.rst:12
msgid "Join us on Slack"
msgstr "Join us on Slack"

#: ../../source/index.rst:20
msgid "Flower Framework"
msgstr "Flower Framework"

#: ../../source/index.rst:22
msgid ""
"The user guide is targeted at researchers and developers who want to use "
"Flower to bring existing machine learning workloads into a federated "
"setting. One of Flower's design goals was to make this simple. Read on to"
" learn more."
msgstr ""
"Ce guide utilisateur s'adresse à des chercheurs et des développeurs qui "
"veulent utiliser Flower pour transposer des workloads de Machine Learning"
" existantes dans un scenario fédéré. Un des buts de Flower est de rendre "
"cela le plus evident possible. Lisez la suite pour en apprendre plus."

#: ../../source/index.rst:27
msgid "Tutorials"
msgstr "Tutoriels"

#: ../../source/index.rst:29
msgid ""
"A learning-oriented series of federated learning tutorials, the best "
"place to start."
msgstr ""
"Une serie de tutoriels de Federated Learning, l'endroit parfait pour "
"débuter."

#: ../../source/index.rst:59
#, fuzzy
msgid ""
"QUICKSTART TUTORIALS: :doc:`PyTorch <tutorial-quickstart-pytorch>` | "
":doc:`TensorFlow <tutorial-quickstart-tensorflow>` | :doc:`🤗 Transformers"
" <tutorial-quickstart-huggingface>` | :doc:`JAX <tutorial-quickstart-"
"jax>` | :doc:`Pandas <tutorial-quickstart-pandas>` | :doc:`fastai "
"<tutorial-quickstart-fastai>` | :doc:`PyTorch Lightning <tutorial-"
"quickstart-pytorch-lightning>` | :doc:`MXNet <tutorial-quickstart-mxnet>`"
" | :doc:`scikit-learn <tutorial-quickstart-scikitlearn>` | :doc:`XGBoost "
"<tutorial-quickstart-xgboost>` | :doc:`Android <tutorial-quickstart-"
"android>` | :doc:`iOS <tutorial-quickstart-ios>`"
msgstr ""
"QUICKSTART TUTORIALS: :ref:`PyTorch <quickstart-pytorch>` | "
":ref:`TensorFlow <quickstart-tensorflow>` | :ref:`🤗 Transformers "
"<quickstart-huggingface>` | :ref:`JAX <quickstart-jax>` | :ref:`Pandas "
"<quickstart-pandas>` | :ref:`fastai <quickstart-fastai>` | :ref:`PyTorch "
"Lightning <quickstart-pytorch-lightning>` | :ref:`MXNet <quickstart-"
"mxnet>` | :ref:`scikit-learn <quickstart-scikitlearn>` | :ref:`XGBoost "
"<quickstart-xgboost>` | :ref:`Android <quickstart-android>` | :ref:`iOS "
"<quickstart-ios>`"

#: ../../source/index.rst:63
#, fuzzy
msgid "PyTorch"
msgstr "Exemples de PyTorch"

#: ../../source/index.rst:68
#, fuzzy
msgid "TensorFlow"
msgstr "Exemples de TensorFlow"

#: ../../source/index.rst:76
msgid ""
"Problem-oriented how-to guides show step-by-step how to achieve a "
"specific goal."
msgstr ""
"Guides orientés sur la résolutions étapes par étapes de problèmes ou "
"objectifs specifiques."

#: ../../source/index.rst:107
msgid ""
"Understanding-oriented concept guides explain and discuss key topics and "
"underlying ideas behind Flower and collaborative AI."
msgstr ""
"Guides orientés sur la compréhension et l'explication des sujets et idées"
" de fonds sur lesquels sont construits Flower et l'IA collaborative."

#: ../../source/index.rst:117
#, fuzzy
msgid "References"
msgstr "Référence"

#: ../../source/index.rst:119
msgid "Information-oriented API reference and other reference material."
msgstr "Référence de l'API orientée sur l'information pure."

#: ../../source/index.rst:139
#, fuzzy
msgid "Contributor docs"
msgstr "Configuration du contributeur"

#: ../../source/index.rst:141
#, fuzzy
msgid ""
"The Flower community welcomes contributions. The following docs are "
"intended to help along the way."
msgstr ""
"Les auteurs de Flower sont heureux d'accueillir des contributions "
"externes. Les guides suivant sont là pour vous accompagner dans cette "
"direction."

#: ../../source/ref-api-cli.rst:2
#, fuzzy
msgid "Flower CLI reference"
msgstr "Client de Flower"

#: ../../source/ref-api-cli.rst:7
msgid "flower-superlink"
msgstr "flower-superlink"

#: ../../source/ref-api-cli.rst:17
msgid "flower-driver-api"
msgstr "flower-driver-api"

#: ../../source/ref-api-cli.rst:27
msgid "flower-fleet-api"
msgstr "flower-fleet-api"

#: ../../source/ref-api-flwr.rst:2
#, fuzzy
msgid "flwr (Python API reference)"
msgstr "Référence pour l'API"

#: ../../source/ref-api-flwr.rst:8
msgid "client"
msgstr "client"

#: ../../source/ref-api-flwr.rst:24
msgid "start_client"
msgstr "start_client"

#: ../../source/ref-api-flwr.rst:32
msgid "NumPyClient"
msgstr "NumPyClient"

#: ../../source/ref-api-flwr.rst:41
msgid "start_numpy_client"
msgstr "start_numpy_client"

#: ../../source/ref-api-flwr.rst:49
msgid "start_simulation"
msgstr "démarrer_simulation"

#: ../../source/ref-api-flwr.rst:57
msgid "server"
msgstr "serveur"

#: ../../source/ref-api-flwr.rst:65
msgid "server.start_server"
msgstr "serveur.start_server"

#: ../../source/ref-api-flwr.rst:73
msgid "server.strategy"
msgstr "stratégie.du.serveur"

#: ../../source/ref-api-flwr.rst:81
msgid "server.strategy.Strategy"
msgstr "serveur.stratégie.Stratégie"

#: ../../source/ref-api-flwr.rst:90
msgid "server.strategy.FedAvg"
msgstr "serveur.stratégie.FedAvg"

#: ../../source/ref-api-flwr.rst:101
msgid "server.strategy.FedAvgM"
msgstr "stratégie.serveur.FedAvgM"

#: ../../source/ref-api-flwr.rst:112
msgid "server.strategy.QFedAvg"
msgstr "server.strategy.QFedAvg"

#: ../../source/ref-api-flwr.rst:123
msgid "server.strategy.FaultTolerantFedAvg"
msgstr "server.strategy.FaultTolerantFedAvg"

#: ../../source/ref-api-flwr.rst:134
msgid "server.strategy.FedOpt"
msgstr "serveur.stratégie.FedOpt"

#: ../../source/ref-api-flwr.rst:145
msgid "server.strategy.FedProx"
msgstr "serveur.stratégie.FedProx"

#: ../../source/ref-api-flwr.rst:156
msgid "server.strategy.FedAdagrad"
msgstr "serveur.stratégie.FedAdagrad"

#: ../../source/ref-api-flwr.rst:167
msgid "server.strategy.FedAdam"
msgstr "serveur.stratégie.FedAdam"

#: ../../source/ref-api-flwr.rst:178
msgid "server.strategy.FedYogi"
msgstr "serveur.stratégie.FedYogi"

#: ../../source/ref-api-flwr.rst:186
msgid "common"
msgstr "commun"

#: flwr.common:1 of
msgid "Common components shared between server and client."
msgstr "Composants communs partagés entre le serveur et le client."

#: flwr.common.typing.ClientMessage:1 of
msgid "ClientMessage is a container used to hold one result message."
msgstr ""
"ClientMessage est un conteneur utilisé pour contenir un message de "
"résultat."

#: flwr.common.typing.Code:1 of
msgid "Client status codes."
msgstr "Codes d'état du client."

#: flwr.common.typing.DisconnectRes:1 of
msgid "DisconnectRes message from client to server."
msgstr "Message DisconnectRes envoyé par le client au serveur."

#: flwr.common.typing.EvaluateIns:1 of
msgid "Evaluate instructions for a client."
msgstr "Évaluer les instructions pour un client."

#: flwr.common.typing.EvaluateRes:1 of
msgid "Evaluate response from a client."
msgstr "Évaluer la réponse d'un client."

#: flwr.common.telemetry.EventType:1 of
msgid "Types of telemetry events."
msgstr "Types d'événements télémétriques."

#: flwr.common.typing.FitIns:1 of
msgid "Fit instructions for a client."
msgstr "Instructions d'ajustement pour un client."

#: flwr.common.typing.FitRes:1 of
msgid "Fit response from a client."
msgstr "Réponse adaptée d'un client."

#: flwr.common.typing.GetParametersIns:1 of
msgid "Parameters request for a client."
msgstr "Demande de paramètres pour un client."

#: flwr.common.typing.GetParametersRes:1 of
msgid "Response when asked to return parameters."
msgstr "Réponse lorsqu'on te demande de renvoyer des paramètres."

#: flwr.common.typing.GetPropertiesIns:1 of
msgid "Properties request for a client."
msgstr "Demande de propriétés pour un client."

#: flwr.common.typing.GetPropertiesRes:1 of
msgid "Properties response from a client."
msgstr "Réponse des propriétés d'un client."

#: flwr.common.typing.Parameters:1 of
msgid "Model parameters."
msgstr "Paramètres du modèle."

#: flwr.common.typing.ReconnectIns:1 of
msgid "ReconnectIns message from server to client."
msgstr "Message de reconnexion du serveur au client."

#: flwr.common.typing.ServerMessage:1 of
msgid "ServerMessage is a container used to hold one instruction message."
msgstr ""
"ServerMessage est un conteneur utilisé pour contenir un message "
"d'instruction."

#: flwr.common.typing.Status:1 of
msgid "Client status."
msgstr "Statut du client."

#: flwr.common.parameter.bytes_to_ndarray:1 of
msgid "Deserialize NumPy ndarray from bytes."
msgstr "Désérialise le tableau numérique NumPy à partir d'octets."

#: flwr.common.logger.configure:1 of
msgid "Configure logging to file and/or remote log server."
msgstr ""
"Configure la journalisation vers un fichier et/ou un serveur de "
"journalisation distant."

#: logging.Logger.log:1 of
msgid "Log 'msg % args' with the integer severity 'level'."
msgstr "Enregistre 'msg % args' avec le niveau de sévérité entier 'level'."

#: logging.Logger.log:3 of
msgid ""
"To pass exception information, use the keyword argument exc_info with a "
"true value, e.g."
msgstr ""
"Pour transmettre des informations sur les exceptions, utilise l'argument "
"mot-clé exc_info avec une valeur vraie, par ex."

#: logging.Logger.log:6 of
#, python-format
msgid "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"
msgstr "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"

#: flwr.common.parameter.ndarray_to_bytes:1 of
msgid "Serialize NumPy ndarray to bytes."
msgstr "Sérialise le tableau numérique NumPy en octets."

#: flwr.common.parameter.ndarrays_to_parameters:1 of
msgid "Convert NumPy ndarrays to parameters object."
msgstr "Convertit les ndarrays NumPy en objets de paramètres."

#: flwr.common.date.now:1 of
msgid "Construct a datetime from time.time() with time zone set to UTC."
msgstr ""
"Construit une date à partir de time.time() avec le fuseau horaire réglé "
"sur UTC."

#: flwr.common.parameter.parameters_to_ndarrays:1 of
msgid "Convert parameters object to NumPy ndarrays."
msgstr "Convertit l'objet des paramètres en ndarrays NumPy."

#: ../../source/ref-changelog.md:1
msgid "Changelog"
msgstr "Changelog"

#: ../../source/ref-changelog.md:3
#, fuzzy
msgid "Unreleased"
msgstr "Inédit"

#: ../../source/ref-changelog.md:5 ../../source/ref-changelog.md:21
#: ../../source/ref-changelog.md:105 ../../source/ref-changelog.md:169
#: ../../source/ref-changelog.md:227 ../../source/ref-changelog.md:296
#: ../../source/ref-changelog.md:425 ../../source/ref-changelog.md:467
#: ../../source/ref-changelog.md:534 ../../source/ref-changelog.md:600
#: ../../source/ref-changelog.md:645 ../../source/ref-changelog.md:684
#: ../../source/ref-changelog.md:717 ../../source/ref-changelog.md:767
msgid "What's new?"
msgstr "Quoi de neuf ?"

#: ../../source/ref-changelog.md:7 ../../source/ref-changelog.md:93
#: ../../source/ref-changelog.md:157 ../../source/ref-changelog.md:215
#: ../../source/ref-changelog.md:284 ../../source/ref-changelog.md:346
#: ../../source/ref-changelog.md:365 ../../source/ref-changelog.md:521
#: ../../source/ref-changelog.md:592 ../../source/ref-changelog.md:629
#: ../../source/ref-changelog.md:672
msgid "Incompatible changes"
msgstr "Changements incompatibles"

#: ../../source/ref-changelog.md:9
#, fuzzy
msgid ""
"**Remove support for Python 3.7** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299))"
msgstr ""
"**Nouvelles stratégies intégrées** "
"([#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822))"

#: ../../source/ref-changelog.md:11
msgid ""
"Python 3.7 support was deprecated in Flower 1.5, and this release removes"
" support. Flower now requires Python 3.8."
msgstr ""

#: ../../source/ref-changelog.md:13
#, fuzzy
msgid "v1.5.0 (2023-08-31)"
msgstr "v1.4.0 (2023-04-21)"

#: ../../source/ref-changelog.md:15 ../../source/ref-changelog.md:99
#: ../../source/ref-changelog.md:163 ../../source/ref-changelog.md:221
#: ../../source/ref-changelog.md:290 ../../source/ref-changelog.md:359
msgid "Thanks to our contributors"
msgstr "Merci à nos contributeurs"

#: ../../source/ref-changelog.md:17 ../../source/ref-changelog.md:101
#: ../../source/ref-changelog.md:165 ../../source/ref-changelog.md:223
msgid ""
"We would like to give our special thanks to all the contributors who made"
" the new version of Flower possible (in `git shortlog` order):"
msgstr ""
"Nous tenons à remercier tout particulièrement tous les contributeurs qui "
"ont rendu possible la nouvelle version de Flower (dans l'ordre `git "
"shortlog`) :"

#: ../../source/ref-changelog.md:19
msgid ""
"`achiverram28`, `Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, "
"`Dana-Farber`, `Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo "
"Gabrielli`, `eunchung`, `Gustavo Bertoli`, `Heng Pan`, `Javier`, `Mahdi`,"
" `Ruth Galindo`, `Steven Hé (Sīchàng)`, `Taner Topal`"
msgstr ""

#: ../../source/ref-changelog.md:23
#, fuzzy
msgid ""
"**Introduce new simulation engine** "
"([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"
msgstr ""
"**Introduire la télémétrie optionnelle** "
"([#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584))"

#: ../../source/ref-changelog.md:25
msgid ""
"The new simulation engine has been rewritten from the ground up, yet it "
"remains fully backwards compatible. It offers much improved stability and"
" memory handling, especially when working with GPUs. Simulations "
"transparently adapt to different settings to scale simulation in CPU-"
"only, CPU+GPU, multi-GPU, or multi-node multi-GPU environments."
msgstr ""

#: ../../source/ref-changelog.md:27
msgid ""
"Comprehensive documentation includes a new [how-to run "
"simulations](https://flower.dev/docs/framework/how-to-run-"
"simulations.html) guide, new [simulation-"
"pytorch](https://flower.dev/docs/examples/simulation-pytorch.html) and "
"[simulation-tensorflow](https://flower.dev/docs/examples/simulation-"
"tensorflow.html) notebooks, and a new [YouTube tutorial "
"series](https://www.youtube.com/watch?v=cRebUIGB5RU&list=PLNG4feLHqCWlnj8a_E1A_n5zr2-8pafTB)."
msgstr ""

#: ../../source/ref-changelog.md:29
msgid ""
"**Restructure Flower Docs** "
"([#1824](https://github.com/adap/flower/pull/1824), "
"[#1865](https://github.com/adap/flower/pull/1865), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1887](https://github.com/adap/flower/pull/1887), "
"[#1919](https://github.com/adap/flower/pull/1919), "
"[#1922](https://github.com/adap/flower/pull/1922), "
"[#1920](https://github.com/adap/flower/pull/1920), "
"[#1923](https://github.com/adap/flower/pull/1923), "
"[#1924](https://github.com/adap/flower/pull/1924), "
"[#1962](https://github.com/adap/flower/pull/1962), "
"[#2006](https://github.com/adap/flower/pull/2006), "
"[#2133](https://github.com/adap/flower/pull/2133), "
"[#2203](https://github.com/adap/flower/pull/2203), "
"[#2215](https://github.com/adap/flower/pull/2215), "
"[#2122](https://github.com/adap/flower/pull/2122), "
"[#2223](https://github.com/adap/flower/pull/2223), "
"[#2219](https://github.com/adap/flower/pull/2219), "
"[#2232](https://github.com/adap/flower/pull/2232), "
"[#2233](https://github.com/adap/flower/pull/2233), "
"[#2234](https://github.com/adap/flower/pull/2234), "
"[#2235](https://github.com/adap/flower/pull/2235), "
"[#2237](https://github.com/adap/flower/pull/2237), "
"[#2238](https://github.com/adap/flower/pull/2238), "
"[#2242](https://github.com/adap/flower/pull/2242), "
"[#2231](https://github.com/adap/flower/pull/2231), "
"[#2243](https://github.com/adap/flower/pull/2243), "
"[#2227](https://github.com/adap/flower/pull/2227))"
msgstr ""

#: ../../source/ref-changelog.md:31
msgid ""
"Much effort went into a completely restructured Flower docs experience. "
"The documentation on [flower.dev/docs](flower.dev/docs) is now divided "
"into Flower Framework, Flower Baselines, Flower Android SDK, Flower iOS "
"SDK, and code example projects."
msgstr ""

#: ../../source/ref-changelog.md:33
#, fuzzy
msgid ""
"**Introduce Flower Swift SDK** "
"([#1858](https://github.com/adap/flower/pull/1858), "
"[#1897](https://github.com/adap/flower/pull/1897))"
msgstr ""
"**Introduction du SDK iOS (aperçu)** "
"([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"

#: ../../source/ref-changelog.md:35
msgid ""
"This is the first preview release of the Flower Swift SDK. Flower support"
" on iOS is improving, and alongside the Swift SDK and code example, there"
" is now also an iOS quickstart tutorial."
msgstr ""

#: ../../source/ref-changelog.md:37
#, fuzzy
msgid ""
"**Introduce Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"
msgstr ""
"**Introduire une nouvelle ligne de base pour les fleurs : FedAvg "
"FEMNIST** ([#1655](https://github.com/adap/flower/pull/1655))"

#: ../../source/ref-changelog.md:39
msgid ""
"This is the first preview release of the Flower Kotlin SDK. Flower "
"support on Android is improving, and alongside the Kotlin SDK and code "
"example, there is now also an Android quickstart tutorial."
msgstr ""

#: ../../source/ref-changelog.md:41
#, fuzzy
msgid ""
"**Introduce new end-to-end testing infrastructure** "
"([#1842](https://github.com/adap/flower/pull/1842), "
"[#2071](https://github.com/adap/flower/pull/2071), "
"[#2072](https://github.com/adap/flower/pull/2072), "
"[#2068](https://github.com/adap/flower/pull/2068), "
"[#2067](https://github.com/adap/flower/pull/2067), "
"[#2069](https://github.com/adap/flower/pull/2069), "
"[#2073](https://github.com/adap/flower/pull/2073), "
"[#2070](https://github.com/adap/flower/pull/2070), "
"[#2074](https://github.com/adap/flower/pull/2074), "
"[#2082](https://github.com/adap/flower/pull/2082), "
"[#2084](https://github.com/adap/flower/pull/2084), "
"[#2093](https://github.com/adap/flower/pull/2093), "
"[#2109](https://github.com/adap/flower/pull/2109), "
"[#2095](https://github.com/adap/flower/pull/2095), "
"[#2140](https://github.com/adap/flower/pull/2140), "
"[#2137](https://github.com/adap/flower/pull/2137), "
"[#2165](https://github.com/adap/flower/pull/2165))"
msgstr ""
"**Améliorer l'API (expérimentale) du pilote** "
"([#1663](https://github.com/adap/flower/pull/1663), "
"[#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"

#: ../../source/ref-changelog.md:43
msgid ""
"A new testing infrastructure ensures that new changes stay compatible "
"with existing framework integrations or strategies."
msgstr ""

#: ../../source/ref-changelog.md:45
#, fuzzy
msgid "**Deprecate Python 3.7**"
msgstr "**Créer le PR**"

#: ../../source/ref-changelog.md:47
msgid ""
"Since Python 3.7 reached its end of life (EOL) on 2023-06-27, support for"
" Python 3.7 is now deprecated and will be removed in an upcoming release."
msgstr ""

#: ../../source/ref-changelog.md:49
#, fuzzy
msgid ""
"**Add new** `FedTrimmedAvg` **strategy** "
"([#1769](https://github.com/adap/flower/pull/1769), "
"[#1853](https://github.com/adap/flower/pull/1853))"
msgstr ""
"**Ajouter un nouvel exemple de Federated Analytics avec Pandas** "
"([#1469](https://github.com/adap/flower/pull/1469), "
"[#1535](https://github.com/adap/flower/pull/1535))"

#: ../../source/ref-changelog.md:51
#, fuzzy
msgid ""
"The new `FedTrimmedAvg` strategy implements Trimmed Mean by [Dong Yin, "
"2018](https://arxiv.org/abs/1803.01498)."
msgstr ""
"La nouvelle stratégie `FedMedian` met en œuvre Federated Median "
"(FedMedian) par [Yin et al., 2018] "
"(https://arxiv.org/pdf/1803.01498v1.pdf)."

#: ../../source/ref-changelog.md:53
#, fuzzy
msgid ""
"**Introduce start_driver** "
"([#1697](https://github.com/adap/flower/pull/1697))"
msgstr ""
"**Ajouter une nouvelle stratégie `FedProx`** "
"([#1619](https://github.com/adap/flower/pull/1619))"

#: ../../source/ref-changelog.md:55
msgid ""
"In addition to `start_server` and using the raw Driver API, there is a "
"new `start_driver` function that allows for running `start_server` "
"scripts as a Flower driver with only a single-line code change. Check out"
" the `mt-pytorch` code example to see a working example using "
"`start_driver`."
msgstr ""

#: ../../source/ref-changelog.md:57
#, fuzzy
msgid ""
"**Add parameter aggregation to** `mt-pytorch` **code example** "
"([#1785](https://github.com/adap/flower/pull/1785))"
msgstr ""
"**Nouvel exemple de code PyTorch avancé** "
"([#1007](https://github.com/adap/flower/pull/1007))"

#: ../../source/ref-changelog.md:59
msgid ""
"The `mt-pytorch` example shows how to aggregate parameters when writing a"
" driver script. The included `driver.py` and `server.py` have been "
"aligned to demonstrate both the low-level way and the high-level way of "
"building server-side logic."
msgstr ""

#: ../../source/ref-changelog.md:61
#, fuzzy
msgid ""
"**Migrate experimental REST API to Starlette** "
"([2171](https://github.com/adap/flower/pull/2171))"
msgstr ""
"**Nouvelle stratégie expérimentale TensorBoard** "
"([#789](https://github.com/adap/flower/pull/789))"

#: ../../source/ref-changelog.md:63
msgid ""
"The (experimental) REST API used to be implemented in "
"[FastAPI](https://fastapi.tiangolo.com/), but it has now been migrated to"
" use [Starlette](https://www.starlette.io/) directly."
msgstr ""

#: ../../source/ref-changelog.md:65
#, fuzzy
msgid ""
"Please note: The REST request-response API is still experimental and will"
" likely change significantly over time."
msgstr ""
"Remarque : l'API REST est encore expérimentale et est susceptible de "
"changer de manière significative au fil du temps."

#: ../../source/ref-changelog.md:67
#, fuzzy
msgid ""
"**Introduce experimental gRPC request-response API** "
"([#1867](https://github.com/adap/flower/pull/1867), "
"[#1901](https://github.com/adap/flower/pull/1901))"
msgstr ""
"**Introduire les enveloppes de confidentialité différentielle (aperçu)** "
"([#1357](https://github.com/adap/flower/pull/1357), "
"[#1460](https://github.com/adap/flower/pull/1460))"

#: ../../source/ref-changelog.md:69
msgid ""
"In addition to the existing gRPC API (based on bidirectional streaming) "
"and the experimental REST API, there is now a new gRPC API that uses a "
"request-response model to communicate with client nodes."
msgstr ""

#: ../../source/ref-changelog.md:71
#, fuzzy
msgid ""
"Please note: The gRPC request-response API is still experimental and will"
" likely change significantly over time."
msgstr ""
"Remarque : l'API REST est encore expérimentale et est susceptible de "
"changer de manière significative au fil du temps."

#: ../../source/ref-changelog.md:73
#, fuzzy
msgid ""
"**Replace the experimental** `start_client(rest=True)` **with the new** "
"`start_client(transport=\"rest\")` "
"([#1880](https://github.com/adap/flower/pull/1880))"
msgstr ""
"**Initialise** `start_simulation` **avec une liste d'ID de clients** "
"([#860](https://github.com/adap/flower/pull/860))"

#: ../../source/ref-changelog.md:75
msgid ""
"The (experimental) `start_client` argument `rest` was deprecated in "
"favour of a new argument `transport`. `start_client(transport=\"rest\")` "
"will yield the same behaviour as `start_client(rest=True)` did before. "
"All code should migrate to the new argument `transport`. The deprecated "
"argument `rest` will be removed in a future release."
msgstr ""

#: ../../source/ref-changelog.md:77
#, fuzzy
msgid ""
"**Add a new gRPC option** "
"([#2197](https://github.com/adap/flower/pull/2197))"
msgstr ""
"**Ajouter une nouvelle stratégie `FedProx`** "
"([#1619](https://github.com/adap/flower/pull/1619))"

#: ../../source/ref-changelog.md:79
msgid ""
"We now start a gRPC server with the `grpc.keepalive_permit_without_calls`"
" option set to 0 by default. This prevents the clients from sending "
"keepalive pings when there is no outstanding stream."
msgstr ""

#: ../../source/ref-changelog.md:81
#, fuzzy
msgid ""
"**Improve example notebooks** "
"([#2005](https://github.com/adap/flower/pull/2005))"
msgstr ""
"**Supprimer les stratégies expérimentales** "
"([#1280](https://github.com/adap/flower/pull/1280))"

#: ../../source/ref-changelog.md:83
#, fuzzy
msgid "There's a new 30min Federated Learning PyTorch tutorial!"
msgstr "Bienvenue au tutoriel sur l'apprentissage fédéré de la fleur !"

#: ../../source/ref-changelog.md:85
msgid ""
"**Example updates** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), "
"[#1981](https://github.com/adap/flower/pull/1981), "
"[#1988](https://github.com/adap/flower/pull/1988), "
"[#1984](https://github.com/adap/flower/pull/1984), "
"[#1982](https://github.com/adap/flower/pull/1982), "
"[#2112](https://github.com/adap/flower/pull/2112), "
"[#2144](https://github.com/adap/flower/pull/2144), "
"[#2174](https://github.com/adap/flower/pull/2174), "
"[#2225](https://github.com/adap/flower/pull/2225), "
"[#2183](https://github.com/adap/flower/pull/2183))"
msgstr ""

#: ../../source/ref-changelog.md:87
msgid ""
"Many examples have received significant updates, including simplified "
"advanced-tensorflow and advanced-pytorch examples, improved macOS "
"compatibility of TensorFlow examples, and code examples for simulation. A"
" major upgrade is that all code examples now have a `requirements.txt` "
"(in addition to `pyproject.toml`)."
msgstr ""

#: ../../source/ref-changelog.md:89
#, fuzzy
msgid ""
"**General improvements** "
"([#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"
msgstr ""
"**Mise à jour de la documentation** "
"([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614))"

#: ../../source/ref-changelog.md:91 ../../source/ref-changelog.md:155
#: ../../source/ref-changelog.md:209 ../../source/ref-changelog.md:276
msgid "Flower received many improvements under the hood, too many to list here."
msgstr ""
"Flower a reçu de nombreuses améliorations sous le capot, trop nombreuses "
"pour être énumérées ici."

#: ../../source/ref-changelog.md:95 ../../source/ref-changelog.md:159
#: ../../source/ref-changelog.md:217 ../../source/ref-changelog.md:286
#: ../../source/ref-changelog.md:348
msgid "None"
msgstr "Aucun"

#: ../../source/ref-changelog.md:97
msgid "v1.4.0 (2023-04-21)"
msgstr "v1.4.0 (2023-04-21)"

#: ../../source/ref-changelog.md:103
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, "
"`Iacob-Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal "
"Sarkhel`, `L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic "
"Lane`, `Nikolaos Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, "
"`Steve Laskaridis`, `Steven Hé (Sīchàng)`, `Taner Topal`"
msgstr ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, "
"`Iacob-Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal "
"Sarkhel`, `L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic "
"Lane`, `Nikolaos Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, "
"`Steve Laskaridis`, `Steven Hé (Sīchàng)`, `Taner Topal`"

#: ../../source/ref-changelog.md:107
msgid ""
"**Introduce support for XGBoost (**`FedXgbNnAvg` **strategy and "
"example)** ([#1694](https://github.com/adap/flower/pull/1694), "
"[#1709](https://github.com/adap/flower/pull/1709), "
"[#1715](https://github.com/adap/flower/pull/1715), "
"[#1717](https://github.com/adap/flower/pull/1717), "
"[#1763](https://github.com/adap/flower/pull/1763), "
"[#1795](https://github.com/adap/flower/pull/1795))"
msgstr ""
"**Introduire la prise en charge de XGBoost (**`FedXgbNnAvg` **stratégie "
"et exemple)** ([#1694](https://github.com/adap/flower/pull/1694), "
"[#1709](https://github.com/adap/flower/pull/1709), "
"[#1715](https://github.com/adap/flower/pull/1715), "
"[#1717](https://github.com/adap/flower/pull/1717), "
"[#1763](https://github.com/adap/flower/pull/1763), "
"[#1795](https://github.com/adap/flower/pull/1795))"

#: ../../source/ref-changelog.md:109
msgid ""
"XGBoost is a tree-based ensemble machine learning algorithm that uses "
"gradient boosting to improve model accuracy. We added a new `FedXgbNnAvg`"
" "
"[strategy](https://github.com/adap/flower/tree/main/src/py/flwr/server/strategy/fedxgb_nn_avg.py),"
" and a [code "
"example](https://github.com/adap/flower/tree/main/examples/quickstart_xgboost_horizontal)"
" that demonstrates the usage of this new strategy in an XGBoost project."
msgstr ""
"Nous avons ajouté une nouvelle [stratégie] `FedXgbNnAvg` "
"(https://github.com/adap/flower/tree/main/src/py/flwr/server/strategy/fedxgb_nn_avg.py),"
" et un [exemple de code] "
"(https://github.com/adap/flower/tree/main/examples/quickstart_xgboost_horizontal)"
" qui démontre l'utilisation de cette nouvelle stratégie dans un projet "
"XGBoost."

#: ../../source/ref-changelog.md:111
msgid ""
"**Introduce iOS SDK (preview)** "
"([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"
msgstr ""
"**Introduction du SDK iOS (aperçu)** "
"([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"

#: ../../source/ref-changelog.md:113
msgid ""
"This is a major update for anyone wanting to implement Federated Learning"
" on iOS mobile devices. We now have a swift iOS SDK present under "
"[src/swift/flwr](https://github.com/adap/flower/tree/main/src/swift/flwr)"
" that will facilitate greatly the app creating process. To showcase its "
"use, the [iOS "
"example](https://github.com/adap/flower/tree/main/examples/ios) has also "
"been updated!"
msgstr ""
"Il s'agit d'une mise à jour majeure pour tous ceux qui souhaitent mettre "
"en œuvre l'apprentissage fédéré sur les appareils mobiles iOS. Nous "
"disposons désormais d'un SDK swift iOS présent sous "
"[src/swift/flwr](https://github.com/adap/flower/tree/main/src/swift/flwr)"
" qui facilitera grandement le processus de création d'applications. Pour "
"présenter son utilisation, l'[exemple "
"iOS](https://github.com/adap/flower/tree/main/examples/ios) a également "
"été mis à jour !"

#: ../../source/ref-changelog.md:115
msgid ""
"**Introduce new \"What is Federated Learning?\" tutorial** "
"([#1657](https://github.com/adap/flower/pull/1657), "
"[#1721](https://github.com/adap/flower/pull/1721))"
msgstr ""
"**Introduire un nouveau tutoriel \"Qu'est-ce que l'apprentissage fédéré ?"
" \"** ([#1657](https://github.com/adap/flower/pull/1657), "
"[#1721](https://github.com/adap/flower/pull/1721))"

#: ../../source/ref-changelog.md:117
#, fuzzy
msgid ""
"A new [entry-level tutorial](https://flower.dev/docs/framework/tutorial-"
"what-is-federated-learning.html) in our documentation explains the basics"
" of Fedetated Learning. It enables anyone who's unfamiliar with Federated"
" Learning to start their journey with Flower. Forward it to anyone who's "
"interested in Federated Learning!"
msgstr ""
"Un nouveau [tutoriel d'entrée de gamme] "
"(https://flower.dev/docs/tutorial/Flower-0-What-is-FL.html) dans notre "
"documentation explique les bases de l'apprentissage fédéré. Il permet à "
"tous ceux qui ne connaissent pas l'apprentissage fédéré de commencer leur"
" voyage avec Flower. Fais-le suivre à tous ceux qui s'intéressent à "
"l'apprentissage fédéré !"

#: ../../source/ref-changelog.md:119
msgid ""
"**Introduce new Flower Baseline: FedProx MNIST** "
"([#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679))"
msgstr ""
"**Introduire une nouvelle fleur Référence : FedProx MNIST** "
"([#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679))"

#: ../../source/ref-changelog.md:121
msgid ""
"This new baseline replicates the MNIST+CNN task from the paper [Federated"
" Optimization in Heterogeneous Networks (Li et al., "
"2018)](https://arxiv.org/abs/1812.06127). It uses the `FedProx` strategy,"
" which aims at making convergence more robust in heterogenous settings."
msgstr ""
"Cette nouvelle ligne de base reproduit la tâche MNIST+CNN de l'article "
"[Federated Optimization in Heterogeneous Networks (Li et al., 2018)] "
"(https://arxiv.org/abs/1812.06127). Elle utilise la stratégie `FedProx`, "
"qui vise à rendre la convergence plus robuste dans des contextes "
"hétérogènes."

#: ../../source/ref-changelog.md:123
msgid ""
"**Introduce new Flower Baseline: FedAvg FEMNIST** "
"([#1655](https://github.com/adap/flower/pull/1655))"
msgstr ""
"**Introduire une nouvelle ligne de base pour les fleurs : FedAvg "
"FEMNIST** ([#1655](https://github.com/adap/flower/pull/1655))"

#: ../../source/ref-changelog.md:125
msgid ""
"This new baseline replicates an experiment evaluating the performance of "
"the FedAvg algorithm on the FEMNIST dataset from the paper [LEAF: A "
"Benchmark for Federated Settings (Caldas et al., "
"2018)](https://arxiv.org/abs/1812.01097)."
msgstr ""
"Cette nouvelle ligne de base reproduit une expérience évaluant les "
"performances de l'algorithme FedAvg sur le jeu de données FEMNIST tiré de"
" l'article [LEAF : A Benchmark for Federated Settings (Caldas et al., "
"2018)] (https://arxiv.org/abs/1812.01097)."

#: ../../source/ref-changelog.md:127
msgid ""
"**Introduce (experimental) REST API** "
"([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"
msgstr ""
"**Introduire l'API REST (expérimentale)** "
"([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"

#: ../../source/ref-changelog.md:129
msgid ""
"A new REST API has been introduced as an alternative to the gRPC-based "
"communication stack. In this initial version, the REST API only supports "
"anonymous clients."
msgstr ""
"Une nouvelle API REST a été introduite comme alternative à la pile de "
"communication basée sur gRPC. Dans cette version initiale, l'API REST ne "
"prend en charge que les clients anonymes."

#: ../../source/ref-changelog.md:131
msgid ""
"Please note: The REST API is still experimental and will likely change "
"significantly over time."
msgstr ""
"Remarque : l'API REST est encore expérimentale et est susceptible de "
"changer de manière significative au fil du temps."

#: ../../source/ref-changelog.md:133
msgid ""
"**Improve the (experimental) Driver API** "
"([#1663](https://github.com/adap/flower/pull/1663), "
"[#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"
msgstr ""
"**Améliorer l'API (expérimentale) du pilote** "
"([#1663](https://github.com/adap/flower/pull/1663), "
"[#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"

#: ../../source/ref-changelog.md:135
msgid ""
"The Driver API is still an experimental feature, but this release "
"introduces some major upgrades. One of the main improvements is the "
"introduction of an SQLite database to store server state on disk (instead"
" of in-memory). Another improvement is that tasks (instructions or "
"results) that have been delivered will now be deleted. This greatly "
"improves the memory efficiency of a long-running Flower server."
msgstr ""
"L'API du pilote est encore une fonction expérimentale, mais cette version"
" introduit quelques améliorations majeures. L'une des principales "
"améliorations est l'introduction d'une base de données SQLite pour "
"stocker l'état du serveur sur le disque (au lieu de la mémoire). Une "
"autre amélioration est que les tâches (instructions ou résultats) qui ont"
" été livrées seront désormais supprimées, ce qui améliore "
"considérablement l'efficacité de la mémoire d'un serveur Flower "
"fonctionnant depuis longtemps."

#: ../../source/ref-changelog.md:137
msgid ""
"**Fix spilling issues related to Ray during simulations** "
"([#1698](https://github.com/adap/flower/pull/1698))"
msgstr ""
"**Répare les problèmes de déversement liés à Ray pendant les "
"simulations** ([#1698](https://github.com/adap/flower/pull/1698))"

#: ../../source/ref-changelog.md:139
#, fuzzy
msgid ""
"While running long simulations, `ray` was sometimes spilling huge amounts"
" of data that would make the training unable to continue. This is now "
"fixed! 🎉"
msgstr ""
"Lors de l'exécution de longues simulations, `ray` déversait parfois "
"d'énormes quantités de données qui rendaient l'entraînement incapable de "
"continuer. ce problème est maintenant corrigé ! 🎉"

#: ../../source/ref-changelog.md:141
msgid ""
"**Add new example using** `TabNet` **and Flower** "
"([#1725](https://github.com/adap/flower/pull/1725))"
msgstr ""
"**Ajouter un nouvel exemple utilisant** `TabNet` **et Flower** "
"([#1725](https://github.com/adap/flower/pull/1725))"

#: ../../source/ref-changelog.md:143
msgid ""
"TabNet is a powerful and flexible framework for training machine learning"
" models on tabular data. We now have a federated example using Flower: "
"[https://github.com/adap/flower/tree/main/examples/tabnet](https://github.com/adap/flower/tree/main/examples/quickstart_tabnet)."
msgstr ""
"TabNet est un cadre puissant et flexible pour former des modèles "
"d'apprentissage automatique sur des données tabulaires. Nous avons "
"maintenant un exemple fédéré utilisant Flower : "
"[https://github.com/adap/flower/tree/main/examples/tabnet](https://github.com/adap/flower/tree/main/examples/quickstart_tabnet)."

#: ../../source/ref-changelog.md:145
msgid ""
"**Add new how-to guide for monitoring simulations** "
"([#1649](https://github.com/adap/flower/pull/1649))"
msgstr ""
"**Ajouter un nouveau guide pratique pour le suivi des simulations** "
"([#1649](https://github.com/adap/flower/pull/1649))"

#: ../../source/ref-changelog.md:147
msgid ""
"We now have a documentation guide to help users monitor their performance"
" during simulations."
msgstr ""
"Nous avons maintenant un guide de documentation pour aider les "
"utilisateurs à surveiller leurs performances pendant les simulations."

#: ../../source/ref-changelog.md:149
msgid ""
"**Add training metrics to** `History` **object during simulations** "
"([#1696](https://github.com/adap/flower/pull/1696))"
msgstr ""
"**Ajouter des mesures de formation à** `History` **objet pendant les "
"simulations** ([#1696](https://github.com/adap/flower/pull/1696))"

#: ../../source/ref-changelog.md:151
msgid ""
"The `fit_metrics_aggregation_fn` can be used to aggregate training "
"metrics, but previous releases did not save the results in the `History` "
"object. This is now the case!"
msgstr ""
"La fonction `fit_metrics_aggregation_fn` peut être utilisée pour agréger "
"les mesures d'entraînement, mais les versions précédentes "
"n'enregistraient pas les résultats dans l'objet `History`. c'est "
"désormais le cas !"

#: ../../source/ref-changelog.md:153
msgid ""
"**General improvements** "
"([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), "
"[#1647](https://github.com/adap/flower/pull/1647), "
"[#1471](https://github.com/adap/flower/pull/1471), "
"[#1648](https://github.com/adap/flower/pull/1648), "
"[#1651](https://github.com/adap/flower/pull/1651), "
"[#1652](https://github.com/adap/flower/pull/1652), "
"[#1653](https://github.com/adap/flower/pull/1653), "
"[#1659](https://github.com/adap/flower/pull/1659), "
"[#1665](https://github.com/adap/flower/pull/1665), "
"[#1670](https://github.com/adap/flower/pull/1670), "
"[#1672](https://github.com/adap/flower/pull/1672), "
"[#1677](https://github.com/adap/flower/pull/1677), "
"[#1684](https://github.com/adap/flower/pull/1684), "
"[#1683](https://github.com/adap/flower/pull/1683), "
"[#1686](https://github.com/adap/flower/pull/1686), "
"[#1682](https://github.com/adap/flower/pull/1682), "
"[#1685](https://github.com/adap/flower/pull/1685), "
"[#1692](https://github.com/adap/flower/pull/1692), "
"[#1705](https://github.com/adap/flower/pull/1705), "
"[#1708](https://github.com/adap/flower/pull/1708), "
"[#1711](https://github.com/adap/flower/pull/1711), "
"[#1713](https://github.com/adap/flower/pull/1713), "
"[#1714](https://github.com/adap/flower/pull/1714), "
"[#1718](https://github.com/adap/flower/pull/1718), "
"[#1716](https://github.com/adap/flower/pull/1716), "
"[#1723](https://github.com/adap/flower/pull/1723), "
"[#1735](https://github.com/adap/flower/pull/1735), "
"[#1678](https://github.com/adap/flower/pull/1678), "
"[#1750](https://github.com/adap/flower/pull/1750), "
"[#1753](https://github.com/adap/flower/pull/1753), "
"[#1736](https://github.com/adap/flower/pull/1736), "
"[#1766](https://github.com/adap/flower/pull/1766), "
"[#1760](https://github.com/adap/flower/pull/1760), "
"[#1775](https://github.com/adap/flower/pull/1775), "
"[#1776](https://github.com/adap/flower/pull/1776), "
"[#1777](https://github.com/adap/flower/pull/1777), "
"[#1779](https://github.com/adap/flower/pull/1779), "
"[#1784](https://github.com/adap/flower/pull/1784), "
"[#1773](https://github.com/adap/flower/pull/1773), "
"[#1755](https://github.com/adap/flower/pull/1755), "
"[#1789](https://github.com/adap/flower/pull/1789), "
"[#1788](https://github.com/adap/flower/pull/1788), "
"[#1798](https://github.com/adap/flower/pull/1798), "
"[#1799](https://github.com/adap/flower/pull/1799), "
"[#1739](https://github.com/adap/flower/pull/1739), "
"[#1800](https://github.com/adap/flower/pull/1800), "
"[#1804](https://github.com/adap/flower/pull/1804), "
"[#1805](https://github.com/adap/flower/pull/1805))"
msgstr ""
"**General improvements** "
"([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), "
"[#1647](https://github.com/adap/flower/pull/1647), "
"[#1471](https://github.com/adap/flower/pull/1471), "
"[#1648](https://github.com/adap/flower/pull/1648), "
"[#1651](https://github.com/adap/flower/pull/1651), "
"[#1652](https://github.com/adap/flower/pull/1652), "
"[#1653](https://github.com/adap/flower/pull/1653), "
"[#1659](https://github.com/adap/flower/pull/1659), "
"[#1665](https://github.com/adap/flower/pull/1665), "
"[#1670](https://github.com/adap/flower/pull/1670), "
"[#1672](https://github.com/adap/flower/pull/1672), "
"[#1677](https://github.com/adap/flower/pull/1677), "
"[#1684](https://github.com/adap/flower/pull/1684), "
"[#1683](https://github.com/adap/flower/pull/1683), "
"[#1686](https://github.com/adap/flower/pull/1686), "
"[#1682](https://github.com/adap/flower/pull/1682), "
"[#1685](https://github.com/adap/flower/pull/1685), "
"[#1692](https://github.com/adap/flower/pull/1692), "
"[#1705](https://github.com/ada"

#: ../../source/ref-changelog.md:161
msgid "v1.3.0 (2023-02-06)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:167
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Daniel J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"
msgstr ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Daniel J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"

#: ../../source/ref-changelog.md:171
msgid ""
"**Add support for** `workload_id` **and** `group_id` **in Driver API** "
"([#1595](https://github.com/adap/flower/pull/1595))"
msgstr ""
"**Ajouter la prise en charge de** `workload_id` **et** `group_id` **dans "
"l'API du pilote** ([#1595](https://github.com/adap/flower/pull/1595))"

#: ../../source/ref-changelog.md:173
msgid ""
"The (experimental) Driver API now supports a `workload_id` that can be "
"used to identify which workload a task belongs to. It also supports a new"
" `group_id` that can be used, for example, to indicate the current "
"training round. Both the `workload_id` and `group_id` enable client nodes"
" to decide whether they want to handle a task or not."
msgstr ""
"L'API (expérimentale) Driver prend désormais en charge un `workload_id` "
"qui peut être utilisé pour identifier la charge de travail à laquelle une"
" tâche appartient. Elle prend également en charge un nouveau `group_id` "
"qui peut être utilisé, par exemple, pour indiquer le cycle de formation "
"en cours. Le `workload_id` et le `group_id` permettent tous deux aux "
"nœuds clients de décider s'ils veulent traiter une tâche ou non."

#: ../../source/ref-changelog.md:175
msgid ""
"**Make Driver API and Fleet API address configurable** "
"([#1637](https://github.com/adap/flower/pull/1637))"
msgstr ""
"**Faire en sorte que l'adresse de l'API du conducteur et de l'API de la "
"flotte soit configurable** "
"([#1637](https://github.com/adap/flower/pull/1637))"

#: ../../source/ref-changelog.md:177
msgid ""
"The (experimental) long-running Flower server (Driver API and Fleet API) "
"can now configure the server address of both Driver API (via `--driver-"
"api-address`) and Fleet API (via `--fleet-api-address`) when starting:"
msgstr ""
"Le serveur Flower (expérimental) de longue durée (Driver API et Fleet "
"API) peut maintenant configurer l'adresse du serveur de Driver API (via "
"`--driver-api-address`) et de Fleet API (via `--fleet-api-address`) lors "
"de son démarrage :"

#: ../../source/ref-changelog.md:179
#, fuzzy
msgid ""
"`flower-superlink --driver-api-address \"0.0.0.0:8081\" --fleet-api-address "
"\"0.0.0.0:8086\"`"
msgstr ""
"``flower-superlink --driver-api-address \"0.0.0.0:8081\" --fleet-api-address"
" \"0.0.0.0:8086\" ``"

#: ../../source/ref-changelog.md:181
msgid "Both IPv4 and IPv6 addresses are supported."
msgstr "Les adresses IPv4 et IPv6 sont toutes deux prises en charge."

#: ../../source/ref-changelog.md:183
msgid ""
"**Add new example of Federated Learning using fastai and Flower** "
"([#1598](https://github.com/adap/flower/pull/1598))"
msgstr ""
"**Ajouter un nouvel exemple d'apprentissage fédéré utilisant fastai et "
"Flower** ([#1598](https://github.com/adap/flower/pull/1598))"

#: ../../source/ref-changelog.md:185
msgid ""
"A new code example (`quickstart_fastai`) demonstrates federated learning "
"with [fastai](https://www.fast.ai/) and Flower. You can find it here: "
"[quickstart_fastai](https://github.com/adap/flower/tree/main/examples/quickstart_fastai)."
msgstr ""
"Un nouvel exemple de code (`quickstart_fastai`) démontre l'apprentissage "
"fédéré avec [fastai](https://www.fast.ai/) et Flower. Tu peux le trouver "
"ici : "
"[quickstart_fastai](https://github.com/adap/flower/tree/main/examples/quickstart_fastai)."

#: ../../source/ref-changelog.md:187
msgid ""
"**Make Android example compatible with** `flwr >= 1.0.0` **and the latest"
" versions of Android** "
"([#1603](https://github.com/adap/flower/pull/1603))"
msgstr ""
"**Rendre l'exemple Android compatible avec** `flwr >= 1.0.0` **et les "
"dernières versions d'Android** "
"([#1603](https://github.com/adap/flower/pull/1603))"

#: ../../source/ref-changelog.md:189
#, fuzzy
msgid ""
"The Android code example has received a substantial update: the project "
"is compatible with Flower 1.0 (and later), the UI received a full "
"refresh, and the project is updated to be compatible with newer Android "
"tooling."
msgstr ""
"L'exemple de code Android a reçu une mise à jour substantielle : le "
"projet est compatible avec Flower 1.0 et les versions ultérieures, "
"l'interface utilisateur a reçu un rafraîchissement complet, et le projet "
"est mis à jour pour être compatible avec les outils Android les plus "
"récents."

#: ../../source/ref-changelog.md:191
msgid ""
"**Add new `FedProx` strategy** "
"([#1619](https://github.com/adap/flower/pull/1619))"
msgstr ""
"**Ajouter une nouvelle stratégie `FedProx`** "
"([#1619](https://github.com/adap/flower/pull/1619))"

#: ../../source/ref-changelog.md:193
msgid ""
"This "
"[strategy](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedprox.py)"
" is almost identical to "
"[`FedAvg`](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedavg.py),"
" but helps users replicate what is described in this "
"[paper](https://arxiv.org/abs/1812.06127). It essentially adds a "
"parameter called `proximal_mu` to regularize the local models with "
"respect to the global models."
msgstr ""
"Cette "
"[stratégie](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedprox.py)"
" est presque identique à "
"[`FedAvg`](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedavg.py),"
" mais aide les utilisateurs à reproduire ce qui est décrit dans cet "
"[article](https://arxiv.org/abs/1812.06127). Elle ajoute essentiellement "
"un paramètre appelé `proximal_mu` pour régulariser les modèles locaux par"
" rapport aux modèles globaux."

#: ../../source/ref-changelog.md:195
msgid ""
"**Add new metrics to telemetry events** "
"([#1640](https://github.com/adap/flower/pull/1640))"
msgstr ""
"**Ajouter de nouvelles métriques aux événements de télémétrie** "
"([#1640](https://github.com/adap/flower/pull/1640))"

#: ../../source/ref-changelog.md:197
msgid ""
"An updated event structure allows, for example, the clustering of events "
"within the same workload."
msgstr ""
"Une structure d'événements mise à jour permet, par exemple, de regrouper "
"des événements au sein d'une même charge de travail."

#: ../../source/ref-changelog.md:199
msgid ""
"**Add new custom strategy tutorial section** "
"[#1623](https://github.com/adap/flower/pull/1623)"
msgstr ""
"**Ajouter une nouvelle section de tutoriel sur les stratégies "
"personnalisées** [#1623](https://github.com/adap/flower/pull/1623)"

#: ../../source/ref-changelog.md:201
#, fuzzy
msgid ""
"The Flower tutorial now has a new section that covers implementing a "
"custom strategy from scratch: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-build-a-strategy-from-scratch-pytorch.ipynb)"
msgstr ""
"Le tutoriel sur les fleurs comporte désormais une nouvelle section qui "
"traite de la mise en œuvre d'une stratégie personnalisée à partir de zéro"
" : [Ouvrir dans "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source/tutorial/Flower-3-Building-a"
"-Strategy-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:203
msgid ""
"**Add new custom serialization tutorial section** "
"([#1622](https://github.com/adap/flower/pull/1622))"
msgstr ""
"**Ajouter une nouvelle section de tutoriel sur la sérialisation "
"personnalisée** ([#1622](https://github.com/adap/flower/pull/1622))"

#: ../../source/ref-changelog.md:205
#, fuzzy
msgid ""
"The Flower tutorial now has a new section that covers custom "
"serialization: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-customize-the-client-pytorch.ipynb)"
msgstr ""
"Le tutoriel sur les fleurs comporte désormais une nouvelle section qui "
"traite de la sérialisation personnalisée : [Ouvrir dans "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source/tutorial/Flower-4"
"-Client-and-NumPyClient-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:207
msgid ""
"**General improvements** "
"([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), "
"[#1636](https://github.com/adap/flower/pull/1636), "
"[#1635](https://github.com/adap/flower/pull/1635), "
"[#1633](https://github.com/adap/flower/pull/1633), "
"[#1632](https://github.com/adap/flower/pull/1632), "
"[#1631](https://github.com/adap/flower/pull/1631), "
"[#1630](https://github.com/adap/flower/pull/1630), "
"[#1627](https://github.com/adap/flower/pull/1627), "
"[#1593](https://github.com/adap/flower/pull/1593), "
"[#1616](https://github.com/adap/flower/pull/1616), "
"[#1615](https://github.com/adap/flower/pull/1615), "
"[#1607](https://github.com/adap/flower/pull/1607), "
"[#1609](https://github.com/adap/flower/pull/1609), "
"[#1608](https://github.com/adap/flower/pull/1608), "
"[#1603](https://github.com/adap/flower/pull/1603), "
"[#1590](https://github.com/adap/flower/pull/1590), "
"[#1580](https://github.com/adap/flower/pull/1580), "
"[#1599](https://github.com/adap/flower/pull/1599), "
"[#1600](https://github.com/adap/flower/pull/1600), "
"[#1601](https://github.com/adap/flower/pull/1601), "
"[#1597](https://github.com/adap/flower/pull/1597), "
"[#1595](https://github.com/adap/flower/pull/1595), "
"[#1591](https://github.com/adap/flower/pull/1591), "
"[#1588](https://github.com/adap/flower/pull/1588), "
"[#1589](https://github.com/adap/flower/pull/1589), "
"[#1587](https://github.com/adap/flower/pull/1587), "
"[#1573](https://github.com/adap/flower/pull/1573), "
"[#1581](https://github.com/adap/flower/pull/1581), "
"[#1578](https://github.com/adap/flower/pull/1578), "
"[#1574](https://github.com/adap/flower/pull/1574), "
"[#1572](https://github.com/adap/flower/pull/1572), "
"[#1586](https://github.com/adap/flower/pull/1586))"
msgstr ""
"**General improvements** "
"([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), "
"[#1636](https://github.com/adap/flower/pull/1636), "
"[#1635](https://github.com/adap/flower/pull/1635), "
"[#1633](https://github.com/adap/flower/pull/1633), "
"[#1632](https://github.com/adap/flower/pull/1632), "
"[#1631](https://github.com/adap/flower/pull/1631), "
"[#1630](https://github.com/adap/flower/pull/1630), "
"[#1627](https://github.com/adap/flower/pull/1627), "
"[#1593](https://github.com/adap/flower/pull/1593), "
"[#1616](https://github.com/adap/flower/pull/1616), "
"[#1615](https://github.com/adap/flower/pull/1615), "
"[#1607](https://github.com/adap/flower/pull/1607), "
"[#1609](https://github.com/adap/flower/pull/1609), "
"[#1608](https://github.com/adap/flower/pull/1608), "
"[#1603](https://github.com/adap/flower/pull/1603), "
"[#1590](https://github.com/adap/flower/pull/1590), "
"[#1580](https://github.com/adap/flower/pull/1580), "
"[#1599](https://github.com/adap/flower/pull/1599), "
"[#1600](https://github.com/ada"

#: ../../source/ref-changelog.md:211
msgid ""
"**Updated documentation** "
"([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614))"
msgstr ""
"**Mise à jour de la documentation** "
"([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614))"

#: ../../source/ref-changelog.md:213 ../../source/ref-changelog.md:280
msgid ""
"As usual, the documentation has improved quite a bit. It is another step "
"in our effort to make the Flower documentation the best documentation of "
"any project. Stay tuned and as always, feel free to provide feedback!"
msgstr ""
"Comme d'habitude, la documentation s'est beaucoup améliorée. C'est une "
"autre étape dans notre effort pour faire de la documentation de Flower la"
" meilleure documentation de tout projet. Reste à l'écoute et comme "
"toujours, n'hésite pas à nous faire part de tes commentaires !"

#: ../../source/ref-changelog.md:219
msgid "v1.2.0 (2023-01-13)"
msgstr "v1.2.0 (2023-01-13)"

#: ../../source/ref-changelog.md:225
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L."
" Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"
msgstr ""
"adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L. "
"Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"

#: ../../source/ref-changelog.md:229
msgid ""
"**Introduce new Flower Baseline: FedAvg MNIST** "
"([#1497](https://github.com/adap/flower/pull/1497), "
"[#1552](https://github.com/adap/flower/pull/1552))"
msgstr ""
"**Introduire une nouvelle fleur Référence : FedAvg MNIST** "
"([#1497](https://github.com/adap/flower/pull/1497), "
"[#1552](https://github.com/adap/flower/pull/1552))"

#: ../../source/ref-changelog.md:231
msgid ""
"Over the coming weeks, we will be releasing a number of new reference "
"implementations useful especially to FL newcomers. They will typically "
"revisit well known papers from the literature, and be suitable for "
"integration in your own application or for experimentation, in order to "
"deepen your knowledge of FL in general. Today's release is the first in "
"this series. [Read more.](https://flower.dev/blog/2023-01-12-fl-starter-"
"pack-fedavg-mnist-cnn/)"
msgstr ""
"Au cours des prochaines semaines, nous publierons un certain nombre de "
"nouvelles implémentations de référence utiles en particulier pour les "
"nouveaux venus en FL. Elles revisiteront généralement des articles bien "
"connus de la littérature, et seront adaptées à l'intégration dans votre "
"propre application ou à l'expérimentation, afin d'approfondir votre "
"connaissance de FL en général. La publication d'aujourd'hui est la "
"première de cette série. [Lire la "
"suite.](https://flower.dev/blog/2023-01-12-fl-starter-pack-fedavg-mnist-"
"cnn/)"

#: ../../source/ref-changelog.md:233
msgid ""
"**Improve GPU support in simulations** "
"([#1555](https://github.com/adap/flower/pull/1555))"
msgstr ""
"**Améliorer la prise en charge des GPU dans les simulations** "
"([#1555](https://github.com/adap/flower/pull/1555))"

#: ../../source/ref-changelog.md:235
msgid ""
"The Ray-based Virtual Client Engine (`start_simulation`) has been updated"
" to improve GPU support. The update includes some of the hard-earned "
"lessons from scaling simulations in GPU cluster environments. New "
"defaults make running GPU-based simulations substantially more robust."
msgstr ""
"Le moteur client virtuel basé sur Ray (`start_simulation`) a été mis à "
"jour pour améliorer la prise en charge des GPU. La mise à jour inclut "
"certaines des leçons durement apprises lors de la mise à l'échelle des "
"simulations dans des environnements de grappes de GPU. De nouveaux "
"paramètres par défaut rendent l'exécution des simulations basées sur les "
"GPU beaucoup plus robuste."

#: ../../source/ref-changelog.md:237
msgid ""
"**Improve GPU support in Jupyter Notebook tutorials** "
"([#1527](https://github.com/adap/flower/pull/1527), "
"[#1558](https://github.com/adap/flower/pull/1558))"
msgstr ""
"**Améliorer la prise en charge du GPU dans les tutoriels Jupyter "
"Notebook** ([#1527](https://github.com/adap/flower/pull/1527), "
"[#1558](https://github.com/adap/flower/pull/1558))"

#: ../../source/ref-changelog.md:239
msgid ""
"Some users reported that Jupyter Notebooks have not always been easy to "
"use on GPU instances. We listened and made improvements to all of our "
"Jupyter notebooks! Check out the updated notebooks here:"
msgstr ""
"Certains utilisateurs ont signalé que les carnets Jupyter n'ont pas "
"toujours été faciles à utiliser sur les instances GPU. Nous les avons "
"écoutés et avons apporté des améliorations à tous nos carnets Jupyter ! "
"Découvre les carnets mis à jour ici :"

#: ../../source/ref-changelog.md:241
#, fuzzy
msgid ""
"[An Introduction to Federated Learning](https://flower.dev/docs/framework"
"/tutorial-get-started-with-flower-pytorch.html)"
msgstr ""
"[Une introduction à l'apprentissage fédéré] "
"(https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html)"

#: ../../source/ref-changelog.md:242
#, fuzzy
msgid ""
"[Strategies in Federated Learning](https://flower.dev/docs/framework"
"/tutorial-use-a-federated-learning-strategy-pytorch.html)"
msgstr ""
"[Stratégies d'apprentissage fédéré] "
"(https://flower.dev/docs/tutorial/Flower-2-Strategies-in-FL-PyTorch.html)"

#: ../../source/ref-changelog.md:243
#, fuzzy
msgid ""
"[Building a Strategy](https://flower.dev/docs/framework/tutorial-build-a"
"-strategy-from-scratch-pytorch.html)"
msgstr ""
"[Construire une stratégie] "
"(https://flower.dev/docs/tutorial/Flower-3-Building-a-Strategy-"
"PyTorch.html)"

#: ../../source/ref-changelog.md:244
#, fuzzy
msgid ""
"[Client and NumPyClient](https://flower.dev/docs/framework/tutorial-"
"customize-the-client-pytorch.html)"
msgstr ""
"[Client et NumPyClient] (https://flower.dev/docs/tutorial/Flower-4"
"-Client-and-NumPyClient-PyTorch.html)"

#: ../../source/ref-changelog.md:246
msgid ""
"**Introduce optional telemetry** "
"([#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584))"
msgstr ""
"**Introduire la télémétrie optionnelle** "
"([#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584))"

#: ../../source/ref-changelog.md:248
msgid ""
"After a [request for "
"feedback](https://github.com/adap/flower/issues/1534) from the community,"
" the Flower open-source project introduces optional collection of "
"*anonymous* usage metrics to make well-informed decisions to improve "
"Flower. Doing this enables the Flower team to understand how Flower is "
"used and what challenges users might face."
msgstr ""
"À la suite d'une [demande de commentaires] "
"(https://github.com/adap/flower/issues/1534) de la part de la communauté,"
" le projet open-source Flower introduit la collecte optionnelle de "
"mesures d'utilisation *anonymes* afin de prendre des décisions éclairées "
"pour améliorer Flower. Cela permet à l'équipe de Flower de comprendre "
"comment Flower est utilisé et quels sont les défis auxquels les "
"utilisateurs peuvent être confrontés."

#: ../../source/ref-changelog.md:250
#, fuzzy
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.**"
" Staying true to this statement, Flower makes it easy to disable "
"telemetry for users who do not want to share anonymous usage metrics. "
"[Read more.](https://flower.dev/docs/telemetry.html)."
msgstr ""
"**Flower est un cadre convivial pour l'IA collaborative et la science des"
" données.** Restant fidèle à cette déclaration, Flower permet de "
"désactiver facilement la télémétrie pour les utilisateurs qui ne "
"souhaitent pas partager des métriques d'utilisation anonymes.[Lire la "
"suite.](https://flower.dev/docs/telemetry.html)."

#: ../../source/ref-changelog.md:252
msgid ""
"**Introduce (experimental) Driver API** "
"([#1520](https://github.com/adap/flower/pull/1520), "
"[#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), "
"[#1546](https://github.com/adap/flower/pull/1546), "
"[#1550](https://github.com/adap/flower/pull/1550), "
"[#1551](https://github.com/adap/flower/pull/1551), "
"[#1567](https://github.com/adap/flower/pull/1567))"
msgstr ""
"**([#1520](https://github.com/adap/flower/pull/1520), "
"[#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), "
"[#1546](https://github.com/adap/flower/pull/1546), "
"[#1550](https://github.com/adap/flower/pull/1550), "
"[#1551](https://github.com/adap/flower/pull/1551), "
"[#1567](https://github.com/adap/flower/pull/1567))"

#: ../../source/ref-changelog.md:254
msgid ""
"Flower now has a new (experimental) Driver API which will enable fully "
"programmable, async, and multi-tenant Federated Learning and Federated "
"Analytics applications. Phew, that's a lot! Going forward, the Driver API"
" will be the abstraction that many upcoming features will be built on - "
"and you can start building those things now, too."
msgstr ""
"Flower dispose désormais d'une nouvelle API de pilote (expérimentale) qui"
" permettra de créer des applications Federated Learning et Federated "
"Analytics entièrement programmables, asynchrones et multi-tenant. Ouf, "
"c'est beaucoup ! À l'avenir, l'API de pilote sera l'abstraction sur "
"laquelle de nombreuses fonctionnalités à venir seront construites - et tu"
" peux commencer à construire ces choses dès maintenant, aussi."

#: ../../source/ref-changelog.md:256
msgid ""
"The Driver API also enables a new execution mode in which the server runs"
" indefinitely. Multiple individual workloads can run concurrently and "
"start and stop their execution independent of the server. This is "
"especially useful for users who want to deploy Flower in production."
msgstr ""
"L'API du pilote permet également un nouveau mode d'exécution dans lequel "
"le serveur s'exécute indéfiniment. Plusieurs charges de travail "
"individuelles peuvent s'exécuter simultanément et démarrer et arrêter "
"leur exécution indépendamment du serveur. Ceci est particulièrement utile"
" pour les utilisateurs qui souhaitent déployer Flower en production."

#: ../../source/ref-changelog.md:258
msgid ""
"To learn more, check out the `mt-pytorch` code example. We look forward "
"to you feedback!"
msgstr ""
"Pour en savoir plus, consulte l'exemple de code `mt-pytorch`. Nous "
"attendons tes commentaires avec impatience !"

#: ../../source/ref-changelog.md:260
msgid ""
"Please note: *The Driver API is still experimental and will likely change"
" significantly over time.*"
msgstr ""
"Remarque : *L'API du pilote est encore expérimentale et est susceptible "
"de changer de manière significative au fil du temps.*"

#: ../../source/ref-changelog.md:262
msgid ""
"**Add new Federated Analytics with Pandas example** "
"([#1469](https://github.com/adap/flower/pull/1469), "
"[#1535](https://github.com/adap/flower/pull/1535))"
msgstr ""
"**Ajouter un nouvel exemple de Federated Analytics avec Pandas** "
"([#1469](https://github.com/adap/flower/pull/1469), "
"[#1535](https://github.com/adap/flower/pull/1535))"

#: ../../source/ref-changelog.md:264
msgid ""
"A new code example (`quickstart_pandas`) demonstrates federated analytics"
" with Pandas and Flower. You can find it here: "
"[quickstart_pandas](https://github.com/adap/flower/tree/main/examples/quickstart_pandas)."
msgstr ""
"Un nouvel exemple de code (`quickstart_pandas`) démontre l'analyse "
"fédérée avec Pandas et Flower. Tu peux le trouver ici : "
"[quickstart_pandas](https://github.com/adap/flower/tree/main/examples/quickstart_pandas)."

#: ../../source/ref-changelog.md:266
msgid ""
"**Add new strategies: Krum and MultiKrum** "
"([#1481](https://github.com/adap/flower/pull/1481))"
msgstr ""
"**Ajouter de nouvelles stratégies : Krum et MultiKrum** "
"([#1481](https://github.com/adap/flower/pull/1481))"

#: ../../source/ref-changelog.md:268
msgid ""
"Edoardo, a computer science student at the Sapienza University of Rome, "
"contributed a new `Krum` strategy that enables users to easily use Krum "
"and MultiKrum in their workloads."
msgstr ""
"Edoardo, étudiant en informatique à l'Université Sapienza de Rome, a "
"contribué à une nouvelle stratégie `Krum` qui permet aux utilisateurs "
"d'utiliser facilement Krum et MultiKrum dans leurs charges de travail."

#: ../../source/ref-changelog.md:270
msgid ""
"**Update C++ example to be compatible with Flower v1.2.0** "
"([#1495](https://github.com/adap/flower/pull/1495))"
msgstr ""
"**Mettre à jour l'exemple C++ pour qu'il soit compatible avec Flower "
"v1.2.0** ([#1495](https://github.com/adap/flower/pull/1495))"

#: ../../source/ref-changelog.md:272
msgid ""
"The C++ code example has received a substantial update to make it "
"compatible with the latest version of Flower."
msgstr ""
"L'exemple de code C++ a reçu une mise à jour substantielle pour le rendre"
" compatible avec la dernière version de Flower."

#: ../../source/ref-changelog.md:274
msgid ""
"**General improvements** "
"([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), "
"[#1506](https://github.com/adap/flower/pull/1506), "
"[#1514](https://github.com/adap/flower/pull/1514), "
"[#1522](https://github.com/adap/flower/pull/1522), "
"[#1523](https://github.com/adap/flower/pull/1523), "
"[#1526](https://github.com/adap/flower/pull/1526), "
"[#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), "
"[#1549](https://github.com/adap/flower/pull/1549), "
"[#1560](https://github.com/adap/flower/pull/1560), "
"[#1564](https://github.com/adap/flower/pull/1564), "
"[#1566](https://github.com/adap/flower/pull/1566))"
msgstr ""
"**Améliorations générales** "
"([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), "
"[#1506](https://github.com/adap/flower/pull/1506), "
"[#1514](https://github.com/adap/flower/pull/1514), "
"[#1522](https://github.com/adap/flower/pull/1522), "
"[#1523](https://github.com/adap/flower/pull/1523), "
"[#1526](https://github.com/adap/flower/pull/1526), "
"[#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), "
"[#1549](https://github.com/adap/flower/pull/1549), "
"[#1560](https://github.com/adap/flower/pull/1560), "
"[#1564](https://github.com/adap/flower/pull/1564), "
"[#1566](https://github.com/adap/flower/pull/1566))"

#: ../../source/ref-changelog.md:278
msgid ""
"**Updated documentation** "
"([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"
msgstr ""
"**Documentation mise à jour** "
"([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"

#: ../../source/ref-changelog.md:282
msgid ""
"One highlight is the new [first time contributor "
"guide](https://flower.dev/docs/first-time-contributors.html): if you've "
"never contributed on GitHub before, this is the perfect place to start!"
msgstr ""
"L'un des points forts est le nouveau [guide du premier contributeur] "
"(https://flower.dev/docs/first-time-contributors.html) : si tu n'as "
"jamais contribué sur GitHub auparavant, c'est l'endroit idéal pour "
"commencer !"

#: ../../source/ref-changelog.md:288
msgid "v1.1.0 (2022-10-31)"
msgstr "v1.1.0 (2022-10-31)"

#: ../../source/ref-changelog.md:292
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made the new version of Flower possible (in `git shortlog` order):"
msgstr ""
"Nous aimerions **remercier tout particulièrement** tous les contributeurs"
" qui ont rendu possible la nouvelle version de Flower (dans l'ordre `git "
"shortlog`) :"

#: ../../source/ref-changelog.md:294
msgid ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, "
"`danielnugraha`, `edogab33`"
msgstr ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, "
"`danielnugraha`, `edogab33`"

#: ../../source/ref-changelog.md:298
msgid ""
"**Introduce Differential Privacy wrappers (preview)** "
"([#1357](https://github.com/adap/flower/pull/1357), "
"[#1460](https://github.com/adap/flower/pull/1460))"
msgstr ""
"**Introduire les enveloppes de confidentialité différentielle (aperçu)** "
"([#1357](https://github.com/adap/flower/pull/1357), "
"[#1460](https://github.com/adap/flower/pull/1460))"

#: ../../source/ref-changelog.md:300
msgid ""
"The first (experimental) preview of pluggable Differential Privacy "
"wrappers enables easy configuration and usage of differential privacy "
"(DP). The pluggable DP wrappers enable framework-agnostic **and** "
"strategy-agnostic usage of both client-side DP and server-side DP. Head "
"over to the Flower docs, a new explainer goes into more detail."
msgstr ""
"Le premier aperçu (expérimental) des wrappers enfichables de "
"confidentialité différentielle permet de configurer et d'utiliser "
"facilement la confidentialité différentielle (DP). Les wrappers DP "
"enfichables permettent une utilisation agnostique du cadre **et** de la "
"stratégie à la fois de la DP côté client et de la DP côté serveur. Va "
"voir les documents de Flower, un nouvel explicatif va plus loin dans les "
"détails."

#: ../../source/ref-changelog.md:302
msgid ""
"**New iOS CoreML code example** "
"([#1289](https://github.com/adap/flower/pull/1289))"
msgstr ""
"**Nouvel exemple de code CoreML pour iOS** "
"([#1289](https://github.com/adap/flower/pull/1289))"

#: ../../source/ref-changelog.md:304
msgid ""
"Flower goes iOS! A massive new code example shows how Flower clients can "
"be built for iOS. The code example contains both Flower iOS SDK "
"components that can be used for many tasks, and one task example running "
"on CoreML."
msgstr ""
"Flower passe à iOS ! Un nouvel exemple de code massif montre comment les "
"clients Flower peuvent être construits pour iOS. L'exemple de code "
"contient à la fois des composants Flower iOS SDK qui peuvent être "
"utilisés pour de nombreuses tâches, et un exemple de tâche fonctionnant "
"sur CoreML."

#: ../../source/ref-changelog.md:306
msgid ""
"**New FedMedian strategy** "
"([#1461](https://github.com/adap/flower/pull/1461))"
msgstr ""
"**Nouvelle stratégie de FedMedian** "
"([#1461](https://github.com/adap/flower/pull/1461))"

#: ../../source/ref-changelog.md:308
msgid ""
"The new `FedMedian` strategy implements Federated Median (FedMedian) by "
"[Yin et al., 2018](https://arxiv.org/pdf/1803.01498v1.pdf)."
msgstr ""
"La nouvelle stratégie `FedMedian` met en œuvre Federated Median "
"(FedMedian) par [Yin et al., 2018] "
"(https://arxiv.org/pdf/1803.01498v1.pdf)."

#: ../../source/ref-changelog.md:310
msgid ""
"**Log** `Client` **exceptions in Virtual Client Engine** "
"([#1493](https://github.com/adap/flower/pull/1493))"
msgstr ""
"**Log** `Client` **exceptions dans le moteur de client virtuel** "
"([#1493](https://github.com/adap/flower/pull/1493))"

#: ../../source/ref-changelog.md:312
msgid ""
"All `Client` exceptions happening in the VCE are now logged by default "
"and not just exposed to the configured `Strategy` (via the `failures` "
"argument)."
msgstr ""
"Toutes les exceptions `Client` qui se produisent dans le VCE sont "
"maintenant enregistrées par défaut et ne sont pas seulement exposées à la"
" `Stratégie` configurée (via l'argument `failures`)."

#: ../../source/ref-changelog.md:314
msgid ""
"**Improve Virtual Client Engine internals** "
"([#1401](https://github.com/adap/flower/pull/1401), "
"[#1453](https://github.com/adap/flower/pull/1453))"
msgstr ""
"**Améliorer le moteur du client virtuel** "
"([#1401](https://github.com/adap/flower/pull/1401), "
"[#1453](https://github.com/adap/flower/pull/1453))"

#: ../../source/ref-changelog.md:316
msgid ""
"Some internals of the Virtual Client Engine have been revamped. The VCE "
"now uses Ray 2.0 under the hood, the value type of the `client_resources`"
" dictionary changed to `float` to allow fractions of resources to be "
"allocated."
msgstr ""
"Le VCE utilise maintenant Ray 2.0 sous le capot, le type de valeur du "
"dictionnaire `client_resources` a été remplacé par `float` pour permettre"
" l'allocation de fractions de ressources."

#: ../../source/ref-changelog.md:318
msgid ""
"**Support optional** `Client`**/**`NumPyClient` **methods in Virtual "
"Client Engine**"
msgstr ""
"**Support optional** `Client`**/**`NumPyClient` **methods in Virtual "
"Client Engine**"

#: ../../source/ref-changelog.md:320
msgid ""
"The Virtual Client Engine now has full support for optional `Client` (and"
" `NumPyClient`) methods."
msgstr ""
"Le moteur de client virtuel prend désormais en charge les méthodes "
"optionnelles `Client` (et `NumPyClient`)."

#: ../../source/ref-changelog.md:322
msgid ""
"**Provide type information to packages using** `flwr` "
"([#1377](https://github.com/adap/flower/pull/1377))"
msgstr ""
"**Fournir des informations de type aux paquets en utilisant** `flwr` "
"([#1377](https://github.com/adap/flower/pull/1377))"

#: ../../source/ref-changelog.md:324
msgid ""
"The package `flwr` is now bundled with a `py.typed` file indicating that "
"the package is typed. This enables typing support for projects or "
"packages that use `flwr` by enabling them to improve their code using "
"static type checkers like `mypy`."
msgstr ""
"Le paquet `flwr` est maintenant accompagné d'un fichier `py.typed` "
"indiquant que le paquet est typé. Cela permet de prendre en charge le "
"typage pour les projets ou les paquets qui utilisent `flwr` en leur "
"permettant d'améliorer leur code à l'aide de vérificateurs de types "
"statiques comme `mypy`."

#: ../../source/ref-changelog.md:326
msgid ""
"**Updated code example** "
"([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"
msgstr ""
"**Exemple de code mis à jour** "
"([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"

#: ../../source/ref-changelog.md:328
msgid ""
"The code examples covering scikit-learn and PyTorch Lightning have been "
"updated to work with the latest version of Flower."
msgstr ""
"Les exemples de code couvrant scikit-learn et PyTorch Lightning ont été "
"mis à jour pour fonctionner avec la dernière version de Flower."

#: ../../source/ref-changelog.md:330
msgid ""
"**Updated documentation** "
"([#1355](https://github.com/adap/flower/pull/1355), "
"[#1558](https://github.com/adap/flower/pull/1558), "
"[#1379](https://github.com/adap/flower/pull/1379), "
"[#1380](https://github.com/adap/flower/pull/1380), "
"[#1381](https://github.com/adap/flower/pull/1381), "
"[#1332](https://github.com/adap/flower/pull/1332), "
"[#1391](https://github.com/adap/flower/pull/1391), "
"[#1403](https://github.com/adap/flower/pull/1403), "
"[#1364](https://github.com/adap/flower/pull/1364), "
"[#1409](https://github.com/adap/flower/pull/1409), "
"[#1419](https://github.com/adap/flower/pull/1419), "
"[#1444](https://github.com/adap/flower/pull/1444), "
"[#1448](https://github.com/adap/flower/pull/1448), "
"[#1417](https://github.com/adap/flower/pull/1417), "
"[#1449](https://github.com/adap/flower/pull/1449), "
"[#1465](https://github.com/adap/flower/pull/1465), "
"[#1467](https://github.com/adap/flower/pull/1467))"
msgstr ""
"**Documentation mise à jour** "
"([#1355](https://github.com/adap/flower/pull/1355), "
"[#1558](https://github.com/adap/flower/pull/1558), "
"[#1379](https://github.com/adap/flower/pull/1379), "
"[#1380](https://github.com/adap/flower/pull/1380), "
"[#1381](https://github.com/adap/flower/pull/1381), "
"[#1332](https://github.com/adap/flower/pull/1332), "
"[#1391](https://github.com/adap/flower/pull/1391), "
"[#1403](https://github.com/adap/flower/pull/1403), "
"[#1364](https://github.com/adap/flower/pull/1364), "
"[#1409](https://github.com/adap/flower/pull/1409), "
"[#1419](https://github.com/adap/flower/pull/1419), "
"[#1444](https://github.com/adap/flower/pull/1444), "
"[#1448](https://github.com/adap/flower/pull/1448), "
"[#1417](https://github.com/adap/flower/pull/1417), "
"[#1449](https://github.com/adap/flower/pull/1449), "
"[#1465](https://github.com/adap/flower/pull/1465), "
"[#1467](https://github.com/adap/flower/pull/1467))"

#: ../../source/ref-changelog.md:332
msgid ""
"There have been so many documentation updates that it doesn't even make "
"sense to list them individually."
msgstr ""
"Il y a eu tellement de mises à jour de la documentation que cela n'a même"
" pas de sens de les énumérer individuellement."

#: ../../source/ref-changelog.md:334
msgid ""
"**Restructured documentation** "
"([#1387](https://github.com/adap/flower/pull/1387))"
msgstr ""
"**Documentation restructurée** "
"([#1387](https://github.com/adap/flower/pull/1387))"

#: ../../source/ref-changelog.md:336
msgid ""
"The documentation has been restructured to make it easier to navigate. "
"This is just the first step in a larger effort to make the Flower "
"documentation the best documentation of any project ever. Stay tuned!"
msgstr ""
"La documentation a été restructurée pour faciliter la navigation. Ce "
"n'est que la première étape d'un effort plus important visant à faire de "
"la documentation de Flower la meilleure documentation de tous les projets"

#: ../../source/ref-changelog.md:338
msgid ""
"**Open in Colab button** "
"([#1389](https://github.com/adap/flower/pull/1389))"
msgstr ""
"**Ouvrir dans le bouton Colab** "
"([#1389](https://github.com/adap/flower/pull/1389))"

#: ../../source/ref-changelog.md:340
msgid ""
"The four parts of the Flower Federated Learning Tutorial now come with a "
"new `Open in Colab` button. No need to install anything on your local "
"machine, you can now use and learn about Flower in your browser, it's "
"only a single click away."
msgstr ""
"Les quatre parties du didacticiel d'apprentissage fédéré Flower sont "
"maintenant accompagnées d'un nouveau bouton \"Ouvrir dans Colab\". Pas "
"besoin d'installer quoi que ce soit sur ta machine locale, tu peux "
"maintenant utiliser et apprendre à connaître Flower dans ton navigateur, "
"il te suffit d'un simple clic."

#: ../../source/ref-changelog.md:342
msgid ""
"**Improved tutorial** ([#1468](https://github.com/adap/flower/pull/1468),"
" [#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475))"
msgstr ""
"**Tutoriel amélioré** ([#1468](https://github.com/adap/flower/pull/1468),"
" [#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475))"

#: ../../source/ref-changelog.md:344
msgid ""
"The Flower Federated Learning Tutorial has two brand-new parts covering "
"custom strategies (still WIP) and the distinction between `Client` and "
"`NumPyClient`. The existing parts one and two have also been improved "
"(many small changes and fixes)."
msgstr ""
"Le tutoriel sur l'apprentissage fédéré des fleurs a deux toutes nouvelles"
" parties couvrant les stratégies personnalisées (encore WIP) et la "
"distinction entre `Client` et `NumPyClient`. Les parties un et deux "
"existantes ont également été améliorées (beaucoup de petits changements "
"et de corrections)."

#: ../../source/ref-changelog.md:350
msgid "v1.0.0 (2022-07-28)"
msgstr "v1.0.0 (2022-07-28)"

#: ../../source/ref-changelog.md:352
msgid "Highlights"
msgstr "Points forts"

#: ../../source/ref-changelog.md:354
msgid "Stable **Virtual Client Engine** (accessible via `start_simulation`)"
msgstr "Moteur de client virtuel stable** (accessible via `start_simulation`)"

#: ../../source/ref-changelog.md:355
msgid "All `Client`/`NumPyClient` methods are now optional"
msgstr "Toutes les méthodes `Client`/`NumPyClient` sont maintenant optionnelles"

#: ../../source/ref-changelog.md:356
msgid "Configurable `get_parameters`"
msgstr "`get_parameters` configurable"

#: ../../source/ref-changelog.md:357
msgid ""
"Tons of small API cleanups resulting in a more coherent developer "
"experience"
msgstr ""
"Des tonnes de petits nettoyages d'API résultant en une expérience plus "
"cohérente pour les développeurs"

#: ../../source/ref-changelog.md:361
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made Flower 1.0 possible (in reverse [GitHub "
"Contributors](https://github.com/adap/flower/graphs/contributors) order):"
msgstr ""
"Nous tenons à remercier **particulièrement** tous les contributeurs qui "
"ont rendu Flower 1.0 possible (dans l'ordre inverse de [GitHub "
"Contributors](https://github.com/adap/flower/graphs/contributors)) :"

#: ../../source/ref-changelog.md:363
msgid ""
"[@rtaiello](https://github.com/rtaiello), "
"[@g-pichler](https://github.com/g-pichler), [@rob-"
"luke](https://github.com/rob-luke), [@andreea-zaharia](https://github.com"
"/andreea-zaharia), [@kinshukdua](https://github.com/kinshukdua), "
"[@nfnt](https://github.com/nfnt), "
"[@tatiana-s](https://github.com/tatiana-s), "
"[@TParcollet](https://github.com/TParcollet), "
"[@vballoli](https://github.com/vballoli), "
"[@negedng](https://github.com/negedng), "
"[@RISHIKESHAVAN](https://github.com/RISHIKESHAVAN), "
"[@hei411](https://github.com/hei411), "
"[@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), "
"[@Rubiel1](https://github.com/Rubiel1), [@FANTOME-PAN](https://github.com"
"/FANTOME-PAN), [@Rono-BC](https://github.com/Rono-BC), "
"[@lbhm](https://github.com/lbhm), "
"[@sishtiaq](https://github.com/sishtiaq), "
"[@remde](https://github.com/remde), [@Jueun-Park](https://github.com"
"/Jueun-Park), [@architjen](https://github.com/architjen), "
"[@PratikGarai](https://github.com/PratikGarai), "
"[@mrinaald](https://github.com/mrinaald), "
"[@zliel](https://github.com/zliel), "
"[@MeiruiJiang](https://github.com/MeiruiJiang), "
"[@sandracl72](https://github.com/sandracl72), "
"[@gubertoli](https://github.com/gubertoli), "
"[@Vingt100](https://github.com/Vingt100), "
"[@MakGulati](https://github.com/MakGulati), "
"[@cozek](https://github.com/cozek), "
"[@jafermarq](https://github.com/jafermarq), "
"[@sisco0](https://github.com/sisco0), "
"[@akhilmathurs](https://github.com/akhilmathurs), "
"[@CanTuerk](https://github.com/CanTuerk), "
"[@mariaboerner1987](https://github.com/mariaboerner1987), "
"[@pedropgusmao](https://github.com/pedropgusmao), "
"[@tanertopal](https://github.com/tanertopal), "
"[@danieljanes](https://github.com/danieljanes)."
msgstr ""
"[@rtaiello](https://github.com/rtaiello), "
"[@g-pichler](https://github.com/g-pichler), [@rob-"
"luke](https://github.com/rob-luke), [@andreea-zaharia](https://github.com"
"/andreea-zaharia), [@kinshukdua](https://github.com/kinshukdua), "
"[@nfnt](https://github.com/nfnt), "
"[@tatiana-s](https://github.com/tatiana-s), "
"[@TParcollet](https://github.com/TParcollet), "
"[@vballoli](https://github.com/vballoli), "
"[@negedng](https://github.com/negedng), "
"[@RISHIKESHAVAN](https://github.com/RISHIKESHAVAN), "
"[@hei411](https://github.com/hei411), "
"[@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), "
"[@Rubiel1](https://github.com/Rubiel1), [@FANTOME-PAN](https://github.com"
"/FANTOME-PAN), [@Rono-BC](https://github.com/Rono-BC), "
"[@lbhm](https://github.com/lbhm), "
"[@sishtiaq](https://github.com/sishtiaq), "
"[@remde](https://github.com/remde), [@Jueun-Park](https://github.com"
"/Jueun-Park), [@architjen](https://github.com/architjen), "
"[@PratikGarai](https://github.com/PratikGarai), [@mrinaald]("

#: ../../source/ref-changelog.md:367
msgid ""
"**All arguments must be passed as keyword arguments** "
"([#1338](https://github.com/adap/flower/pull/1338))"
msgstr ""
"**Tous les arguments doivent être passés comme des arguments de mot-clé**"
" ([#1338](https://github.com/adap/flower/pull/1338))"

#: ../../source/ref-changelog.md:369
#, fuzzy
msgid ""
"Pass all arguments as keyword arguments, positional arguments are not "
"longer supported. Code that uses positional arguments (e.g., "
"`start_client(\"127.0.0.1:8080\", FlowerClient())`) must add the keyword "
"for each positional argument (e.g., "
"`start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())`)."
msgstr ""
"Le code qui utilise des arguments positionnels (par exemple, "
"``start_client(\"127.0.0.1:8080\", FlowerClient())`) doit ajouter le mot-"
"clé pour chaque argument positionnel (par exemple, "
"``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())`)."

#: ../../source/ref-changelog.md:371
msgid ""
"**Introduce configuration object** `ServerConfig` **in** `start_server` "
"**and** `start_simulation` "
"([#1317](https://github.com/adap/flower/pull/1317))"
msgstr ""
"**Introduire l'objet de configuration** `ServerConfig` **dans** "
"`start_server` **et** `start_simulation` "
"([#1317](https://github.com/adap/flower/pull/1317))"

#: ../../source/ref-changelog.md:373
msgid ""
"Instead of a config dictionary `{\"num_rounds\": 3, \"round_timeout\": "
"600.0}`, `start_server` and `start_simulation` now expect a configuration"
" object of type `flwr.server.ServerConfig`. `ServerConfig` takes the same"
" arguments that as the previous config dict, but it makes writing type-"
"safe code easier and the default parameters values more transparent."
msgstr ""
"Au lieu d'un dictionnaire de configuration `{\"num_rounds\" : 3, "
"\"round_timeout\" : 600.0}`, `start_server` et `start_simulation` "
"attendent maintenant un objet de configuration de type "
"`flwr.server.ServerConfig`. `ServerConfig` prend les mêmes arguments que "
"le dict de configuration précédent, mais il rend l'écriture de code "
"sécurisé plus facile et les valeurs des paramètres par défaut plus "
"transparentes."

#: ../../source/ref-changelog.md:375
msgid ""
"**Rename built-in strategy parameters for clarity** "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""
"**Renommer les paramètres de la stratégie intégrée pour plus de clarté** "
"([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:377
msgid ""
"The following built-in strategy parameters were renamed to improve "
"readability and consistency with other API's:"
msgstr ""
"Les paramètres de stratégie intégrés suivants ont été renommés pour "
"améliorer la lisibilité et la cohérence avec d'autres API :"

#: ../../source/ref-changelog.md:379
msgid "`fraction_eval` --> `fraction_evaluate`"
msgstr "`fraction_eval` --> `fraction_evaluate`"

#: ../../source/ref-changelog.md:380
msgid "`min_eval_clients` --> `min_evaluate_clients`"
msgstr "`min_eval_clients` --> `min_evaluate_clients`"

#: ../../source/ref-changelog.md:381
msgid "`eval_fn` --> `evaluate_fn`"
msgstr "`eval_fn` --> `evaluate_fn`"

#: ../../source/ref-changelog.md:383
msgid ""
"**Update default arguments of built-in strategies** "
"([#1278](https://github.com/adap/flower/pull/1278))"
msgstr ""
"**Mettre à jour les arguments par défaut des stratégies intégrées** "
"([#1278](https://github.com/adap/flower/pull/1278))"

#: ../../source/ref-changelog.md:385
msgid ""
"All built-in strategies now use `fraction_fit=1.0` and "
"`fraction_evaluate=1.0`, which means they select *all* currently "
"available clients for training and evaluation. Projects that relied on "
"the previous default values can get the previous behaviour by "
"initializing the strategy in the following way:"
msgstr ""
"Toutes les stratégies intégrées utilisent désormais `fraction_fit=1.0` et"
" `fraction_evaluate=1.0`, ce qui signifie qu'elles sélectionnent *tous* "
"les clients actuellement disponibles pour l'entraînement et l'évaluation."
" Les projets qui s'appuyaient sur les valeurs par défaut précédentes "
"peuvent retrouver le comportement antérieur en initialisant la stratégie "
"de la manière suivante :"

#: ../../source/ref-changelog.md:387
msgid "`strategy = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"
msgstr "`stratégie = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"

#: ../../source/ref-changelog.md:389
msgid ""
"**Add** `server_round` **to** `Strategy.evaluate` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""
"**Ajouter** `server_round` **à** `Strategy.evaluate` "
"([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:391
msgid ""
"The `Strategy` method `evaluate` now receives the current round of "
"federated learning/evaluation as the first parameter."
msgstr ""
"La méthode `Stratégie` `évaluer` reçoit maintenant le cycle actuel "
"d'apprentissage/évaluation fédéré comme premier paramètre."

#: ../../source/ref-changelog.md:393
msgid ""
"**Add** `server_round` **and** `config` **parameters to** `evaluate_fn` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""
"**Ajouter** `server_round` **et** `config` **paramètres à** `evaluate_fn`"
" ([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:395
msgid ""
"The `evaluate_fn` passed to built-in strategies like `FedAvg` now takes "
"three parameters: (1) The current round of federated learning/evaluation "
"(`server_round`), (2) the model parameters to evaluate (`parameters`), "
"and (3) a config dictionary (`config`)."
msgstr ""
"Le `evaluate_fn` passé aux stratégies intégrées comme `FedAvg` prend "
"maintenant trois paramètres : (1) le cycle actuel "
"d'apprentissage/évaluation fédéré (`server_round`), (2) les paramètres du"
" modèle à évaluer (`parameters`), et (3) un dictionnaire de configuration"
" (`config`)."

#: ../../source/ref-changelog.md:397
msgid ""
"**Rename** `rnd` **to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"
msgstr ""
"**Rename** `rnd` **to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"

#: ../../source/ref-changelog.md:399
msgid ""
"Several Flower methods and functions (`evaluate_fn`, `configure_fit`, "
"`aggregate_fit`, `configure_evaluate`, `aggregate_evaluate`) receive the "
"current round of federated learning/evaluation as their first parameter. "
"To improve reaability and avoid confusion with *random*, this parameter "
"has been renamed from `rnd` to `server_round`."
msgstr ""
"Plusieurs méthodes et fonctions de Flower (`evaluate_fn`, "
"`configure_fit`, `aggregate_fit`, `configure_evaluate`, "
"`aggregate_evaluate`) reçoivent le cycle actuel "
"d'apprentissage/évaluation fédéré comme premier paramètre. Pour améliorer"
" la fiabilité et éviter la confusion avec *random*, ce paramètre a été "
"renommé de `rnd` à `server_round`."

#: ../../source/ref-changelog.md:401
msgid ""
"**Move** `flwr.dataset` **to** `flwr_baselines` "
"([#1273](https://github.com/adap/flower/pull/1273))"
msgstr ""
"**Déplacer** `flwr.dataset` **vers** `flwr_baselines` "
"([#1273](https://github.com/adap/flower/pull/1273))"

#: ../../source/ref-changelog.md:403
msgid "The experimental package `flwr.dataset` was migrated to Flower Baselines."
msgstr "Le paquet expérimental `flwr.dataset` a été migré vers Flower Baselines."

#: ../../source/ref-changelog.md:405
msgid ""
"**Remove experimental strategies** "
"([#1280](https://github.com/adap/flower/pull/1280))"
msgstr ""
"**Supprimer les stratégies expérimentales** "
"([#1280](https://github.com/adap/flower/pull/1280))"

#: ../../source/ref-changelog.md:407
msgid ""
"Remove unmaintained experimental strategies (`FastAndSlow`, `FedFSv0`, "
"`FedFSv1`)."
msgstr ""
"Supprimer les stratégies expérimentales non maintenues (`FastAndSlow`, "
"`FedFSv0`, `FedFSv1`)."

#: ../../source/ref-changelog.md:409
msgid ""
"**Rename** `Weights` **to** `NDArrays` "
"([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"**Rename** `Weights` **to** `NDArrays` "
"([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"

#: ../../source/ref-changelog.md:411
msgid ""
"`flwr.common.Weights` was renamed to `flwr.common.NDArrays` to better "
"capture what this type is all about."
msgstr ""
"`flwr.common.Weights` a été renommé en `flwr.common.NDArys` pour mieux "
"rendre compte de la nature de ce type."

#: ../../source/ref-changelog.md:413
msgid ""
"**Remove antiquated** `force_final_distributed_eval` **from** "
"`start_server` ([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"**Supprimez l'ancien** `force_final_distributed_eval` **de** "
"`start_server` ([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"

#: ../../source/ref-changelog.md:415
msgid ""
"The `start_server` parameter `force_final_distributed_eval` has long been"
" a historic artefact, in this release it is finally gone for good."
msgstr ""
"Le paramètre `start_server` `force_final_distributed_eval` a longtemps "
"été un artefact historique, dans cette version il a finalement disparu "
"pour de bon."

#: ../../source/ref-changelog.md:417
msgid ""
"**Make** `get_parameters` **configurable** "
"([#1242](https://github.com/adap/flower/pull/1242))"
msgstr ""
"**Make** `get_parameters` **configurable** "
"([#1242](https://github.com/adap/flower/pull/1242))"

#: ../../source/ref-changelog.md:419
msgid ""
"The `get_parameters` method now accepts a configuration dictionary, just "
"like `get_properties`, `fit`, and `evaluate`."
msgstr ""
"La méthode `get_parameters` accepte maintenant un dictionnaire de "
"configuration, tout comme `get_properties`, `fit`, et `evaluate`."

#: ../../source/ref-changelog.md:421
msgid ""
"**Replace** `num_rounds` **in** `start_simulation` **with new** `config` "
"**parameter** ([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""
"**Remplace** `num_rounds` **dans** `start_simulation` **avec le nouveau**"
" `config` **paramètre** "
"([#1281](https://github.com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:423
msgid ""
"The `start_simulation` function now accepts a configuration dictionary "
"`config` instead of the `num_rounds` integer. This improves the "
"consistency between `start_simulation` and `start_server` and makes "
"transitioning between the two easier."
msgstr ""
"La fonction `start_simulation` accepte maintenant un dictionnaire de "
"configuration `config` au lieu de l'entier `num_rounds`. Cela améliore la"
" cohérence entre `start_simulation` et `start_server` et facilite la "
"transition entre les deux."

#: ../../source/ref-changelog.md:427
msgid ""
"**Support Python 3.10** "
"([#1320](https://github.com/adap/flower/pull/1320))"
msgstr ""
"**Support Python 3.10** "
"([#1320](https://github.com/adap/flower/pull/1320))"

#: ../../source/ref-changelog.md:429
msgid ""
"The previous Flower release introduced experimental support for Python "
"3.10, this release declares Python 3.10 support as stable."
msgstr ""
"La version précédente de Flower a introduit la prise en charge "
"expérimentale de Python 3.10, cette version déclare la prise en charge de"
" Python 3.10 comme stable."

#: ../../source/ref-changelog.md:431
msgid ""
"**Make all** `Client` **and** `NumPyClient` **methods optional** "
"([#1260](https://github.com/adap/flower/pull/1260), "
"[#1277](https://github.com/adap/flower/pull/1277))"
msgstr ""
"**Rendre toutes les **méthodes `Client` **et** `NumPyClient` "
"**facultatives** ([#1260](https://github.com/adap/flower/pull/1260), "
"[#1277](https://github.com/adap/flower/pull/1277))"

#: ../../source/ref-changelog.md:433
msgid ""
"The `Client`/`NumPyClient` methods `get_properties`, `get_parameters`, "
"`fit`, and `evaluate` are all optional. This enables writing clients that"
" implement, for example, only `fit`, but no other method. No need to "
"implement `evaluate` when using centralized evaluation!"
msgstr ""
"Les méthodes `Client`/`NumPyClient` `get_properties`, `get_parameters`, "
"`fit`, et `evaluate` sont toutes optionnelles. Cela permet d'écrire des "
"clients qui n'implémentent, par exemple, que `fit`, mais aucune autre "
"méthode. Pas besoin d'implémenter `evaluate` quand on utilise "
"l'évaluation centralisée !"

#: ../../source/ref-changelog.md:435
msgid ""
"**Enable passing a** `Server` **instance to** `start_simulation` "
"([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""
"**Autoriser le passage d'une **instance `Server` à** `start_simulation` "
"([#1281](https://github.com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:437
msgid ""
"Similar to `start_server`, `start_simulation` now accepts a full `Server`"
" instance. This enables users to heavily customize the execution of "
"eperiments and opens the door to running, for example, async FL using the"
" Virtual Client Engine."
msgstr ""
"Comme pour `start_server`, `start_simulation` accepte maintenant une "
"instance complète de `Server`. Cela permet aux utilisateurs de "
"personnaliser fortement l'exécution des expériences et ouvre la porte à "
"l'exécution, par exemple, de FL asynchrones à l'aide du moteur de client "
"virtuel."

#: ../../source/ref-changelog.md:439
msgid ""
"**Update code examples** "
"([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), "
"[#1282](https://github.com/adap/flower/pull/1282))"
msgstr ""
"**Mettre à jour les exemples de code** "
"([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), "
"[#1282](https://github.com/adap/flower/pull/1282))"

#: ../../source/ref-changelog.md:441
msgid ""
"Many code examples received small or even large maintenance updates, "
"among them are"
msgstr ""
"De nombreux exemples de code ont reçu de petites ou même de grandes mises"
" à jour de maintenance"

#: ../../source/ref-changelog.md:443
msgid "`scikit-learn`"
msgstr "`scikit-learn`"

#: ../../source/ref-changelog.md:444
msgid "`simulation_pytorch`"
msgstr "`simulation_pytorch`"

#: ../../source/ref-changelog.md:445
msgid "`quickstart_pytorch`"
msgstr "`quickstart_pytorch` (démarrage rapide)"

#: ../../source/ref-changelog.md:446
msgid "`quickstart_simulation`"
msgstr "`quickstart_simulation`"

#: ../../source/ref-changelog.md:447
msgid "`quickstart_tensorflow`"
msgstr "`quickstart_tensorflow`"

#: ../../source/ref-changelog.md:448
msgid "`advanced_tensorflow`"
msgstr "`advanced_tensorflow` (en anglais)"

#: ../../source/ref-changelog.md:450
msgid ""
"**Remove the obsolete simulation example** "
"([#1328](https://github.com/adap/flower/pull/1328))"
msgstr ""
"**Supprime l'exemple de simulation obsolète** "
"([#1328](https://github.com/adap/flower/pull/1328))"

#: ../../source/ref-changelog.md:452
msgid ""
"Removes the obsolete `simulation` example and renames "
"`quickstart_simulation` to `simulation_tensorflow` so it fits withs the "
"naming of `simulation_pytorch`"
msgstr ""
"Supprime l'exemple obsolète `simulation` et renomme "
"`quickstart_simulation` en `simulation_tensorflow` pour qu'il corresponde"
" au nom de `simulation_pytorch`"

#: ../../source/ref-changelog.md:454
msgid ""
"**Update documentation** "
"([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"
msgstr ""
"**Mise à jour de la documentation** "
"([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"

#: ../../source/ref-changelog.md:456
msgid ""
"One substantial documentation update fixes multiple smaller rendering "
"issues, makes titles more succinct to improve navigation, removes a "
"deprecated library, updates documentation dependencies, includes the "
"`flwr.common` module in the API reference, includes support for markdown-"
"based documentation, migrates the changelog from `.rst` to `.md`, and "
"fixes a number of smaller details!"
msgstr ""
"Une mise à jour substantielle de la documentation corrige plusieurs "
"petits problèmes de rendu, rend les titres plus succincts pour améliorer "
"la navigation, supprime une bibliothèque obsolète, met à jour les "
"dépendances de la documentation, inclut le module `flwr.common` dans la "
"référence de l'API, inclut le support de la documentation basée sur le "
"markdown, migre le changelog de `.rst` vers `.md`, et corrige un certain "
"nombre de détails plus petits !"

#: ../../source/ref-changelog.md:458 ../../source/ref-changelog.md:513
#: ../../source/ref-changelog.md:582 ../../source/ref-changelog.md:621
msgid "**Minor updates**"
msgstr "**Mises à jour mineures**"

#: ../../source/ref-changelog.md:460
msgid ""
"Add round number to fit and evaluate log messages "
"([#1266](https://github.com/adap/flower/pull/1266))"
msgstr ""
"Ajoute un chiffre rond pour ajuster et évaluer les messages du journal "
"([#1266](https://github.com/adap/flower/pull/1266))"

#: ../../source/ref-changelog.md:461
msgid ""
"Add secure gRPC connection to the `advanced_tensorflow` code example "
"([#847](https://github.com/adap/flower/pull/847))"
msgstr ""
"Ajouter une connexion gRPC sécurisée à l'exemple de code "
"`advanced_tensorflow` ([#847](https://github.com/adap/flower/pull/847))"

#: ../../source/ref-changelog.md:462
msgid ""
"Update developer tooling "
"([#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310))"
msgstr ""
"Mettre à jour les outils de développement "
"([#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310))"

#: ../../source/ref-changelog.md:463
msgid ""
"Rename ProtoBuf messages to improve consistency "
"([#1214](https://github.com/adap/flower/pull/1214), "
"[#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"Renomme les messages ProtoBuf pour améliorer la cohérence "
"([#1214](https://github.com/adap/flower/pull/1214), "
"[#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"

#: ../../source/ref-changelog.md:465
msgid "v0.19.0 (2022-05-18)"
msgstr "v0.19.0 (2022-05-18)"

#: ../../source/ref-changelog.md:469
msgid ""
"**Flower Baselines (preview): FedOpt, FedBN, FedAvgM** "
"([#919](https://github.com/adap/flower/pull/919), "
"[#1127](https://github.com/adap/flower/pull/1127), "
"[#914](https://github.com/adap/flower/pull/914))"
msgstr ""
"**Flower Baselines (preview) : FedOpt, FedBN, FedAvgM** "
"([#919](https://github.com/adap/flower/pull/919), "
"[#1127](https://github.com/adap/flower/pull/1127), "
"[#914](https://github.com/adap/flower/pull/914))"

#: ../../source/ref-changelog.md:471
msgid ""
"The first preview release of Flower Baselines has arrived! We're "
"kickstarting Flower Baselines with implementations of FedOpt (FedYogi, "
"FedAdam, FedAdagrad), FedBN, and FedAvgM. Check the documentation on how "
"to use [Flower Baselines](https://flower.dev/docs/using-baselines.html). "
"With this first preview release we're also inviting the community to "
"[contribute their own baselines](https://flower.dev/docs/contributing-"
"baselines.html)."
msgstr ""
"La première version préliminaire de Flower Baselines est arrivée ! Nous "
"démarrons Flower Baselines avec des implémentations de FedOpt (FedYogi, "
"FedAdam, FedAdagrad), FedBN, et FedAvgM. Consultez la documentation sur "
"l'utilisation de [Flower Baselines](https://flower.dev/docs/using-"
"baselines.html). Avec cette première version préliminaire, nous invitons "
"également la communauté à [contribuer à leurs propres lignes de "
"base](https://flower.dev/docs/contributing-baselines.html)."

#: ../../source/ref-changelog.md:473
msgid ""
"**C++ client SDK (preview) and code example** "
"([#1111](https://github.com/adap/flower/pull/1111))"
msgstr ""
"**SDK client C++ (aperçu) et exemple de code** "
"([#1111](https://github.com/adap/flower/pull/1111))"

#: ../../source/ref-changelog.md:475
msgid ""
"Preview support for Flower clients written in C++. The C++ preview "
"includes a Flower client SDK and a quickstart code example that "
"demonstrates a simple C++ client using the SDK."
msgstr ""
"L'aperçu C++ comprend un SDK pour les clients Flower et un exemple de "
"code de démarrage rapide qui démontre un client C++ simple utilisant le "
"SDK."

#: ../../source/ref-changelog.md:477
msgid ""
"**Add experimental support for Python 3.10 and Python 3.11** "
"([#1135](https://github.com/adap/flower/pull/1135))"
msgstr ""
"**Ajouter la prise en charge expérimentale de Python 3.10 et Python "
"3.11** ([#1135](https://github.com/adap/flower/pull/1135))"

#: ../../source/ref-changelog.md:479
msgid ""
"Python 3.10 is the latest stable release of Python and Python 3.11 is due"
" to be released in October. This Flower release adds experimental support"
" for both Python versions."
msgstr ""
"Python 3.10 est la dernière version stable de Python et Python 3.11 "
"devrait sortir en octobre. Cette version de Flower ajoute une prise en "
"charge expérimentale pour les deux versions de Python."

#: ../../source/ref-changelog.md:481
msgid ""
"**Aggregate custom metrics through user-provided functions** "
"([#1144](https://github.com/adap/flower/pull/1144))"
msgstr ""
"**Agréger des mesures personnalisées grâce à des fonctions fournies par "
"l'utilisateur** ([#1144](https://github.com/adap/flower/pull/1144))"

#: ../../source/ref-changelog.md:483
msgid ""
"Custom metrics (e.g., `accuracy`) can now be aggregated without having to"
" customize the strategy. Built-in strategies support two new arguments, "
"`fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`, that "
"allow passing custom metric aggregation functions."
msgstr ""
"Les stratégies intégrées prennent en charge deux nouveaux arguments, "
"`fit_metrics_aggregation_fn` et `evaluate_metrics_aggregation_fn`, qui "
"permettent de passer des fonctions d'agrégation de métriques "
"personnalisées."

#: ../../source/ref-changelog.md:485
msgid ""
"**User-configurable round timeout** "
"([#1162](https://github.com/adap/flower/pull/1162))"
msgstr ""
"**Temps d'attente configurable par l'utilisateur** "
"([#1162](https://github.com/adap/flower/pull/1162))"

#: ../../source/ref-changelog.md:487
msgid ""
"A new configuration value allows the round timeout to be set for "
"`start_server` and `start_simulation`. If the `config` dictionary "
"contains a `round_timeout` key (with a `float` value in seconds), the "
"server will wait *at least* `round_timeout` seconds before it closes the "
"connection."
msgstr ""
"Si le dictionnaire `config` contient une clé `round_timeout` (avec une "
"valeur `float` en secondes), le serveur attendra *au moins* "
"`round_timeout` secondes avant de fermer la connexion."

#: ../../source/ref-changelog.md:489
msgid ""
"**Enable both federated evaluation and centralized evaluation to be used "
"at the same time in all built-in strategies** "
"([#1091](https://github.com/adap/flower/pull/1091))"
msgstr ""
"**Permettre l'utilisation simultanée de l'évaluation fédérée et de "
"l'évaluation centralisée dans toutes les stratégies intégrées** "
"([#1091](https://github.com/adap/flower/pull/1091))"

#: ../../source/ref-changelog.md:491
msgid ""
"Built-in strategies can now perform both federated evaluation (i.e., "
"client-side) and centralized evaluation (i.e., server-side) in the same "
"round. Federated evaluation can be disabled by setting `fraction_eval` to"
" `0.0`."
msgstr ""
"Les stratégies intégrées peuvent maintenant effectuer une évaluation "
"fédérée (c'est-à-dire côté client) et une évaluation centralisée "
"(c'est-à-dire côté serveur) dans le même tour. L'évaluation fédérée peut "
"être désactivée en réglant `fraction_eval` sur `0.0`."

#: ../../source/ref-changelog.md:493
msgid ""
"**Two new Jupyter Notebook tutorials** "
"([#1141](https://github.com/adap/flower/pull/1141))"
msgstr ""
"**Deux nouveaux tutoriels Jupyter Notebook** "
"([#1141](https://github.com/adap/flower/pull/1141))"

#: ../../source/ref-changelog.md:495
msgid ""
"Two Jupyter Notebook tutorials (compatible with Google Colab) explain "
"basic and intermediate Flower features:"
msgstr ""
"Deux tutoriels Jupyter Notebook (compatibles avec Google Colab) "
"expliquent les fonctionnalités de base et intermédiaires de Flower :"

#: ../../source/ref-changelog.md:497
msgid ""
"*An Introduction to Federated Learning*: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-1"
"-Intro-to-FL-PyTorch.ipynb)"
msgstr ""
"*Introduction à l'apprentissage fédéré* : [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-1"
"-Intro-to-FL-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:499
msgid ""
"*Using Strategies in Federated Learning*: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-2"
"-Strategies-in-FL-PyTorch.ipynb)"
msgstr ""
"*Utiliser des stratégies dans l'apprentissage fédéré* : [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-2"
"-Strategies-in-FL-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:501
msgid ""
"**New FedAvgM strategy (Federated Averaging with Server Momentum)** "
"([#1076](https://github.com/adap/flower/pull/1076))"
msgstr ""
"**Nouvelle stratégie FedAvgM (Federated Averaging with Server Momentum)**"
" ([#1076](https://github.com/adap/flower/pull/1076))"

#: ../../source/ref-changelog.md:503
#, fuzzy
msgid ""
"The new `FedAvgM` strategy implements Federated Averaging with Server "
"Momentum \\[Hsu et al., 2019\\]."
msgstr ""
"La nouvelle stratégie `FedAvgM` met en œuvre la moyenne fédérée avec le "
"momentum du serveur [Hsu et al., 2019]."

#: ../../source/ref-changelog.md:505
msgid ""
"**New advanced PyTorch code example** "
"([#1007](https://github.com/adap/flower/pull/1007))"
msgstr ""
"**Nouvel exemple de code PyTorch avancé** "
"([#1007](https://github.com/adap/flower/pull/1007))"

#: ../../source/ref-changelog.md:507
msgid ""
"A new code example (`advanced_pytorch`) demonstrates advanced Flower "
"concepts with PyTorch."
msgstr ""
"Un nouvel exemple de code (`advanced_pytorch`) démontre des concepts de "
"fleur avancés avec PyTorch."

#: ../../source/ref-changelog.md:509
msgid ""
"**New JAX code example** "
"([#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143))"
msgstr ""
"**Nouvel exemple de code JAX** "
"([#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143))"

#: ../../source/ref-changelog.md:511
msgid ""
"A new code example (`jax_from_centralized_to_federated`) shows federated "
"learning with JAX and Flower."
msgstr ""
"Un nouvel exemple de code (`jax_from_centralized_to_federated`) montre "
"l'apprentissage fédéré avec JAX et Flower."

#: ../../source/ref-changelog.md:515
msgid ""
"New option to keep Ray running if Ray was already initialized in "
"`start_simulation` ([#1177](https://github.com/adap/flower/pull/1177))"
msgstr ""
"Nouvelle option pour continuer à faire fonctionner Ray si Ray a déjà été "
"initialisé dans `start_simulation` "
"([#1177](https://github.com/adap/flower/pull/1177))"

#: ../../source/ref-changelog.md:516
msgid ""
"Add support for custom `ClientManager` as a `start_simulation` parameter "
"([#1171](https://github.com/adap/flower/pull/1171))"
msgstr ""
"Ajout de la prise en charge d'un `ClientManager` personnalisé comme "
"paramètre de `start_simulation` "
"([#1171](https://github.com/adap/flower/pull/1171))"

#: ../../source/ref-changelog.md:517
msgid ""
"New documentation for [implementing strategies](https://flower.dev/docs"
"/how-to-implement-strategies.html) "
"([#1097](https://github.com/adap/flower/pull/1097), "
"[#1175](https://github.com/adap/flower/pull/1175))"
msgstr ""
"Nouvelle documentation pour [mettre en œuvre des "
"stratégies](https://flower.dev/docs/framework/how-to-implement-strategies.html) "
"([#1097](https://github.com/adap/flower/pull/1097), "
"[#1175](https://github.com/adap/flower/pull/1175))"

#: ../../source/ref-changelog.md:518
msgid ""
"New mobile-friendly documentation theme "
"([#1174](https://github.com/adap/flower/pull/1174))"
msgstr ""
"Nouveau thème de documentation adapté aux mobiles "
"([#1174](https://github.com/adap/flower/pull/1174))"

#: ../../source/ref-changelog.md:519
msgid ""
"Limit version range for (optional) `ray` dependency to include only "
"compatible releases (`>=1.9.2,<1.12.0`) "
"([#1205](https://github.com/adap/flower/pull/1205))"
msgstr ""
"Limite la plage de versions pour la dépendance (optionnelle) `ray` pour "
"n'inclure que les versions compatibles (`>=1.9.2,<1.12.0`) "
"([#1205](https://github.com/adap/flower/pull/1205))"

#: ../../source/ref-changelog.md:523
msgid ""
"**Remove deprecated support for Python 3.6** "
"([#871](https://github.com/adap/flower/pull/871))"
msgstr ""
"**Supprime la prise en charge obsolète de Python 3.6** "
"([#871](https://github.com/adap/flower/pull/871))"

#: ../../source/ref-changelog.md:524
msgid ""
"**Remove deprecated KerasClient** "
"([#857](https://github.com/adap/flower/pull/857))"
msgstr ""
"**Supprimez KerasClient** "
"([#857](https://github.com/adap/flower/pull/857))"

#: ../../source/ref-changelog.md:525
msgid ""
"**Remove deprecated no-op extra installs** "
"([#973](https://github.com/adap/flower/pull/973))"
msgstr ""
"**Supprimer les installations supplémentaires no-op dépréciées** "
"([#973](https://github.com/adap/flower/pull/973))"

#: ../../source/ref-changelog.md:526
msgid ""
"**Remove deprecated proto fields from** `FitRes` **and** `EvaluateRes` "
"([#869](https://github.com/adap/flower/pull/869))"
msgstr ""
"**Supprimez les champs proto obsolètes de** `FitRes` **et** `EvaluateRes`"
" ([#869](https://github.com/adap/flower/pull/869))"

#: ../../source/ref-changelog.md:527
msgid ""
"**Remove deprecated QffedAvg strategy (replaced by QFedAvg)** "
"([#1107](https://github.com/adap/flower/pull/1107))"
msgstr ""
"**Supprime la stratégie QffedAvg (remplacée par QFedAvg)** "
"([#1107](https://github.com/adap/flower/pull/1107))"

#: ../../source/ref-changelog.md:528
msgid ""
"**Remove deprecated DefaultStrategy strategy** "
"([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**Supprime la stratégie DefaultStrategy qui est obsolète** "
"([#1142](https://github.com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:529
msgid ""
"**Remove deprecated support for eval_fn accuracy return value** "
"([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**Supprimer la prise en charge obsolète de la valeur de retour de la "
"précision eval_fn** ([#1142](https://github.com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:530
msgid ""
"**Remove deprecated support for passing initial parameters as NumPy "
"ndarrays** ([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**Supprime la prise en charge obsolète du passage des paramètres initiaux"
" en tant que ndarrays NumPy** "
"([#1142](https://github.com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:532
msgid "v0.18.0 (2022-02-28)"
msgstr "v0.18.0 (2022-02-28)"

#: ../../source/ref-changelog.md:536
msgid ""
"**Improved Virtual Client Engine compatibility with Jupyter Notebook / "
"Google Colab** ([#866](https://github.com/adap/flower/pull/866), "
"[#872](https://github.com/adap/flower/pull/872), "
"[#833](https://github.com/adap/flower/pull/833), "
"[#1036](https://github.com/adap/flower/pull/1036))"
msgstr ""
"**Amélioration de la compatibilité du moteur de client virtuel avec "
"Jupyter Notebook / Google Colab** "
"([#866](https://github.com/adap/flower/pull/866), "
"[#872](https://github.com/adap/flower/pull/872), "
"[#833](https://github.com/adap/flower/pull/833), "
"[#1036](https://github.com/adap/flower/pull/1036))"

#: ../../source/ref-changelog.md:538
msgid ""
"Simulations (using the Virtual Client Engine through `start_simulation`) "
"now work more smoothly on Jupyter Notebooks (incl. Google Colab) after "
"installing Flower with the `simulation` extra (`pip install "
"flwr[simulation]`)."
msgstr ""
"Les simulations (utilisant le moteur de client virtuel via "
"`start_simulation`) fonctionnent maintenant plus facilement sur les "
"Notebooks Jupyter (y compris Google Colab) après avoir installé Flower "
"avec l'option `simulation` (`pip install flwr[simulation]`)."

#: ../../source/ref-changelog.md:540
msgid ""
"**New Jupyter Notebook code example** "
"([#833](https://github.com/adap/flower/pull/833))"
msgstr ""
"**Nouvel exemple de code Jupyter Notebook** "
"([#833](https://github.com/adap/flower/pull/833))"

#: ../../source/ref-changelog.md:542
msgid ""
"A new code example (`quickstart_simulation`) demonstrates Flower "
"simulations using the Virtual Client Engine through Jupyter Notebook "
"(incl. Google Colab)."
msgstr ""
"Un nouvel exemple de code (`quickstart_simulation`) démontre des "
"simulations de Flower en utilisant le moteur de client virtuel via "
"Jupyter Notebook (y compris Google Colab)."

#: ../../source/ref-changelog.md:544
msgid ""
"**Client properties (feature preview)** "
"([#795](https://github.com/adap/flower/pull/795))"
msgstr ""
"**Propriétés du client (aperçu des fonctionnalités)** "
"([#795](https://github.com/adap/flower/pull/795))"

#: ../../source/ref-changelog.md:546
msgid ""
"Clients can implement a new method `get_properties` to enable server-side"
" strategies to query client properties."
msgstr ""
"Les clients peuvent implémenter une nouvelle méthode `get_properties` "
"pour permettre aux stratégies côté serveur d'interroger les propriétés du"
" client."

#: ../../source/ref-changelog.md:548
msgid ""
"**Experimental Android support with TFLite** "
"([#865](https://github.com/adap/flower/pull/865))"
msgstr ""
"**Support expérimental d'Android avec TFLite** "
"([#865](https://github.com/adap/flower/pull/865))"

#: ../../source/ref-changelog.md:550
msgid ""
"Android support has finally arrived in `main`! Flower is both client-"
"agnostic and framework-agnostic by design. One can integrate arbitrary "
"client platforms and with this release, using Flower on Android has "
"become a lot easier."
msgstr ""
"La prise en charge d'Android est enfin arrivée dans `main` ! Flower est à"
" la fois agnostique au niveau du client et du cadre de travail. On peut "
"intégrer des plates-formes client arbitraires et avec cette version, "
"l'utilisation de Flower sur Android est devenue beaucoup plus facile."

#: ../../source/ref-changelog.md:552
msgid ""
"The example uses TFLite on the client side, along with a new "
"`FedAvgAndroid` strategy. The Android client and `FedAvgAndroid` are "
"still experimental, but they are a first step towards a fully-fledged "
"Android SDK and a unified `FedAvg` implementation that integrated the new"
" functionality from `FedAvgAndroid`."
msgstr ""
"L'exemple utilise TFLite du côté client, ainsi qu'une nouvelle stratégie "
"`FedAvgAndroid`. Le client Android et `FedAvgAndroid` sont encore "
"expérimentaux, mais ils constituent un premier pas vers un SDK Android à "
"part entière et une implémentation unifiée de `FedAvg` intégrant la "
"nouvelle fonctionnalité de `FedAvgAndroid`."

#: ../../source/ref-changelog.md:554
msgid ""
"**Make gRPC keepalive time user-configurable and decrease default "
"keepalive time** ([#1069](https://github.com/adap/flower/pull/1069))"
msgstr ""
"**Rendre le temps de garde gRPC configurable par l'utilisateur et "
"diminuer le temps de garde par défaut** "
"([#1069](https://github.com/adap/flower/pull/1069))"

#: ../../source/ref-changelog.md:556
msgid ""
"The default gRPC keepalive time has been reduced to increase the "
"compatibility of Flower with more cloud environments (for example, "
"Microsoft Azure). Users can configure the keepalive time to customize the"
" gRPC stack based on specific requirements."
msgstr ""
"Le temps de keepalive gRPC par défaut a été réduit pour augmenter la "
"compatibilité de Flower avec davantage d'environnements cloud (par "
"exemple, Microsoft Azure). Les utilisateurs peuvent configurer le temps "
"de keepalive pour personnaliser la pile gRPC en fonction d'exigences "
"spécifiques."

#: ../../source/ref-changelog.md:558
msgid ""
"**New differential privacy example using Opacus and PyTorch** "
"([#805](https://github.com/adap/flower/pull/805))"
msgstr ""
"**Nouvel exemple de confidentialité différentielle utilisant Opacus et "
"PyTorch** ([#805](https://github.com/adap/flower/pull/805))"

#: ../../source/ref-changelog.md:560
msgid ""
"A new code example (`opacus`) demonstrates differentially-private "
"federated learning with Opacus, PyTorch, and Flower."
msgstr ""
"Un nouvel exemple de code (`opacus`) démontre l'apprentissage fédéré "
"différentiellement privé avec Opacus, PyTorch et Flower."

#: ../../source/ref-changelog.md:562
msgid ""
"**New Hugging Face Transformers code example** "
"([#863](https://github.com/adap/flower/pull/863))"
msgstr ""
"**Nouvel exemple de code pour les Transformers à visage embrassant** "
"([#863](https://github.com/adap/flower/pull/863))"

#: ../../source/ref-changelog.md:564
msgid ""
"A new code example (`quickstart_huggingface`) demonstrates usage of "
"Hugging Face Transformers with Flower."
msgstr ""
"Un nouvel exemple de code (`quickstart_huggingface`) démontre "
"l'utilisation des transformateurs Hugging Face avec Flower."

#: ../../source/ref-changelog.md:566
msgid ""
"**New MLCube code example** "
"([#779](https://github.com/adap/flower/pull/779), "
"[#1034](https://github.com/adap/flower/pull/1034), "
"[#1065](https://github.com/adap/flower/pull/1065), "
"[#1090](https://github.com/adap/flower/pull/1090))"
msgstr ""
"**Nouvel exemple de code MLCube** "
"([#779](https://github.com/adap/flower/pull/779), "
"[#1034](https://github.com/adap/flower/pull/1034), "
"[#1065](https://github.com/adap/flower/pull/1065), "
"[#1090](https://github.com/adap/flower/pull/1090))"

#: ../../source/ref-changelog.md:568
msgid ""
"A new code example (`quickstart_mlcube`) demonstrates usage of MLCube "
"with Flower."
msgstr ""
"Un nouvel exemple de code (`quickstart_mlcube`) démontre l'utilisation de"
" MLCube avec Flower."

#: ../../source/ref-changelog.md:570
msgid ""
"**SSL-enabled server and client** "
"([#842](https://github.com/adap/flower/pull/842),  "
"[#844](https://github.com/adap/flower/pull/844),  "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"
msgstr ""
"**([#842](https://github.com/adap/flower/pull/842), "
"[#844](https://github.com/adap/flower/pull/844), "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"

#: ../../source/ref-changelog.md:572
msgid ""
"SSL enables secure encrypted connections between clients and servers. "
"This release open-sources the Flower secure gRPC implementation to make "
"encrypted communication channels accessible to all Flower users."
msgstr ""
"SSL permet d'établir des connexions cryptées et sécurisées entre les "
"clients et les serveurs. Cette version met en open-source "
"l'implémentation gRPC sécurisée de Flower afin de rendre les canaux de "
"communication cryptés accessibles à tous les utilisateurs de Flower."

#: ../../source/ref-changelog.md:574
msgid ""
"**Updated** `FedAdam` **and** `FedYogi` **strategies** "
"([#885](https://github.com/adap/flower/pull/885), "
"[#895](https://github.com/adap/flower/pull/895))"
msgstr ""
"**Mise à jour** `FedAdam` **et** `FedYogi` **stratégies** "
"([#885](https://github.com/adap/flower/pull/885), "
"[#895](https://github.com/adap/flower/pull/895))"

#: ../../source/ref-changelog.md:576
msgid ""
"`FedAdam` and `FedAdam` match the latest version of the Adaptive "
"Federated Optimization paper."
msgstr ""
"`FedAdam` et `FedAdam` correspondent à la dernière version de l'article "
"sur l'optimisation fédérée adaptative."

#: ../../source/ref-changelog.md:578
msgid ""
"**Initialize** `start_simulation` **with a list of client IDs** "
"([#860](https://github.com/adap/flower/pull/860))"
msgstr ""
"**Initialise** `start_simulation` **avec une liste d'ID de clients** "
"([#860](https://github.com/adap/flower/pull/860))"

#: ../../source/ref-changelog.md:580
msgid ""
"`start_simulation` can now be called with a list of client IDs "
"(`clients_ids`, type: `List[str]`). Those IDs will be passed to the "
"`client_fn` whenever a client needs to be initialized, which can make it "
"easier to load data partitions that are not accessible through `int` "
"identifiers."
msgstr ""
"`start_simulation` peut maintenant être appelé avec une liste "
"d'identifiants de clients (`clients_ids`, type : `List[str]`). Ces "
"identifiants seront passés à `client_fn` chaque fois qu'un client doit "
"être initialisé, ce qui peut faciliter le chargement de partitions de "
"données qui ne sont pas accessibles par des identifiants `int`."

#: ../../source/ref-changelog.md:584
msgid ""
"Update `num_examples` calculation in PyTorch code examples in "
"([#909](https://github.com/adap/flower/pull/909))"
msgstr ""
"Mettre à jour le calcul de `num_examples` dans les exemples de code "
"PyTorch dans ([#909](https://github.com/adap/flower/pull/909))"

#: ../../source/ref-changelog.md:585
msgid ""
"Expose Flower version through `flwr.__version__` "
"([#952](https://github.com/adap/flower/pull/952))"
msgstr ""
"Exposer la version de Flower à travers `flwr.__version__` "
"([#952](https://github.com/adap/flower/pull/952))"

#: ../../source/ref-changelog.md:586
msgid ""
"`start_server` in `app.py` now returns a `History` object containing "
"metrics from training ([#974](https://github.com/adap/flower/pull/974))"
msgstr ""
"`start_server` dans `app.py` renvoie maintenant un objet `History` "
"contenant les métriques de l'entraînement "
"([#974](https://github.com/adap/flower/pull/974))"

#: ../../source/ref-changelog.md:587
msgid ""
"Make `max_workers` (used by `ThreadPoolExecutor`) configurable "
"([#978](https://github.com/adap/flower/pull/978))"
msgstr ""
"Rendre `max_workers` (utilisé par `ThreadPoolExecutor`) configurable "
"([#978](https://github.com/adap/flower/pull/978))"

#: ../../source/ref-changelog.md:588
msgid ""
"Increase sleep time after server start to three seconds in all code "
"examples ([#1086](https://github.com/adap/flower/pull/1086))"
msgstr ""
"Augmente le temps de sommeil après le démarrage du serveur à trois "
"secondes dans tous les exemples de code "
"([#1086](https://github.com/adap/flower/pull/1086))"

#: ../../source/ref-changelog.md:589
msgid ""
"Added a new FAQ section to the documentation "
"([#948](https://github.com/adap/flower/pull/948))"
msgstr ""
"Ajout d'une nouvelle section FAQ à la documentation "
"([#948](https://github.com/adap/flower/pull/948))"

#: ../../source/ref-changelog.md:590
msgid ""
"And many more under-the-hood changes, library updates, documentation "
"changes, and tooling improvements!"
msgstr ""
"Et bien d'autres changements sous le capot, des mises à jour de la "
"bibliothèque, des modifications de la documentation et des améliorations "
"de l'outillage !"

#: ../../source/ref-changelog.md:594
msgid ""
"**Removed** `flwr_example` **and** `flwr_experimental` **from release "
"build** ([#869](https://github.com/adap/flower/pull/869))"
msgstr ""
"**Supprimé** `flwr_example` **et** `flwr_experimental` **de la version "
"release build** ([#869](https://github.com/adap/flower/pull/869))"

#: ../../source/ref-changelog.md:596
msgid ""
"The packages `flwr_example` and `flwr_experimental` have been deprecated "
"since Flower 0.12.0 and they are not longer included in Flower release "
"builds. The associated extras (`baseline`, `examples-pytorch`, `examples-"
"tensorflow`, `http-logger`, `ops`) are now no-op and will be removed in "
"an upcoming release."
msgstr ""
"Les paquets `flwr_example` et `flwr_experimental` ont été dépréciés "
"depuis Flower 0.12.0 et ils ne sont plus inclus dans les builds de "
"Flower. Les extras associés (`baseline`, `examples-pytorch`, `examples-"
"tensorflow`, `http-logger`, `ops`) sont maintenant no-op et seront "
"supprimés dans une prochaine version."

#: ../../source/ref-changelog.md:598
msgid "v0.17.0 (2021-09-24)"
msgstr "v0.17.0 (2021-09-24)"

#: ../../source/ref-changelog.md:602
msgid ""
"**Experimental virtual client engine** "
"([#781](https://github.com/adap/flower/pull/781) "
"[#790](https://github.com/adap/flower/pull/790) "
"[#791](https://github.com/adap/flower/pull/791))"
msgstr ""
"**Moteur expérimental de client virtuel** "
"([#781](https://github.com/adap/flower/pull/781) "
"[#790](https://github.com/adap/flower/pull/790) "
"[#791](https://github.com/adap/flower/pull/791))"

#: ../../source/ref-changelog.md:604
msgid ""
"One of Flower's goals is to enable research at scale. This release "
"enables a first (experimental) peek at a major new feature, codenamed the"
" virtual client engine. Virtual clients enable simulations that scale to "
"a (very) large number of clients on a single machine or compute cluster. "
"The easiest way to test the new functionality is to look at the two new "
"code examples called `quickstart_simulation` and `simulation_pytorch`."
msgstr ""
"L'un des objectifs de Flower est de permettre la recherche à grande "
"échelle. Cette version donne un premier aperçu (expérimental) d'une "
"nouvelle fonctionnalité majeure, connue sous le nom de code de moteur de "
"client virtuel. Les clients virtuels permettent des simulations qui "
"s'étendent à un (très) grand nombre de clients sur une seule machine ou "
"une grappe de calcul. La façon la plus simple de tester la nouvelle "
"fonctionnalité est de regarder les deux nouveaux exemples de code appelés"
" `quickstart_simulation` et `simulation_pytorch`."

#: ../../source/ref-changelog.md:606
msgid ""
"The feature is still experimental, so there's no stability guarantee for "
"the API. It's also not quite ready for prime time and comes with a few "
"known caveats. However, those who are curious are encouraged to try it "
"out and share their thoughts."
msgstr ""
"La fonction est encore expérimentale, il n'y a donc aucune garantie de "
"stabilité pour l'API. Elle n'est pas non plus tout à fait prête pour le "
"prime time et s'accompagne de quelques mises en garde connues. Cependant,"
" les personnes curieuses sont encouragées à l'essayer et à faire part de "
"leurs réflexions."

#: ../../source/ref-changelog.md:608
msgid ""
"**New built-in strategies** "
"([#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822))"
msgstr ""
"**Nouvelles stratégies intégrées** "
"([#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822))"

#: ../../source/ref-changelog.md:610
msgid ""
"FedYogi - Federated learning strategy using Yogi on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr ""
"FedYogi - Stratégie d'apprentissage fédéré utilisant Yogi côté serveur. "
"Mise en oeuvre basée sur https://arxiv.org/abs/2003.00295"

#: ../../source/ref-changelog.md:611
msgid ""
"FedAdam - Federated learning strategy using Adam on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr ""
"FedAdam - Stratégie d'apprentissage fédéré utilisant Adam côté serveur. "
"Mise en œuvre basée sur https://arxiv.org/abs/2003.00295"

#: ../../source/ref-changelog.md:613
msgid ""
"**New PyTorch Lightning code example** "
"([#617](https://github.com/adap/flower/pull/617))"
msgstr ""
"**Nouvel exemple de code PyTorch Lightning** "
"([#617](https://github.com/adap/flower/pull/617))"

#: ../../source/ref-changelog.md:615
msgid ""
"**New Variational Auto-Encoder code example** "
"([#752](https://github.com/adap/flower/pull/752))"
msgstr ""
"**Nouvel exemple de code d'autocodage variationnel** "
"([#752](https://github.com/adap/flower/pull/752))"

#: ../../source/ref-changelog.md:617
msgid ""
"**New scikit-learn code example** "
"([#748](https://github.com/adap/flower/pull/748))"
msgstr ""
"**Nouvel exemple de code scikit-learn** "
"([#748](https://github.com/adap/flower/pull/748))"

#: ../../source/ref-changelog.md:619
msgid ""
"**New experimental TensorBoard strategy** "
"([#789](https://github.com/adap/flower/pull/789))"
msgstr ""
"**Nouvelle stratégie expérimentale TensorBoard** "
"([#789](https://github.com/adap/flower/pull/789))"

#: ../../source/ref-changelog.md:623
msgid ""
"Improved advanced TensorFlow code example "
"([#769](https://github.com/adap/flower/pull/769))"
msgstr ""
"Amélioration de l'exemple de code TensorFlow avancé "
"([#769](https://github.com/adap/flower/pull/769))"

#: ../../source/ref-changelog.md:624
msgid ""
"Warning when `min_available_clients` is misconfigured "
"([#830](https://github.com/adap/flower/pull/830))"
msgstr ""
"Avertissement lorsque `min_available_clients` est mal configuré "
"([#830](https://github.com/adap/flower/pull/830))"

#: ../../source/ref-changelog.md:625
msgid ""
"Improved gRPC server docs "
"([#841](https://github.com/adap/flower/pull/841))"
msgstr ""
"Amélioration de la documentation sur le serveur gRPC "
"([#841](https://github.com/adap/flower/pull/841))"

#: ../../source/ref-changelog.md:626
msgid ""
"Improved error message in `NumPyClient` "
"([#851](https://github.com/adap/flower/pull/851))"
msgstr ""
"Amélioration du message d'erreur dans `NumPyClient` "
"([#851](https://github.com/adap/flower/pull/851))"

#: ../../source/ref-changelog.md:627
msgid ""
"Improved PyTorch quickstart code example "
"([#852](https://github.com/adap/flower/pull/852))"
msgstr ""
"Exemple de code de démarrage rapide PyTorch amélioré "
"([#852](https://github.com/adap/flower/pull/852))"

#: ../../source/ref-changelog.md:631
msgid ""
"**Disabled final distributed evaluation** "
"([#800](https://github.com/adap/flower/pull/800))"
msgstr ""
"**Désactivé l'évaluation finale distribuée** "
"([#800](https://github.com/adap/flower/pull/800))"

#: ../../source/ref-changelog.md:633
msgid ""
"Prior behaviour was to perform a final round of distributed evaluation on"
" all connected clients, which is often not required (e.g., when using "
"server-side evaluation). The prior behaviour can be enabled by passing "
"`force_final_distributed_eval=True` to `start_server`."
msgstr ""
"Le comportement précédent consistait à effectuer un dernier tour "
"d'évaluation distribuée sur tous les clients connectés, ce qui n'est "
"souvent pas nécessaire (par exemple, lors de l'utilisation de "
"l'évaluation côté serveur). Le comportement précédent peut être activé en"
" passant `force_final_distributed_eval=True` à `start_server`."

#: ../../source/ref-changelog.md:635
msgid ""
"**Renamed q-FedAvg strategy** "
"([#802](https://github.com/adap/flower/pull/802))"
msgstr ""
"**Renommé stratégie q-FedAvg** "
"([#802](https://github.com/adap/flower/pull/802))"

#: ../../source/ref-changelog.md:637
msgid ""
"The strategy named `QffedAvg` was renamed to `QFedAvg` to better reflect "
"the notation given in the original paper (q-FFL is the optimization "
"objective, q-FedAvg is the proposed solver). Note the the original (now "
"deprecated) `QffedAvg` class is still available for compatibility reasons"
" (it will be removed in a future release)."
msgstr ""
"La stratégie nommée `QffedAvg` a été renommée en `QFedAvg` pour mieux "
"refléter la notation donnée dans l'article original (q-FFL est l'objectif"
" d'optimisation, q-FedAvg est le solveur proposé). Notez que la classe "
"`QffedAvg` originale (maintenant obsolète) est toujours disponible pour "
"des raisons de compatibilité (elle sera supprimée dans une prochaine "
"version)."

#: ../../source/ref-changelog.md:639
msgid ""
"**Deprecated and renamed code example** `simulation_pytorch` **to** "
"`simulation_pytorch_legacy` "
"([#791](https://github.com/adap/flower/pull/791))"
msgstr ""
"**Exemple de code déprécié et renommé** `simulation_pytorch` **en** "
"`simulation_pytorch_legacy` "
"([#791](https://github.com/adap/flower/pull/791))"

#: ../../source/ref-changelog.md:641
msgid ""
"This example has been replaced by a new example. The new example is based"
" on the experimental virtual client engine, which will become the new "
"default way of doing most types of large-scale simulations in Flower. The"
" existing example was kept for reference purposes, but it might be "
"removed in the future."
msgstr ""
"Cet exemple a été remplacé par un nouvel exemple. Le nouvel exemple est "
"basé sur le moteur expérimental du client virtuel, qui deviendra la "
"nouvelle méthode par défaut pour effectuer la plupart des types de "
"simulations à grande échelle dans Flower. L'exemple existant a été "
"conservé à des fins de référence, mais il pourrait être supprimé à "
"l'avenir."

#: ../../source/ref-changelog.md:643
msgid "v0.16.0 (2021-05-11)"
msgstr "v0.16.0 (2021-05-11)"

#: ../../source/ref-changelog.md:647
msgid ""
"**New built-in strategies** "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr ""
"**Nouvelles stratégies intégrées** "
"([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:649
msgid "(abstract) FedOpt"
msgstr "(résumé) FedOpt"

#: ../../source/ref-changelog.md:650
msgid "FedAdagrad"
msgstr "FedAdagrad"

#: ../../source/ref-changelog.md:652
msgid ""
"**Custom metrics for server and strategies** "
"([#717](https://github.com/adap/flower/pull/717))"
msgstr ""
"**Métriques personnalisées pour le serveur et les stratégies** "
"([#717](https://github.com/adap/flower/pull/717))"

#: ../../source/ref-changelog.md:654
msgid ""
"The Flower server is now fully task-agnostic, all remaining instances of "
"task-specific metrics (such as `accuracy`) have been replaced by custom "
"metrics dictionaries. Flower 0.15 introduced the capability to pass a "
"dictionary containing custom metrics from client to server. As of this "
"release, custom metrics replace task-specific metrics on the server."
msgstr ""
"Le serveur Flower est maintenant totalement agnostique, toutes les "
"instances restantes de métriques spécifiques à une tâche (telles que "
"`accuracy`) ont été remplacées par des dictionnaires de métriques "
"personnalisées. Flower 0.15 a introduit la possibilité de passer un "
"dictionnaire contenant des métriques personnalisées du client au serveur."
" À partir de cette version, les métriques personnalisées remplacent les "
"métriques spécifiques à une tâche sur le serveur."

#: ../../source/ref-changelog.md:656
msgid ""
"Custom metric dictionaries are now used in two user-facing APIs: they are"
" returned from Strategy methods `aggregate_fit`/`aggregate_evaluate` and "
"they enable evaluation functions passed to build-in strategies (via "
"`eval_fn`) to return more than two evaluation metrics. Strategies can "
"even return *aggregated* metrics dictionaries for the server to keep "
"track of."
msgstr ""
"Les dictionnaires de métriques personnalisés sont maintenant utilisés "
"dans deux API orientées vers l'utilisateur : ils sont renvoyés par les "
"méthodes de stratégie `aggregate_fit`/`aggregate_evaluate` et ils "
"permettent aux fonctions d'évaluation passées aux stratégies intégrées "
"(via `eval_fn`) de renvoyer plus de deux métriques d'évaluation. Les "
"stratégies peuvent même renvoyer des dictionnaires de métriques "
"*agrégées* pour que le serveur puisse en garder la trace."

#: ../../source/ref-changelog.md:658
msgid ""
"Stratey implementations should migrate their `aggregate_fit` and "
"`aggregate_evaluate` methods to the new return type (e.g., by simply "
"returning an empty `{}`), server-side evaluation functions should migrate"
" from `return loss, accuracy` to `return loss, {\"accuracy\": accuracy}`."
msgstr ""
"Les implémentations de Stratey doivent migrer leurs méthodes "
"`aggregate_fit` et `aggregate_evaluate` vers le nouveau type de retour "
"(par exemple, en renvoyant simplement un `{}` vide), les fonctions "
"d'évaluation côté serveur doivent migrer de `return loss, accuracy` à "
"`return loss, {\"accuracy\" : accuracy}`."

#: ../../source/ref-changelog.md:660
msgid ""
"Flower 0.15-style return types are deprecated (but still supported), "
"compatibility will be removed in a future release."
msgstr ""
"Les types de retour du style Flower 0.15 sont dépréciés (mais toujours "
"pris en charge), la compatibilité sera supprimée dans une prochaine "
"version."

#: ../../source/ref-changelog.md:662
msgid ""
"**Migration warnings for deprecated functionality** "
"([#690](https://github.com/adap/flower/pull/690))"
msgstr ""
"**Avertissements de migration pour les fonctionnalités obsolètes** "
"([#690](https://github.com/adap/flower/pull/690))"

#: ../../source/ref-changelog.md:664
msgid ""
"Earlier versions of Flower were often migrated to new APIs, while "
"maintaining compatibility with legacy APIs. This release introduces "
"detailed warning messages if usage of deprecated APIs is detected. The "
"new warning messages often provide details on how to migrate to more "
"recent APIs, thus easing the transition from one release to another."
msgstr ""
"Les versions antérieures de Flower ont souvent été migrées vers de "
"nouvelles API, tout en maintenant la compatibilité avec les anciennes "
"API. Cette version introduit des messages d'avertissement détaillés si "
"l'utilisation d'API obsolètes est détectée. Les nouveaux messages "
"d'avertissement fournissent souvent des détails sur la façon de migrer "
"vers des API plus récentes, facilitant ainsi la transition d'une version "
"à l'autre."

#: ../../source/ref-changelog.md:666
msgid ""
"Improved docs and docstrings "
"([#691](https://github.com/adap/flower/pull/691) "
"[#692](https://github.com/adap/flower/pull/692) "
"[#713](https://github.com/adap/flower/pull/713))"
msgstr ""
"Amélioration des docs et des docstrings "
"([#691](https://github.com/adap/flower/pull/691) "
"[#692](https://github.com/adap/flower/pull/692) "
"[#713](https://github.com/adap/flower/pull/713))"

#: ../../source/ref-changelog.md:668
msgid "MXNet example and documentation"
msgstr "Exemple et documentation MXNet"

#: ../../source/ref-changelog.md:670
msgid ""
"FedBN implementation in example PyTorch: From Centralized To Federated "
"([#696](https://github.com/adap/flower/pull/696) "
"[#702](https://github.com/adap/flower/pull/702) "
"[#705](https://github.com/adap/flower/pull/705))"
msgstr ""
"Mise en œuvre de FedBN dans l'exemple PyTorch : De la centralisation à la"
" fédération ([#696](https://github.com/adap/flower/pull/696) "
"[#702](https://github.com/adap/flower/pull/702) "
"[#705](https://github.com/adap/flower/pull/705))"

#: ../../source/ref-changelog.md:674
msgid ""
"**Serialization-agnostic server** "
"([#721](https://github.com/adap/flower/pull/721))"
msgstr ""
"**Serveur agnostique de sérialisation** "
"([#721](https://github.com/adap/flower/pull/721))"

#: ../../source/ref-changelog.md:676
msgid ""
"The Flower server is now fully serialization-agnostic. Prior usage of "
"class `Weights` (which represents parameters as deserialized NumPy "
"ndarrays) was replaced by class `Parameters` (e.g., in `Strategy`). "
"`Parameters` objects are fully serialization-agnostic and represents "
"parameters as byte arrays, the `tensor_type` attributes indicates how "
"these byte arrays should be interpreted (e.g., for "
"serialization/deserialization)."
msgstr ""
"Le serveur Flower est désormais totalement agnostique en matière de "
"sérialisation. L'utilisation antérieure de la classe `Weights` (qui "
"représente les paramètres sous forme de tableaux NumPy désérialisés) a "
"été remplacée par la classe `Parameters` (par exemple, dans `Strategy`). "
"Les objets `Parameters` sont totalement agnostiques en matière de "
"sérialisation et représentent les paramètres sous forme de tableaux "
"d'octets, les attributs `tensor_type` indiquent comment ces tableaux "
"d'octets doivent être interprétés (par exemple, pour la "
"sérialisation/désérialisation)."

#: ../../source/ref-changelog.md:678
msgid ""
"Built-in strategies implement this approach by handling serialization and"
" deserialization to/from `Weights` internally. Custom/3rd-party Strategy "
"implementations should update to the slighly changed Strategy method "
"definitions. Strategy authors can consult PR "
"[#721](https://github.com/adap/flower/pull/721) to see how strategies can"
" easily migrate to the new format."
msgstr ""
"Les stratégies intégrées mettent en œuvre cette approche en gérant en "
"interne la sérialisation et la désérialisation de `Weights`. Les "
"implémentations de stratégies personnalisées ou tierces doivent être "
"mises à jour avec les définitions de méthodes de stratégie légèrement "
"modifiées. Les auteurs de stratégies peuvent consulter le PR "
"[#721](https://github.com/adap/flower/pull/721) pour voir comment les "
"stratégies peuvent facilement migrer vers le nouveau format."

#: ../../source/ref-changelog.md:680
msgid ""
"Deprecated `flwr.server.Server.evaluate`, use "
"`flwr.server.Server.evaluate_round` instead "
"([#717](https://github.com/adap/flower/pull/717))"
msgstr ""
"Déclassé `flwr.server.Server.evaluate`, utiliser "
"`flwr.server.Server.evaluate_round` à la place "
"([#717](https://github.com/adap/flower/pull/717))"

#: ../../source/ref-changelog.md:682
msgid "v0.15.0 (2021-03-12)"
msgstr "v0.15.0 (2021-03-12)"

#: ../../source/ref-changelog.md:686
msgid ""
"**Server-side parameter initialization** "
"([#658](https://github.com/adap/flower/pull/658))"
msgstr ""
"**Initialisation des paramètres côté serveur** "
"([#658](https://github.com/adap/flower/pull/658))"

#: ../../source/ref-changelog.md:688
msgid ""
"Model parameters can now be initialized on the server-side. Server-side "
"parameter initialization works via a new `Strategy` method called "
"`initialize_parameters`."
msgstr ""
"Les paramètres du modèle peuvent maintenant être initialisés côté "
"serveur. L'initialisation des paramètres côté serveur fonctionne via une "
"nouvelle méthode `Strategy` appelée `initialize_parameters`."

#: ../../source/ref-changelog.md:690
msgid ""
"Built-in strategies support a new constructor argument called "
"`initial_parameters` to set the initial parameters. Built-in strategies "
"will provide these initial parameters to the server on startup and then "
"delete them to free the memory afterwards."
msgstr ""
"Les stratégies intégrées prennent en charge un nouvel argument du "
"constructeur appelé `initial_parameters` pour définir les paramètres "
"initiaux. Les stratégies intégrées fourniront ces paramètres initiaux au "
"serveur au démarrage et les supprimeront ensuite pour libérer la mémoire."

#: ../../source/ref-changelog.md:709
msgid ""
"If no initial parameters are provided to the strategy, the server will "
"continue to use the current behaviour (namely, it will ask one of the "
"connected clients for its parameters and use these as the initial global "
"parameters)."
msgstr ""
"Si aucun paramètre initial n'est fourni à la stratégie, le serveur "
"continuera à utiliser le comportement actuel (à savoir qu'il demandera à "
"l'un des clients connectés ses paramètres et les utilisera comme "
"paramètres globaux initiaux)."

#: ../../source/ref-changelog.md:711
msgid "Deprecations"
msgstr "Dépréciations"

#: ../../source/ref-changelog.md:713
msgid ""
"Deprecate `flwr.server.strategy.DefaultStrategy` (migrate to "
"`flwr.server.strategy.FedAvg`, which is equivalent)"
msgstr ""
"Déclasser `flwr.server.strategy.DefaultStrategy` (migrer vers "
"`flwr.server.strategy.FedAvg`, qui est équivalent)"

#: ../../source/ref-changelog.md:715
msgid "v0.14.0 (2021-02-18)"
msgstr "v0.14.0 (2021-02-18)"

#: ../../source/ref-changelog.md:719
msgid ""
"**Generalized** `Client.fit` **and** `Client.evaluate` **return values** "
"([#610](https://github.com/adap/flower/pull/610) "
"[#572](https://github.com/adap/flower/pull/572) "
"[#633](https://github.com/adap/flower/pull/633))"
msgstr ""
"**Généralisé** `Client.fit` **et** `Client.evaluate` **valeurs de "
"retour** ([#610](https://github.com/adap/flower/pull/610) "
"[#572](https://github.com/adap/flower/pull/572) "
"[#633](https://github.com/adap/flower/pull/633))"

#: ../../source/ref-changelog.md:721
msgid ""
"Clients can now return an additional dictionary mapping `str` keys to "
"values of the following types: `bool`, `bytes`, `float`, `int`, `str`. "
"This means one can return almost arbitrary values from `fit`/`evaluate` "
"and make use of them on the server side!"
msgstr ""
"Les clients peuvent maintenant renvoyer un dictionnaire supplémentaire "
"associant les clés `str` aux valeurs des types suivants : `bool`, "
"`bytes`, `float`, `int`, `str`. Cela signifie que l'on peut renvoyer des "
"valeurs presque arbitraires de `fit`/`evaluate` et les utiliser du côté "
"du serveur !"

#: ../../source/ref-changelog.md:723
msgid ""
"This improvement also allowed for more consistent return types between "
"`fit` and `evaluate`: `evaluate` should now return a tuple `(float, int, "
"dict)` representing the loss, number of examples, and a dictionary "
"holding arbitrary problem-specific values like accuracy."
msgstr ""
"Cette amélioration a également permis de rendre plus cohérents les types "
"de retour entre `fit` et `evaluate` : `evaluate` devrait maintenant "
"retourner un tuple `(float, int, dict)` représentant la perte, le nombre "
"d'exemples, et un dictionnaire contenant des valeurs arbitraires "
"spécifiques au problème comme la précision."

#: ../../source/ref-changelog.md:725
msgid ""
"In case you wondered: this feature is compatible with existing projects, "
"the additional dictionary return value is optional. New code should "
"however migrate to the new return types to be compatible with upcoming "
"Flower releases (`fit`: `List[np.ndarray], int, Dict[str, Scalar]`, "
"`evaluate`: `float, int, Dict[str, Scalar]`). See the example below for "
"details."
msgstr ""
"Au cas où tu te poserais la question : cette fonctionnalité est "
"compatible avec les projets existants, la valeur de retour supplémentaire"
" du dictionnaire est facultative. Le nouveau code doit cependant migrer "
"vers les nouveaux types de retour pour être compatible avec les "
"prochaines versions de Flower (`fit` : `List[np.ndarray], int, Dict[str, "
"Scalar]`, `evaluate` : `float, int, Dict[str, Scalar]`). Voir l'exemple "
"ci-dessous pour plus de détails."

#: ../../source/ref-changelog.md:727
msgid ""
"*Code example:* note the additional dictionary return values in both "
"`FlwrClient.fit` and `FlwrClient.evaluate`:"
msgstr ""
"*Exemple de code:* note les valeurs de retour du dictionnaire "
"supplémentaires dans `FlwrClient.fit` et `FlwrClient.evaluate` :"

#: ../../source/ref-changelog.md:742
msgid ""
"**Generalized** `config` **argument in** `Client.fit` **and** "
"`Client.evaluate` ([#595](https://github.com/adap/flower/pull/595))"
msgstr ""
"**Généralisé** `config` **argument dans** `Client.fit` **et** "
"`Client.evaluate` ([#595](https://github.com/adap/flower/pull/595))"

#: ../../source/ref-changelog.md:744
msgid ""
"The `config` argument used to be of type `Dict[str, str]`, which means "
"that dictionary values were expected to be strings. The new release "
"generalizes this to enable values of the following types: `bool`, "
"`bytes`, `float`, `int`, `str`."
msgstr ""
"L'argument `config` était auparavant de type `Dict[str, str]`, ce qui "
"signifie que les valeurs du dictionnaire devaient être des chaînes. La "
"nouvelle version généralise cela pour permettre les valeurs des types "
"suivants : `bool`, `bytes`, `float`, `int`, `str`."

#: ../../source/ref-changelog.md:746
msgid ""
"This means one can now pass almost arbitrary values to `fit`/`evaluate` "
"using the `config` dictionary. Yay, no more `str(epochs)` on the server-"
"side and `int(config[\"epochs\"])` on the client side!"
msgstr ""
"Cela signifie que l'on peut maintenant passer des valeurs presque "
"arbitraires à `fit`/`evaluate` en utilisant le dictionnaire `config`. "
"Yay, plus de `str(epochs)` du côté serveur et `int(config[\"epochs\"])` "
"du côté client !"

#: ../../source/ref-changelog.md:748
msgid ""
"*Code example:* note that the `config` dictionary now contains non-`str` "
"values in both `Client.fit` and `Client.evaluate`:"
msgstr ""
"*Exemple de code:* Notez que le dictionnaire `config` contient maintenant"
" des valeurs autres que `str` dans `Client.fit` et `Client.evaluate` :"

#: ../../source/ref-changelog.md:765
msgid "v0.13.0 (2021-01-08)"
msgstr "v0.13.0 (2021-01-08)"

#: ../../source/ref-changelog.md:769
msgid ""
"New example: PyTorch From Centralized To Federated "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr ""
"Nouvel exemple : PyTorch de centralisé à fédéré "
"([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:770
msgid "Improved documentation"
msgstr "Amélioration de la documentation"

#: ../../source/ref-changelog.md:771
msgid "New documentation theme ([#551](https://github.com/adap/flower/pull/551))"
msgstr ""
"Nouveau thème de documentation "
"([#551](https://github.com/adap/flower/pull/551))"

#: ../../source/ref-changelog.md:772
msgid "New API reference ([#554](https://github.com/adap/flower/pull/554))"
msgstr "Nouvelle référence API ([#554](https://github.com/adap/flower/pull/554))"

#: ../../source/ref-changelog.md:773
msgid ""
"Updated examples documentation "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr ""
"Mise à jour de la documentation des exemples "
"([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:774
msgid ""
"Removed obsolete documentation "
"([#548](https://github.com/adap/flower/pull/548))"
msgstr ""
"Suppression de la documentation obsolète "
"([#548](https://github.com/adap/flower/pull/548))"

#: ../../source/ref-changelog.md:776
msgid "Bugfix:"
msgstr "Correction de bogues :"

#: ../../source/ref-changelog.md:778
msgid ""
"`Server.fit` does not disconnect clients when finished, disconnecting the"
" clients is now handled in `flwr.server.start_server` "
"([#553](https://github.com/adap/flower/pull/553) "
"[#540](https://github.com/adap/flower/issues/540))."
msgstr ""
"`Server.fit` ne déconnecte pas les clients lorsqu'il est terminé, la "
"déconnexion des clients est maintenant gérée dans "
"`flwr.server.start_server` "
"([#553](https://github.com/adap/flower/pull/553) "
"[#540](https://github.com/adap/flower/issues/540))."

#: ../../source/ref-changelog.md:780
msgid "v0.12.0 (2020-12-07)"
msgstr "v0.12.0 (2020-12-07)"

#: ../../source/ref-changelog.md:782 ../../source/ref-changelog.md:798
msgid "Important changes:"
msgstr "Changements importants :"

#: ../../source/ref-changelog.md:784
msgid ""
"Added an example for embedded devices "
"([#507](https://github.com/adap/flower/pull/507))"
msgstr ""
"Ajout d'un exemple pour les périphériques embarqués "
"([#507](https://github.com/adap/flower/pull/507))"

#: ../../source/ref-changelog.md:785
msgid ""
"Added a new NumPyClient (in addition to the existing KerasClient) "
"([#504](https://github.com/adap/flower/pull/504) "
"[#508](https://github.com/adap/flower/pull/508))"
msgstr ""
"Ajout d'un nouveau NumPyClient (en plus du KerasClient existant) "
"([#504](https://github.com/adap/flower/pull/504) "
"[#508](https://github.com/adap/flower/pull/508))"

#: ../../source/ref-changelog.md:786
msgid ""
"Deprecated `flwr_example` package and started to migrate examples into "
"the top-level `examples` directory "
"([#494](https://github.com/adap/flower/pull/494) "
"[#512](https://github.com/adap/flower/pull/512))"
msgstr ""
"Déclassement du paquet `flwr_example` et migration des exemples dans le "
"répertoire de premier niveau `examples` "
"([#494](https://github.com/adap/flower/pull/494) "
"[#512](https://github.com/adap/flower/pull/512))"

#: ../../source/ref-changelog.md:788
msgid "v0.11.0 (2020-11-30)"
msgstr "v0.11.0 (2020-11-30)"

#: ../../source/ref-changelog.md:790
msgid "Incompatible changes:"
msgstr "Changements incompatibles :"

#: ../../source/ref-changelog.md:792
msgid ""
"Renamed strategy methods "
"([#486](https://github.com/adap/flower/pull/486)) to unify the naming of "
"Flower's public APIs. Other public methods/functions (e.g., every method "
"in `Client`, but also `Strategy.evaluate`) do not use the `on_` prefix, "
"which is why we're removing it from the four methods in Strategy. To "
"migrate rename the following `Strategy` methods accordingly:"
msgstr ""
"Renommé les méthodes de stratégie "
"([#486](https://github.com/adap/flower/pull/486)) pour unifier le nommage"
" des API publiques de Flower. D'autres méthodes/fonctions publiques (par "
"exemple, toutes les méthodes de `Client`, mais aussi `Strategy.evaluate`)"
" n'utilisent pas le préfixe `on_`, c'est pourquoi nous le supprimons des "
"quatre méthodes de Stratégie. Pour migrer, renommez les méthodes de "
"`Strategy` suivantes en conséquence :"

#: ../../source/ref-changelog.md:793
msgid "`on_configure_evaluate` => `configure_evaluate`"
msgstr "`on_configure_evaluate` => `configure_evaluate`"

#: ../../source/ref-changelog.md:794
msgid "`on_aggregate_evaluate` => `aggregate_evaluate`"
msgstr "`on_aggregate_evaluate` => `aggregate_evaluate`"

#: ../../source/ref-changelog.md:795
msgid "`on_configure_fit` => `configure_fit`"
msgstr "`on_configure_fit` => `configure_fit`"

#: ../../source/ref-changelog.md:796
msgid "`on_aggregate_fit` => `aggregate_fit`"
msgstr "`on_aggregate_fit` => `aggregate_fit`"

#: ../../source/ref-changelog.md:800
msgid ""
"Deprecated `DefaultStrategy` "
"([#479](https://github.com/adap/flower/pull/479)). To migrate use "
"`FedAvg` instead."
msgstr ""
"Déclassé `DefaultStrategy` "
"([#479](https://github.com/adap/flower/pull/479)). Pour migrer, utilisez "
"`FedAvg` à la place."

#: ../../source/ref-changelog.md:801
msgid ""
"Simplified examples and baselines "
"([#484](https://github.com/adap/flower/pull/484))."
msgstr ""
"Exemples simplifiés et lignes de base "
"([#484](https://github.com/adap/flower/pull/484))."

#: ../../source/ref-changelog.md:802
msgid ""
"Removed presently unused `on_conclude_round` from strategy interface "
"([#483](https://github.com/adap/flower/pull/483))."
msgstr ""
"Suppression de `on_conclude_round` actuellement inutilisé de l'interface "
"de stratégie ([#483](https://github.com/adap/flower/pull/483))."

#: ../../source/ref-changelog.md:803
msgid ""
"Set minimal Python version to 3.6.1 instead of 3.6.9 "
"([#471](https://github.com/adap/flower/pull/471))."
msgstr ""
"Fixe la version minimale de Python à 3.6.1 au lieu de 3.6.9 "
"([#471](https://github.com/adap/flower/pull/471))."

#: ../../source/ref-changelog.md:804
msgid ""
"Improved `Strategy` docstrings "
"([#470](https://github.com/adap/flower/pull/470))."
msgstr ""
"Amélioration des docstrings `Stratégie` "
"([#470](https://github.com/adap/flower/pull/470))."

#: ../../source/ref-example-projects.rst:2
#, fuzzy
msgid "Example projects"
msgstr "Exemples de PyTorch"

#: ../../source/ref-example-projects.rst:4
msgid ""
"Flower comes with a number of usage examples. The examples demonstrate "
"how Flower can be used to federate different kinds of existing machine "
"learning pipelines, usually leveraging popular machine learning "
"frameworks such as `PyTorch <https://pytorch.org/>`_ or `TensorFlow "
"<https://www.tensorflow.org/>`_."
msgstr ""
"Flower est livré avec un certain nombre d'exemples d'utilisation, qui "
"montrent comment Flower peut être utilisé pour fédérer différents types "
"de pipelines d'apprentissage automatique existants, qui s'appuient "
"généralement sur des frameworks d'apprentissage automatique populaires "
"tels que `PyTorch <https://pytorch.org/>`_ ou `TensorFlow "
"<https://www.tensorflow.org/>`_."

#: ../../source/ref-example-projects.rst:11
msgid ""
"Flower usage examples used to be bundled with Flower in a package called "
"``flwr_example``. We are migrating those examples to standalone projects "
"to make them easier to use. All new examples are based in the directory "
"`examples <https://github.com/adap/flower/tree/main/examples>`_."
msgstr ""
"Les exemples d'utilisation de Flower étaient auparavant regroupés avec "
"Flower dans un paquet appelé ``flwr_example``. Nous migrons ces exemples "
"vers des projets autonomes pour les rendre plus faciles à utiliser. Tous "
"les nouveaux exemples sont basés dans le répertoire ``examples "
"<https://github.com/adap/flower/tree/main/examples>`_."

#: ../../source/ref-example-projects.rst:16
msgid "The following examples are available as standalone projects."
msgstr "Les exemples suivants sont disponibles sous forme de projets autonomes."

#: ../../source/ref-example-projects.rst:20
msgid "Quickstart TensorFlow/Keras"
msgstr "Démarrage rapide de TensorFlow/Keras"

#: ../../source/ref-example-projects.rst:22
msgid ""
"The TensorFlow/Keras quickstart example shows CIFAR-10 image "
"classification with MobileNetV2:"
msgstr ""
"L'exemple de démarrage rapide TensorFlow/Keras montre la classification "
"d'images CIFAR-10 avec MobileNetV2 :"

#: ../../source/ref-example-projects.rst:25
#, fuzzy
msgid ""
"`Quickstart TensorFlow (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_"
msgstr ""
"`Quickstart TensorFlow (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_"

#: ../../source/ref-example-projects.rst:26
msgid ""
"`Quickstart TensorFlow (Tutorial) <https://flower.dev/docs/quickstart-"
"tensorflow.html>`_"
msgstr ""
"`Quickstart TensorFlow (Tutorial) <https://flower.dev/docs/quickstart-"
"tensorflow.html>`_"

#: ../../source/ref-example-projects.rst:27
msgid ""
"`Quickstart TensorFlow (Blog Post) <https://flower.dev/blog/2020-12-11"
"-federated-learning-in-less-than-20-lines-of-code>`_"
msgstr ""
"`Quickstart TensorFlow (Blog Post) <https://flower.dev/blog/2020-12-11"
"-federated-learning-in-less-than-20-lines-of-code>`_"

#: ../../source/ref-example-projects.rst:31
#: ../../source/tutorial-quickstart-pytorch.rst:5
msgid "Quickstart PyTorch"
msgstr "Démarrage rapide de PyTorch"

#: ../../source/ref-example-projects.rst:33
msgid ""
"The PyTorch quickstart example shows CIFAR-10 image classification with a"
" simple Convolutional Neural Network:"
msgstr ""
"L'exemple de démarrage rapide PyTorch montre la classification d'images "
"CIFAR-10 avec un simple réseau neuronal convolutif :"

#: ../../source/ref-example-projects.rst:36
#, fuzzy
msgid ""
"`Quickstart PyTorch (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pytorch>`_"
msgstr ""
"`Quickstart PyTorch (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pytorch>`_"

#: ../../source/ref-example-projects.rst:37
msgid ""
"`Quickstart PyTorch (Tutorial) <https://flower.dev/docs/quickstart-"
"pytorch.html>`_"
msgstr ""
"`Quickstart PyTorch (Tutorial) <https://flower.dev/docs/quickstart-"
"pytorch.html>`_"

#: ../../source/ref-example-projects.rst:41
msgid "PyTorch: From Centralized To Federated"
msgstr "PyTorch : De la centralisation à la fédération"

#: ../../source/ref-example-projects.rst:43
msgid ""
"This example shows how a regular PyTorch project can be federated using "
"Flower:"
msgstr ""
"Cet exemple montre comment un projet PyTorch ordinaire peut être fédéré à"
" l'aide de Flower :"

#: ../../source/ref-example-projects.rst:45
#, fuzzy
msgid ""
"`PyTorch: From Centralized To Federated (Code) "
"<https://github.com/adap/flower/tree/main/examples/pytorch-from-"
"centralized-to-federated>`_"
msgstr ""
"`PyTorch : De la centralisation à la fédération (Code) "
"<https://github.com/adap/flower/tree/main/examples/pytorch-from-"
"centralized-to-federated>`_"

#: ../../source/ref-example-projects.rst:46
msgid ""
"`PyTorch: From Centralized To Federated (Tutorial) "
"<https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`_"
msgstr ""
"`PyTorch : De la centralisation à la fédération (Tutoriel) "
"<https://flower.dev/docs/example-pytorch-from-centralized-to-"
"federated.html>`_"

#: ../../source/ref-example-projects.rst:50
msgid "Federated Learning on Raspberry Pi and Nvidia Jetson"
msgstr "Apprentissage fédéré sur Raspberry Pi et Nvidia Jetson"

#: ../../source/ref-example-projects.rst:52
msgid ""
"This example shows how Flower can be used to build a federated learning "
"system that run across Raspberry Pi and Nvidia Jetson:"
msgstr ""
"Cet exemple montre comment Flower peut être utilisé pour construire un "
"système d'apprentissage fédéré qui fonctionne sur Raspberry Pi et Nvidia "
"Jetson :"

#: ../../source/ref-example-projects.rst:54
#, fuzzy
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Code) "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_"
msgstr ""
"`L'apprentissage fédéré sur Raspberry Pi et Nvidia Jetson (Code) "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_"

#: ../../source/ref-example-projects.rst:55
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Blog Post) "
"<https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
msgstr ""
"`L'apprentissage fédéré sur Raspberry Pi et Nvidia Jetson (Blog Post) "
"<https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"

#: ../../source/ref-example-projects.rst:60
msgid "Legacy Examples (`flwr_example`)"
msgstr "Exemples hérités (`flwr_example`)"

#: ../../source/ref-example-projects.rst:63
msgid ""
"The useage examples in `flwr_example` are deprecated and will be removed "
"in the future. New examples are provided as standalone projects in "
"`examples <https://github.com/adap/flower/tree/main/examples>`_."
msgstr ""
"Les exemples d'utilisation dans `flwr_example` sont obsolètes et seront "
"supprimés à l'avenir. De nouveaux exemples sont fournis en tant que "
"projets autonomes dans `examples "
"<https://github.com/adap/flower/tree/main/examples>`_."

#: ../../source/ref-example-projects.rst:69
msgid "Extra Dependencies"
msgstr "Dépendances supplémentaires"

#: ../../source/ref-example-projects.rst:71
msgid ""
"The core Flower framework keeps a minimal set of dependencies. The "
"examples demonstrate Flower in the context of different machine learning "
"frameworks, so additional dependencies need to be installed before an "
"example can be run."
msgstr ""
"Le noyau du framework Flower conserve un ensemble minimal de dépendances."
" Les exemples démontrent Flower dans le contexte de différents frameworks"
" d'apprentissage automatique, de sorte que des dépendances "
"supplémentaires doivent être installées avant qu'un exemple puisse être "
"exécuté."

#: ../../source/ref-example-projects.rst:75
msgid "For PyTorch examples::"
msgstr "Pour les exemples de PyTorch: :"

#: ../../source/ref-example-projects.rst:79
msgid "For TensorFlow examples::"
msgstr "Pour les exemples de TensorFlow : :"

#: ../../source/ref-example-projects.rst:83
msgid "For both PyTorch and TensorFlow examples::"
msgstr "Pour les exemples PyTorch et TensorFlow: :"

#: ../../source/ref-example-projects.rst:87
msgid ""
"Please consult :code:`pyproject.toml` for a full list of possible extras "
"(section :code:`[tool.poetry.extras]`)."
msgstr ""
"Tu peux consulter :code:`pyproject.toml` pour une liste complète des "
"extras possibles (section :code:`[tool.poetry.extras]`)."

#: ../../source/ref-example-projects.rst:92
msgid "PyTorch Examples"
msgstr "Exemples de PyTorch"

#: ../../source/ref-example-projects.rst:94
msgid ""
"Our PyTorch examples are based on PyTorch 1.7. They should work with "
"other releases as well. So far, we provide the following examples."
msgstr ""
"Nos exemples PyTorch sont basés sur PyTorch 1.7. Ils devraient "
"fonctionner avec d'autres versions également. Jusqu'à présent, nous "
"fournissons les exemples suivants."

#: ../../source/ref-example-projects.rst:98
msgid "CIFAR-10 Image Classification"
msgstr "Classification d'images CIFAR-10"

#: ../../source/ref-example-projects.rst:100
msgid ""
"`CIFAR-10 and CIFAR-100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ "
"are popular RGB image datasets. The Flower CIFAR-10 example uses PyTorch "
"to train a simple CNN classifier in a federated learning setup with two "
"clients."
msgstr ""
"`CIFAR-10 et CIFAR-100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ "
"sont des ensembles de données d'images RVB populaires. L'exemple Flower "
"CIFAR-10 utilise PyTorch pour former un classificateur CNN simple dans "
"une configuration d'apprentissage fédéré avec deux clients."

#: ../../source/ref-example-projects.rst:104
#: ../../source/ref-example-projects.rst:121
#: ../../source/ref-example-projects.rst:146
msgid "First, start a Flower server:"
msgstr "Tout d'abord, démarre un serveur Flower :"

#: ../../source/ref-example-projects.rst:106
msgid "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"
msgstr "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"

#: ../../source/ref-example-projects.rst:108
#: ../../source/ref-example-projects.rst:125
#: ../../source/ref-example-projects.rst:150
msgid "Then, start the two clients in a new terminal window:"
msgstr "Ensuite, démarre les deux clients dans une nouvelle fenêtre de terminal :"

#: ../../source/ref-example-projects.rst:110
msgid "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"
msgstr "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"

#: ../../source/ref-example-projects.rst:112
msgid "For more details, see :code:`src/py/flwr_example/pytorch_cifar`."
msgstr "Pour plus de détails, voir :code:`src/py/flwr_example/pytorch_cifar`."

#: ../../source/ref-example-projects.rst:115
msgid "ImageNet-2012 Image Classification"
msgstr "ImageNet-2012 Classification des images"

#: ../../source/ref-example-projects.rst:117
msgid ""
"`ImageNet-2012 <http://www.image-net.org/>`_ is one of the major computer"
" vision datasets. The Flower ImageNet example uses PyTorch to train a "
"ResNet-18 classifier in a federated learning setup with ten clients."
msgstr ""
"`ImageNet-2012 <http://www.image-net.org/>`_ est l'un des principaux "
"ensembles de données de vision par ordinateur. L'exemple Flower ImageNet "
"utilise PyTorch pour entraîner un classificateur ResNet-18 dans une "
"configuration d'apprentissage fédéré avec dix clients."

#: ../../source/ref-example-projects.rst:123
msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"
msgstr "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"

#: ../../source/ref-example-projects.rst:127
msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"
msgstr "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"

#: ../../source/ref-example-projects.rst:129
msgid "For more details, see :code:`src/py/flwr_example/pytorch_imagenet`."
msgstr "Pour plus de détails, voir :code:`src/py/flwr_example/pytorch_imagenet`."

#: ../../source/ref-example-projects.rst:133
msgid "TensorFlow Examples"
msgstr "Exemples de TensorFlow"

#: ../../source/ref-example-projects.rst:135
msgid ""
"Our TensorFlow examples are based on TensorFlow 2.0 or newer. So far, we "
"provide the following examples."
msgstr ""
"Nos exemples TensorFlow sont basés sur TensorFlow 2.0 ou une version plus"
" récente. Jusqu'à présent, nous te proposons les exemples suivants."

#: ../../source/ref-example-projects.rst:139
msgid "Fashion-MNIST Image Classification"
msgstr "Classification d'images Fashion-MNIST"

#: ../../source/ref-example-projects.rst:141
msgid ""
"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ is "
"often used as the \"Hello, world!\" of machine learning. We follow this "
"tradition and provide an example which samples random local datasets from"
" Fashion-MNIST and trains a simple image classification model over those "
"partitions."
msgstr ""
"nous suivons cette tradition et fournissons un exemple qui échantillonne "
"des ensembles de données locales aléatoires de Fashion-MNIST et entraîne "
"un modèle simple de classification d'images sur ces partitions."

#: ../../source/ref-example-projects.rst:148
msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"
msgstr "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"

#: ../../source/ref-example-projects.rst:152
msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"
msgstr "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"

#: ../../source/ref-example-projects.rst:154
msgid ""
"For more details, see "
":code:`src/py/flwr_example/tensorflow_fashion_mnist`."
msgstr ""
"Pour plus de détails, voir "
":code:`src/py/flwr_example/tensorflow_fashion_mnist`."

#: ../../source/ref-faq.rst:4
msgid ""
"This page collects answers to commonly asked questions about Federated "
"Learning with Flower."
msgstr ""
"Cette page rassemble les réponses aux questions les plus fréquemment "
"posées sur l'apprentissage fédéré avec Flower."

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can Flower run on Juptyter Notebooks / Google Colab?"
msgstr ""
":fa:`eye,mr-1` Flower peut-il fonctionner sur les ordinateurs portables "
"Juptyter / Google Colab ?"

#: ../../source/ref-faq.rst:8
msgid ""
"Yes, it can! Flower even comes with a few under-the-hood optimizations to"
" make it work even better on Colab. Here's a quickstart example:"
msgstr ""
"Oui, c'est possible ! Flower est même livré avec quelques optimisations "
"pour qu'il fonctionne encore mieux sur Colab. Voici un exemple de "
"démarrage rapide :"

#: ../../source/ref-faq.rst:10
#, fuzzy
msgid ""
"`Flower simulation PyTorch "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-pytorch/sim.ipynb>`_"
msgstr ""
"`Flower Quickstart (TensorFlow/Keras) "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples/simulation_tensorflow/sim.ipynb>`_"

#: ../../source/ref-faq.rst:11
#, fuzzy
msgid ""
"`Flower simulation TensorFlow/Keras "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-tensorflow/sim.ipynb>`_"
msgstr ""
"`Flower Quickstart (TensorFlow/Keras) "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples/simulation_tensorflow/sim.ipynb>`_"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` How can I run Federated Learning on a Raspberry Pi?"
msgstr ""
":fa:`eye,mr-1` Comment puis-je faire fonctionner l'apprentissage fédéré "
"sur un Raspberry Pi ?"

#: ../../source/ref-faq.rst:15
#, fuzzy
msgid ""
"Find the `blog post about federated learning on embedded device here "
"<https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
" and the corresponding `GitHub code example "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_."
msgstr ""
"Trouve le `blog post about federated learning on embedded device ici "
"<https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
" et l'exemple de code GitHub correspondant "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_."

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Does Flower support federated learning on Android devices?"
msgstr ""
":fa:`eye,mr-1` Est-ce que Flower prend en charge l'apprentissage fédéré "
"sur les appareils Android ?"

#: ../../source/ref-faq.rst:19
#, fuzzy
msgid ""
"Yes, it does. Please take a look at our `blog post "
"<https://flower.dev/blog/2021-12-15-federated-learning-on-android-"
"devices-with-flower>`_ or check out the code examples:"
msgstr ""
"Oui. Jetez un coup d'œil à notre `blog post "
"<https://flower.dev/blog/2021-12-15-federated-learning-on-android-"
"devices-with-flower>`_ ou consultez l'`exemple de code Android sur GitHub"
" <https://github.com/adap/flower/tree/main/examples/android>`_."

#: ../../source/ref-faq.rst:21
msgid ""
"`Android Kotlin example <https://flower.dev/docs/examples/android-"
"kotlin.html>`_"
msgstr ""

#: ../../source/ref-faq.rst:22
msgid "`Android Java example <https://flower.dev/docs/examples/android.html>`_"
msgstr ""

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can I combine federated learning with blockchain?"
msgstr ""
":fa:`eye,mr-1` Puis-je combiner l'apprentissage fédéré avec la blockchain"
" ?"

#: ../../source/ref-faq.rst:26
msgid ""
"Yes, of course. A list of available examples using Flower within a "
"blockchain environment is available here:"
msgstr ""
"Oui, bien sûr, une liste d'exemples disponibles utilisant Flower dans un "
"environnement blockchain est disponible ici :"

#: ../../source/ref-faq.rst:28
msgid ""
"`Flower meets Nevermined GitHub Repository <https://github.com"
"/nevermined-io/fl-demo/tree/master/image-classification-flower>`_."
msgstr ""
"`Flower meets Nevermined GitHub Repository <https://github.com"
"/nevermined-io/fl-demo/tree/master/image-classification-flower>`_."

#: ../../source/ref-faq.rst:29
msgid ""
"`Flower meets Nevermined YouTube video "
"<https://www.youtube.com/watch?v=A0A9hSlPhKI>`_."
msgstr ""
"`Flower rencontre Nevermined vidéo YouTube "
"<https://www.youtube.com/watch?v=A0A9hSlPhKI>`_."

#: ../../source/ref-faq.rst:30
msgid ""
"`Flower meets KOSMoS <https://www.kosmos-bmbf.de/wp-"
"content/uploads/sites/13/2021/05/Talk-Flower-Summit-2021.pdf>`_."
msgstr ""
"`Flower rencontre KOSMoS <https://www.kosmos-bmbf.de/wp-"
"content/uploads/sites/13/2021/05/Talk-Flower-Summit-2021.pdf>`_."

#: ../../source/ref-faq.rst:31
msgid ""
"`Flower meets Talan blog post <https://www.linkedin.com/pulse/federated-"
"learning-same-mask-different-faces-imen-"
"ayari/?trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ ."
msgstr ""
"`Flower meets Talan blog post <https://www.linkedin.com/pulse/federated-"
"learning-same-mask-different-faces-imen-"
"ayari/?trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ ."

#: ../../source/ref-faq.rst:32
msgid ""
"`Flower meets Talan GitHub Repository "
"<https://gitlab.com/Talan_Innovation_Factory/food-waste-prevention>`_ ."
msgstr ""
"`Flower rencontre Talan Dépôt GitHub "
"<https://gitlab.com/Talan_Innovation_Factory/food-waste-prevention>`_ ."

#: ../../source/ref-telemetry.md:1
msgid "Telemetry"
msgstr "Télémétrie"

#: ../../source/ref-telemetry.md:3
msgid ""
"The Flower open-source project collects **anonymous** usage metrics to "
"make well-informed decisions to improve Flower. Doing this enables the "
"Flower team to understand how Flower is used and what challenges users "
"might face."
msgstr ""
"Le projet open-source Flower recueille des mesures d'utilisation "
"**anonymes** afin de prendre des décisions éclairées pour améliorer "
"Flower. Cela permet à l'équipe de Flower de comprendre comment Flower est"
" utilisé et quels sont les défis auxquels les utilisateurs peuvent être "
"confrontés."

#: ../../source/ref-telemetry.md:5
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.**"
" Staying true to this statement, Flower makes it easy to disable "
"telemetry for users that do not want to share anonymous usage metrics."
msgstr ""
"**Flower est un cadre convivial pour l'IA collaborative et la science des"
" données.** En restant fidèle à cette déclaration, Flower permet de "
"désactiver facilement la télémétrie pour les utilisateurs qui ne "
"souhaitent pas partager des mesures d'utilisation anonymes."

#: ../../source/ref-telemetry.md:7
msgid "Principles"
msgstr "Principes"

#: ../../source/ref-telemetry.md:9
msgid "We follow strong principles guarding anonymous usage metrics collection:"
msgstr ""
"Nous suivons des principes stricts concernant la collecte de données "
"anonymes sur l'utilisation :"

#: ../../source/ref-telemetry.md:11
msgid ""
"**Optional:** You will always be able to disable telemetry; read on to "
"learn “[How to opt-out](#how-to-opt-out)”."
msgstr ""
"**Optionnel:** Tu pourras toujours désactiver la télémétrie ; lis la "
"suite pour apprendre \"[Comment se désengager](#how-to-opt-out)\"."

#: ../../source/ref-telemetry.md:12
msgid ""
"**Anonymous:** The reported usage metrics are anonymous and do not "
"contain any personally identifiable information (PII). See “[Collected "
"metrics](#collected-metrics)” to understand what metrics are being "
"reported."
msgstr ""
"**Anonyme:** Les mesures d'utilisation rapportées sont anonymes et ne "
"contiennent aucune information personnelle identifiable (PII). Voir "
"\"[Collected metrics](#collected-metrics)\" pour comprendre quelles "
"mesures sont rapportées."

#: ../../source/ref-telemetry.md:13
msgid ""
"**Transparent:** You can easily inspect what anonymous metrics are being "
"reported; see the section “[How to inspect what is being reported](#how-"
"to-inspect-what-is-being-reported)”"
msgstr ""
"**Transparent:** Tu peux facilement inspecter les métriques anonymes qui "
"sont rapportées ; voir la section \"[Comment inspecter ce qui est "
"rapporté](#how-to-inspect-what-is-being-reported)\""

#: ../../source/ref-telemetry.md:14
#, fuzzy
msgid ""
"**Open for feedback:** You can always reach out to us if you have "
"feedback; see the section “[How to contact us](#how-to-contact-us)” for "
"details."
msgstr ""
"**Ouvert pour les commentaires:** Tu peux toujours nous contacter si tu "
"as des commentaires ; voir la section \"[Comment nous contacter ](#how-"
"to-contact-us)\" pour plus de détails."

#: ../../source/ref-telemetry.md:16
msgid "How to opt-out"
msgstr "Comment se désinscrire"

#: ../../source/ref-telemetry.md:18
msgid ""
"When Flower starts, it will check for an environment variable called "
"`FLWR_TELEMETRY_ENABLED`. Telemetry can easily be disabled by setting "
"`FLWR_TELEMETRY_ENABLED=0`. Assuming you are starting a Flower server or "
"client, simply do so by prepending your command as in:"
msgstr ""
"Lorsque Flower démarre, il vérifie la présence d'une variable "
"d'environnement appelée `FLWR_TELEMETRY_ENABLED`. La télémétrie peut "
"facilement être désactivée en réglant `FLWR_TELEMETRY_ENABLED=0`. En "
"supposant que tu démarres un serveur ou un client Flower, fais-le "
"simplement en faisant précéder ta commande de la façon suivante :"

#: ../../source/ref-telemetry.md:24
msgid ""
"Alternatively, you can export `FLWR_TELEMETRY_ENABLED=0` in, for example,"
" `.bashrc` (or whatever configuration file applies to your environment) "
"to disable Flower telemetry permanently."
msgstr ""
"Tu peux aussi exporter `FLWR_TELEMETRY_ENABLED=0` dans, par exemple, "
"`.bashrc` (ou tout autre fichier de configuration qui s'applique à ton "
"environnement) pour désactiver la télémétrie de la fleur de façon "
"permanente."

#: ../../source/ref-telemetry.md:26
msgid "Collected metrics"
msgstr "Mesures collectées"

#: ../../source/ref-telemetry.md:28
msgid "Flower telemetry collects the following metrics:"
msgstr "La télémétrie des fleurs recueille les métriques suivantes :"

#: ../../source/ref-telemetry.md:30
msgid ""
"**Flower version.** Understand which versions of Flower are currently "
"being used. This helps us to decide whether we should invest effort into "
"releasing a patch version for an older version of Flower or instead use "
"the bandwidth to build new features."
msgstr ""
"**Cela nous aide à décider si nous devons investir des efforts dans la "
"publication d'une version corrective pour une version plus ancienne de "
"Flower ou si nous devons plutôt utiliser la bande passante pour "
"développer de nouvelles fonctionnalités."

#: ../../source/ref-telemetry.md:32
msgid ""
"**Operating system.** Enables us to answer questions such as: *Should we "
"create more guides for Linux, macOS, or Windows?*"
msgstr ""
"**Système d'exploitation.** Nous permet de répondre à des questions "
"telles que : *Faudrait-il créer plus de guides pour Linux, macOS ou "
"Windows ?"

#: ../../source/ref-telemetry.md:34
msgid ""
"**Python version.** Knowing the Python version helps us, for example, to "
"decide whether we should invest effort into supporting old versions of "
"Python or stop supporting them and start taking advantage of new Python "
"features."
msgstr ""
"**Version de Python.** Connaître la version de Python nous aide, par "
"exemple, à décider si nous devons investir des efforts dans la prise en "
"charge des anciennes versions de Python ou cesser de les prendre en "
"charge et commencer à tirer parti des nouvelles fonctionnalités de "
"Python."

#: ../../source/ref-telemetry.md:36
msgid ""
"**Hardware properties.** Understanding the hardware environment that "
"Flower is being used in helps to decide whether we should, for example, "
"put more effort into supporting low-resource environments."
msgstr ""
"**Comprendre l'environnement matériel dans lequel Flower est utilisé "
"permet de décider si nous devrions, par exemple, faire plus d'efforts "
"pour prendre en charge les environnements à faibles ressources."

#: ../../source/ref-telemetry.md:38
msgid ""
"**Execution mode.** Knowing what execution mode Flower starts in enables "
"us to understand how heavily certain features are being used and better "
"prioritize based on that."
msgstr ""
"**Mode d'exécution** Connaître le mode d'exécution dans lequel Flower "
"démarre nous permet de comprendre à quel point certaines fonctionnalités "
"sont utilisées et de mieux établir les priorités en fonction de cela."

#: ../../source/ref-telemetry.md:40
msgid ""
"**Cluster.** Flower telemetry assigns a random in-memory cluster ID each "
"time a Flower workload starts. This allows us to understand which device "
"types not only start Flower workloads but also successfully complete "
"them."
msgstr ""
"**Cluster.** La télémétrie Flower attribue un ID de cluster en mémoire "
"aléatoire à chaque fois qu'une charge de travail Flower démarre. Cela "
"nous permet de comprendre quels types d'appareils non seulement démarrent"
" les charges de travail Flower, mais aussi les terminent avec succès."

#: ../../source/ref-telemetry.md:42
msgid ""
"**Source.** Flower telemetry tries to store a random source ID in "
"`~/.flwr/source` the first time a telemetry event is generated. The "
"source ID is important to identify whether an issue is recurring or "
"whether an issue is triggered by multiple clusters running concurrently "
"(which often happens in simulation). For example, if a device runs "
"multiple workloads at the same time, and this results in an issue, then, "
"in order to reproduce the issue, multiple workloads must be started at "
"the same time."
msgstr ""
"**Source.** La télémétrie de Flower essaie de stocker un ID de source "
"aléatoire dans `~/.flwr/source` la première fois qu'un événement de "
"télémétrie est généré. L'ID de source est important pour identifier si un"
" problème est récurrent ou si un problème est déclenché par plusieurs "
"clusters fonctionnant simultanément (ce qui arrive souvent en "
"simulation). Par exemple, si un périphérique exécute plusieurs charges de"
" travail en même temps, et que cela entraîne un problème, alors, afin de "
"reproduire le problème, plusieurs charges de travail doivent être "
"démarrées en même temps."

#: ../../source/ref-telemetry.md:44
msgid ""
"You may delete the source ID at any time. If you wish for all events "
"logged under a specific source ID to be deleted, you can send a deletion "
"request mentioning the source ID to `telemetry@flower.dev`. All events "
"related to that source ID will then be permanently deleted."
msgstr ""
"Tu peux supprimer l'identifiant de la source à tout moment. Si tu "
"souhaites que tous les événements enregistrés sous un identifiant de "
"source spécifique soient supprimés, tu peux envoyer une demande de "
"suppression mentionnant l'identifiant de source à `telemetry@flower.dev`."
" Tous les événements liés à cet identifiant de source seront alors "
"définitivement supprimés."

#: ../../source/ref-telemetry.md:46
msgid ""
"We will not collect any personally identifiable information. If you think"
" any of the metrics collected could be misused in any way, please [get in"
" touch with us](#how-to-contact-us). We will update this page to reflect "
"any changes to the metrics collected and publish changes in the "
"changelog."
msgstr ""
"Nous ne collecterons aucune information personnelle identifiable. Si tu "
"penses que l'une des métriques collectées pourrait être utilisée à "
"mauvais escient de quelque manière que ce soit, merci de [nous "
"contacter](#commentnouscontacter). Nous mettrons à jour cette page pour "
"refléter toute modification des métriques collectées et nous publierons "
"les changements dans le journal des modifications (changelog)."

#: ../../source/ref-telemetry.md:48
msgid ""
"If you think other metrics would be helpful for us to better guide our "
"decisions, please let us know! We will carefully review them; if we are "
"confident that they do not compromise user privacy, we may add them."
msgstr ""
"Si tu penses que d'autres mesures nous seraient utiles pour mieux "
"orienter nos décisions, fais-le nous savoir ! Nous les examinerons "
"attentivement ; si nous sommes convaincus qu'elles ne compromettent pas "
"la vie privée des utilisateurs, nous pourrons les ajouter."

#: ../../source/ref-telemetry.md:50
msgid "How to inspect what is being reported"
msgstr "Comment inspecter ce qui est rapporté"

#: ../../source/ref-telemetry.md:52
msgid ""
"We wanted to make it very easy for you to inspect what anonymous usage "
"metrics are reported. You can view all the reported telemetry information"
" by setting the environment variable `FLWR_TELEMETRY_LOGGING=1`. Logging "
"is disabled by default. You may use logging independently from "
"`FLWR_TELEMETRY_ENABLED` so that you can inspect the telemetry feature "
"without sending any metrics."
msgstr ""
"Nous avons voulu qu'il soit très facile pour toi d'inspecter les mesures "
"d'utilisation anonymes qui sont rapportées. Tu peux voir toutes les "
"informations de télémétrie rapportées en définissant la variable "
"d'environnement `FLWR_TELEMETRY_LOGGING=1`. La journalisation est "
"désactivée par défaut. Tu peux utiliser la journalisation indépendamment "
"de `FLWR_TELEMETRY_ENABLED` afin d'inspecter la fonction de télémétrie "
"sans envoyer de mesures."

#: ../../source/ref-telemetry.md:58
msgid ""
"The inspect Flower telemetry without sending any anonymous usage metrics,"
" use both environment variables:"
msgstr ""
"L'inspecteur Flower telemetry sans envoyer de métriques d'utilisation "
"anonymes, utilise les deux variables d'environnement :"

#: ../../source/ref-telemetry.md:64
msgid "How to contact us"
msgstr "Comment nous contacter"

#: ../../source/ref-telemetry.md:66
msgid ""
"We want to hear from you. If you have any feedback or ideas on how to "
"improve the way we handle anonymous usage metrics, reach out to us via "
"[Slack](https://flower.dev/join-slack/) (channel `#telemetry`) or email "
"(`telemetry@flower.dev`)."
msgstr ""
"Si tu as des commentaires ou des idées pour améliorer la façon dont nous "
"traitons les mesures d'utilisation anonymes, contacte-nous via "
"[Slack](https://flower.dev/join-slack/) (canal `#telemetry`) ou par "
"courriel (`telemetry@flower.dev`)."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:9
#, fuzzy
msgid "Build a strategy from scratch"
msgstr "Élaborer une stratégie à partir de zéro"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:11
#, fuzzy
msgid ""
"Welcome to the third part of the Flower federated learning tutorial. In "
"previous parts of this tutorial, we introduced federated learning with "
"PyTorch and Flower (`part 1 <https://flower.dev/docs/framework/tutorial-"
"get-started-with-flower-pytorch.html>`__) and we learned how strategies "
"can be used to customize the execution on both the server and the clients"
" (`part 2 <https://flower.dev/docs/framework/tutorial-use-a-federated-"
"learning-strategy-pytorch.html>`__)."
msgstr ""
"Bienvenue dans la troisième partie du tutoriel sur l'apprentissage fédéré"
" Flower. Dans les parties précédentes de ce tutoriel, nous avons présenté"
" l'apprentissage fédéré avec PyTorch et Flower (`partie 1 "
"<https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html>`__) "
"et nous avons appris comment les stratégies peuvent être utilisées pour "
"personnaliser l'exécution à la fois sur le serveur et sur les clients "
"(`partie 2 <https://flower.dev/docs/tutorial/Flower-2-Strategies-in-FL-"
"PyTorch.html>`__)."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:13
msgid ""
"In this notebook, we'll continue to customize the federated learning "
"system we built previously by creating a custom version of FedAvg (again,"
" using `Flower <https://flower.dev/>`__ and `PyTorch "
"<https://pytorch.org/>`__)."
msgstr ""
"Dans ce carnet, nous allons continuer à personnaliser le système "
"d'apprentissage fédéré que nous avons construit précédemment en créant "
"une version personnalisée de FedAvg (encore une fois, en utilisant "
"`Flower <https://flower.dev/>`__ et `PyTorch <https://pytorch.org/>`__)."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:15
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:16
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:15
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:15
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join "
"the Flower community on Slack to connect, ask questions, and get help: "
"`Join Slack <https://flower.dev/join-slack>`__ 🌼 We'd love to hear from "
"you in the ``#introductions`` channel! And if anything is unclear, head "
"over to the ``#questions`` channel."
msgstr ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ et "
"rejoignez la communauté Flower sur Slack pour vous connecter, poser des "
"questions et obtenir de l'aide : `Join Slack <https://flower.dev/join-"
"slack>`__ 🌼 Nous serions ravis d'avoir de vos nouvelles dans le canal "
"``#introductions`` ! Et si quelque chose n'est pas clair, rendez-vous sur"
" le canal ``#questions``."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:17
msgid "Let's build a new ``Strategy`` from scratch!"
msgstr "Construisons une nouvelle ``Stratégie`` à partir de zéro !"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:29
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:29
msgid "Preparation"
msgstr "Préparation"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:31
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:32
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:31
msgid ""
"Before we begin with the actual code, let's make sure that we have "
"everything we need."
msgstr ""
"Avant de commencer le code proprement dit, assurons-nous que nous "
"disposons de tout ce dont nous avons besoin."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:43
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:44
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:43
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:43
msgid "Installing dependencies"
msgstr "Installation des dépendances"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:45
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:46
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:45
msgid "First, we install the necessary packages:"
msgstr "Tout d'abord, nous installons les paquets nécessaires :"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:65
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:66
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:65
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:65
msgid ""
"Now that we have all dependencies installed, we can import everything we "
"need for this tutorial:"
msgstr ""
"Maintenant que toutes les dépendances sont installées, nous pouvons "
"importer tout ce dont nous avons besoin pour ce tutoriel :"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:101
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:102
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:104
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:101
msgid ""
"It is possible to switch to a runtime that has GPU acceleration enabled "
"(on Google Colab: ``Runtime > Change runtime type > Hardware acclerator: "
"GPU > Save``). Note, however, that Google Colab is not always able to "
"offer GPU acceleration. If you see an error related to GPU availability "
"in one of the following sections, consider switching back to CPU-based "
"execution by setting ``DEVICE = torch.device(\"cpu\")``. If the runtime "
"has GPU acceleration enabled, you should see the output ``Training on "
"cuda``, otherwise it'll say ``Training on cpu``."
msgstr ""
"Il est possible de passer à un runtime dont l'accélération GPU est "
"activée (sur Google Colab : ``Runtime > Change runtime type > Hardware "
"acclerator : GPU > Save``). Note cependant que Google Colab n'est pas "
"toujours en mesure de proposer l'accélération GPU. Si tu vois une erreur "
"liée à la disponibilité du GPU dans l'une des sections suivantes, "
"envisage de repasser à une exécution basée sur le CPU en définissant "
"``DEVICE = torch.device(\"cpu\")``. Si le runtime a activé l'accélération"
" GPU, tu devrais voir apparaître le résultat ``Training on cuda``, sinon "
"il dira ``Training on cpu``."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:114
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:115
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:114
msgid "Data loading"
msgstr "Chargement des données"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:116
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:116
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap everything in their own ``DataLoader``. We introduce a new parameter"
" ``num_clients`` which allows us to call ``load_datasets`` with different"
" numbers of clients."
msgstr ""
"Chargeons maintenant les ensembles d'entraînement et de test CIFAR-10, "
"divisons-les en dix ensembles de données plus petits (chacun divisé en "
"ensemble d'entraînement et de validation), et enveloppons le tout dans "
"leur propre ``DataLoader``. Nous introduisons un nouveau paramètre "
"``num_clients`` qui nous permet d'appeler ``load_datasets`` avec "
"différents nombres de clients."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:167
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:168
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:167
msgid "Model training/evaluation"
msgstr "Formation/évaluation du modèle"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:169
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:170
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:169
msgid ""
"Let's continue with the usual model definition (including "
"``set_parameters`` and ``get_parameters``), training and test functions:"
msgstr ""
"Continuons avec la définition habituelle du modèle (y compris "
"``set_parameters`` et ``get_parameters``), les fonctions d'entraînement "
"et de test :"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:258
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:258
msgid "Flower client"
msgstr "Client de Flower"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:260
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:260
msgid ""
"To implement the Flower client, we (again) create a subclass of "
"``flwr.client.NumPyClient`` and implement the three methods "
"``get_parameters``, ``fit``, and ``evaluate``. Here, we also pass the "
"``cid`` to the client and use it log additional details:"
msgstr ""
"Pour mettre en œuvre le client Flower, nous créons (à nouveau) une sous-"
"classe de ``flwr.client.NumPyClient`` et mettons en œuvre les trois "
"méthodes ``get_parameters``, ``fit`` et ``evaluate``. Ici, nous "
"transmettons également le ``cid`` au client et l'utilisons pour consigner"
" des détails supplémentaires :"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:308
msgid "Let's test what we have so far before we continue:"
msgstr "Testons ce que nous avons jusqu'à présent avant de continuer :"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:339
msgid "Build a Strategy from scratch"
msgstr "Élaborer une stratégie à partir de zéro"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:341
msgid ""
"Let’s overwrite the ``configure_fit`` method such that it passes a higher"
" learning rate (potentially also other hyperparameters) to the optimizer "
"of a fraction of the clients. We will keep the sampling of the clients as"
" it is in ``FedAvg`` and then change the configuration dictionary (one of"
" the ``FitIns`` attributes)."
msgstr ""
"Remplaçons la méthode ``configure_fit`` de façon à ce qu'elle transmette "
"un taux d'apprentissage plus élevé (potentiellement aussi d'autres "
"hyperparamètres) à l'optimiseur d'une fraction des clients. Nous "
"garderons l'échantillonnage des clients tel qu'il est dans ``FedAvg`` et "
"changerons ensuite le dictionnaire de configuration (l'un des attributs "
"``FitIns``)."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:507
msgid ""
"The only thing left is to use the newly created custom Strategy "
"``FedCustom`` when starting the experiment:"
msgstr ""
"Il ne reste plus qu'à utiliser la stratégie personnalisée nouvellement "
"créée ``FedCustom`` lors du démarrage de l'expérience :"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:534
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:932
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:697
msgid "Recap"
msgstr "Récapitulation"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:536
msgid ""
"In this notebook, we’ve seen how to implement a custom strategy. A custom"
" strategy enables granular control over client node configuration, result"
" aggregation, and more. To define a custom strategy, you only have to "
"overwrite the abstract methods of the (abstract) base class ``Strategy``."
" To make custom strategies even more powerful, you can pass custom "
"functions to the constructor of your new class (``__init__``) and then "
"call these functions whenever needed."
msgstr ""
"Dans ce carnet, nous avons vu comment mettre en place une stratégie "
"personnalisée. Une stratégie personnalisée permet un contrôle granulaire "
"sur la configuration des nœuds clients, l'agrégation des résultats, et "
"bien plus encore. Pour définir une stratégie personnalisée, il te suffit "
"d'écraser les méthodes abstraites de la classe de base (abstraite) "
"``Strategy``. Pour rendre les stratégies personnalisées encore plus "
"puissantes, tu peux passer des fonctions personnalisées au constructeur "
"de ta nouvelle classe (``__init__``) et appeler ensuite ces fonctions à "
"chaque fois que c'est nécessaire."

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:550
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:948
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:749
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:715
#: ../../source/tutorial-what-is-federated-learning.ipynb:369
msgid ""
"Before you continue, make sure to join the Flower community on Slack: "
"`Join Slack <https://flower.dev/join-slack/>`__"
msgstr ""
"Avant de continuer, n'oublie pas de rejoindre la communauté Flower sur "
"Slack : `Join Slack <https://flower.dev/join-slack/>`__"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:552
#: ../../source/tutorial-customize-the-client-pytorch.ipynb:950
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:751
#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:717
#: ../../source/tutorial-what-is-federated-learning.ipynb:371
msgid ""
"There's a dedicated ``#questions`` channel if you need help, but we'd "
"also love to hear who you are in ``#introductions``!"
msgstr ""
"Il existe un canal dédié aux ``questions`` si vous avez besoin d'aide, "
"mais nous aimerions aussi savoir qui vous êtes dans ``#introductions`` !"

#: ../../source/tutorial-build-a-strategy-from-scratch-pytorch.ipynb:554
#, fuzzy
msgid ""
"The `Flower Federated Learning Tutorial - Part 4 "
"<https://flower.dev/docs/framework/tutorial-customize-the-client-"
"pytorch.html>`__ introduces ``Client``, the flexible API underlying "
"``NumPyClient``."
msgstr ""
"Le `Tutoriel d'apprentissage fédéré Flower - Partie 4 "
"<https://flower.dev/docs/tutorial/Flower-4-Client-and-NumPyClient-"
"PyTorch.html>`__ présente ``Client``, l'API flexible qui sous-tend "
"``NumPyClient``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:9
#, fuzzy
msgid "Customize the client"
msgstr "Création du client IMDBC"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:11
#, fuzzy
msgid ""
"Welcome to the fourth part of the Flower federated learning tutorial. In "
"the previous parts of this tutorial, we introduced federated learning "
"with PyTorch and Flower (`part 1 <https://flower.dev/docs/framework"
"/tutorial-get-started-with-flower-pytorch.html>`__), we learned how "
"strategies can be used to customize the execution on both the server and "
"the clients (`part 2 <https://flower.dev/docs/framework/tutorial-use-a"
"-federated-learning-strategy-pytorch.html>`__), and we built our own "
"custom strategy from scratch (`part 3 <https://flower.dev/docs/framework"
"/tutorial-build-a-strategy-from-scratch-pytorch.html>`__)."
msgstr ""
"Bienvenue dans la quatrième partie du tutoriel sur l'apprentissage fédéré"
" Flower. Dans les parties précédentes de ce tutoriel, nous avons présenté"
" l'apprentissage fédéré avec PyTorch et Flower (`partie 1 "
"<https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html>`__),"
" nous avons appris comment les stratégies peuvent être utilisées pour "
"personnaliser l'exécution à la fois sur le serveur et les clients "
"(`partie 2 <https://flower.dev/docs/tutorial/Flower-2-Strategies-in-FL-"
"PyTorch.html>`__), et nous avons construit notre propre stratégie "
"personnalisée à partir de zéro (`partie 3 - WIP "
"<https://flower.dev/docs/tutorial/Flower-3-Building-a-Strategy-"
"PyTorch.html>`__)."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:14
msgid ""
"In this notebook, we revisit ``NumPyClient`` and introduce a new "
"baseclass for building clients, simply named ``Client``. In previous "
"parts of this tutorial, we've based our client on ``NumPyClient``, a "
"convenience class which makes it easy to work with machine learning "
"libraries that have good NumPy interoperability. With ``Client``, we gain"
" a lot of flexibility that we didn't have before, but we'll also have to "
"do a few things the we didn't have to do before."
msgstr ""
"Dans ce carnet, nous revisitons `NumPyClient`` et introduisons une "
"nouvelle classe de base pour construire des clients, simplement appelée "
"`Client``. Dans les parties précédentes de ce tutoriel, nous avons basé "
"notre client sur ``NumPyClient``, une classe de commodité qui facilite le"
" travail avec les bibliothèques d'apprentissage automatique qui ont une "
"bonne interopérabilité NumPy. Avec ``Client``, nous gagnons beaucoup de "
"flexibilité que nous n'avions pas auparavant, mais nous devrons également"
" faire quelques choses que nous n'avions pas à faire auparavant."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:18
msgid ""
"Let's go deeper and see what it takes to move from ``NumPyClient`` to "
"``Client``!"
msgstr ""
"Allons plus loin et voyons ce qu'il faut faire pour passer de "
"``NumPyClient`` à ``Client`` !"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:30
#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:29
msgid "Step 0: Preparation"
msgstr "Étape 0 : Préparation"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:117
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap everything in their own ``DataLoader``."
msgstr ""
"Chargeons maintenant les ensembles d'entraînement et de test CIFAR-10, "
"divisons-les en dix ensembles de données plus petits (chacun divisé en "
"ensemble d'entraînement et de validation) et enveloppons le tout dans "
"leur propre ``DataLoader``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:259
msgid "Step 1: Revisiting NumPyClient"
msgstr "Étape 1 : Revoir NumPyClient"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:261
msgid ""
"So far, we've implemented our client by subclassing "
"``flwr.client.NumPyClient``. The three methods we implemented are "
"``get_parameters``, ``fit``, and ``evaluate``. Finally, we wrap the "
"creation of instances of this class in a function called ``client_fn``:"
msgstr ""
"Jusqu'à présent, nous avons implémenté notre client en sous-classant "
"``flwr.client.NumPyClient``. Les trois méthodes que nous avons "
"implémentées sont ``get_parameters``, ``fit`` et ``evaluate``. Enfin, "
"nous enveloppons la création d'instances de cette classe dans une "
"fonction appelée ``client_fn`` :"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:309
msgid ""
"We've seen this before, there's nothing new so far. The only *tiny* "
"difference compared to the previous notebook is naming, we've changed "
"``FlowerClient`` to ``FlowerNumPyClient`` and ``client_fn`` to "
"``numpyclient_fn``. Let's run it to see the output we get:"
msgstr ""
"Nous avons déjà vu cela auparavant, il n'y a rien de nouveau jusqu'à "
"présent. La seule *petite* différence par rapport au carnet précédent est"
" le nommage, nous avons changé ``FlowerClient`` en ``FlowerNumPyClient`` "
"et ``client_fn`` en ``numpyclient_fn``. Exécutons-le pour voir la sortie "
"que nous obtenons :"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:339
msgid ""
"This works as expected, two clients are training for three rounds of "
"federated learning."
msgstr ""
"Cela fonctionne comme prévu, deux clients s'entraînent pour trois tours "
"d'apprentissage fédéré."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:341
msgid ""
"Let's dive a little bit deeper and discuss how Flower executes this "
"simulation. Whenever a client is selected to do some work, "
"``start_simulation`` calls the function ``numpyclient_fn`` to create an "
"instance of our ``FlowerNumPyClient`` (along with loading the model and "
"the data)."
msgstr ""
"Plongeons un peu plus profondément et discutons de la façon dont Flower "
"exécute cette simulation. Chaque fois qu'un client est sélectionné pour "
"effectuer un travail, ``start_simulation`` appelle la fonction "
"``numpyclient_fn`` pour créer une instance de notre ``FlowerNumPyClient``"
" (en même temps qu'il charge le modèle et les données)."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:343
msgid ""
"But here's the perhaps surprising part: Flower doesn't actually use the "
"``FlowerNumPyClient`` object directly. Instead, it wraps the object to "
"makes it look like a subclass of ``flwr.client.Client``, not "
"``flwr.client.NumPyClient``. In fact, the Flower core framework doesn't "
"know how to handle ``NumPyClient``'s, it only knows how to handle "
"``Client``'s. ``NumPyClient`` is just a convenience abstraction built on "
"top of ``Client``."
msgstr ""
"Mais voici la partie la plus surprenante : Flower n'utilise pas "
"directement l'objet `FlowerNumPyClient`. Au lieu de cela, il enveloppe "
"l'objet pour le faire ressembler à une sous-classe de "
"`flwr.client.Client`, et non de `flwr.client.NumPyClient`. En fait, le "
"noyau de Flower ne sait pas comment gérer les `NumPyClient`, il sait "
"seulement comment gérer les `Client`. `NumPyClient` est juste une "
"abstraction de commodité construite au dessus de `Client`."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:345
msgid ""
"Instead of building on top of ``NumPyClient``, we can directly build on "
"top of ``Client``."
msgstr ""
"Au lieu de construire par-dessus `NumPyClient``, nous pouvons construire "
"directement par-dessus `Client``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:357
msgid "Step 2: Moving from ``NumPyClient`` to ``Client``"
msgstr "Étape 2 : Passer de ``NumPyClient`` à ``Client``"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:359
msgid ""
"Let's try to do the same thing using ``Client`` instead of "
"``NumPyClient``."
msgstr ""
"Essayons de faire la même chose en utilisant ``Client`` au lieu de "
"``NumPyClient``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:465
msgid ""
"Before we discuss the code in more detail, let's try to run it! Gotta "
"make sure our new ``Client``-based client works, right?"
msgstr ""
"Avant de discuter du code plus en détail, essayons de l'exécuter ! Nous "
"devons nous assurer que notre nouveau client basé sur le ``Client`` "
"fonctionne, n'est-ce pas ?"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:490
msgid ""
"That's it, we're now using ``Client``. It probably looks similar to what "
"we've done with ``NumPyClient``. So what's the difference?"
msgstr ""
"Voilà, nous utilisons maintenant ``Client``. Cela ressemble probablement "
"à ce que nous avons fait avec ``NumPyClient``. Alors quelle est la "
"différence ?"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:492
msgid ""
"First of all, it's more code. But why? The difference comes from the fact"
" that ``Client`` expects us to take care of parameter serialization and "
"deserialization. For Flower to be able to send parameters over the "
"network, it eventually needs to turn these parameters into ``bytes``. "
"Turning parameters (e.g., NumPy ``ndarray``'s) into raw bytes is called "
"serialization. Turning raw bytes into something more useful (like NumPy "
"``ndarray``'s) is called deserialization. Flower needs to do both: it "
"needs to serialize parameters on the server-side and send them to the "
"client, the client needs to deserialize them to use them for local "
"training, and then serialize the updated parameters again to send them "
"back to the server, which (finally!) deserializes them again in order to "
"aggregate them with the updates received from other clients."
msgstr ""
"First of all, it's more code. But why? The difference comes from the fact"
" that ``Client`` expects us to take care of parameter serialization and "
"deserialization. For Flower to be able to send parameters over the "
"network, it eventually needs to turn these parameters into ``bytes``. "
"Turning parameters (e.g., NumPy ``ndarray``'s) into raw bytes is called "
"serialization. Turning raw bytes into something more useful (like NumPy "
"``ndarray``'s) is called deserialization. Flower needs to do both: it "
"needs to serialize parameters on the server-side and send them to the "
"client, the client needs to deserialize them to use them for local "
"training, and then serialize the updated parameters again to send them "
"back to the server, which (finally!) deserializes them again in order to "
"aggregate them with the updates received from other clients."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:495
msgid ""
"The only *real* difference between Client and NumPyClient is that "
"NumPyClient takes care of serialization and deserialization for you. It "
"can do so because it expects you to return parameters as NumPy ndarray's,"
" and it knows how to handle these. This makes working with machine "
"learning libraries that have good NumPy support (most of them) a breeze."
msgstr ""
"La seule *vraie* différence entre Client et NumPyClient est que "
"NumPyClient s'occupe de la sérialisation et de la désérialisation pour "
"toi. Il peut le faire parce qu'il s'attend à ce que tu renvoies des "
"paramètres sous forme de NumPy ndarray, et il sait comment les gérer. "
"Cela permet de travailler avec des bibliothèques d'apprentissage "
"automatique qui ont une bonne prise en charge de NumPy (la plupart "
"d'entre elles) en un clin d'œil."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:497
msgid ""
"In terms of API, there's one major difference: all methods in Client take"
" exactly one argument (e.g., ``FitIns`` in ``Client.fit``) and return "
"exactly one value (e.g., ``FitRes`` in ``Client.fit``). The methods in "
"``NumPyClient`` on the other hand have multiple arguments (e.g., "
"``parameters`` and ``config`` in ``NumPyClient.fit``) and multiple return"
" values (e.g., ``parameters``, ``num_example``, and ``metrics`` in "
"``NumPyClient.fit``) if there are multiple things to handle. These "
"``*Ins`` and ``*Res`` objects in ``Client`` wrap all the individual "
"values you're used to from ``NumPyClient``."
msgstr ""
"In terms of API, there's one major difference: all methods in Client take"
" exactly one argument (e.g., ``FitIns`` in ``Client.fit``) and return "
"exactly one value (e.g., ``FitRes`` in ``Client.fit``). The methods in "
"``NumPyClient`` on the other hand have multiple arguments (e.g., "
"``parameters`` and ``config`` in ``NumPyClient.fit``) and multiple return"
" values (e.g., ``parameters``, ``num_example``, and ``metrics`` in "
"``NumPyClient.fit``) if there are multiple things to handle. These "
"``*Ins`` and ``*Res`` objects in ``Client`` wrap all the individual "
"values you're used to from ``NumPyClient``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:510
msgid "Step 3: Custom serialization"
msgstr "Étape 3 : Sérialisation personnalisée"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:512
msgid ""
"Here we will explore how to implement custom serialization with a simple "
"example."
msgstr ""
"Nous allons ici explorer comment mettre en œuvre une sérialisation "
"personnalisée à l'aide d'un exemple simple."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:514
msgid ""
"But first what is serialization? Serialization is just the process of "
"converting an object into raw bytes, and equally as important, "
"deserialization is the process of converting raw bytes back into an "
"object. This is very useful for network communication. Indeed, without "
"serialization, you could not just a Python object through the internet."
msgstr ""
"Mais d'abord, qu'est-ce que la sérialisation ? La sérialisation est "
"simplement le processus de conversion d'un objet en octets bruts, et tout"
" aussi important, la désérialisation est le processus de reconversion des"
" octets bruts en objet. Ceci est très utile pour la communication réseau."
" En effet, sans la sérialisation, tu ne pourrais pas faire passer un "
"objet Python par Internet."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:516
msgid ""
"Federated Learning relies heavily on internet communication for training "
"by sending Python objects back and forth between the clients and the "
"server. This means that serialization is an essential part of Federated "
"Learning."
msgstr ""
"L'apprentissage fédéré s'appuie fortement sur la communication Internet "
"pour la formation en envoyant des objets Python dans les deux sens entre "
"les clients et le serveur, ce qui signifie que la sérialisation est un "
"élément essentiel de l'apprentissage fédéré."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:518
msgid ""
"In the following section, we will write a basic example where instead of "
"sending a serialized version of our ``ndarray``\\ s containing our "
"parameters, we will first convert the ``ndarray`` into sparse matrices, "
"before sending them. This technique can be used to save bandwidth, as in "
"certain cases where the weights of a model are sparse (containing many 0 "
"entries), converting them to a sparse matrix can greatly improve their "
"bytesize."
msgstr ""
"Dans la section suivante, nous allons écrire un exemple de base où, au "
"lieu d'envoyer une version sérialisée de nos ``ndarray`` contenant nos "
"paramètres, nous allons d'abord convertir les ``ndarray`` en matrices "
"éparses, avant de les envoyer. Cette technique peut être utilisée pour "
"économiser de la bande passante, car dans certains cas où les poids d'un "
"modèle sont épars (contenant de nombreuses entrées 0), les convertir en "
"une matrice éparse peut grandement améliorer leur taille en octets."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:521
msgid "Our custom serialization/deserialization functions"
msgstr "Nos fonctions de sérialisation/désérialisation personnalisées"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:523
msgid ""
"This is where the real serialization/deserialization will happen, "
"especially in ``ndarray_to_sparse_bytes`` for serialization and "
"``sparse_bytes_to_ndarray`` for deserialization."
msgstr ""
"C'est là que la véritable sérialisation/désérialisation se produira, en "
"particulier dans ``ndarray_to_sparse_bytes`` pour la sérialisation et "
"``sparse_bytes_to_ndarray`` pour la désérialisation."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:525
msgid ""
"Note that we imported the ``scipy.sparse`` library in order to convert "
"our arrays."
msgstr ""
"Notez que nous avons importé la bibliothèque ``scipy.sparse`` afin de "
"convertir nos tableaux."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:613
msgid "Client-side"
msgstr "Côté client"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:615
msgid ""
"To be able to able to serialize our ``ndarray``\\ s into sparse "
"parameters, we will just have to call our custom functions in our "
"``flwr.client.Client``."
msgstr ""
"Pour pouvoir sérialiser nos ``ndarray`` en paramètres sparse, il nous "
"suffira d'appeler nos fonctions personnalisées dans notre "
"``flwr.client.Client``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:617
msgid ""
"Indeed, in ``get_parameters`` we need to serialize the parameters we got "
"from our network using our custom ``ndarrays_to_sparse_parameters`` "
"defined above."
msgstr ""
"En effet, dans ``get_parameters`` nous devons sérialiser les paramètres "
"que nous avons obtenus de notre réseau en utilisant nos "
"``ndarrays_to_sparse_parameters`` personnalisés définis ci-dessus."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:619
msgid ""
"In ``fit``, we first need to deserialize the parameters coming from the "
"server using our custom ``sparse_parameters_to_ndarrays`` and then we "
"need to serialize our local results with "
"``ndarrays_to_sparse_parameters``."
msgstr ""
"Dans ``fit``, nous devons d'abord désérialiser les paramètres provenant "
"du serveur en utilisant notre ``sparse_parameters_to_ndarrays`` "
"personnalisé, puis nous devons sérialiser nos résultats locaux avec "
"``ndarrays_to_sparse_parameters``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:621
msgid ""
"In ``evaluate``, we will only need to deserialize the global parameters "
"with our custom function."
msgstr ""
"Dans ``evaluate``, nous n'aurons besoin que de désérialiser les "
"paramètres globaux avec notre fonction personnalisée."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:725
msgid "Server-side"
msgstr "Côté serveur"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:727
msgid ""
"For this example, we will just use ``FedAvg`` as a strategy. To change "
"the serialization and deserialization here, we only need to reimplement "
"the ``evaluate`` and ``aggregate_fit`` functions of ``FedAvg``. The other"
" functions of the strategy will be inherited from the super class "
"``FedAvg``."
msgstr ""
"Pour cet exemple, nous utiliserons simplement ``FedAvg`` comme stratégie."
" Pour modifier la sérialisation et la désérialisation ici, il suffit de "
"réimplémenter les fonctions ``evaluate`` et ``aggregate_fit`` de "
"``FedAvg``. Les autres fonctions de la stratégie seront héritées de la "
"super-classe ``FedAvg``."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:729
msgid "As you can see only one line as change in ``evaluate``:"
msgstr "Comme tu peux le voir, seule une ligne a été modifiée dans ``evaluate`` :"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:735
msgid ""
"And for ``aggregate_fit``, we will first deserialize every result we "
"received:"
msgstr ""
"Et pour ``aggregate_fit``, nous allons d'abord désérialiser chaque "
"résultat que nous avons reçu :"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:744
msgid "And then serialize the aggregated result:"
msgstr "Puis sérialise le résultat agrégé :"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:903
msgid "We can now run our custom serialization example!"
msgstr ""
"Nous pouvons maintenant exécuter notre exemple de sérialisation "
"personnalisée !"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:934
msgid ""
"In this part of the tutorial, we've seen how we can build clients by "
"subclassing either ``NumPyClient`` or ``Client``. ``NumPyClient`` is a "
"convenience abstraction that makes it easier to work with machine "
"learning libraries that have good NumPy interoperability. ``Client`` is a"
" more flexible abstraction that allows us to do things that are not "
"possible in ``NumPyClient``. In order to do so, it requires us to handle "
"parameter serialization and deserialization ourselves."
msgstr ""
"Dans cette partie du tutoriel, nous avons vu comment construire des "
"clients en sous-classant soit ``NumPyClient``, soit ``Client``. "
"``NumPyClient`` est une abstraction de commodité qui facilite le travail "
"avec les bibliothèques d'apprentissage automatique qui ont une bonne "
"interopérabilité NumPy. ``Client`` est une abstraction plus flexible qui "
"nous permet de faire des choses qui ne sont pas possibles dans "
"``NumPyClient``. Pour ce faire, elle nous oblige à gérer nous-mêmes la "
"sérialisation et la désérialisation des paramètres."

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:952
msgid ""
"This is the final part of the Flower tutorial (for now!), "
"congratulations! You're now well equipped to understand the rest of the "
"documentation. There are many topics we didn't cover in the tutorial, we "
"recommend the following resources:"
msgstr ""
"C'est la dernière partie du tutoriel Flower (pour l'instant !), "
"félicitations ! Tu es maintenant bien équipé pour comprendre le reste de "
"la documentation. Il y a de nombreux sujets que nous n'avons pas abordés "
"dans le tutoriel, nous te recommandons les ressources suivantes :"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:954
msgid "`Read Flower Docs <https://flower.dev/docs/>`__"
msgstr "`Lire les docs sur les fleurs <https://flower.dev/docs/>`__"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:955
msgid ""
"`Check out Flower Code Examples "
"<https://github.com/adap/flower/tree/main/examples>`__"
msgstr ""
"`Check out Flower Code Examples "
"<https://github.com/adap/flower/tree/main/examples>`__"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:956
#, fuzzy
msgid ""
"`Use Flower Baselines for your research "
"<https://flower.dev/docs/baselines/>`__"
msgstr ""
"`Utilise les lignes de base des fleurs pour ta recherche "
"<https://flower.dev/docs/using-baselines.html>`__"

#: ../../source/tutorial-customize-the-client-pytorch.ipynb:957
#, fuzzy
msgid ""
"`Watch Flower Summit 2023 videos <https://flower.dev/conf/flower-"
"summit-2023/>`__"
msgstr ""
"`Regardez les vidéos du Flower Summit 2022 <https://flower.dev/conf"
"/flower-summit-2022/>`__"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:9
msgid "Get started with Flower"
msgstr ""

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:11
#: ../../source/tutorial-what-is-federated-learning.ipynb:11
msgid "Welcome to the Flower federated learning tutorial!"
msgstr "Bienvenue au tutoriel sur l'apprentissage fédéré de la fleur !"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:13
msgid ""
"In this notebook, we'll build a federated learning system using Flower "
"and PyTorch. In part 1, we use PyTorch for the model training pipeline "
"and data loading. In part 2, we continue to federate the PyTorch-based "
"pipeline using Flower."
msgstr ""
"Dans ce carnet, nous allons construire un système d'apprentissage fédéré "
"en utilisant Flower et PyTorch. Dans la première partie, nous utilisons "
"PyTorch pour le pipeline d'entraînement des modèles et le chargement des "
"données. Dans la deuxième partie, nous continuons à fédérer le pipeline "
"basé sur PyTorch en utilisant Flower."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:17
#: ../../source/tutorial-what-is-federated-learning.ipynb:19
msgid "Let's get stated!"
msgstr "Allons-y, déclarons-le !"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:31
msgid ""
"Before we begin with any actual code, let's make sure that we have "
"everything we need."
msgstr ""
"Avant de commencer à coder, assurons-nous que nous disposons de tout ce "
"dont nous avons besoin."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:45
msgid ""
"Next, we install the necessary packages for PyTorch (``torch`` and "
"``torchvision``) and Flower (``flwr``):"
msgstr ""
"Ensuite, nous installons les paquets nécessaires pour PyTorch (``torch`` "
"et ``torchvision``) et Flower (``flwr``) :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:117
msgid "Loading the data"
msgstr "Chargement des données"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:119
msgid ""
"Federated learning can be applied to many different types of tasks across"
" different domains. In this tutorial, we introduce federated learning by "
"training a simple convolutional neural network (CNN) on the popular "
"CIFAR-10 dataset. CIFAR-10 can be used to train image classifiers that "
"distinguish between images from ten different classes:"
msgstr ""
"L'apprentissage fédéré peut être appliqué à de nombreux types de tâches "
"dans différents domaines. Dans ce tutoriel, nous présentons "
"l'apprentissage fédéré en formant un simple réseau neuronal "
"convolutionnel (CNN) sur l'ensemble de données populaire CIFAR-10. "
"CIFAR-10 peut être utilisé pour former des classificateurs d'images qui "
"font la distinction entre les images de dix classes différentes :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:150
msgid ""
"We simulate having multiple datasets from multiple organizations (also "
"called the \"cross-silo\" setting in federated learning) by splitting the"
" original CIFAR-10 dataset into multiple partitions. Each partition will "
"represent the data from a single organization. We're doing this purely "
"for experimentation purposes, in the real world there's no need for data "
"splitting because each organization already has their own data (so the "
"data is naturally partitioned)."
msgstr ""
"Nous simulons le fait d'avoir plusieurs ensembles de données provenant de"
" plusieurs organisations (également appelé le paramètre \"cross-silo\" "
"dans l'apprentissage fédéré) en divisant l'ensemble de données CIFAR-10 "
"original en plusieurs partitions. Chaque partition représentera les "
"données d'une seule organisation. Nous faisons cela purement à des fins "
"d'expérimentation, dans le monde réel, il n'y a pas besoin de diviser les"
" données parce que chaque organisation a déjà ses propres données (les "
"données sont donc naturellement partitionnées)."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:152
msgid ""
"Each organization will act as a client in the federated learning system. "
"So having ten organizations participate in a federation means having ten "
"clients connected to the federated learning server:"
msgstr ""
"Chaque organisation agira comme un client dans le système d'apprentissage"
" fédéré. Ainsi, le fait que dix organisations participent à une "
"fédération signifie que dix clients sont connectés au serveur "
"d'apprentissage fédéré :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:172
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap the resulting partitions by creating a PyTorch ``DataLoader`` for "
"each of them:"
msgstr ""
"Chargeons maintenant l'ensemble de formation et de test CIFAR-10, "
"partitionnons-les en dix ensembles de données plus petits (chacun divisé "
"en ensemble de formation et de validation), et enveloppons les partitions"
" résultantes en créant un PyTorch ``DataLoader`` pour chacun d'entre eux "
":"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:222
msgid ""
"We now have a list of ten training sets and ten validation sets "
"(``trainloaders`` and ``valloaders``) representing the data of ten "
"different organizations. Each ``trainloader``/``valloader`` pair contains"
" 4500 training examples and 500 validation examples. There's also a "
"single ``testloader`` (we did not split the test set). Again, this is "
"only necessary for building research or educational systems, actual "
"federated learning systems have their data naturally distributed across "
"multiple partitions."
msgstr ""
"Nous avons maintenant une liste de dix ensembles de formation et dix "
"ensembles de validation (``trainloaders`` et ``valloaders``) représentant"
" les données de dix organisations différentes. Chaque paire "
"``trainloader`/``valloader`` contient 4500 exemples de formation et 500 "
"exemples de validation. Il y a également un seul ``testloader`` (nous "
"n'avons pas divisé l'ensemble de test). Encore une fois, cela n'est "
"nécessaire que pour construire des systèmes de recherche ou d'éducation, "
"les systèmes d'apprentissage fédérés actuels ont leurs données "
"naturellement distribuées à travers plusieurs partitions."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:225
msgid ""
"Let's take a look at the first batch of images and labels in the first "
"training set (i.e., ``trainloaders[0]``) before we move on:"
msgstr ""
"Jetons un coup d'œil au premier lot d'images et d'étiquettes du premier "
"ensemble d'entraînement (c'est-à-dire ``trainloaders[0]``) avant de "
"poursuivre :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:264
msgid ""
"The output above shows a random batch of images from the first "
"``trainloader`` in our list of ten ``trainloaders``. It also prints the "
"labels associated with each image (i.e., one of the ten possible labels "
"we've seen above). If you run the cell again, you should see another "
"batch of images."
msgstr ""
"La sortie ci-dessus montre un lot aléatoire d'images provenant du premier"
" ``chargeur de formation`` de notre liste de dix ``chargeurs de "
"formation``. Elle imprime également les étiquettes associées à chaque "
"image (c'est-à-dire l'une des dix étiquettes possibles que nous avons "
"vues ci-dessus). Si tu exécutes à nouveau la cellule, tu devrais voir un "
"autre lot d'images."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:276
msgid "Step 1: Centralized Training with PyTorch"
msgstr "Étape 1 : Formation centralisée avec PyTorch"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:287
msgid ""
"Next, we're going to use PyTorch to define a simple convolutional neural "
"network. This introduction assumes basic familiarity with PyTorch, so it "
"doesn't cover the PyTorch-related aspects in full detail. If you want to "
"dive deeper into PyTorch, we recommend `DEEP LEARNING WITH PYTORCH: A 60 "
"MINUTE BLITZ "
"<https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html>`__."
msgstr ""
"Ensuite, nous allons utiliser PyTorch pour définir un simple réseau "
"neuronal convolutif. Cette introduction suppose une familiarité de base "
"avec PyTorch, elle ne couvre donc pas en détail les aspects liés à "
"PyTorch. Si tu veux plonger plus profondément dans PyTorch, nous te "
"recommandons `DEEP LEARNING WITH PYTORCH : A 60 MINUTE BLITZ "
"<https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html>`__."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:299
msgid "Defining the model"
msgstr "Définir le modèle"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:301
msgid ""
"We use the simple CNN described in the `PyTorch tutorial "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a"
"-convolutional-neural-network>`__:"
msgstr ""
"Nous utilisons le CNN simple décrit dans le tutoriel `PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a"
"-convolutional-neural-network>`__ :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:338
msgid "Let's continue with the usual training and test functions:"
msgstr "Poursuivons avec les fonctions habituelles de formation et de test :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:398
msgid "Training the model"
msgstr "Entraîne le modèle"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:400
msgid ""
"We now have all the basic building blocks we need: a dataset, a model, a "
"training function, and a test function. Let's put them together to train "
"the model on the dataset of one of our organizations "
"(``trainloaders[0]``). This simulates the reality of most machine "
"learning projects today: each organization has their own data and trains "
"models only on this internal data:"
msgstr ""
"Nous avons maintenant tous les éléments de base dont nous avons besoin : "
"un ensemble de données, un modèle, une fonction d'entraînement et une "
"fonction de test. Assemblons-les pour entraîner le modèle sur l'ensemble "
"de données de l'une de nos organisations (``trainloaders[0]``). Cela "
"simule la réalité de la plupart des projets d'apprentissage automatique "
"aujourd'hui : chaque organisation possède ses propres données et entraîne"
" les modèles uniquement sur ces données internes :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:430
msgid ""
"Training the simple CNN on our CIFAR-10 split for 5 epochs should result "
"in a test set accuracy of about 41%, which is not good, but at the same "
"time, it doesn't really matter for the purposes of this tutorial. The "
"intent was just to show a simplistic centralized training pipeline that "
"sets the stage for what comes next - federated learning!"
msgstr ""
"L'entraînement du CNN simple sur notre fractionnement CIFAR-10 pendant 5 "
"époques devrait se traduire par une précision de l'ensemble de test "
"d'environ 41 %, ce qui n'est pas bon, mais en même temps, cela n'a pas "
"vraiment d'importance pour les besoins de ce tutoriel. L'intention était "
"juste de montrer un pipeline d'entraînement centralisé simpliste qui "
"prépare le terrain pour ce qui vient ensuite - l'apprentissage fédéré !"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:442
msgid "Step 2: Federated Learning with Flower"
msgstr "Étape 2 : Apprentissage fédéré avec Flower"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:444
msgid ""
"Step 1 demonstrated a simple centralized training pipeline. All data was "
"in one place (i.e., a single ``trainloader`` and a single ``valloader``)."
" Next, we'll simulate a situation where we have multiple datasets in "
"multiple organizations and where we train a model over these "
"organizations using federated learning."
msgstr ""
"L'étape 1 a montré un simple pipeline de formation centralisé. Toutes les"
" données étaient au même endroit (c'est-à-dire un seul ``trainloader`` et"
" un seul ``valloader``). Ensuite, nous allons simuler une situation où "
"nous avons plusieurs ensembles de données dans plusieurs organisations et"
" où nous formons un modèle sur ces organisations à l'aide de "
"l'apprentissage fédéré."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:456
msgid "Updating model parameters"
msgstr "Mise à jour des paramètres du modèle"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:458
msgid ""
"In federated learning, the server sends the global model parameters to "
"the client, and the client updates the local model with the parameters "
"received from the server. It then trains the model on the local data "
"(which changes the model parameters locally) and sends the "
"updated/changed model parameters back to the server (or, alternatively, "
"it sends just the gradients back to the server, not the full model "
"parameters)."
msgstr ""
"Dans l'apprentissage fédéré, le serveur envoie les paramètres du modèle "
"global au client, et le client met à jour le modèle local avec les "
"paramètres reçus du serveur. Il entraîne ensuite le modèle sur les "
"données locales (ce qui modifie les paramètres du modèle localement) et "
"renvoie les paramètres du modèle mis à jour/changés au serveur (ou, "
"alternativement, il renvoie seulement les gradients au serveur, et non "
"pas les paramètres complets du modèle)."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:460
msgid ""
"We need two helper functions to update the local model with parameters "
"received from the server and to get the updated model parameters from the"
" local model: ``set_parameters`` and ``get_parameters``. The following "
"two functions do just that for the PyTorch model above."
msgstr ""
"Nous avons besoin de deux fonctions d'aide pour mettre à jour le modèle "
"local avec les paramètres reçus du serveur et pour obtenir les paramètres"
" mis à jour du modèle local : ``set_parameters`` et ``get_parameters``. "
"Les deux fonctions suivantes font exactement cela pour le modèle PyTorch "
"ci-dessus."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:462
msgid ""
"The details of how this works are not really important here (feel free to"
" consult the PyTorch documentation if you want to learn more). In "
"essence, we use ``state_dict`` to access PyTorch model parameter tensors."
" The parameter tensors are then converted to/from a list of NumPy "
"ndarray's (which Flower knows how to serialize/deserialize):"
msgstr ""
"Les détails de ce fonctionnement ne sont pas vraiment importants ici "
"(n'hésite pas à consulter la documentation PyTorch si tu veux en savoir "
"plus). En substance, nous utilisons ``state_dict`` pour accéder aux "
"tenseurs de paramètres du modèle PyTorch. Les tenseurs de paramètres sont"
" ensuite convertis en/depuis une liste de ndarray NumPy (que Flower sait "
"sérialiser/désérialiser) :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:490
msgid "Implementing a Flower client"
msgstr "Mise en place d'un client Flower"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:492
msgid ""
"With that out of the way, let's move on to the interesting part. "
"Federated learning systems consist of a server and multiple clients. In "
"Flower, we create clients by implementing subclasses of "
"``flwr.client.Client`` or ``flwr.client.NumPyClient``. We use "
"``NumPyClient`` in this tutorial because it is easier to implement and "
"requires us to write less boilerplate."
msgstr ""
"Ceci étant dit, passons à la partie intéressante. Les systèmes "
"d'apprentissage fédérés se composent d'un serveur et de plusieurs "
"clients. Dans Flower, nous créons des clients en mettant en œuvre des "
"sous-classes de ``flwr.client.Client`` ou de ``flwr.client.NumPyClient``."
" Nous utilisons ``NumPyClient`` dans ce tutoriel parce qu'il est plus "
"facile à mettre en œuvre et qu'il nous oblige à rédiger moins de modèles "
"de chaudière."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:494
msgid ""
"To implement the Flower client, we create a subclass of "
"``flwr.client.NumPyClient`` and implement the three methods "
"``get_parameters``, ``fit``, and ``evaluate``:"
msgstr ""
"Pour mettre en œuvre le client Flower, nous créons une sous-classe de "
"``flwr.client.NumPyClient`` et mettons en œuvre les trois méthodes "
"``get_parameters``, ``fit`` et ``evaluate`` :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:496
msgid "``get_parameters``: Return the current local model parameters"
msgstr "``get_parameters`` : renvoie les paramètres du modèle local actuel"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:497
msgid ""
"``fit``: Receive model parameters from the server, train the model "
"parameters on the local data, and return the (updated) model parameters "
"to the server"
msgstr ""
"``fit`` : reçoit les paramètres du modèle du serveur, entraîne les "
"paramètres du modèle sur les données locales et renvoie les paramètres du"
" modèle (mis à jour) au serveur"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:498
msgid ""
"``evaluate``: Receive model parameters from the server, evaluate the "
"model parameters on the local data, and return the evaluation result to "
"the server"
msgstr ""
"``evaluate`` : reçoit les paramètres du modèle du serveur, évalue les "
"paramètres du modèle sur les données locales et renvoie le résultat de "
"l'évaluation au serveur"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:500
msgid ""
"We mentioned that our clients will use the previously defined PyTorch "
"components for model training and evaluation. Let's see a simple Flower "
"client implementation that brings everything together:"
msgstr ""
"Nous avons mentionné que nos clients utiliseront les composants PyTorch "
"définis précédemment pour la formation et l'évaluation des modèles. "
"Voyons une simple mise en œuvre du client Flower qui réunit tout cela :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:537
msgid ""
"Our class ``FlowerClient`` defines how local training/evaluation will be "
"performed and allows Flower to call the local training/evaluation through"
" ``fit`` and ``evaluate``. Each instance of ``FlowerClient`` represents a"
" *single client* in our federated learning system. Federated learning "
"systems have multiple clients (otherwise, there's not much to federate), "
"so each client will be represented by its own instance of "
"``FlowerClient``. If we have, for example, three clients in our workload,"
" then we'd have three instances of ``FlowerClient``. Flower calls "
"``FlowerClient.fit`` on the respective instance when the server selects a"
" particular client for training (and ``FlowerClient.evaluate`` for "
"evaluation)."
msgstr ""
"Our class ``FlowerClient`` defines how local training/evaluation will be "
"performed and allows Flower to call the local training/evaluation through"
" ``fit`` and ``evaluate``. Each instance of ``FlowerClient`` represents a"
" *single client* in our federated learning system. Federated learning "
"systems have multiple clients (otherwise, there's not much to federate), "
"so each client will be represented by its own instance of "
"``FlowerClient``. If we have, for example, three clients in our workload,"
" then we'd have three instances of ``FlowerClient``. Flower calls "
"``FlowerClient.fit`` on the respective instance when the server selects a"
" particular client for training (and ``FlowerClient.evaluate`` for "
"evaluation)."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:541
msgid "Using the Virtual Client Engine"
msgstr "Utilisation du moteur du client virtuel"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:543
msgid ""
"In this notebook, we want to simulate a federated learning system with 10"
" clients on a single machine. This means that the server and all 10 "
"clients will live on a single machine and share resources such as CPU, "
"GPU, and memory. Having 10 clients would mean having 10 instances of "
"``FlowerClient`` in memory. Doing this on a single machine can quickly "
"exhaust the available memory resources, even if only a subset of these "
"clients participates in a single round of federated learning."
msgstr ""
"Dans ce carnet, nous voulons simuler un système d'apprentissage fédéré "
"avec 10 clients sur une seule machine. Cela signifie que le serveur et "
"les 10 clients vivront sur une seule machine et partageront des "
"ressources telles que le CPU, le GPU et la mémoire. Avoir 10 clients "
"signifierait avoir 10 instances de ``FlowerClient`` en mémoire. Faire "
"cela sur une seule machine peut rapidement épuiser les ressources mémoire"
" disponibles, même si seulement un sous-ensemble de ces clients participe"
" à un seul tour d'apprentissage fédéré."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:545
msgid ""
"In addition to the regular capabilities where server and clients run on "
"multiple machines, Flower, therefore, provides special simulation "
"capabilities that create ``FlowerClient`` instances only when they are "
"actually necessary for training or evaluation. To enable the Flower "
"framework to create clients when necessary, we need to implement a "
"function called ``client_fn`` that creates a ``FlowerClient`` instance on"
" demand. Flower calls ``client_fn`` whenever it needs an instance of one "
"particular client to call ``fit`` or ``evaluate`` (those instances are "
"usually discarded after use, so they should not keep any local state). "
"Clients are identified by a client ID, or short ``cid``. The ``cid`` can "
"be used, for example, to load different local data partitions for "
"different clients, as can be seen below:"
msgstr ""
"In addition to the regular capabilities where server and clients run on "
"multiple machines, Flower, therefore, provides special simulation "
"capabilities that create ``FlowerClient`` instances only when they are "
"actually necessary for training or evaluation. To enable the Flower "
"framework to create clients when necessary, we need to implement a "
"function called ``client_fn`` that creates a ``FlowerClient`` instance on"
" demand. Flower calls ``client_fn`` whenever it needs an instance of one "
"particular client to call ``fit`` or ``evaluate`` (those instances are "
"usually discarded after use, so they should not keep any local state). "
"Clients are identified by a client ID, or short ``cid``. The ``cid`` can "
"be used, for example, to load different local data partitions for "
"different clients, as can be seen below:"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:580
msgid "Starting the training"
msgstr "Commencer la formation"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:582
msgid ""
"We now have the class ``FlowerClient`` which defines client-side "
"training/evaluation and ``client_fn`` which allows Flower to create "
"``FlowerClient`` instances whenever it needs to call ``fit`` or "
"``evaluate`` on one particular client. The last step is to start the "
"actual simulation using ``flwr.simulation.start_simulation``."
msgstr ""
"Nous avons maintenant la classe ``FlowerClient`` qui définit "
"l'entraînement/évaluation côté client et ``client_fn`` qui permet à "
"Flower de créer des instances de ``FlowerClient`` chaque fois qu'il a "
"besoin d'appeler ``fit`` ou ``evaluate`` sur un client particulier. La "
"dernière étape consiste à démarrer la simulation réelle en utilisant "
"``flwr.simulation.start_simulation``."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:584
msgid ""
"The function ``start_simulation`` accepts a number of arguments, amongst "
"them the ``client_fn`` used to create ``FlowerClient`` instances, the "
"number of clients to simulate (``num_clients``), the number of federated "
"learning rounds (``num_rounds``), and the strategy. The strategy "
"encapsulates the federated learning approach/algorithm, for example, "
"*Federated Averaging* (FedAvg)."
msgstr ""
"La fonction ``start_simulation`` accepte un certain nombre d'arguments, "
"parmi lesquels le ``client_fn`` utilisé pour créer les instances "
"``FlowerClient``, le nombre de clients à simuler (``num_clients``), le "
"nombre de tours d'apprentissage fédéré (``num_rounds``), et la stratégie."
" La stratégie encapsule l'approche/algorithme d'apprentissage fédéré, par"
" exemple, *Federated Averaging* (FedAvg)."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:586
msgid ""
"Flower has a number of built-in strategies, but we can also use our own "
"strategy implementations to customize nearly all aspects of the federated"
" learning approach. For this example, we use the built-in ``FedAvg`` "
"implementation and customize it using a few basic parameters. The last "
"step is the actual call to ``start_simulation`` which - you guessed it - "
"starts the simulation:"
msgstr ""
"Flower dispose d'un certain nombre de stratégies intégrées, mais nous "
"pouvons également utiliser nos propres implémentations de stratégies pour"
" personnaliser presque tous les aspects de l'approche de l'apprentissage "
"fédéré. Pour cet exemple, nous utilisons l'implémentation intégrée "
"``FedAvg`` et nous la personnalisons en utilisant quelques paramètres de "
"base. La dernière étape est l'appel à ``start_simulation`` qui - tu l'as "
"deviné - démarre la simulation :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:628
msgid "Behind the scenes"
msgstr "Dans les coulisses"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:630
msgid "So how does this work? How does Flower execute this simulation?"
msgstr ""
"Alors, comment cela fonctionne-t-il ? Comment Flower exécute-t-il cette "
"simulation ?"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:632
#, python-format
msgid ""
"When we call ``start_simulation``, we tell Flower that there are 10 "
"clients (``num_clients=10``). Flower then goes ahead an asks the "
"``FedAvg`` strategy to select clients. ``FedAvg`` knows that it should "
"select 100% of the available clients (``fraction_fit=1.0``), so it goes "
"ahead and selects 10 random clients (i.e., 100% of 10)."
msgstr ""
"Lorsque nous appelons ``start_simulation``, nous disons à Flower qu'il y "
"a 10 clients (``num_clients=10``). Flower demande alors à la stratégie "
"``FedAvg`` de sélectionner des clients. ``FedAvg` sait qu'il doit "
"sélectionner 100% des clients disponibles (``fraction_fit=1.0``), alors "
"il choisit 10 clients au hasard (c'est à dire 100% de 10)."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:634
msgid ""
"Flower then asks the selected 10 clients to train the model. When the "
"server receives the model parameter updates from the clients, it hands "
"those updates over to the strategy (*FedAvg*) for aggregation. The "
"strategy aggregates those updates and returns the new global model, which"
" then gets used in the next round of federated learning."
msgstr ""
"Flower demande ensuite aux 10 clients sélectionnés d'entraîner le modèle."
" Lorsque le serveur reçoit les mises à jour des paramètres du modèle de "
"la part des clients, il les transmet à la stratégie (*FedAvg*) pour "
"qu'elle les agrège. La stratégie agrège ces mises à jour et renvoie le "
"nouveau modèle global, qui est ensuite utilisé dans le prochain cycle "
"d'apprentissage fédéré."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:646
msgid "Where's the accuracy?"
msgstr "Où est la précision ?"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:648
msgid ""
"You may have noticed that all metrics except for ``losses_distributed`` "
"are empty. Where did the ``{\"accuracy\": float(accuracy)}`` go?"
msgstr ""
"Tu as peut-être remarqué que toutes les mesures, à l'exception de "
"``pertes_distribuées``, sont vides. Où est passée la ``{\"précision\" : "
"float(précision)}`` ?"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:650
msgid ""
"Flower can automatically aggregate losses returned by individual clients,"
" but it cannot do the same for metrics in the generic metrics dictionary "
"(the one with the ``accuracy`` key). Metrics dictionaries can contain "
"very different kinds of metrics and even key/value pairs that are not "
"metrics at all, so the framework does not (and can not) know how to "
"handle these automatically."
msgstr ""
"Flower peut automatiquement agréger les pertes renvoyées par les clients "
"individuels, mais il ne peut pas faire la même chose pour les mesures "
"dans le dictionnaire de mesures générique (celui avec la clé "
"``accuracy``). Les dictionnaires de mesures peuvent contenir des types de"
" mesures très différents et même des paires clé/valeur qui ne sont pas "
"des mesures du tout, donc le cadre ne sait pas (et ne peut pas) savoir "
"comment les gérer automatiquement."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:652
msgid ""
"As users, we need to tell the framework how to handle/aggregate these "
"custom metrics, and we do so by passing metric aggregation functions to "
"the strategy. The strategy will then call these functions whenever it "
"receives fit or evaluate metrics from clients. The two possible functions"
" are ``fit_metrics_aggregation_fn`` and "
"``evaluate_metrics_aggregation_fn``."
msgstr ""
"En tant qu'utilisateurs, nous devons indiquer au framework comment "
"gérer/agréger ces métriques personnalisées, et nous le faisons en passant"
" des fonctions d'agrégation de métriques à la stratégie. La stratégie "
"appellera alors ces fonctions chaque fois qu'elle recevra des métriques "
"d'ajustement ou d'évaluation de la part des clients. Les deux fonctions "
"possibles sont ``fit_metrics_aggregation_fn`` et "
"``evaluate_metrics_aggregation_fn``."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:654
msgid ""
"Let's create a simple weighted averaging function to aggregate the "
"``accuracy`` metric we return from ``evaluate``:"
msgstr ""
"Créons une simple fonction de calcul de la moyenne pondérée pour agréger "
"la mesure de \"précision\" que nous renvoie ``evaluate`` :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:680
msgid ""
"The only thing left to do is to tell the strategy to call this function "
"whenever it receives evaluation metric dictionaries from the clients:"
msgstr ""
"La seule chose qui reste à faire est d'indiquer à la stratégie d'appeler "
"cette fonction chaque fois qu'elle reçoit des dictionnaires de métriques "
"d'évaluation de la part des clients :"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:717
msgid ""
"We now have a full system that performs federated training and federated "
"evaluation. It uses the ``weighted_average`` function to aggregate custom"
" evaluation metrics and calculates a single ``accuracy`` metric across "
"all clients on the server side."
msgstr ""
"Nous avons maintenant un système complet qui effectue la formation "
"fédérée et l'évaluation fédérée. Il utilise la fonction ``moyenne "
"pondérée`` pour agréger les mesures d'évaluation personnalisées et "
"calcule une seule mesure de ``précision`` pour tous les clients du côté "
"du serveur."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:719
msgid ""
"The other two categories of metrics (``losses_centralized`` and "
"``metrics_centralized``) are still empty because they only apply when "
"centralized evaluation is being used. Part two of the Flower tutorial "
"will cover centralized evaluation."
msgstr ""
"Les deux autres catégories de mesures (``pertes_centralisées`` et "
"``métriques_centralisées``) sont toujours vides car elles ne s'appliquent"
" que lorsque l'évaluation centralisée est utilisée. La deuxième partie du"
" tutoriel sur les fleurs couvrira l'évaluation centralisée."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:731
#: ../../source/tutorial-what-is-federated-learning.ipynb:351
msgid "Final remarks"
msgstr "Remarques finales"

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:733
msgid ""
"Congratulations, you just trained a convolutional neural network, "
"federated over 10 clients! With that, you understand the basics of "
"federated learning with Flower. The same approach you've seen can be used"
" with other machine learning frameworks (not just PyTorch) and tasks (not"
" just CIFAR-10 images classification), for example NLP with Hugging Face "
"Transformers or speech with SpeechBrain."
msgstr ""
"Félicitations, tu viens d'entraîner un réseau neuronal convolutif, fédéré"
" sur 10 clients ! Avec ça, tu comprends les bases de l'apprentissage "
"fédéré avec Flower. La même approche que tu as vue peut être utilisée "
"avec d'autres cadres d'apprentissage automatique (pas seulement PyTorch) "
"et d'autres tâches (pas seulement la classification des images CIFAR-10),"
" par exemple le NLP avec Hugging Face Transformers ou la parole avec "
"SpeechBrain."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:735
msgid ""
"In the next notebook, we're going to cover some more advanced concepts. "
"Want to customize your strategy? Initialize parameters on the server "
"side? Or evaluate the aggregated model on the server side? We'll cover "
"all this and more in the next tutorial."
msgstr ""
"Dans le prochain cahier, nous allons aborder des concepts plus avancés. "
"Tu veux personnaliser ta stratégie ? Initialiser des paramètres côté "
"serveur ? Ou évaluer le modèle agrégé côté serveur ? Nous aborderons tout"
" cela et bien plus encore dans le prochain tutoriel."

#: ../../source/tutorial-get-started-with-flower-pytorch.ipynb:753
#, fuzzy
msgid ""
"The `Flower Federated Learning Tutorial - Part 2 "
"<https://flower.dev/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__ goes into more depth about strategies and all "
"the advanced things you can build with them."
msgstr ""
"Le `Tutoriel d'apprentissage fédéré Flower - Partie 2 "
"<https://flower.dev/docs/tutorial/Flower-2-Strategies-in-FL-"
"PyTorch.html>`__ va plus en profondeur sur les stratégies et toutes les "
"choses avancées que tu peux construire avec elles."

#: ../../source/tutorial-quickstart-android.rst:5
#, fuzzy
msgid "Quickstart Android"
msgstr "Démarrage rapide des Pandas"

#: ../../source/tutorial-quickstart-android.rst:7
#, fuzzy
msgid ""
"Let's build a federated learning system using TFLite and Flower on "
"Android!"
msgstr ""
"Construisons un système d'apprentissage fédéré en utilisant fastai et "
"Flower !"

#: ../../source/tutorial-quickstart-android.rst:9
#, fuzzy
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/android>`_ to learn "
"more."
msgstr ""
"Réfère-toi à l'exemple de code complet "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pandas>`_ "
"pour en savoir plus."

#: ../../source/tutorial-quickstart-fastai.rst:5
msgid "Quickstart fastai"
msgstr "Démarrage rapide fastai"

#: ../../source/tutorial-quickstart-fastai.rst:7
msgid "Let's build a federated learning system using fastai and Flower!"
msgstr ""
"Construisons un système d'apprentissage fédéré en utilisant fastai et "
"Flower !"

#: ../../source/tutorial-quickstart-fastai.rst:9
#, fuzzy
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/quickstart-fastai>`_ "
"to learn more."
msgstr ""
"Réfère-toi à l'exemple de code complet "
"<https://github.com/adap/flower/tree/main/examples/quickstart-fastai>`_ "
"pour en savoir plus."

#: ../../source/tutorial-quickstart-huggingface.rst:5
msgid "Quickstart 🤗 Transformers"
msgstr "Démarrage rapide 🤗 Transformateurs"

#: ../../source/tutorial-quickstart-huggingface.rst:7
msgid ""
"Let's build a federated learning system using Hugging Face Transformers "
"and Flower!"
msgstr ""
"Construisons un système d'apprentissage fédéré à l'aide des "
"transformateurs Hugging Face et de Flower !"

#: ../../source/tutorial-quickstart-huggingface.rst:9
msgid ""
"We will leverage Hugging Face to federate the training of language models"
" over multiple clients using Flower. More specifically, we will fine-tune"
" a pre-trained Transformer model (distilBERT) for sequence classification"
" over a dataset of IMDB ratings. The end goal is to detect if a movie "
"rating is positive or negative."
msgstr ""
"Nous nous appuierons sur Hugging Face pour fédérer l'entraînement de "
"modèles de langage sur plusieurs clients à l'aide de Flower. Plus "
"précisément, nous mettrons au point un modèle Transformer pré-entraîné "
"(distilBERT) pour la classification de séquences sur un ensemble de "
"données d'évaluations IMDB. L'objectif final est de détecter si "
"l'évaluation d'un film est positive ou négative."

#: ../../source/tutorial-quickstart-huggingface.rst:15
msgid "Dependencies"
msgstr "Dépendances"

#: ../../source/tutorial-quickstart-huggingface.rst:17
msgid ""
"To follow along this tutorial you will need to install the following "
"packages: :code:`datasets`, :code:`evaluate`, :code:`flwr`, "
":code:`torch`, and :code:`transformers`. This can be done using "
":code:`pip`:"
msgstr ""
"Pour suivre ce tutoriel, tu devras installer les paquets suivants : "
":code:`datasets`, :code:`evaluate`, :code:`flwr`, :code:`torch`, et "
":code:`transformers`. Cela peut être fait en utilisant :code:`pip` :"

#: ../../source/tutorial-quickstart-huggingface.rst:27
msgid "Standard Hugging Face workflow"
msgstr "Flux de travail standard pour le visage"

#: ../../source/tutorial-quickstart-huggingface.rst:30
msgid "Handling the data"
msgstr "Traitement des données"

#: ../../source/tutorial-quickstart-huggingface.rst:32
msgid ""
"To fetch the IMDB dataset, we will use Hugging Face's :code:`datasets` "
"library. We then need to tokenize the data and create :code:`PyTorch` "
"dataloaders, this is all done in the :code:`load_data` function:"
msgstr ""
"Pour récupérer le jeu de données IMDB, nous utiliserons la bibliothèque "
":code:`datasets` de Hugging Face. Nous devons ensuite tokeniser les "
"données et créer des :code:`PyTorch` dataloaders, ce qui est fait dans la"
" fonction :code:`load_data` :"

#: ../../source/tutorial-quickstart-huggingface.rst:78
msgid "Training and testing the model"
msgstr "Former et tester le modèle"

#: ../../source/tutorial-quickstart-huggingface.rst:80
msgid ""
"Once we have a way of creating our trainloader and testloader, we can "
"take care of the training and testing. This is very similar to any "
":code:`PyTorch` training or testing loop:"
msgstr ""
"Une fois que nous avons trouvé un moyen de créer notre trainloader et "
"notre testloader, nous pouvons nous occuper de l'entraînement et du test."
" C'est très similaire à n'importe quelle boucle d'entraînement ou de test"
" :code:`PyTorch` :"

#: ../../source/tutorial-quickstart-huggingface.rst:118
msgid "Creating the model itself"
msgstr "Créer le modèle lui-même"

#: ../../source/tutorial-quickstart-huggingface.rst:120
msgid ""
"To create the model itself, we will just load the pre-trained distillBERT"
" model using Hugging Face’s :code:`AutoModelForSequenceClassification` :"
msgstr ""
"Pour créer le modèle lui-même, nous allons simplement charger le modèle "
"distillBERT pré-entraîné en utilisant le "
":code:`AutoModelForSequenceClassification` de Hugging Face :"

#: ../../source/tutorial-quickstart-huggingface.rst:133
msgid "Federating the example"
msgstr "Fédérer l'exemple"

#: ../../source/tutorial-quickstart-huggingface.rst:136
msgid "Creating the IMDBClient"
msgstr "Création du client IMDBC"

#: ../../source/tutorial-quickstart-huggingface.rst:138
msgid ""
"To federate our example to multiple clients, we first need to write our "
"Flower client class (inheriting from :code:`flwr.client.NumPyClient`). "
"This is very easy, as our model is a standard :code:`PyTorch` model:"
msgstr ""
"Pour fédérer notre exemple à plusieurs clients, nous devons d'abord "
"écrire notre classe de client Flower (héritant de "
":code:`flwr.client.NumPyClient`). C'est très facile, car notre modèle est"
" un modèle :code:`PyTorch` standard :"

#: ../../source/tutorial-quickstart-huggingface.rst:166
msgid ""
"The :code:`get_parameters` function lets the server get the client's "
"parameters. Inversely, the :code:`set_parameters` function allows the "
"server to send its parameters to the client. Finally, the :code:`fit` "
"function trains the model locally for the client, and the "
":code:`evaluate` function tests the model locally and returns the "
"relevant metrics."
msgstr ""
"La fonction :code:`get_parameters` permet au serveur d'obtenir les "
"paramètres du client. Inversement, la fonction :code:`set_parameters` "
"permet au serveur d'envoyer ses paramètres au client. Enfin, la fonction "
":code:`fit` forme le modèle localement pour le client, et la fonction "
":code:`evaluate` teste le modèle localement et renvoie les mesures "
"correspondantes."

#: ../../source/tutorial-quickstart-huggingface.rst:172
msgid "Starting the server"
msgstr "Démarrer le serveur"

#: ../../source/tutorial-quickstart-huggingface.rst:174
msgid ""
"Now that we have a way to instantiate clients, we need to create our "
"server in order to aggregate the results. Using Flower, this can be done "
"very easily by first choosing a strategy (here, we are using "
":code:`FedAvg`, which will define the global weights as the average of "
"all the clients' weights at each round) and then using the "
":code:`flwr.server.start_server` function:"
msgstr ""
"Maintenant que nous avons un moyen d'instancier les clients, nous devons "
"créer notre serveur afin d'agréger les résultats. Avec Flower, cela peut "
"être fait très facilement en choisissant d'abord une stratégie (ici, nous"
" utilisons :code:`FedAvg`, qui définira les poids globaux comme la "
"moyenne des poids de tous les clients à chaque tour) et en utilisant "
"ensuite la fonction :code:`flwr.server.start_server` :"

#: ../../source/tutorial-quickstart-huggingface.rst:202
msgid ""
"The :code:`weighted_average` function is there to provide a way to "
"aggregate the metrics distributed amongst the clients (basically this "
"allows us to display a nice average accuracy and loss for every round)."
msgstr ""
"La fonction :code:`weighted_average` est là pour fournir un moyen "
"d'agréger les mesures réparties entre les clients (en gros, cela nous "
"permet d'afficher une belle moyenne de précision et de perte pour chaque "
"tour)."

#: ../../source/tutorial-quickstart-huggingface.rst:206
msgid "Putting everything together"
msgstr "Tout assembler"

#: ../../source/tutorial-quickstart-huggingface.rst:208
msgid "We can now start client instances using:"
msgstr "Nous pouvons maintenant démarrer des instances de clients en utilisant :"

#: ../../source/tutorial-quickstart-huggingface.rst:218
msgid ""
"And they will be able to connect to the server and start the federated "
"training."
msgstr "Et ils pourront se connecter au serveur et démarrer la formation fédérée."

#: ../../source/tutorial-quickstart-huggingface.rst:220
#, fuzzy
msgid ""
"If you want to check out everything put together, you should check out "
"the full code example: [https://github.com/adap/flower/tree/main/examples"
"/quickstart-"
"huggingface](https://github.com/adap/flower/tree/main/examples"
"/quickstart-huggingface)."
msgstr ""
"Si tu veux voir tout ce qui est mis ensemble, tu devrais consulter "
"l'exemple de code complet : "
"[https://github.com/adap/flower/tree/main/examples/quickstart-"
"huggingface](https://github.com/adap/flower/tree/main/examples"
"/quickstart-huggingface)."

#: ../../source/tutorial-quickstart-huggingface.rst:224
msgid ""
"Of course, this is a very basic example, and a lot can be added or "
"modified, it was just to showcase how simply we could federate a Hugging "
"Face workflow using Flower."
msgstr ""
"Bien sûr, c'est un exemple très basique, et beaucoup de choses peuvent "
"être ajoutées ou modifiées, il s'agissait juste de montrer avec quelle "
"simplicité on pouvait fédérer un flux de travail Hugging Face à l'aide de"
" Flower."

#: ../../source/tutorial-quickstart-huggingface.rst:227
msgid ""
"Note that in this example we used :code:`PyTorch`, but we could have very"
" well used :code:`TensorFlow`."
msgstr ""
"Notez que dans cet exemple, nous avons utilisé :code:`PyTorch`, mais nous"
" aurions très bien pu utiliser :code:`TensorFlow`."

#: ../../source/tutorial-quickstart-ios.rst:5
#, fuzzy
msgid "Quickstart iOS"
msgstr "Démarrage rapide XGBoost"

#: ../../source/tutorial-quickstart-ios.rst:7
#, fuzzy
msgid ""
"In this tutorial we will learn how to train a Neural Network on MNIST "
"using Flower and CoreML on iOS devices."
msgstr ""
"Dans ce tutoriel, nous allons apprendre, comment former un réseau "
"neuronal convolutif sur MNIST en utilisant Flower et PyTorch."

#: ../../source/tutorial-quickstart-ios.rst:9
#, fuzzy
msgid ""
"First of all, for running the Flower Python server, it is recommended to "
"create a virtual environment and run everything within a `virtualenv "
"<https://flower.dev/docs/recommended-env-setup.html>`_. For the Flower "
"client implementation in iOS, it is recommended to use Xcode as our IDE."
msgstr ""
"Tout d'abord, il est recommandé de créer un environnement virtuel et de "
"tout exécuter au sein d'un `virtualenv <https://flower.dev/docs"
"/recommended-env-setup.html>`_."

#: ../../source/tutorial-quickstart-ios.rst:12
#, fuzzy
msgid ""
"Our example consists of one Python *server* and two iPhone *clients* that"
" all have the same model."
msgstr ""
"Notre exemple consiste en un *serveur* et deux *clients* ayant tous le "
"même modèle."

#: ../../source/tutorial-quickstart-ios.rst:14
#, fuzzy
msgid ""
"*Clients* are responsible for generating individual weight updates for "
"the model based on their local datasets. These updates are then sent to "
"the *server* which will aggregate them to produce a better model. "
"Finally, the *server* sends this improved version of the model back to "
"each *client*. A complete cycle of weight updates is called a *round*."
msgstr ""
"*Les clients* sont chargés de générer des mises à jour de poids "
"individuelles pour le modèle en fonction de leurs ensembles de données "
"locales. Ces mises à jour sont ensuite envoyées au *serveur* qui les "
"agrège pour produire un meilleur modèle. Enfin, le *serveur* renvoie "
"cette version améliorée du modèle à chaque *client*. Un cycle complet de "
"mises à jour de poids s'appelle un *round*."

#: ../../source/tutorial-quickstart-ios.rst:18
#, fuzzy
msgid ""
"Now that we have a rough idea of what is going on, let's get started to "
"setup our Flower server environment. We first need to install Flower. You"
" can do this by using pip:"
msgstr ""
"Maintenant que nous avons une idée générale de ce qui se passe, "
"commençons. Nous devons d'abord installer Flower. Tu peux le faire en "
"exécutant :"

#: ../../source/tutorial-quickstart-ios.rst:24
msgid "Or Poetry:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:33
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training using CoreML as our local training pipeline and "
"MNIST as our dataset. For simplicity reasons we will use the complete "
"Flower client with CoreML, that has been implemented and stored inside "
"the Swift SDK. The client implementation can be seen below:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:69
msgid ""
"Let's create a new application project in Xcode and add :code:`flwr` as a"
" dependency in your project. For our application, we will store the logic"
" of our app in :code:`FLiOSModel.swift` and the UI elements in "
":code:`ContentView.swift`. We will focus more on :code:`FLiOSModel.swift`"
" in this quickstart. Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/ios>`_ to learn more "
"about the app."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:72
msgid "Import Flower and CoreML related packages in :code:`FLiOSModel.swift`:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:80
msgid ""
"Then add the mlmodel to the project simply by drag-and-drop, the mlmodel "
"will be bundled inside the application during deployment to your iOS "
"device. We need to pass the url to access mlmodel and run CoreML machine "
"learning processes, it can be retrieved by calling the function "
":code:`Bundle.main.url`. For the MNIST dataset, we need to preprocess it "
"into :code:`MLBatchProvider` object. The preprocessing is done inside "
":code:`DataLoader.swift`."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:96
msgid ""
"Since CoreML does not allow the model parameters to be seen before "
"training, and accessing the model parameters during or after the training"
" can only be done by specifying the layer name, we need to know this "
"informations beforehand, through looking at the model specification, "
"which are written as proto files. The implementation can be seen in "
":code:`MLModelInspect`."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:99
msgid ""
"After we have all of the necessary informations, let's create our Flower "
"client."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:114
msgid ""
"Then start the Flower gRPC client and start communicating to the server "
"by passing our Flower client to the function :code:`startFlwrGRPC`."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:121
msgid ""
"That's it for the client. We only have to implement :code:`Client` or "
"call the provided :code:`MLFlwrClient` and call :code:`startFlwrGRPC()`. "
"The attribute :code:`hostname` and :code:`port` tells the client which "
"server to connect to. This can be done by entering the hostname and port "
"in the application before clicking the start button to start the "
"federated learning process."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:128
#: ../../source/tutorial-quickstart-mxnet.rst:223
#: ../../source/tutorial-quickstart-pytorch.rst:202
#: ../../source/tutorial-quickstart-tensorflow.rst:97
msgid ""
"For simple workloads we can start a Flower server and leave all the "
"configuration possibilities at their default values. In a file named "
":code:`server.py`, import Flower and start the server:"
msgstr ""
"Pour les charges de travail simples, nous pouvons démarrer un serveur "
"Flower et laisser toutes les possibilités de configuration à leurs "
"valeurs par défaut. Dans un fichier nommé :code:`server.py`, importe "
"Flower et démarre le serveur :"

#: ../../source/tutorial-quickstart-ios.rst:139
#: ../../source/tutorial-quickstart-mxnet.rst:234
#: ../../source/tutorial-quickstart-pytorch.rst:213
#: ../../source/tutorial-quickstart-scikitlearn.rst:212
#: ../../source/tutorial-quickstart-tensorflow.rst:109
msgid "Train the model, federated!"
msgstr "Entraîne le modèle, fédéré !"

#: ../../source/tutorial-quickstart-ios.rst:141
#: ../../source/tutorial-quickstart-pytorch.rst:215
#: ../../source/tutorial-quickstart-tensorflow.rst:111
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. FL systems usually have a server and "
"multiple clients. We therefore have to start the server first:"
msgstr ""
"Le client et le serveur étant prêts, nous pouvons maintenant tout "
"exécuter et voir l'apprentissage fédéré en action. Les systèmes FL ont "
"généralement un serveur et plusieurs clients. Nous devons donc commencer "
"par démarrer le serveur :"

#: ../../source/tutorial-quickstart-ios.rst:149
msgid ""
"Once the server is running we can start the clients in different "
"terminals. Build and run the client through your Xcode, one through Xcode"
" Simulator and the other by deploying it to your iPhone. To see more "
"about how to deploy your app to iPhone or Simulator visit `here "
"<https://developer.apple.com/documentation/xcode/running-your-app-in-"
"simulator-or-on-a-device>`_."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:153
#, fuzzy
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system in your ios device. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/ios>`_ for this "
"example can be found in :code:`examples/ios`."
msgstr ""
"Félicitations ! Tu as réussi à construire et à faire fonctionner ton "
"premier système d'apprentissage fédéré. Le code source complet "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"mxnet/client.py>`_ de cet exemple se trouve dans :code:`examples"
"/quickstart-mxnet`."

#: ../../source/tutorial-quickstart-jax.rst:5
msgid "Quickstart JAX"
msgstr "Démarrage rapide de JAX"

#: ../../source/tutorial-quickstart-mxnet.rst:5
msgid "Quickstart MXNet"
msgstr "Démarrage rapide de MXNet"

#: ../../source/tutorial-quickstart-mxnet.rst:7
msgid ""
"In this tutorial, we will learn how to train a :code:`Sequential` model "
"on MNIST using Flower and MXNet."
msgstr ""
"Dans ce tutoriel, nous allons apprendre à former un modèle "
":code:`Sequential` sur MNIST à l'aide de Flower et de MXNet."

#: ../../source/tutorial-quickstart-mxnet.rst:9
#: ../../source/tutorial-quickstart-scikitlearn.rst:9
msgid ""
"It is recommended to create a virtual environment and run everything "
"within this `virtualenv <https://flower.dev/docs/recommended-env-"
"setup.html>`_."
msgstr ""
"Il est recommandé de créer un environnement virtuel et de tout exécuter "
"dans ce `virtualenv <https://flower.dev/docs/recommended-env-"
"setup.html>`_."

#: ../../source/tutorial-quickstart-mxnet.rst:13
#: ../../source/tutorial-quickstart-scikitlearn.rst:13
msgid ""
"*Clients* are responsible for generating individual model parameter "
"updates for the model based on their local datasets. These updates are "
"then sent to the *server* which will aggregate them to produce an updated"
" global model. Finally, the *server* sends this improved version of the "
"model back to each *client*. A complete cycle of parameters updates is "
"called a *round*."
msgstr ""
"*Les clients* sont chargés de générer des mises à jour individuelles des "
"paramètres du modèle en fonction de leurs ensembles de données locales. "
"Ces mises à jour sont ensuite envoyées au *serveur* qui les agrège pour "
"produire un modèle global mis à jour. Enfin, le *serveur* renvoie cette "
"version améliorée du modèle à chaque *client*. Un cycle complet de mises "
"à jour des paramètres s'appelle un *round*."

#: ../../source/tutorial-quickstart-mxnet.rst:17
#: ../../source/tutorial-quickstart-scikitlearn.rst:17
msgid ""
"Now that we have a rough idea of what is going on, let's get started. We "
"first need to install Flower. You can do this by running:"
msgstr ""
"Maintenant que nous avons une idée approximative de ce qui se passe, "
"commençons. Nous devons d'abord installer Flower. Tu peux le faire en "
"lançant :"

#: ../../source/tutorial-quickstart-mxnet.rst:23
msgid "Since we want to use MXNet, let's go ahead and install it:"
msgstr "Puisque nous voulons utiliser MXNet, allons-y et installons-le :"

#: ../../source/tutorial-quickstart-mxnet.rst:33
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training "
"procedure and network architecture are based on MXNet´s `Hand-written "
"Digit Recognition tutorial "
"<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_."
msgstr ""
"Maintenant que toutes nos dépendances sont installées, lançons une "
"formation distribuée simple avec deux clients et un serveur. Notre "
"procédure de formation et l'architecture du réseau sont basées sur le "
"tutoriel de reconnaissance de chiffres écrits à la main du MXNet "
"<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_."

#: ../../source/tutorial-quickstart-mxnet.rst:35
msgid ""
"In a file called :code:`client.py`, import Flower and MXNet related "
"packages:"
msgstr ""
"Dans un fichier appelé :code:`client.py`, importe Flower et les paquets "
"liés au MXNet :"

#: ../../source/tutorial-quickstart-mxnet.rst:50
msgid "In addition, define the device allocation in MXNet with:"
msgstr "En outre, définis l'attribution de l'appareil dans MXNet avec :"

#: ../../source/tutorial-quickstart-mxnet.rst:56
msgid ""
"We use MXNet to load MNIST, a popular image classification dataset of "
"handwritten digits for machine learning. The MXNet utility "
":code:`mx.test_utils.get_mnist()` downloads the training and test data."
msgstr ""
"Nous utilisons MXNet pour charger MNIST, un ensemble de données de "
"classification d'images populaire de chiffres manuscrits pour "
"l'apprentissage automatique. L'utilitaire MXNet "
":code:`mx.test_utils.get_mnist()` télécharge les données d'entraînement "
"et de test."

#: ../../source/tutorial-quickstart-mxnet.rst:70
msgid ""
"Define the training and loss with MXNet. We train the model by looping "
"over the dataset, measure the corresponding loss, and optimize it."
msgstr ""
"Définis l'entraînement et la perte avec MXNet. Nous entraînons le modèle "
"en parcourant en boucle l'ensemble des données, nous mesurons la perte "
"correspondante et nous l'optimisons."

#: ../../source/tutorial-quickstart-mxnet.rst:108
msgid ""
"Next, we define the validation of our machine learning model. We loop "
"over the test set and measure both loss and accuracy on the test set."
msgstr ""
"Ensuite, nous définissons la validation de notre modèle d'apprentissage "
"automatique. Nous effectuons une boucle sur l'ensemble de test et "
"mesurons à la fois la perte et la précision sur l'ensemble de test."

#: ../../source/tutorial-quickstart-mxnet.rst:132
msgid ""
"After defining the training and testing of a MXNet machine learning "
"model, we use these functions to implement a Flower client."
msgstr ""
"Après avoir défini la formation et le test d'un modèle d'apprentissage "
"automatique MXNet, nous utilisons ces fonctions pour mettre en œuvre un "
"client Flower."

#: ../../source/tutorial-quickstart-mxnet.rst:134
msgid "Our Flower clients will use a simple :code:`Sequential` model:"
msgstr "Nos clients Flower utiliseront un modèle simple :code:`Sequential` :"

#: ../../source/tutorial-quickstart-mxnet.rst:153
msgid ""
"After loading the dataset with :code:`load_data()` we perform one forward"
" propagation to initialize the model and model parameters with "
":code:`model(init)`. Next, we implement a Flower client."
msgstr ""
"Après avoir chargé l'ensemble de données avec :code:`load_data()`, nous "
"effectuons une propagation vers l'avant pour initialiser le modèle et les"
" paramètres du modèle avec :code:`model(init)`. Ensuite, nous "
"implémentons un client Flower."

#: ../../source/tutorial-quickstart-mxnet.rst:155
#: ../../source/tutorial-quickstart-pytorch.rst:141
#: ../../source/tutorial-quickstart-tensorflow.rst:51
msgid ""
"The Flower server interacts with clients through an interface called "
":code:`Client`. When the server selects a particular client for training,"
" it sends training instructions over the network. The client receives "
"those instructions and calls one of the :code:`Client` methods to run "
"your code (i.e., to train the neural network we defined earlier)."
msgstr ""
"Le serveur Flower interagit avec les clients par le biais d'une interface"
" appelée :code:`Client`. Lorsque le serveur sélectionne un client "
"particulier pour la formation, il envoie des instructions de formation "
"sur le réseau. Le client reçoit ces instructions et appelle l'une des "
"méthodes :code:`Client` pour exécuter ton code (c'est-à-dire pour former "
"le réseau neuronal que nous avons défini plus tôt)."

#: ../../source/tutorial-quickstart-mxnet.rst:161
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which "
"makes it easier to implement the :code:`Client` interface when your "
"workload uses MXNet. Implementing :code:`NumPyClient` usually means "
"defining the following methods (:code:`set_parameters` is optional "
"though):"
msgstr ""
"Flower fournit une classe de commodité appelée :code:`NumPyClient` qui "
"facilite l'implémentation de l'interface :code:`Client` lorsque ta charge"
" de travail utilise MXNet. L'implémentation de :code:`NumPyClient` "
"signifie généralement la définition des méthodes suivantes "
"(:code:`set_parameters` est cependant facultatif) :"

#: ../../source/tutorial-quickstart-mxnet.rst:167
#: ../../source/tutorial-quickstart-pytorch.rst:153
#: ../../source/tutorial-quickstart-scikitlearn.rst:106
msgid "return the model weight as a list of NumPy ndarrays"
msgstr "renvoie le poids du modèle sous la forme d'une liste de ndarrays NumPy"

#: ../../source/tutorial-quickstart-mxnet.rst:168
#: ../../source/tutorial-quickstart-pytorch.rst:154
#: ../../source/tutorial-quickstart-scikitlearn.rst:108
msgid ":code:`set_parameters` (optional)"
msgstr ":code:`set_parameters` (optionnel)"

#: ../../source/tutorial-quickstart-mxnet.rst:169
#: ../../source/tutorial-quickstart-pytorch.rst:155
#: ../../source/tutorial-quickstart-scikitlearn.rst:108
msgid ""
"update the local model weights with the parameters received from the "
"server"
msgstr ""
"mettre à jour les poids du modèle local avec les paramètres reçus du "
"serveur"

#: ../../source/tutorial-quickstart-mxnet.rst:171
#: ../../source/tutorial-quickstart-pytorch.rst:157
#: ../../source/tutorial-quickstart-scikitlearn.rst:111
msgid "set the local model weights"
msgstr "fixe les poids du modèle local"

#: ../../source/tutorial-quickstart-mxnet.rst:172
#: ../../source/tutorial-quickstart-pytorch.rst:158
#: ../../source/tutorial-quickstart-scikitlearn.rst:112
msgid "train the local model"
msgstr "entraîne le modèle local"

#: ../../source/tutorial-quickstart-mxnet.rst:173
#: ../../source/tutorial-quickstart-pytorch.rst:159
#: ../../source/tutorial-quickstart-scikitlearn.rst:113
msgid "receive the updated local model weights"
msgstr "recevoir les poids du modèle local mis à jour"

#: ../../source/tutorial-quickstart-mxnet.rst:175
#: ../../source/tutorial-quickstart-pytorch.rst:161
#: ../../source/tutorial-quickstart-scikitlearn.rst:115
msgid "test the local model"
msgstr "teste le modèle local"

#: ../../source/tutorial-quickstart-mxnet.rst:177
msgid "They can be implemented in the following way:"
msgstr "Ils peuvent être mis en œuvre de la manière suivante :"

#: ../../source/tutorial-quickstart-mxnet.rst:207
msgid ""
"We can now create an instance of our class :code:`MNISTClient` and add "
"one line to actually run this client:"
msgstr ""
"Nous pouvons maintenant créer une instance de notre classe "
":code:`MNISTClient` et ajouter une ligne pour exécuter ce client :"

#: ../../source/tutorial-quickstart-mxnet.rst:214
#: ../../source/tutorial-quickstart-scikitlearn.rst:147
msgid ""
"That's it for the client. We only have to implement :code:`Client` or "
":code:`NumPyClient` and call :code:`fl.client.start_client()`. The string "
":code:`\"0.0.0.0:8080\"` tells the client which server to connect to. In "
"our case we can run the server and the client on the same machine, "
"therefore we use :code:`\"0.0.0.0:8080\"`. If we run a truly federated "
"workload with the server and clients running on different machines, all "
"that needs to change is the :code:`server_address` we pass to the client."
msgstr ""
"C'est tout pour le client. Il nous suffit d'implémenter :code:`Client` ou"
" :code:`NumPyClient` et d'appeler :code:`fl.client.start_client()`. La chaîne :code:`\"0.0.0:8080\"` "
"indique au client à quel serveur se connecter. Dans notre cas, nous "
"pouvons exécuter le serveur et le client sur la même machine, c'est "
"pourquoi nous utilisons :code:`\"0.0.0:8080\"`. Si nous exécutons une "
"charge de travail véritablement fédérée avec le serveur et les clients "
"s'exécutant sur des machines différentes, tout ce qui doit changer est "
":code:`server_address` que nous transmettons au client."

#: ../../source/tutorial-quickstart-mxnet.rst:236
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. Federated learning systems usually have a "
"server and multiple clients. We therefore have to start the server first:"
msgstr ""
"Le client et le serveur étant prêts, nous pouvons maintenant tout "
"exécuter et voir l'apprentissage fédéré en action. Les systèmes "
"d'apprentissage fédéré ont généralement un serveur et plusieurs clients. "
"Nous devons donc commencer par démarrer le serveur :"

#: ../../source/tutorial-quickstart-mxnet.rst:244
#: ../../source/tutorial-quickstart-pytorch.rst:223
#: ../../source/tutorial-quickstart-scikitlearn.rst:221
#: ../../source/tutorial-quickstart-tensorflow.rst:119
msgid ""
"Once the server is running we can start the clients in different "
"terminals. Open a new terminal and start the first client:"
msgstr ""
"Une fois que le serveur fonctionne, nous pouvons démarrer les clients "
"dans différents terminaux. Ouvre un nouveau terminal et démarre le "
"premier client :"

#: ../../source/tutorial-quickstart-mxnet.rst:251
#: ../../source/tutorial-quickstart-pytorch.rst:230
#: ../../source/tutorial-quickstart-scikitlearn.rst:228
#: ../../source/tutorial-quickstart-tensorflow.rst:126
msgid "Open another terminal and start the second client:"
msgstr "Ouvre un autre terminal et démarre le deuxième client :"

#: ../../source/tutorial-quickstart-mxnet.rst:257
#: ../../source/tutorial-quickstart-pytorch.rst:236
#: ../../source/tutorial-quickstart-scikitlearn.rst:234
msgid ""
"Each client will have its own dataset. You should now see how the "
"training does in the very first terminal (the one that started the "
"server):"
msgstr ""
"Chaque client aura son propre ensemble de données. Tu devrais maintenant "
"voir comment la formation se déroule dans le tout premier terminal (celui"
" qui a démarré le serveur) :"

#: ../../source/tutorial-quickstart-mxnet.rst:289
#, fuzzy
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"mxnet/client.py>`_ for this example can be found in :code:`examples"
"/quickstart-mxnet`."
msgstr ""
"Félicitations ! Tu as réussi à construire et à faire fonctionner ton "
"premier système d'apprentissage fédéré. Le code source complet "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"mxnet/client.py>`_ de cet exemple se trouve dans :code:`examples"
"/quickstart-mxnet`."

#: ../../source/tutorial-quickstart-pandas.rst:5
msgid "Quickstart Pandas"
msgstr "Démarrage rapide des Pandas"

#: ../../source/tutorial-quickstart-pandas.rst:7
msgid "Let's build a federated analytics system using Pandas and Flower!"
msgstr "Construisons un système d'analyse fédéré à l'aide de Pandas et de Flower !"

#: ../../source/tutorial-quickstart-pandas.rst:9
#, fuzzy
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pandas>`_ "
"to learn more."
msgstr ""
"Réfère-toi à l'exemple de code complet "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pandas>`_ "
"pour en savoir plus."

#: ../../source/tutorial-quickstart-pytorch.rst:10
msgid ""
"In this tutorial we will learn how to train a Convolutional Neural "
"Network on CIFAR10 using Flower and PyTorch."
msgstr ""
"Dans ce tutoriel, nous allons apprendre à entraîner un réseau neuronal "
"convolutif sur CIFAR10 à l'aide de Flower et PyTorch."

#: ../../source/tutorial-quickstart-pytorch.rst:12
msgid ""
"First of all, it is recommended to create a virtual environment and run "
"everything within a `virtualenv <https://flower.dev/docs/recommended-env-"
"setup.html>`_."
msgstr ""
"Tout d'abord, il est recommandé de créer un environnement virtuel et de "
"tout exécuter au sein d'un `virtualenv <https://flower.dev/docs"
"/recommended-env-setup.html>`_."

#: ../../source/tutorial-quickstart-pytorch.rst:26
msgid ""
"Since we want to use PyTorch to solve a computer vision task, let's go "
"ahead and install PyTorch and the **torchvision** library:"
msgstr ""
"Puisque nous voulons utiliser PyTorch pour résoudre une tâche de vision "
"par ordinateur, allons-y et installons PyTorch et la bibliothèque "
"**torchvision** :"

#: ../../source/tutorial-quickstart-pytorch.rst:36
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training "
"procedure and network architecture are based on PyTorch's `Deep Learning "
"with PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
msgstr ""
"Maintenant que nous avons installé toutes nos dépendances, lançons une "
"formation distribuée simple avec deux clients et un serveur. Notre "
"procédure de formation et l'architecture de notre réseau sont basées sur "
"`Deep Learning with PyTorch "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ de"
" PyTorch."

#: ../../source/tutorial-quickstart-pytorch.rst:38
msgid ""
"In a file called :code:`client.py`, import Flower and PyTorch related "
"packages:"
msgstr ""
"Dans un fichier appelé :code:`client.py`, importe Flower et les paquets "
"liés à PyTorch :"

#: ../../source/tutorial-quickstart-pytorch.rst:53
msgid "In addition, we define the device allocation in PyTorch with:"
msgstr "En outre, nous définissons l'attribution des appareils dans PyTorch avec :"

#: ../../source/tutorial-quickstart-pytorch.rst:59
msgid ""
"We use PyTorch to load CIFAR10, a popular colored image classification "
"dataset for machine learning. The PyTorch :code:`DataLoader()` downloads "
"the training and test data that are then normalized."
msgstr ""
"Nous utilisons PyTorch pour charger CIFAR10, un ensemble de données de "
"classification d'images colorées populaire pour l'apprentissage "
"automatique. Le :code:`DataLoader()` de PyTorch télécharge les données "
"d'entraînement et de test qui sont ensuite normalisées."

#: ../../source/tutorial-quickstart-pytorch.rst:75
msgid ""
"Define the loss and optimizer with PyTorch. The training of the dataset "
"is done by looping over the dataset, measure the corresponding loss and "
"optimize it."
msgstr ""
"Définis la perte et l'optimiseur avec PyTorch L'entraînement de "
"l'ensemble de données se fait en bouclant sur l'ensemble de données, en "
"mesurant la perte correspondante et en l'optimisant."

#: ../../source/tutorial-quickstart-pytorch.rst:91
msgid ""
"Define then the validation of the  machine learning network. We loop over"
" the test set and measure the loss and accuracy of the test set."
msgstr ""
"Définis ensuite la validation du réseau d'apprentissage automatique. Nous"
" passons en boucle sur l'ensemble de test et mesurons la perte et la "
"précision de l'ensemble de test."

#: ../../source/tutorial-quickstart-pytorch.rst:110
msgid ""
"After defining the training and testing of a PyTorch machine learning "
"model, we use the functions for the Flower clients."
msgstr ""
"Après avoir défini l'entraînement et le test d'un modèle d'apprentissage "
"automatique PyTorch, nous utilisons les fonctions pour les clients "
"Flower."

#: ../../source/tutorial-quickstart-pytorch.rst:112
msgid ""
"The Flower clients will use a simple CNN adapted from 'PyTorch: A 60 "
"Minute Blitz':"
msgstr ""
"Les clients de Flower utiliseront un CNN simple adapté de \"PyTorch : A "
"60 Minute Blitz\" :"

#: ../../source/tutorial-quickstart-pytorch.rst:139
msgid ""
"After loading the data set with :code:`load_data()` we define the Flower "
"interface."
msgstr ""
"Après avoir chargé l'ensemble des données avec :code:`load_data()`, nous "
"définissons l'interface Flower."

#: ../../source/tutorial-quickstart-pytorch.rst:147
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which "
"makes it easier to implement the :code:`Client` interface when your "
"workload uses PyTorch. Implementing :code:`NumPyClient` usually means "
"defining the following methods (:code:`set_parameters` is optional "
"though):"
msgstr ""
"Flower fournit une classe de commodité appelée :code:`NumPyClient` qui "
"facilite la mise en œuvre de l'interface :code:`Client` lorsque ta charge"
" de travail utilise PyTorch. Mettre en œuvre :code:`NumPyClient` signifie"
" généralement définir les méthodes suivantes (:code:`set_parameters` est "
"cependant facultatif) :"

#: ../../source/tutorial-quickstart-pytorch.rst:163
msgid "which can be implemented in the following way:"
msgstr "qui peut être mis en œuvre de la manière suivante :"

#: ../../source/tutorial-quickstart-pytorch.rst:186
#: ../../source/tutorial-quickstart-tensorflow.rst:79
msgid ""
"We can now create an instance of our class :code:`CifarClient` and add "
"one line to actually run this client:"
msgstr ""
"Nous pouvons maintenant créer une instance de notre classe "
":code:`CifarClient` et ajouter une ligne pour exécuter ce client :"

#: ../../source/tutorial-quickstart-pytorch.rst:193
#: ../../source/tutorial-quickstart-tensorflow.rst:87
msgid ""
"That's it for the client. We only have to implement :code:`Client` or "
":code:`NumPyClient` and call :code:`fl.client.start_client()`. The string :code:`\"[::]:8080\"` "
"tells the client which server to connect to. In our case we can run the "
"server and the client on the same machine, therefore we use "
":code:`\"[::]:8080\"`. If we run a truly federated workload with the "
"server and clients running on different machines, all that needs to "
"change is the :code:`server_address` we point the client at."
msgstr ""
"C'est tout pour le client. Il nous suffit d'implémenter :code:`Client` ou"
" :code:`NumPyClient` et d'appeler :code:`fl.client.start_client()`. La chaîne :code:`\"[: :]:8080\"` "
"indique au client à quel serveur se connecter. Dans notre cas, nous "
"pouvons exécuter le serveur et le client sur la même machine, c'est "
"pourquoi nous utilisons :code:`\"[: :]:8080\"`. Si nous exécutons une "
"charge de travail véritablement fédérée avec le serveur et les clients "
"fonctionnant sur des machines différentes, tout ce qui doit changer est "
"l'adresse :code:`server_address` vers laquelle nous dirigeons le client."

#: ../../source/tutorial-quickstart-pytorch.rst:268
#, fuzzy
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"pytorch/client.py>`_ for this example can be found in :code:`examples"
"/quickstart-pytorch`."
msgstr ""
"Félicitations ! Tu as réussi à construire et à faire fonctionner ton "
"premier système d'apprentissage fédéré. Le code source complet "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"pytorch/client.py>`_ de cet exemple se trouve dans :code:`examples"
"/quickstart-pytorch`."

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:5
msgid "Quickstart PyTorch Lightning"
msgstr "Démarrage rapide de PyTorch Lightning"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:7
msgid ""
"Let's build a federated learning system using PyTorch Lightning and "
"Flower!"
msgstr ""
"Construisons un système d'apprentissage fédéré en utilisant PyTorch "
"Lightning et Flower !"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:9
#, fuzzy
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pytorch-"
"lightning>`_ to learn more."
msgstr ""
"Réfère-toi à l'exemple de code complet "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pytorch-"
"lightning>`_ pour en savoir plus."

#: ../../source/tutorial-quickstart-scikitlearn.rst:5
msgid "Quickstart scikit-learn"
msgstr "Démarrage rapide de scikit-learn"

#: ../../source/tutorial-quickstart-scikitlearn.rst:7
msgid ""
"In this tutorial, we will learn how to train a :code:`Logistic "
"Regression` model on MNIST using Flower and scikit-learn."
msgstr ""
"Dans ce tutoriel, nous allons apprendre à former un :code:`modèle de "
"régression logistique` sur MNIST en utilisant Flower et scikit-learn."

#: ../../source/tutorial-quickstart-scikitlearn.rst:23
msgid "Since we want to use scikt-learn, let's go ahead and install it:"
msgstr "Puisque nous voulons utiliser scikt-learn, allons-y et installons-le :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:29
msgid "Or simply install all dependencies using Poetry:"
msgstr "Ou installe simplement toutes les dépendances à l'aide de Poetry :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:39
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. However, before "
"setting up the client and server, we will define all functionalities that"
" we need for our federated learning setup within :code:`utils.py`. The "
":code:`utils.py` contains different functions defining all the machine "
"learning basics:"
msgstr ""
"Maintenant que toutes nos dépendances sont installées, exécutons une "
"formation distribuée simple avec deux clients et un serveur. Cependant, "
"avant de configurer le client et le serveur, nous allons définir toutes "
"les fonctionnalités dont nous avons besoin pour notre configuration "
"d'apprentissage fédéré dans :code:`utils.py`. Le :code:`utils.py` "
"contient différentes fonctions définissant toutes les bases de "
"l'apprentissage automatique :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:42
msgid ":code:`get_model_parameters()`"
msgstr ":code:`get_model_parameters()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:43
msgid "Returns the paramters of a :code:`sklearn` LogisticRegression model"
msgstr ""
"Renvoie les paramètres d'un modèle de régression logistique "
":code:`sklearn`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:44
msgid ":code:`set_model_params()`"
msgstr ":code:`set_model_params()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:45
msgid "Sets the parameters of a :code:`sklean` LogisticRegression model"
msgstr "Définit les paramètres d'un modèle de régression logistique :code:`sklean`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:46
msgid ":code:`set_initial_params()`"
msgstr ":code:`set_initial_params()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:47
msgid "Initializes the model parameters that the Flower server will ask for"
msgstr "Initialise les paramètres du modèle que le serveur de Flower demandera"

#: ../../source/tutorial-quickstart-scikitlearn.rst:48
msgid ":code:`load_mnist()`"
msgstr ":code:`load_mnist()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:49
msgid "Loads the MNIST dataset using OpenML"
msgstr "Charge l'ensemble de données MNIST à l'aide d'OpenML"

#: ../../source/tutorial-quickstart-scikitlearn.rst:50
msgid ":code:`shuffle()`"
msgstr ":code:`shuffle()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:51
msgid "Shuffles data and its label"
msgstr "Mélange les données et leur étiquette"

#: ../../source/tutorial-quickstart-scikitlearn.rst:53
msgid ":code:`partition()`"
msgstr ":code:`partition()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:53
msgid "Splits datasets into a number of partitions"
msgstr "Divise les ensembles de données en un certain nombre de partitions"

#: ../../source/tutorial-quickstart-scikitlearn.rst:55
msgid ""
"Please check out :code:`utils.py` `here "
"<https://github.com/adap/flower/blob/main/examples/sklearn-logreg-"
"mnist/utils.py>`_ for more details. The pre-defined functions are used in"
" the :code:`client.py` and imported. The :code:`client.py` also requires "
"to import several packages such as Flower and scikit-learn:"
msgstr ""
"Tu peux consulter :code:`utils.py` `ici "
"<https://github.com/adap/flower/blob/main/examples/sklearn-logreg-"
"mnist/utils.py>`_ pour plus de détails. Les fonctions prédéfinies sont "
"utilisées dans :code:`client.py` et importées. :code:`client.py` "
"nécessite également d'importer plusieurs paquets tels que Flower et "
"scikit-learn :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:70
msgid ""
"We load the MNIST dataset from `OpenML <https://www.openml.org/d/554>`_, "
"a popular image classification dataset of handwritten digits for machine "
"learning. The utility :code:`utils.load_mnist()` downloads the training "
"and test data. The training set is split afterwards into 10 partitions "
"with :code:`utils.partition()`."
msgstr ""
"Nous chargeons l'ensemble de données MNIST de `OpenML "
"<https://www.openml.org/d/554>`_, un ensemble de données de "
"classification d'images populaires de chiffres manuscrits pour "
"l'apprentissage automatique. L'utilitaire :code:`utils.load_mnist()` "
"télécharge les données d'entraînement et de test. L'ensemble "
"d'entraînement est ensuite divisé en 10 partitions avec "
":code:`utils.partition()`."

#: ../../source/tutorial-quickstart-scikitlearn.rst:82
msgid ""
"Next, the logistic regression model is defined and initialized with "
":code:`utils.set_initial_params()`."
msgstr ""
"Ensuite, le modèle de régression logistique est défini et initialisé avec"
" :code:`utils.set_initial_params()`."

#: ../../source/tutorial-quickstart-scikitlearn.rst:94
msgid ""
"The Flower server interacts with clients through an interface called "
":code:`Client`. When the server selects a particular client for training,"
" it sends training instructions over the network. The client receives "
"those instructions and calls one of the :code:`Client` methods to run "
"your code (i.e., to fit the logistic regression we defined earlier)."
msgstr ""
"Le serveur Flower interagit avec les clients par le biais d'une interface"
" appelée :code:`Client`. Lorsque le serveur sélectionne un client "
"particulier pour la formation, il envoie des instructions de formation "
"sur le réseau. Le client reçoit ces instructions et appelle l'une des "
"méthodes :code:`Client` pour exécuter ton code (c'est-à-dire pour ajuster"
" la régression logistique que nous avons définie plus tôt)."

#: ../../source/tutorial-quickstart-scikitlearn.rst:100
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which "
"makes it easier to implement the :code:`Client` interface when your "
"workload uses scikit-learn. Implementing :code:`NumPyClient` usually "
"means defining the following methods (:code:`set_parameters` is optional "
"though):"
msgstr ""
"Flower fournit une classe de commodité appelée :code:`NumPyClient` qui "
"facilite la mise en œuvre de l'interface :code:`Client` lorsque ta charge"
" de travail utilise scikit-learn. Mettre en œuvre :code:`NumPyClient` "
"signifie généralement définir les méthodes suivantes "
"(:code:`set_parameters` est cependant facultatif) :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:109
msgid "is directly imported with :code:`utils.set_model_params()`"
msgstr "est directement importé avec :code:`utils.set_model_params()`"

#: ../../source/tutorial-quickstart-scikitlearn.rst:117
msgid "The methods can be implemented in the following way:"
msgstr "Les méthodes peuvent être mises en œuvre de la manière suivante :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:140
msgid ""
"We can now create an instance of our class :code:`MnistClient` and add "
"one line to actually run this client:"
msgstr ""
"Nous pouvons maintenant créer une instance de notre classe "
":code:`MnistClient` et ajouter une ligne pour exécuter ce client :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:156
msgid ""
"The following Flower server is a little bit more advanced and returns an "
"evaluation function for the server-side evaluation. First, we import "
"again all required libraries such as Flower and scikit-learn."
msgstr ""
"Le serveur Flower suivant est un peu plus avancé et renvoie une fonction "
"d'évaluation pour l'évaluation côté serveur. Tout d'abord, nous importons"
" à nouveau toutes les bibliothèques requises telles que Flower et scikit-"
"learn."

#: ../../source/tutorial-quickstart-scikitlearn.rst:159
msgid ":code:`server.py`, import Flower and start the server:"
msgstr ":code:`server.py`, importe Flower et démarre le serveur :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:170
msgid ""
"The number of federated learning rounds is set in :code:`fit_round()` and"
" the evaluation is defined in :code:`get_evaluate_fn()`. The evaluation "
"function is called after each federated learning round and gives you "
"information about loss and accuracy."
msgstr ""
"Le nombre de tours d'apprentissage fédéré est défini dans "
":code:`fit_round()` et l'évaluation est définie dans "
":code:`get_evaluate_fn()`. La fonction d'évaluation est appelée après "
"chaque tour d'apprentissage fédéré et te donne des informations sur la "
"perte et la précision."

#: ../../source/tutorial-quickstart-scikitlearn.rst:195
msgid ""
"The :code:`main` contains the server-side parameter initialization "
":code:`utils.set_initial_params()` as well as the aggregation strategy "
":code:`fl.server.strategy:FedAvg()`. The strategy is the default one, "
"federated averaging (or FedAvg), with two clients and evaluation after "
"each federated learning round. The server can be started with the command"
" :code:`fl.server.start_server(server_address=\"0.0.0.0:8080\", "
"strategy=strategy, config=fl.server.ServerConfig(num_rounds=3))`."
msgstr ""
"Le :code:`main` contient l'initialisation des paramètres côté serveur "
":code:`utils.set_initial_params()` ainsi que la stratégie d'agrégation "
":code:`fl.server.strategy:FedAvg()`. La stratégie est celle par défaut, "
"la moyenne fédérée (ou FedAvg), avec deux clients et une évaluation après"
" chaque tour d'apprentissage fédéré. Le serveur peut être démarré avec la"
" commande :code:`fl.server.start_server(server_address=\"0.0.0.0:8080\", "
"strategy=strategy, config=fl.server.ServerConfig(num_rounds=3))`."

#: ../../source/tutorial-quickstart-scikitlearn.rst:214
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. Federated learning systems usually have a "
"server and multiple clients. We, therefore, have to start the server "
"first:"
msgstr ""
"Le client et le serveur étant prêts, nous pouvons maintenant tout lancer "
"et voir l'apprentissage fédéré en action. Les systèmes d'apprentissage "
"fédéré ont généralement un serveur et plusieurs clients. Nous devons donc"
" commencer par lancer le serveur :"

#: ../../source/tutorial-quickstart-scikitlearn.rst:268
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code "
"<https://github.com/adap/flower/tree/main/examples/sklearn-logreg-"
"mnist>`_ for this example can be found in :code:`examples/sklearn-logreg-"
"mnist`."
msgstr ""
"Félicitations ! Tu as réussi à construire et à faire fonctionner ton "
"premier système d'apprentissage fédéré. Le code source complet "
"<https://github.com/adap/flower/tree/main/examples/sklearn-logreg-"
"mnist>`_ de cet exemple se trouve dans :code:`examples/sklearn-logreg-"
"mnist`."

#: ../../source/tutorial-quickstart-tensorflow.rst:5
msgid "Quickstart TensorFlow"
msgstr "Démarrage rapide de TensorFlow"

#: ../../source/tutorial-quickstart-tensorflow.rst:10
msgid "Let's build a federated learning system in less than 20 lines of code!"
msgstr ""
"Construisons un système d'apprentissage fédéré en moins de 20 lignes de "
"code !"

#: ../../source/tutorial-quickstart-tensorflow.rst:12
msgid "Before Flower can be imported we have to install it:"
msgstr "Avant de pouvoir importer une fleur, nous devons l'installer :"

#: ../../source/tutorial-quickstart-tensorflow.rst:18
msgid ""
"Since we want to use the Keras API of TensorFlow (TF), we have to install"
" TF as well:"
msgstr ""
"Comme nous voulons utiliser l'API Keras de TensorFlow (TF), nous devons "
"également installer TF :"

#: ../../source/tutorial-quickstart-tensorflow.rst:28
msgid "Next, in a file called :code:`client.py`, import Flower and TensorFlow:"
msgstr ""
"Ensuite, dans un fichier appelé :code:`client.py`, importe Flower et "
"TensorFlow :"

#: ../../source/tutorial-quickstart-tensorflow.rst:35
msgid ""
"We use the Keras utilities of TF to load CIFAR10, a popular colored image"
" classification dataset for machine learning. The call to "
":code:`tf.keras.datasets.cifar10.load_data()` downloads CIFAR10, caches "
"it locally, and then returns the entire training and test set as NumPy "
"ndarrays."
msgstr ""
"Nous utilisons les utilitaires Keras de TF pour charger CIFAR10, un "
"ensemble de données de classification d'images colorées populaire pour "
"l'apprentissage automatique. L'appel à "
":code:`tf.keras.datasets.cifar10.load_data()` télécharge CIFAR10, le met "
"en cache localement, puis renvoie l'ensemble d'entraînement et de test "
"sous forme de NumPy ndarrays."

#: ../../source/tutorial-quickstart-tensorflow.rst:44
msgid ""
"Next, we need a model. For the purpose of this tutorial, we use "
"MobilNetV2 with 10 output classes:"
msgstr ""
"Ensuite, nous avons besoin d'un modèle. Pour les besoins de ce tutoriel, "
"nous utilisons MobilNetV2 avec 10 classes de sortie :"

#: ../../source/tutorial-quickstart-tensorflow.rst:57
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which "
"makes it easier to implement the :code:`Client` interface when your "
"workload uses Keras. The :code:`NumPyClient` interface defines three "
"methods which can be implemented in the following way:"
msgstr ""
"Flower fournit une classe de commodité appelée :code:`NumPyClient` qui "
"facilite la mise en œuvre de l'interface :code:`Client` lorsque ta charge"
" de travail utilise Keras. L'interface :code:`NumPyClient` définit trois "
"méthodes qui peuvent être mises en œuvre de la manière suivante :"

#: ../../source/tutorial-quickstart-tensorflow.rst:132
msgid "Each client will have its own dataset."
msgstr "Chaque client aura son propre ensemble de données."

#: ../../source/tutorial-quickstart-tensorflow.rst:134
msgid ""
"You should now see how the training does in the very first terminal (the "
"one that started the server):"
msgstr ""
"Tu devrais maintenant voir comment la formation se déroule dans le tout "
"premier terminal (celui qui a démarré le serveur) :"

#: ../../source/tutorial-quickstart-tensorflow.rst:166
#, fuzzy
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"tensorflow/client.py>`_ for this can be found in :code:`examples"
"/quickstart-tensorflow/client.py`."
msgstr ""
"Félicitations ! Tu as réussi à construire et à faire fonctionner ton "
"premier système d'apprentissage fédéré. Le `code source complet "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"tensorflow/client.py>`_ pour cela se trouve dans :code:`examples"
"/quickstart-tensorflow/client.py`."

#: ../../source/tutorial-quickstart-xgboost.rst:5
msgid "Quickstart XGBoost"
msgstr "Démarrage rapide XGBoost"

#: ../../source/tutorial-quickstart-xgboost.rst:7
msgid ""
"Let's build a horizontal federated learning system using XGBoost and "
"Flower!"
msgstr ""
"Construisons un système d'apprentissage fédéré horizontal en utilisant "
"XGBoost et Flower !"

#: ../../source/tutorial-quickstart-xgboost.rst:9
#, fuzzy
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/quickstart-xgboost-"
"horizontal>`_ to learn more."
msgstr ""
"Réfère-toi à l'exemple de code complet "
"<https://github.com/adap/flower/tree/main/examples/quickstart-xgboost-"
"horizontal>`_ pour en savoir plus."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:9
#, fuzzy
msgid "Use a federated learning strategy"
msgstr "Stratégie de moyenne fédérée."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:11
#, fuzzy
msgid ""
"Welcome to the next part of the federated learning tutorial. In previous "
"parts of this tutorial, we introduced federated learning with PyTorch and"
" Flower (`part 1 <https://flower.dev/docs/framework/tutorial-get-started-"
"with-flower-pytorch.html>`__)."
msgstr ""
"Bienvenue dans la prochaine partie du tutoriel sur l'apprentissage "
"fédéré. Dans les parties précédentes de ce tutoriel, nous avons présenté "
"l'apprentissage fédéré avec PyTorch et Flower (`partie 1 "
"<https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html>`__)."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:13
msgid ""
"In this notebook, we'll begin to customize the federated learning system "
"we built in the introductory notebook (again, using `Flower "
"<https://flower.dev/>`__ and `PyTorch <https://pytorch.org/>`__)."
msgstr ""
"Dans ce carnet, nous allons commencer à personnaliser le système "
"d'apprentissage fédéré que nous avons construit dans le carnet "
"d'introduction (toujours en utilisant `Flower <https://flower.dev/>`__ et"
" `PyTorch <https://pytorch.org/>`__)."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:17
#, fuzzy
msgid "Let's move beyond FedAvg with Flower strategies!"
msgstr "Dépassons FedAvg avec les stratégies florales !"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:309
msgid "Strategy customization"
msgstr "Personnalisation de la stratégie"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:311
msgid ""
"So far, everything should look familiar if you've worked through the "
"introductory notebook. With that, we're ready to introduce a number of "
"new features."
msgstr ""
"Jusqu'à présent, tout devrait te sembler familier si tu as travaillé sur "
"le cahier d'introduction. Avec cela, nous sommes prêts à présenter un "
"certain nombre de nouvelles fonctionnalités."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:323
msgid "Server-side parameter **initialization**"
msgstr "Paramètres côté serveur **initialisation**"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:325
msgid ""
"Flower, by default, initializes the global model by asking one random "
"client for the initial parameters. In many cases, we want more control "
"over parameter initialization though. Flower therefore allows you to "
"directly pass the initial parameters to the Strategy:"
msgstr ""
"Flower, par défaut, initialise le modèle global en demandant à un client "
"aléatoire les paramètres initiaux. Dans de nombreux cas, nous voulons "
"cependant avoir plus de contrôle sur l'initialisation des paramètres. "
"Flower te permet donc de passer directement les paramètres initiaux à la "
"Stratégie :"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:370
msgid ""
"Passing ``initial_parameters`` to the ``FedAvg`` strategy prevents Flower"
" from asking one of the clients for the initial parameters. If we look "
"closely, we can see that the logs do not show any calls to the "
"``FlowerClient.get_parameters`` method."
msgstr ""
"Le fait de passer ``initial_parameters`` à la stratégie ``FedAvg`` "
"empêche Flower de demander les paramètres initiaux à l'un des clients. Si"
" nous regardons de près, nous pouvons voir que les journaux ne montrent "
"aucun appel à la méthode ``FlowerClient.get_parameters``."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:382
msgid "Starting with a customized strategy"
msgstr "Commencer par une stratégie personnalisée"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:384
msgid ""
"We've seen the function ``start_simulation`` before. It accepts a number "
"of arguments, amongst them the ``client_fn`` used to create "
"``FlowerClient`` instances, the number of clients to simulate "
"``num_clients``, the number of rounds ``num_rounds``, and the strategy."
msgstr ""
"Elle accepte un certain nombre d'arguments, parmi lesquels le "
"``client_fn`` utilisé pour créer les instances de ``FlowerClient``, le "
"nombre de clients à simuler ``num_clients``, le nombre de rounds "
"``num_rounds``, et la stratégie."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:386
msgid ""
"The strategy encapsulates the federated learning approach/algorithm, for "
"example, ``FedAvg`` or ``FedAdagrad``. Let's try to use a different "
"strategy this time:"
msgstr ""
"La stratégie englobe l'approche/l'algorithme d'apprentissage fédéré, par "
"exemple, ``FedAvg`` ou ``FedAdagrad``. Essayons d'utiliser une stratégie "
"différente cette fois-ci :"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:424
msgid "Server-side parameter **evaluation**"
msgstr "Paramètre côté serveur **évaluation**"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:426
msgid ""
"Flower can evaluate the aggregated model on the server-side or on the "
"client-side. Client-side and server-side evaluation are similar in some "
"ways, but different in others."
msgstr ""
"Flower peut évaluer le modèle agrégé côté serveur ou côté client. Les "
"évaluations côté client et côté serveur sont similaires à certains "
"égards, mais différentes à d'autres."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:428
msgid ""
"**Centralized Evaluation** (or *server-side evaluation*) is conceptually "
"simple: it works the same way that evaluation in centralized machine "
"learning does. If there is a server-side dataset that can be used for "
"evaluation purposes, then that's great. We can evaluate the newly "
"aggregated model after each round of training without having to send the "
"model to clients. We're also fortunate in the sense that our entire "
"evaluation dataset is available at all times."
msgstr ""
"**L'évaluation centralisée** (ou *évaluation côté serveur*) est "
"conceptuellement simple : elle fonctionne de la même manière que "
"l'évaluation dans l'apprentissage automatique centralisé. S'il existe un "
"ensemble de données côté serveur qui peut être utilisé à des fins "
"d'évaluation, alors c'est parfait. Nous pouvons évaluer le modèle "
"nouvellement agrégé après chaque cycle de formation sans avoir à envoyer "
"le modèle aux clients. Nous avons également la chance que l'ensemble de "
"notre ensemble de données d'évaluation soit disponible à tout moment."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:430
msgid ""
"**Federated Evaluation** (or *client-side evaluation*) is more complex, "
"but also more powerful: it doesn't require a centralized dataset and "
"allows us to evaluate models over a larger set of data, which often "
"yields more realistic evaluation results. In fact, many scenarios require"
" us to use **Federated Evaluation** if we want to get representative "
"evaluation results at all. But this power comes at a cost: once we start "
"to evaluate on the client side, we should be aware that our evaluation "
"dataset can change over consecutive rounds of learning if those clients "
"are not always available. Moreover, the dataset held by each client can "
"also change over consecutive rounds. This can lead to evaluation results "
"that are not stable, so even if we would not change the model, we'd see "
"our evaluation results fluctuate over consecutive rounds."
msgstr ""
"**L'évaluation fédérée** (ou évaluation côté client) est plus complexe, "
"mais aussi plus puissante : elle ne nécessite pas d'ensemble de données "
"centralisé et nous permet d'évaluer les modèles sur un plus grand "
"ensemble de données, ce qui donne souvent des résultats d'évaluation plus"
" réalistes. En fait, de nombreux scénarios exigent que nous utilisions "
"l'évaluation fédérée** si nous voulons obtenir des résultats d'évaluation"
" représentatifs. Mais cette puissance a un coût : une fois que nous "
"commençons à évaluer côté client, nous devons savoir que notre ensemble "
"de données d'évaluation peut changer au cours des cycles d'apprentissage "
"consécutifs si ces clients ne sont pas toujours disponibles. De plus, "
"l'ensemble de données détenu par chaque client peut également changer au "
"cours des cycles consécutifs. Cela peut conduire à des résultats "
"d'évaluation qui ne sont pas stables, donc même si nous ne changions pas "
"le modèle, nous verrions nos résultats d'évaluation fluctuer au cours des"
" cycles consécutifs."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:433
msgid ""
"We've seen how federated evaluation works on the client side (i.e., by "
"implementing the ``evaluate`` method in ``FlowerClient``). Now let's see "
"how we can evaluate aggregated model parameters on the server-side:"
msgstr ""
"Nous avons vu comment l'évaluation fédérée fonctionne du côté client "
"(c'est-à-dire en implémentant la méthode ``evaluate`` dans "
"``FlowerClient``). Voyons maintenant comment nous pouvons évaluer les "
"paramètres du modèle agrégé du côté serveur :"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:490
msgid "Sending/receiving arbitrary values to/from clients"
msgstr "Envoi/réception de valeurs arbitraires vers/depuis les clients"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:492
#, fuzzy
msgid ""
"In some situations, we want to configure client-side execution (training,"
" evaluation) from the server-side. One example for that is the server "
"asking the clients to train for a certain number of local epochs. Flower "
"provides a way to send configuration values from the server to the "
"clients using a dictionary. Let's look at an example where the clients "
"receive values from the server through the ``config`` parameter in "
"``fit`` (``config`` is also available in ``evaluate``). The ``fit`` "
"method receives the configuration dictionary through the ``config`` "
"parameter and can then read values from this dictionary. In this example,"
" it reads ``server_round`` and ``local_epochs`` and uses those values to "
"improve the logging and configure the number of local training epochs:"
msgstr ""
"In some situations, we want to configure client-side execution (training,"
" evaluation) from the server-side. One example for that is the server "
"asking the clients to train for a certain number of local epochs. Flower "
"provides a way to send configuration values from the server to the "
"clients using a dictionary. Let's look at an example where the clients "
"receive values from the server through the ``config`` parameter in "
"``fit`` (``config`` is also available in ``evaluate``). The ``fit`` "
"method receives the configuration dictionary through the ``config`` "
"parameter and can then read values from this dictionary. In this example,"
" it reads ``server_round`` and ``local_epochs`` and uses those values to "
"improve the logging and configure the number of local training epochs:"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:546
msgid ""
"So how can we send this config dictionary from server to clients? The "
"built-in Flower Strategies provide way to do this, and it works similarly"
" to the way server-side evaluation works. We provide a function to the "
"strategy, and the strategy calls this function for every round of "
"federated learning:"
msgstr ""
"Comment pouvons-nous donc envoyer ce dictionnaire de configuration du "
"serveur aux clients ? Les stratégies de Flower intégrées fournissent un "
"moyen de le faire, et cela fonctionne de la même façon que l'évaluation "
"côté serveur. Nous fournissons une fonction à la stratégie, et la "
"stratégie appelle cette fonction pour chaque cycle d'apprentissage fédéré"
" :"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:576
msgid ""
"Next, we'll just pass this function to the FedAvg strategy before "
"starting the simulation:"
msgstr ""
"Ensuite, nous allons simplement passer cette fonction à la stratégie "
"FedAvg avant de commencer la simulation :"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:613
msgid ""
"As we can see, the client logs now include the current round of federated"
" learning (which they read from the ``config`` dictionary). We can also "
"configure local training to run for one epoch during the first and second"
" round of federated learning, and then for two epochs during the third "
"round."
msgstr ""
"Comme nous pouvons le voir, les journaux des clients incluent maintenant "
"le cycle actuel d'apprentissage fédéré (qu'ils lisent depuis le "
"dictionnaire ``config``). Nous pouvons également configurer "
"l'apprentissage local pour qu'il s'exécute pendant une époque au cours du"
" premier et du deuxième cycle d'apprentissage fédéré, puis pendant deux "
"époques au cours du troisième cycle."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:615
msgid ""
"Clients can also return arbitrary values to the server. To do so, they "
"return a dictionary from ``fit`` and/or ``evaluate``. We have seen and "
"used this concept throughout this notebook without mentioning it "
"explicitly: our ``FlowerClient`` returns a dictionary containing a custom"
" key/value pair as the third return value in ``evaluate``."
msgstr ""
"Les clients peuvent également renvoyer des valeurs arbitraires au "
"serveur. Pour ce faire, ils renvoient un dictionnaire depuis ``fit`` "
"et/ou ``evaluate``. Nous avons vu et utilisé ce concept tout au long de "
"ce carnet sans le mentionner explicitement : notre ``FlowerClient`` "
"renvoie un dictionnaire contenant une paire clé/valeur personnalisée en "
"tant que troisième valeur de retour dans ``evaluate``."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:627
msgid "Scaling federated learning"
msgstr "Mise à l'échelle de l'apprentissage fédéré"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:629
msgid ""
"As a last step in this notebook, let's see how we can use Flower to "
"experiment with a large number of clients."
msgstr ""
"Comme dernière étape de ce carnet, voyons comment nous pouvons utiliser "
"Flower pour expérimenter avec un grand nombre de clients."

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:651
#, python-format
msgid ""
"We now have 1000 partitions, each holding 45 training and 5 validation "
"examples. Given that the number of training examples on each client is "
"quite small, we should probably train the model a bit longer, so we "
"configure the clients to perform 3 local training epochs. We should also "
"adjust the fraction of clients selected for training during each round "
"(we don't want all 1000 clients participating in every round), so we "
"adjust ``fraction_fit`` to ``0.05``, which means that only 5% of "
"available clients (so 50 clients) will be selected for training each "
"round:"
msgstr ""
"Nous avons maintenant 1000 partitions, chacune contenant 45 exemples "
"d'entraînement et 5 exemples de validation. Etant donné que le nombre "
"d'exemples d'entraînement sur chaque client est assez faible, nous "
"devrions probablement entraîner le modèle un peu plus longtemps, nous "
"configurons donc les clients pour qu'ils effectuent 3 époques "
"d'entraînement local. Nous devrions également ajuster la fraction de "
"clients sélectionnés pour l'entraînement à chaque tour (nous ne voulons "
"pas que les 1000 clients participent à chaque tour), nous ajustons donc "
"``fraction_fit`` à ``0.05``, ce qui signifie que seulement 5% des clients"
" disponibles (donc 50 clients) seront sélectionnés pour l'entraînement à "
"chaque tour :"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:699
msgid ""
"In this notebook, we've seen how we can gradually enhance our system by "
"customizing the strategy, initializing parameters on the server side, "
"choosing a different strategy, and evaluating models on the server-side. "
"That's quite a bit of flexibility with so little code, right?"
msgstr ""
"Dans ce carnet, nous avons vu comment nous pouvons progressivement "
"améliorer notre système en personnalisant la stratégie, en initialisant "
"les paramètres côté serveur, en choisissant une stratégie différente et "
"en évaluant les modèles côté serveur. C'est une sacrée flexibilité avec "
"si peu de code, n'est-ce pas ?"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:701
msgid ""
"In the later sections, we've seen how we can communicate arbitrary values"
" between server and clients to fully customize client-side execution. "
"With that capability, we built a large-scale Federated Learning "
"simulation using the Flower Virtual Client Engine and ran an experiment "
"involving 1000 clients in the same workload - all in a Jupyter Notebook!"
msgstr ""
"Dans les sections ultérieures, nous avons vu comment nous pouvons "
"communiquer des valeurs arbitraires entre le serveur et les clients pour "
"personnaliser entièrement l'exécution côté client. Grâce à cette "
"capacité, nous avons construit une simulation d'apprentissage fédéré à "
"grande échelle en utilisant le moteur de client virtuel Flower et nous "
"avons mené une expérience impliquant 1000 clients dans la même charge de "
"travail - le tout dans un carnet Jupyter !"

#: ../../source/tutorial-use-a-federated-learning-strategy-pytorch.ipynb:719
#, fuzzy
msgid ""
"The `Flower Federated Learning Tutorial - Part 3 "
"<https://flower.dev/docs/framework/tutorial-build-a-strategy-from-"
"scratch-pytorch.html>`__ shows how to build a fully custom ``Strategy`` "
"from scratch."
msgstr ""
"Le `Tutoriel d'apprentissage fédéré Flower - Partie 3 [WIP] "
"<https://flower.dev/docs/tutorial/Flower-3-Building-a-Strategy-"
"PyTorch.html>`__ montre comment construire une ``Stratégie`` entièrement "
"personnalisée à partir de zéro."

#: ../../source/tutorial-what-is-federated-learning.ipynb:9
msgid "What is Federated Learning?"
msgstr "Qu'est-ce que l'apprentissage fédéré ?"

#: ../../source/tutorial-what-is-federated-learning.ipynb:13
#, fuzzy
msgid ""
"In this tutorial, you will learn what federated learning is, build your "
"first system in Flower, and gradually extend it. If you work through all "
"parts of the tutorial, you will be able to build advanced federated "
"learning systems that approach the current state of the art in the field."
msgstr ""
"Dans ce tutoriel, tu apprendras ce qu'est l'apprentissage fédéré, tu "
"construiras ton premier système dans Flower, et tu l'étendras "
"progressivement. Si tu travailles sur toutes les parties du tutoriel, tu "
"seras capable de construire des systèmes d'apprentissage fédéré avancés "
"qui se rapprochent de l'état actuel de l'art dans le domaine."

#: ../../source/tutorial-what-is-federated-learning.ipynb:15
msgid ""
"🧑‍🏫 This tutorial starts at zero and expects no familiarity with "
"federated learning. Only a basic understanding of data science and Python"
" programming is assumed."
msgstr ""
"🧑‍🏫 Ce tutoriel part de zéro et n'attend aucune familiarité avec "
"l'apprentissage fédéré. Seule une compréhension de base de la science des"
" données et de la programmation Python est supposée."

#: ../../source/tutorial-what-is-federated-learning.ipynb:17
#, fuzzy
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join "
"the open-source Flower community on Slack to connect, ask questions, and "
"get help: `Join Slack <https://flower.dev/join-slack>`__ 🌼 We'd love to "
"hear from you in the ``#introductions`` channel! And if anything is "
"unclear, head over to the ``#questions`` channel."
msgstr ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ et "
"rejoignez la communauté Flower sur Slack pour vous connecter, poser des "
"questions et obtenir de l'aide : `Join Slack <https://flower.dev/join-"
"slack>`__ 🌼 Nous serions ravis d'avoir de vos nouvelles dans le canal "
"``#introductions`` ! Et si quelque chose n'est pas clair, rendez-vous sur"
" le canal ``#questions``."

#: ../../source/tutorial-what-is-federated-learning.ipynb:31
msgid "Classic machine learning"
msgstr "Apprentissage automatique classique"

#: ../../source/tutorial-what-is-federated-learning.ipynb:33
msgid ""
"Before we begin to discuss federated learning, let us quickly recap how "
"most machine learning works today."
msgstr ""
"Avant de commencer à discuter de l'apprentissage fédéré, récapitulons "
"rapidement la façon dont la plupart des apprentissages automatiques "
"fonctionnent aujourd'hui."

#: ../../source/tutorial-what-is-federated-learning.ipynb:35
msgid ""
"In machine learning, we have a model, and we have data. The model could "
"be a neural network (as depicted here), or something else, like classical"
" linear regression."
msgstr ""
"Dans l'apprentissage automatique, nous avons un modèle et des données. Le"
" modèle peut être un réseau neuronal (comme illustré ici), ou quelque "
"chose d'autre, comme la régression linéaire classique."

#: ../../source/tutorial-what-is-federated-learning.ipynb:41
msgid "|3ff4c820a01d4a5abb022617de537c54|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:109
msgid "Model and data"
msgstr "Modèle et données"

#: ../../source/tutorial-what-is-federated-learning.ipynb:47
msgid ""
"We train the model using the data to perform a useful task. A task could "
"be to detect objects in images, transcribe an audio recording, or play a "
"game like Go."
msgstr ""
"Nous entraînons le modèle en utilisant les données pour effectuer une "
"tâche utile. Une tâche peut consister à détecter des objets dans des "
"images, à transcrire un enregistrement audio ou à jouer à un jeu comme le"
" Go."

#: ../../source/tutorial-what-is-federated-learning.ipynb:53
msgid "|7f1889391ad448e2a65920165f0d798c|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:111
msgid "Train model using data"
msgstr "Entraîne le modèle à l'aide des données"

#: ../../source/tutorial-what-is-federated-learning.ipynb:59
#, fuzzy
msgid ""
"Now, in practice, the training data we work with doesn't originate on the"
" machine we train the model on. It gets created somewhere else."
msgstr ""
"Dans la pratique, les données d'entraînement avec lesquelles nous "
"travaillons ne proviennent pas de la machine sur laquelle nous entraînons"
" le modèle. Elles sont créées ailleurs."

#: ../../source/tutorial-what-is-federated-learning.ipynb:61
#, fuzzy
msgid ""
"It originates on a smartphone by the user interacting with an app, a car "
"collecting sensor data, a laptop receiving input via the keyboard, or a "
"smart speaker listening to someone trying to sing a song."
msgstr ""
"Elle prend naissance sur un smartphone par l'interaction de l'utilisateur"
" avec une application, une voiture qui collecte des données de capteurs, "
"un ordinateur portable qui reçoit des entrées via le clavier, ou un haut-"
"parleur intelligent qui écoute quelqu'un qui essaie de chanter une "
"chanson."

#: ../../source/tutorial-what-is-federated-learning.ipynb:67
msgid "|a171dc4a0d044e70b5d585cc10ace0e0|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:113
msgid "Data on a phone"
msgstr "Données sur un téléphone"

#: ../../source/tutorial-what-is-federated-learning.ipynb:73
msgid ""
"What's also important to mention, this \"somewhere else\" is usually not "
"just one place, it's many places. It could be several devices all running"
" the same app. But it could also be several organizations, all generating"
" data for the same task."
msgstr ""
"Il est également important de mentionner que cet \"ailleurs\" n'est "
"généralement pas un seul endroit, mais plusieurs. Il peut s'agir de "
"plusieurs appareils fonctionnant tous avec la même application. Mais il "
"peut également s'agir de plusieurs organisations, qui génèrent toutes des"
" données pour la même tâche."

#: ../../source/tutorial-what-is-federated-learning.ipynb:79
msgid "|fe518aa0d86341f7b2fc87bd6e3bbf0c|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:115
msgid "Data is on many devices"
msgstr "Les données se trouvent sur de nombreux appareils"

#: ../../source/tutorial-what-is-federated-learning.ipynb:85
msgid ""
"So to use machine learning, or any kind of data analysis, the approach "
"that has been used in the past was to collect all data on a central "
"server. This server can be somewhere in a data center, or somewhere in "
"the cloud."
msgstr ""
"Ainsi, pour utiliser l'apprentissage automatique, ou tout autre type "
"d'analyse de données, l'approche utilisée par le passé consistait à "
"collecter toutes les données sur un serveur central. Ce serveur peut se "
"trouver quelque part dans un centre de données, ou quelque part dans le "
"cloud."

#: ../../source/tutorial-what-is-federated-learning.ipynb:91
msgid "|6abfdf0dade44469ae9f08c8dc7d148c|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:117
msgid "Central data collection"
msgstr "Collecte centralisée des données"

#: ../../source/tutorial-what-is-federated-learning.ipynb:97
#, fuzzy
msgid ""
"Once all the data is collected in one place, we can finally use machine "
"learning algorithms to train our model on the data. This is the machine "
"learning approach that we've basically always relied on."
msgstr ""
"Une fois que toutes les données sont rassemblées en un seul endroit, nous"
" pouvons enfin utiliser des algorithmes d'apprentissage automatique pour "
"entraîner notre modèle sur les données. C'est l'approche d'apprentissage "
"automatique sur laquelle nous nous sommes fondamentalement toujours "
"appuyés."

#: ../../source/tutorial-what-is-federated-learning.ipynb:103
msgid "|b4f147db24bb4da9a786e1d6676a1c2d|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:119
msgid "Central model training"
msgstr "Formation au modèle central"

#: ../../source/tutorial-what-is-federated-learning.ipynb:130
msgid "Challenges of classical machine learning"
msgstr "Les défis de l'apprentissage automatique classique"

#: ../../source/tutorial-what-is-federated-learning.ipynb:132
msgid ""
"The classic machine learning approach we've just seen can be used in some"
" cases. Great examples include categorizing holiday photos, or analyzing "
"web traffic. Cases, where all the data is naturally available on a "
"centralized server."
msgstr ""
"L'approche classique de l'apprentissage automatique que nous venons de "
"voir peut être utilisée dans certains cas. Parmi les grands exemples, on "
"peut citer la catégorisation des photos de vacances, ou l'analyse du "
"trafic web. Des cas, où toutes les données sont naturellement disponibles"
" sur un serveur centralisé."

#: ../../source/tutorial-what-is-federated-learning.ipynb:138
msgid "|5c62032f589a457bb37b5fee5b2adbde|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:173
msgid "Centralized possible"
msgstr "Possibilité de centralisation"

#: ../../source/tutorial-what-is-federated-learning.ipynb:144
msgid ""
"But the approach can not be used in many other cases. Cases, where the "
"data is not available on a centralized server, or cases where the data "
"available on one server is not enough to train a good model."
msgstr ""
"Mais cette approche ne peut pas être utilisée dans de nombreux autres cas"
" : lorsque les données ne sont pas disponibles sur un serveur centralisé,"
" ou lorsque les données disponibles sur un serveur ne sont pas "
"suffisantes pour former un bon modèle."

#: ../../source/tutorial-what-is-federated-learning.ipynb:150
msgid "|f154df1846dd44f79a94f1dc3ae8b088|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:175
msgid "Centralized impossible"
msgstr "Impossible de centraliser"

#: ../../source/tutorial-what-is-federated-learning.ipynb:156
#, fuzzy
msgid ""
"There are many reasons why the classic centralized machine learning "
"approach does not work for a large number of highly important real-world "
"use cases. Those reasons include:"
msgstr ""
"Il existe de nombreuses raisons pour lesquelles l'approche classique "
"centralisée de l'apprentissage automatique ne fonctionne pas pour un "
"grand nombre de cas d'utilisation très importants dans le monde réel, "
"notamment :"

#: ../../source/tutorial-what-is-federated-learning.ipynb:158
#, fuzzy
msgid ""
"**Regulations**: GDPR (Europe), CCPA (California), PIPEDA (Canada), LGPD "
"(Brazil), PDPL (Argentina), KVKK (Turkey), POPI (South Africa), FSS "
"(Russia), CDPR (China), PDPB (India), PIPA (Korea), APPI (Japan), PDP "
"(Indonesia), PDPA (Singapore), APP (Australia), and other regulations "
"protect sensitive data from being moved. In fact, those regulations "
"sometimes even prevent single organizations from combining their own "
"users' data for artificial intelligence training because those users live"
" in different parts of the world, and their data is governed by different"
" data protection regulations."
msgstr ""
"**Réglementations** : GDPR (Europe), CCPA (Californie), PIPEDA (Canada), "
"LGPD (Brésil), PDPL (Argentine), KVKK (Turquie), POPI (Afrique du Sud), "
"FSS (Russie), CDPR (Chine), PDPB (Inde), PIPA (Corée), APPI (Japon), PDP "
"(Indonésie), PDPA (Singapour), APP (Australie), et d'autres "
"réglementations protègent les données sensibles contre le déplacement. En"
" fait, ces réglementations empêchent même parfois des organisations "
"individuelles de combiner les données de leurs propres utilisateurs pour "
"la formation à l'intelligence artificielle parce que ces utilisateurs "
"vivent dans différentes parties du monde, et que leurs données sont "
"régies par des réglementations différentes en matière de protection des "
"données."

#: ../../source/tutorial-what-is-federated-learning.ipynb:160
msgid ""
"**User preference**: In addition to regulation, there are use cases where"
" users just expect that no data leaves their device, ever. If you type "
"your passwords and credit card info into the digital keyboard of your "
"phone, you don't expect those passwords to end up on the server of the "
"company that developed that keyboard, do you? In fact, that use case was "
"the reason federated learning was invented in the first place."
msgstr ""
"**Préférence de l'utilisateur** : En plus de la réglementation, il existe"
" des cas d'utilisation où les utilisateurs s'attendent tout simplement à "
"ce qu'aucune donnée ne quitte leur appareil, jamais. Si tu tapes tes mots"
" de passe et tes informations de carte de crédit sur le clavier numérique"
" de ton téléphone, tu ne t'attends pas à ce que ces mots de passe "
"finissent sur le serveur de l'entreprise qui a développé ce clavier, n"
"'est-ce pas ? En fait, ce cas d'utilisation est la raison pour laquelle "
"l'apprentissage fédéré a été inventé en premier lieu."

#: ../../source/tutorial-what-is-federated-learning.ipynb:161
#, fuzzy
msgid ""
"**Data volume**: Some sensors, like cameras, produce such a high data "
"volume that it is neither feasible nor economic to collect all the data "
"(due to, for example, bandwidth or communication efficiency). Think about"
" a national rail service with hundreds of train stations across the "
"country. If each of these train stations is outfitted with a number of "
"security cameras, the volume of raw on-device data they produce requires "
"incredibly powerful and exceedingly expensive infrastructure to process "
"and store. And most of the data isn't even useful."
msgstr ""
"**volume de données** : certains capteurs, comme les caméras, produisent "
"un volume de données si important qu'il n'est ni possible ni économique "
"de collecter toutes les données (en raison, par exemple, de la bande "
"passante ou de l'efficacité des communications). Pensez à un service "
"ferroviaire national comptant des centaines de gares à travers le pays. "
"Si chacune de ces gares est équipée d'un certain nombre de caméras de "
"sécurité, le volume de données brutes sur les appareils qu'elles "
"produisent nécessite une infrastructure incroyablement puissante et "
"excessivement coûteuse pour les traiter et les stocker. Et la plupart de "
"ces données ne sont même pas utiles."

#: ../../source/tutorial-what-is-federated-learning.ipynb:164
msgid "Examples where centralized machine learning does not work include:"
msgstr ""
"Voici quelques exemples où l'apprentissage automatique centralisé ne "
"fonctionne pas :"

#: ../../source/tutorial-what-is-federated-learning.ipynb:166
#, fuzzy
msgid ""
"Sensitive healthcare records from multiple hospitals to train cancer "
"detection models"
msgstr ""
"Des dossiers médicaux sensibles provenant de plusieurs hôpitaux pour "
"former des modèles de détection du cancer"

#: ../../source/tutorial-what-is-federated-learning.ipynb:167
msgid ""
"Financial information from different organizations to detect financial "
"fraud"
msgstr ""
"Informations financières provenant de différentes organisations pour "
"détecter les fraudes financières"

#: ../../source/tutorial-what-is-federated-learning.ipynb:168
msgid "Location data from your electric car to make better range prediction"
msgstr ""
"Les données de localisation de ta voiture électrique pour mieux prédire "
"l'autonomie"

#: ../../source/tutorial-what-is-federated-learning.ipynb:169
msgid "End-to-end encrypted messages to train better auto-complete models"
msgstr ""
"Messages cryptés de bout en bout pour former de meilleurs modèles "
"d'autocomplétion"

#: ../../source/tutorial-what-is-federated-learning.ipynb:171
#, fuzzy
msgid ""
"The popularity of privacy-enhancing systems like the `Brave "
"<https://brave.com/>`__ browser or the `Signal <https://signal.org/>`__ "
"messenger shows that users care about privacy. In fact, they choose the "
"privacy-enhancing version over other alternatives, if such an alernative "
"exists. But what can we do to apply machine learning and data science to "
"these cases to utilize private data? After all, these are all areas that "
"would benefit significantly from recent advances in AI."
msgstr ""
"La popularité des systèmes améliorant la confidentialité comme le "
"navigateur `Brave <https://brave.com/>`__ ou le messager `Signal "
"<https://signal.org/>`__ montre que les utilisateurs se soucient de la "
"confidentialité. En fait, ils choisissent la version améliorant la "
"confidentialité plutôt que d'autres alternatives, si une telle "
"alternative existe. Mais que pouvons-nous faire pour appliquer "
"l'apprentissage automatique et la science des données à ces cas afin "
"d'utiliser les données privées ? Après tout, ce sont tous des domaines "
"qui bénéficieraient de manière significative des récentes avancées en "
"matière d'IA."

#: ../../source/tutorial-what-is-federated-learning.ipynb:186
msgid "Federated learning"
msgstr "Apprentissage fédéré"

#: ../../source/tutorial-what-is-federated-learning.ipynb:188
msgid ""
"Federated learning simply reverses this approach. It enables machine "
"learning on distributed data by moving the training to the data, instead "
"of moving the data to the training. Here's the single-sentence "
"explanation:"
msgstr ""
"L'apprentissage fédéré inverse simplement cette approche. Il permet "
"l'apprentissage automatique sur des données distribuées en déplaçant la "
"formation vers les données, au lieu de déplacer les données vers la "
"formation. Voici l'explication en une seule phrase :"

#: ../../source/tutorial-what-is-federated-learning.ipynb:190
msgid "Central machine learning: move the data to the computation"
msgstr "Apprentissage automatique central : déplace les données vers le calcul"

#: ../../source/tutorial-what-is-federated-learning.ipynb:191
msgid "Federated (machine) learning: move the computation to the data"
msgstr "Apprentissage (machine) fédéré : déplacer le calcul vers les données"

#: ../../source/tutorial-what-is-federated-learning.ipynb:193
msgid ""
"By doing so, it enables us to use machine learning (and other data "
"science approaches) in areas where it wasn't possible before. We can now "
"train excellent medical AI models by enabling different hospitals to work"
" together. We can solve financial fraud by training AI models on the data"
" of different financial institutions. We can build novel privacy-"
"enhancing applications (such as secure messaging) that have better built-"
"in AI than their non-privacy-enhancing alternatives. And those are just a"
" few of the examples that come to mind. As we deploy federated learning, "
"we discover more and more areas that can suddenly be reinvented because "
"they now have access to vast amounts of previously inaccessible data."
msgstr ""
"Ce faisant, il nous permet d'utiliser l'apprentissage automatique (et "
"d'autres approches de science des données) dans des domaines où cela "
"n'était pas possible auparavant. Nous pouvons désormais former "
"d'excellents modèles d'IA médicale en permettant à différents hôpitaux de"
" travailler ensemble. Nous pouvons résoudre les fraudes financières en "
"formant des modèles d'IA sur les données de différentes institutions "
"financières. Nous pouvons créer de nouvelles applications d'amélioration "
"de la confidentialité (telles que la messagerie sécurisée) qui ont une "
"meilleure IA intégrée que leurs alternatives d'amélioration de la "
"confidentialité. Et ce ne sont là que quelques exemples qui me viennent à"
" l'esprit. Au fur et à mesure que nous déployons l'apprentissage fédéré, "
"nous découvrons de plus en plus de domaines qui peuvent soudainement être"
" réinventés parce qu'ils ont maintenant accès à de vastes quantités de "
"données auparavant inaccessibles."

#: ../../source/tutorial-what-is-federated-learning.ipynb:196
msgid ""
"So how does federated learning work, exactly? Let's start with an "
"intuitive explanation."
msgstr ""
"Comment fonctionne l'apprentissage fédéré ? Commençons par une "
"explication intuitive."

#: ../../source/tutorial-what-is-federated-learning.ipynb:199
msgid "Federated learning in five steps"
msgstr "L'apprentissage fédéré en cinq étapes"

#: ../../source/tutorial-what-is-federated-learning.ipynb:202
msgid "Step 0: Initialize global model"
msgstr "Étape 0 : Initialisation du modèle global"

#: ../../source/tutorial-what-is-federated-learning.ipynb:204
msgid ""
"We start by initializing the model on the server. This is exactly the "
"same in classic centralized learning: we initialize the model parameters,"
" either randomly or from a previously saved checkpoint."
msgstr ""
"Nous commençons par initialiser le modèle sur le serveur. C'est "
"exactement la même chose dans l'apprentissage centralisé classique : nous"
" initialisons les paramètres du modèle, soit de façon aléatoire, soit à "
"partir d'un point de contrôle précédemment sauvegardé."

#: ../../source/tutorial-what-is-federated-learning.ipynb:210
msgid "|9d20be8160f7451fb0f33b194506503f|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:307
msgid "Initialize global model"
msgstr "Initialise le modèle global"

#: ../../source/tutorial-what-is-federated-learning.ipynb:217
msgid ""
"Step 1: Send model to a number of connected organizations/devices (client"
" nodes)"
msgstr ""
"Étape 1 : envoyer le modèle à un certain nombre d'organisations/appareils"
" connectés (nœuds clients)"

#: ../../source/tutorial-what-is-federated-learning.ipynb:219
#, fuzzy
msgid ""
"Next, we send the parameters of the global model to the connected client "
"nodes (think: edge devices like smartphones or servers belonging to "
"organizations). This is to ensure that each participating node starts "
"their local training using the same model parameters. We often use only a"
" few of the connected nodes instead of all nodes. The reason for this is "
"that selecting more and more client nodes has diminishing returns."
msgstr ""
"Ensuite, nous envoyons les paramètres du modèle global aux nœuds clients "
"connectés (par exemple, les appareils périphériques comme les smartphones"
" ou les serveurs appartenant à des organisations). Cela permet de "
"s'assurer que chaque nœud participant commence sa formation locale en "
"utilisant les mêmes paramètres de modèle. Nous n'utilisons souvent que "
"quelques-uns des nœuds connectés au lieu de tous les nœuds. La raison en "
"est que la sélection d'un nombre croissant de nœuds clients a des "
"rendements décroissants."

#: ../../source/tutorial-what-is-federated-learning.ipynb:225
msgid "|3d949f76988443c59990d2e64f05c386|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:309
msgid "Send global model"
msgstr "Envoyer le modèle global"

#: ../../source/tutorial-what-is-federated-learning.ipynb:232
msgid ""
"Step 2: Train model locally on the data of each organization/device "
"(client node)"
msgstr ""
"Étape 2 : Entraîne le modèle localement sur les données de chaque "
"organisation/appareil (nœud client)"

#: ../../source/tutorial-what-is-federated-learning.ipynb:234
msgid ""
"Now that all (selected) client nodes have the latest version of the "
"global model parameters, they start the local training. They use their "
"own local dataset to train their own local model. They don't train the "
"model until full convergence, but they only train for a little while. "
"This could be as little as one epoch on the local data, or even just a "
"few steps (mini-batches)."
msgstr ""
"Maintenant que tous les nœuds clients (sélectionnés) disposent de la "
"dernière version des paramètres du modèle global, ils commencent "
"l'entraînement local. Ils utilisent leur propre ensemble de données "
"locales pour entraîner leur propre modèle local. Ils n'entraînent pas le "
"modèle jusqu'à la convergence totale, mais ils ne s'entraînent que "
"pendant un petit moment. Il peut s'agir d'une seule époque sur les "
"données locales, ou même de quelques étapes (mini-batchs)."

#: ../../source/tutorial-what-is-federated-learning.ipynb:240
msgid "|526c6d9140f6404f8a226d9056327b3b|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:311
msgid "Train on local data"
msgstr "Forme-toi aux données locales"

#: ../../source/tutorial-what-is-federated-learning.ipynb:247
msgid "Step 3: Return model updates back to the server"
msgstr "Étape 3 : Renvoyer les mises à jour du modèle au serveur"

#: ../../source/tutorial-what-is-federated-learning.ipynb:249
msgid ""
"After local training, each client node has a slightly different version "
"of the model parameters they originally received. The parameters are all "
"different because each client node has different examples in its local "
"dataset. The client nodes then send those model updates back to the "
"server. The model updates they send can either be the full model "
"parameters or just the gradients that were accumulated during local "
"training."
msgstr ""
"Après l'entraînement local, chaque nœud client possède une version "
"légèrement différente des paramètres du modèle qu'il a reçus à l'origine."
" Les paramètres sont tous différents parce que chaque nœud client a des "
"exemples différents dans son ensemble de données local. Les nœuds clients"
" renvoient ensuite ces mises à jour du modèle au serveur. Les mises à "
"jour du modèle qu'ils envoient peuvent être soit les paramètres complets "
"du modèle, soit seulement les gradients qui ont été accumulés au cours de"
" l'entraînement local."

#: ../../source/tutorial-what-is-federated-learning.ipynb:255
msgid "|a5f6af14cd7c4550929b17f83b4f63c7|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:313
msgid "Send model updates"
msgstr "Envoyer les mises à jour du modèle"

#: ../../source/tutorial-what-is-federated-learning.ipynb:262
msgid "Step 4: Aggregate model updates into a new global model"
msgstr ""
"Étape 4 : Agréger les mises à jour des modèles dans un nouveau modèle "
"global"

#: ../../source/tutorial-what-is-federated-learning.ipynb:264
msgid ""
"The server receives model updates from the selected client nodes. If it "
"selected 100 client nodes, it now has 100 slightly different versions of "
"the original global model, each trained on the local data of one client. "
"But didn't we want to have one model that contains the learnings from the"
" data of all 100 client nodes?"
msgstr ""
"Le serveur reçoit les mises à jour du modèle des nœuds clients "
"sélectionnés. S'il a sélectionné 100 nœuds clients, il dispose maintenant"
" de 100 versions légèrement différentes du modèle global original, "
"chacune ayant été formée sur les données locales d'un client. Mais ne "
"voulions-nous pas avoir un seul modèle qui contienne les apprentissages "
"des données de l'ensemble des 100 nœuds clients ?"

#: ../../source/tutorial-what-is-federated-learning.ipynb:266
msgid ""
"In order to get one single model, we have to combine all the model "
"updates we received from the client nodes. This process is called "
"*aggregation*, and there are many different ways to do it. The most basic"
" way to do it is called *Federated Averaging* (`McMahan et al., 2016 "
"<https://arxiv.org/abs/1602.05629>`__), often abbreviated as *FedAvg*. "
"*FedAvg* takes the 100 model updates and, as the name suggests, averages "
"them. To be more precise, it takes the *weighted average* of the model "
"updates, weighted by the number of examples each client used for "
"training. The weighting is important to make sure that each data example "
"has the same \"influence\" on the resulting global model. If one client "
"has 10 examples, and another client has 100 examples, then - without "
"weighting - each of the 10 examples would influence the global model ten "
"times as much as each of the 100 examples."
msgstr ""
"In order to get one single model, we have to combine all the model "
"updates we received from the client nodes. This process is called "
"*aggregation*, and there are many different ways to do it. The most basic"
" way to do it is called *Federated Averaging* (`McMahan et al., 2016 "
"<https://arxiv.org/abs/1602.05629>`__), often abbreviated as *FedAvg*. "
"*FedAvg* takes the 100 model updates and, as the name suggests, averages "
"them. To be more precise, it takes the *weighted average* of the model "
"updates, weighted by the number of examples each client used for "
"training. The weighting is important to make sure that each data example "
"has the same \"influence\" on the resulting global model. If one client "
"has 10 examples, and another client has 100 examples, then - without "
"weighting - each of the 10 examples would influence the global model ten "
"times as much as each of the 100 examples."

#: ../../source/tutorial-what-is-federated-learning.ipynb:273
msgid "|bcd571c4f4ee4803a54f71b5c20448cb|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:315
msgid "Aggregate model updates"
msgstr "Mises à jour globales du modèle"

#: ../../source/tutorial-what-is-federated-learning.ipynb:280
msgid "Step 5: Repeat steps 1 to 4 until the model converges"
msgstr "Étape 5 : répète les étapes 1 à 4 jusqu'à ce que le modèle converge"

#: ../../source/tutorial-what-is-federated-learning.ipynb:282
msgid ""
"Steps 1 to 4 are what we call a single round of federated learning. The "
"global model parameters get sent to the participating client nodes (step "
"1), the client nodes train on their local data (step 2), they send their "
"updated models to the server (step 3), and the server then aggregates the"
" model updates to get a new version of the global model (step 4)."
msgstr ""
"Les étapes 1 à 4 constituent ce que nous appelons un cycle unique "
"d'apprentissage fédéré. Les paramètres du modèle global sont envoyés aux "
"nœuds clients participants (étape 1), les nœuds clients s'entraînent sur "
"leurs données locales (étape 2), ils envoient leurs modèles mis à jour au"
" serveur (étape 3), et le serveur agrège ensuite les mises à jour du "
"modèle pour obtenir une nouvelle version du modèle global (étape 4)."

#: ../../source/tutorial-what-is-federated-learning.ipynb:284
#, fuzzy
msgid ""
"During a single round, each client node that participates in that "
"iteration only trains for a little while. This means that after the "
"aggregation step (step 4), we have a model that has been trained on all "
"the data of all participating client nodes, but only for a little while. "
"We then have to repeat this training process over and over again to "
"eventually arrive at a fully trained model that performs well across the "
"data of all client nodes."
msgstr ""
"Au cours d'un seul tour, chaque nœud client qui participe à cette "
"itération ne s'entraîne que pendant un petit moment. Cela signifie "
"qu'après l'étape d'agrégation (étape 4), nous avons un modèle qui a été "
"entraîné sur toutes les données de tous les nœuds clients participants, "
"mais seulement pendant un petit moment. Nous devons ensuite répéter ce "
"processus d'entraînement encore et encore pour finalement arriver à un "
"modèle entièrement entraîné qui fonctionne bien sur l'ensemble des "
"données de tous les nœuds clients."

#: ../../source/tutorial-what-is-federated-learning.ipynb:289
msgid ""
"Congratulations, you now understand the basics of federated learning. "
"There's a lot more to discuss, of course, but that was federated learning"
" in a nutshell. In later parts of this tutorial, we will go into more "
"detail. Interesting questions include: How can we select the best client "
"nodes that should participate in the next round? What's the best way to "
"aggregate model updates? How can we handle failing client nodes "
"(stragglers)?"
msgstr ""
"Félicitations, tu comprends maintenant les bases de l'apprentissage "
"fédéré. Il y a bien sûr beaucoup plus à discuter, mais c'était "
"l'apprentissage fédéré en quelques mots. Dans les parties suivantes de ce"
" tutoriel, nous irons plus en détail. Les questions intéressantes "
"comprennent : comment pouvons-nous sélectionner les meilleurs nœuds "
"clients qui devraient participer au prochain tour ? Quelle est la "
"meilleure façon d'agréger les mises à jour du modèle ? Comment pouvons-"
"nous gérer les nœuds clients qui échouent (stragglers) ?"

#: ../../source/tutorial-what-is-federated-learning.ipynb:294
#, fuzzy
msgid ""
"Just like we can train a model on the decentralized data of different "
"client nodes, we can also evaluate the model on that data to receive "
"valuable metrics. This is called federated evaluation, sometimes "
"abbreviated as FE. In fact, federated evaluation is an integral part of "
"most federated learning systems."
msgstr ""
"Tout comme nous pouvons former un modèle sur les données décentralisées "
"de différents nœuds clients, nous pouvons également évaluer le modèle sur"
" ces données pour recevoir des mesures précieuses. C'est ce qu'on appelle"
" l'évaluation fédérée, parfois abrégée en FE. En fait, l'évaluation "
"fédérée fait partie intégrante de la plupart des systèmes d'apprentissage"
" fédéré."

#: ../../source/tutorial-what-is-federated-learning.ipynb:297
msgid "Federated analytics"
msgstr "Analyses fédérées"

#: ../../source/tutorial-what-is-federated-learning.ipynb:299
msgid ""
"In many cases, machine learning isn't necessary to derive value from "
"data. Data analysis can yield valuable insights, but again, there's often"
" not enough data to get a clear answer. What's the average age at which "
"people develop a certain type of health condition? Federated analytics "
"enables such queries over multiple client nodes. It is usually used in "
"conjunction with other privacy-enhancing technologies like secure "
"aggregation to prevent the server from seeing the results submitted by "
"individual client nodes."
msgstr ""
"Dans de nombreux cas, l'apprentissage automatique n'est pas nécessaire "
"pour tirer de la valeur des données. L'analyse des données peut donner "
"des indications précieuses, mais là encore, il n'y a souvent pas assez de"
" données pour obtenir une réponse claire. Quel est l'âge moyen auquel les"
" gens développent un certain type de problème de santé ? L'analyse "
"fédérée permet de telles requêtes sur plusieurs nœuds clients. Elle est "
"généralement utilisée en conjonction avec d'autres technologies de "
"renforcement de la confidentialité, comme l'agrégation sécurisée, pour "
"empêcher le serveur de voir les résultats soumis par les nœuds clients "
"individuels."

#: ../../source/tutorial-what-is-federated-learning.ipynb:303
#, fuzzy
msgid "Differential Privacy"
msgstr "Confidentialité différentielle"

#: ../../source/tutorial-what-is-federated-learning.ipynb:305
msgid ""
"Differential privacy (DP) is often mentioned in the context of Federated "
"Learning. It is a privacy-preserving method used when analyzing and "
"sharing statistical data, ensuring the privacy of individual "
"participants. DP achieves this by adding statistical noise to the model "
"updates, ensuring any individual participants’ information cannot be "
"distinguished or re-identified. This technique can be considered an "
"optimization that provides a quantifiable privacy protection measure."
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:326
msgid "Flower"
msgstr "Fleur"

#: ../../source/tutorial-what-is-federated-learning.ipynb:328
msgid ""
"Federated learning, federated evaluation, and federated analytics require"
" infrastructure to move machine learning models back and forth, train and"
" evaluate them on local data, and then aggregate the updated models. "
"Flower provides the infrastructure to do exactly that in an easy, "
"scalable, and secure way. In short, Flower presents a unified approach to"
" federated learning, analytics, and evaluation. It allows the user to "
"federate any workload, any ML framework, and any programming language."
msgstr ""
"L'apprentissage fédéré, l'évaluation fédérée et l'analyse fédérée "
"nécessitent une infrastructure pour déplacer les modèles d'apprentissage "
"automatique dans les deux sens, les entraîner et les évaluer sur des "
"données locales, puis agréger les modèles mis à jour. Flower fournit "
"l'infrastructure pour faire exactement cela de manière simple, évolutive "
"et sécurisée. En bref, Flower présente une approche unifiée de "
"l'apprentissage, de l'analyse et de l'évaluation fédérés. Il permet à "
"l'utilisateur de fédérer n'importe quelle charge de travail, n'importe "
"quel cadre de ML et n'importe quel langage de programmation."

#: ../../source/tutorial-what-is-federated-learning.ipynb:334
msgid "|c76452ae1ed84965be7ef23c72b95845|"
msgstr ""

#: ../../source/tutorial-what-is-federated-learning.ipynb:340
msgid ""
"Flower federated learning server and client nodes (car, scooter, personal"
" computer, roomba, and phone)"
msgstr ""
"Serveur d'apprentissage fédéré de Flower et nœuds clients (voiture, "
"scooter, ordinateur personnel, roomba et téléphone)"

#: ../../source/tutorial-what-is-federated-learning.ipynb:353
msgid ""
"Congratulations, you just learned the basics of federated learning and "
"how it relates to the classic (centralized) machine learning!"
msgstr ""
"Félicitations, tu viens d'apprendre les bases de l'apprentissage fédéré "
"et son rapport avec l'apprentissage automatique classique (centralisé) !"

#: ../../source/tutorial-what-is-federated-learning.ipynb:355
msgid ""
"In the next part of this tutorial, we are going to build a first "
"federated learning system with Flower."
msgstr ""
"Dans la prochaine partie de ce tutoriel, nous allons construire un "
"premier système d'apprentissage fédéré avec Flower."

#: ../../source/tutorial-what-is-federated-learning.ipynb:373
#, fuzzy
msgid ""
"The `Flower Federated Learning Tutorial - Part 1 "
"<https://flower.dev/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__ shows how to build a simple federated learning system "
"with PyTorch and Flower."
msgstr ""
"Le `Tutoriel d'apprentissage fédéré Flower - Partie 1 "
"<https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html>`__ "
"montre comment construire un système d'apprentissage fédéré simple avec "
"PyTorch et Flower."

#~ msgid "Flower CLI commands"
#~ msgstr "Commandes CLI Flower"

#~ msgid "Contributor guide"
#~ msgstr "Guide pour les contributeurs"

#~ msgid "API Reference - Flower CLI commands"
#~ msgstr "Référence API - Commandes CLI pour Flower"

#~ msgid "API Reference - flwr (Python package)"
#~ msgstr "Référence API - flwr (paquetage Python)"

#~ msgid "Flower client."
#~ msgstr "Client de Flower"

#~ msgid "Abstract base class for Flower clients."
#~ msgstr ""

#~ msgid "Evaluate the provided parameters using the locally held dataset."
#~ msgstr "évaluer le modèle mis à jour sur l'ensemble de test local"

#~ msgid "Parameters"
#~ msgstr "Paramètres du modèle."

#~ msgid ""
#~ "The evaluation instructions containing "
#~ "(global) model parameters received from "
#~ "the server and a dictionary of "
#~ "configuration values used to customize "
#~ "the local evaluation process."
#~ msgstr ""

#~ msgid "Returns"
#~ msgstr "Ressources"

#~ msgid ""
#~ "The evaluation result containing the "
#~ "loss on the local dataset and "
#~ "other details such as the number "
#~ "of local data examples used for "
#~ "evaluation."
#~ msgstr ""

#~ msgid "Return type"
#~ msgstr ""

#~ msgid "Refine the provided parameters using the locally held dataset."
#~ msgstr ""

#~ msgid ""
#~ "The training instructions containing (global)"
#~ " model parameters received from the "
#~ "server and a dictionary of configuration"
#~ " values used to customize the local"
#~ " training process."
#~ msgstr ""

#~ msgid ""
#~ "The training result containing updated "
#~ "parameters and other details such as "
#~ "the number of local training examples"
#~ " used for training."
#~ msgstr ""

#~ msgid "Return the current local model parameters."
#~ msgstr "``get_parameters`` : renvoie les paramètres du modèle local actuel"

#~ msgid ""
#~ "The get parameters instructions received "
#~ "from the server containing a dictionary"
#~ " of configuration values."
#~ msgstr ""

#~ msgid "The current local model parameters."
#~ msgstr "``get_parameters`` : renvoie les paramètres du modèle local actuel"

#~ msgid "Return set of client's properties."
#~ msgstr ""

#~ msgid ""
#~ "The get properties instructions received "
#~ "from the server containing a dictionary"
#~ " of configuration values."
#~ msgstr ""

#~ msgid "The current client properties."
#~ msgstr ""

#~ msgid "Start a Flower client node which connects to a Flower server."
#~ msgstr ""

#~ msgid ""
#~ "The IPv4 or IPv6 address of the"
#~ " server. If the Flower server runs"
#~ " on the same machine on port "
#~ "8080, then `server_address` would be "
#~ "`\"[::]:8080\"`."
#~ msgstr ""

#~ msgid "An implementation of the abstract base class `flwr.client.Client`."
#~ msgstr ""

#~ msgid ""
#~ "The maximum length of gRPC messages "
#~ "that can be exchanged with the "
#~ "Flower server. The default should be "
#~ "sufficient for most models. Users who"
#~ " train very large models might need"
#~ " to increase this value. Note that"
#~ " the Flower server needs to be "
#~ "started with the same value (see "
#~ "`flwr.server.start_server`), otherwise it will "
#~ "not know about the increased limit "
#~ "and block larger messages."
#~ msgstr ""

#~ msgid ""
#~ "The PEM-encoded root certificates as "
#~ "a byte string or a path string."
#~ " If provided, a secure connection "
#~ "using the certificates will be "
#~ "established to an SSL-enabled Flower "
#~ "server."
#~ msgstr ""

#~ msgid ""
#~ "DEPRECATED - USE 'transport' INSTEAD. "
#~ "Defines whether or not the client "
#~ "is interacting with the server using "
#~ "the experimental REST API. This feature"
#~ " is experimental, it might change "
#~ "considerably in future versions of "
#~ "Flower."
#~ msgstr ""
#~ "DÉPRÉCIÉ - UTILISER 'transport' À LA "
#~ "PLACE Définit si le client interagit "
#~ "ou non avec le serveur à l'aide"
#~ " de l'API REST expérimentale. Cette "
#~ "fonctionnalité est expérimentale, elle "
#~ "pourrait changer considérablement dans les "
#~ "futures versions de Flower."

#~ msgid ""
#~ "Configure the transport layer. Allowed "
#~ "values: - 'grpc-bidi': gRPC, "
#~ "bidirectional streaming - 'grpc-rere': "
#~ "gRPC, request-response (experimental) - "
#~ "'rest': HTTP (experimental)"
#~ msgstr ""
#~ "Valeurs autorisées : - 'grpc-bidi' "
#~ ": gRPC, flux bidirectionnel - 'grpc-"
#~ "rere' : gRPC, requête-réponse "
#~ "(expérimental) - 'rest' : HTTP "
#~ "(expérimental)"

#~ msgid "Starting a gRPC client with an insecure server connection:"
#~ msgstr ""

#~ msgid "Starting an SSL-enabled gRPC client:"
#~ msgstr ""

#~ msgid "Abstract base class for Flower clients using NumPy."
#~ msgstr ""

#~ msgid "The current (global) model parameters."
#~ msgstr "``get_parameters`` : renvoie les paramètres du modèle local actuel"

#~ msgid ""
#~ "Configuration parameters which allow the "
#~ "server to influence evaluation on the"
#~ " client. It can be used to "
#~ "communicate arbitrary values from the "
#~ "server to the client, for example, "
#~ "to influence the number of examples "
#~ "used for evaluation."
#~ msgstr ""

#~ msgid ""
#~ "* **loss** (*float*) -- The evaluation"
#~ " loss of the model on the local"
#~ " dataset. * **num_examples** (*int*) -- "
#~ "The number of examples used for "
#~ "evaluation. * **metrics** (*Dict[str, "
#~ "Scalar]*) -- A dictionary mapping "
#~ "arbitrary string keys to values of   "
#~ "type bool, bytes, float, int, or "
#~ "str. It can be used to   "
#~ "communicate arbitrary values back to the"
#~ " server."
#~ msgstr ""

#~ msgid ""
#~ "**loss** (*float*) -- The evaluation "
#~ "loss of the model on the local "
#~ "dataset."
#~ msgstr ""

#~ msgid "**num_examples** (*int*) -- The number of examples used for evaluation."
#~ msgstr ""

#~ msgid ""
#~ "**metrics** (*Dict[str, Scalar]*) -- A "
#~ "dictionary mapping arbitrary string keys "
#~ "to values of type bool, bytes, "
#~ "float, int, or str. It can be "
#~ "used to communicate arbitrary values "
#~ "back to the server."
#~ msgstr ""

#~ msgid ""
#~ "The previous return type format (int,"
#~ " float, float) and the extended "
#~ "format (int, float, float, Dict[str, "
#~ "Scalar]) have been deprecated and "
#~ "removed since Flower 0.19."
#~ msgstr ""

#~ msgid "Train the provided parameters using the locally held dataset."
#~ msgstr "entraîne le modèle sur l'ensemble d'apprentissage local"

#~ msgid ""
#~ "Configuration parameters which allow the "
#~ "server to influence training on the "
#~ "client. It can be used to "
#~ "communicate arbitrary values from the "
#~ "server to the client, for example, "
#~ "to set the number of (local) "
#~ "training epochs."
#~ msgstr ""

#~ msgid ""
#~ "* **parameters** (*NDArrays*) -- The "
#~ "locally updated model parameters. * "
#~ "**num_examples** (*int*) -- The number "
#~ "of examples used for training. * "
#~ "**metrics** (*Dict[str, Scalar]*) -- A "
#~ "dictionary mapping arbitrary string keys "
#~ "to values of type   bool, bytes, "
#~ "float, int, or str. It can be "
#~ "used to communicate   arbitrary values "
#~ "back to the server."
#~ msgstr ""

#~ msgid "**parameters** (*NDArrays*) -- The locally updated model parameters."
#~ msgstr "``get_parameters`` : renvoie les paramètres du modèle local actuel"

#~ msgid "**num_examples** (*int*) -- The number of examples used for training."
#~ msgstr ""

#~ msgid ""
#~ "Configuration parameters requested by the "
#~ "server. This can be used to tell"
#~ " the client which parameters are "
#~ "needed along with some Scalar "
#~ "attributes."
#~ msgstr ""

#~ msgid ""
#~ "**parameters** -- The local model "
#~ "parameters as a list of NumPy "
#~ "ndarrays."
#~ msgstr "renvoie le poids du modèle sous la forme d'une liste de ndarrays NumPy"

#~ msgid "Return a client's set of properties."
#~ msgstr "Renvoie l'ensemble des propriétés d'un client."

#~ msgid ""
#~ "Configuration parameters requested by the "
#~ "server. This can be used to tell"
#~ " the client which properties are "
#~ "needed along with some Scalar "
#~ "attributes."
#~ msgstr ""

#~ msgid ""
#~ "**properties** -- A dictionary mapping "
#~ "arbitrary string keys to values of "
#~ "type bool, bytes, float, int, or "
#~ "str. It can be used to communicate"
#~ " arbitrary property values back to "
#~ "the server."
#~ msgstr ""

#~ msgid "Start a Flower NumPyClient which connects to a gRPC server."
#~ msgstr ""

#~ msgid "An implementation of the abstract base class `flwr.client.NumPyClient`."
#~ msgstr ""

#~ msgid "Starting a client with an insecure server connection:"
#~ msgstr ""

#~ msgid "Starting a SSL-enabled client:"
#~ msgstr ""

#~ msgid "Start a Ray-based Flower simulation server."
#~ msgstr "Simulation de moniteur"

#~ msgid ""
#~ "A function creating client instances. "
#~ "The function must take a single "
#~ "`str` argument called `cid`. It should"
#~ " return a single client instance of"
#~ " type ClientLike. Note that the "
#~ "created client instances are ephemeral "
#~ "and will often be destroyed after "
#~ "a single method invocation. Since client"
#~ " instances are not long-lived, they"
#~ " should not attempt to carry state"
#~ " over method invocations. Any state "
#~ "required by the instance (model, "
#~ "dataset, hyperparameters, ...) should be "
#~ "(re-)created in either the call to "
#~ "`client_fn` or the call to any of"
#~ " the client methods (e.g., load "
#~ "evaluation data in the `evaluate` method"
#~ " itself)."
#~ msgstr ""
#~ "Une fonction créant des instances de "
#~ "client. La fonction doit prendre un "
#~ "seul argument `str` appelé `cid`. Elle"
#~ " doit retourner une seule instance de"
#~ " client de type ClientLike. Notez que"
#~ " les instances de client créées sont"
#~ " éphémères et seront souvent détruites "
#~ "après une seule invocation de méthode."
#~ " Puisque les instances de client ne"
#~ " sont pas de longue durée, elles "
#~ "ne doivent pas essayer de transporter"
#~ " l'état sur les invocations de "
#~ "méthode. Tout état requis par l'instance"
#~ " (modèle, jeu de données, hyperparamètres,"
#~ " ...) doit être (re)créé dans l'appel"
#~ " à `client_fn` ou dans l'appel à "
#~ "n'importe quelle méthode de client (par"
#~ " exemple, charger les données d'évaluation"
#~ " dans la méthode `evaluate` elle-"
#~ "même)."

#~ msgid ""
#~ "The total number of clients in "
#~ "this simulation. This must be set "
#~ "if `clients_ids` is not set and "
#~ "vice-versa."
#~ msgstr ""

#~ msgid ""
#~ "List `client_id`s for each client. This"
#~ " is only required if `num_clients` is"
#~ " not set. Setting both `num_clients` "
#~ "and `clients_ids` with `len(clients_ids)` not"
#~ " equal to `num_clients` generates an "
#~ "error."
#~ msgstr ""

#~ msgid ""
#~ "CPU and GPU resources for a single"
#~ " client. Supported keys are `num_cpus` "
#~ "and `num_gpus`. Example: `{\"num_cpus\": 4,"
#~ " \"num_gpus\": 1}`. To understand the "
#~ "GPU utilization caused by `num_gpus`, "
#~ "consult the Ray documentation on GPU "
#~ "support."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.Server`. If no instance"
#~ " is provided, then `start_server` will "
#~ "create one."
#~ msgstr ""

#~ msgid ""
#~ "Currently supported values are `num_rounds`"
#~ " (int, default: 1) and `round_timeout` "
#~ "in seconds (float, default: None)."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.Strategy`. If no "
#~ "strategy is provided, then `start_server` "
#~ "will use `flwr.server.strategy.FedAvg`."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.ClientManager`. If no "
#~ "implementation is provided, then "
#~ "`start_simulation` will use "
#~ "`flwr.server.client_manager.SimpleClientManager`."
#~ msgstr ""

#~ msgid ""
#~ "Optional dictionary containing arguments for"
#~ " the call to `ray.init`. If "
#~ "ray_init_args is None (the default), Ray"
#~ " will be initialized with the "
#~ "following default args:  { "
#~ "\"ignore_reinit_error\": True, \"include_dashboard\": "
#~ "False }  An empty dictionary can "
#~ "be used (ray_init_args={}) to prevent "
#~ "any arguments from being passed to "
#~ "ray.init."
#~ msgstr ""

#~ msgid ""
#~ "Optional dictionary containing arguments for"
#~ " the call to `ray.init`. If "
#~ "ray_init_args is None (the default), Ray"
#~ " will be initialized with the "
#~ "following default args:"
#~ msgstr ""

#~ msgid "{ \"ignore_reinit_error\": True, \"include_dashboard\": False }"
#~ msgstr ""

#~ msgid ""
#~ "An empty dictionary can be used "
#~ "(ray_init_args={}) to prevent any arguments"
#~ " from being passed to ray.init."
#~ msgstr ""

#~ msgid ""
#~ "Set to True to prevent `ray.shutdown()`"
#~ " in case `ray.is_initialized()=True`."
#~ msgstr ""

#~ msgid "**hist** -- Object containing metrics from training."
#~ msgstr ""

#~ msgid "Flower server."
#~ msgstr "Serveur de Flower"

#~ msgid "Start a Flower server using the gRPC transport layer."
#~ msgstr ""

#~ msgid "The IPv4 or IPv6 address of the server. Defaults to `\"[::]:8080\"`."
#~ msgstr ""

#~ msgid ""
#~ "A server implementation, either "
#~ "`flwr.server.Server` or a subclass thereof."
#~ " If no instance is provided, then "
#~ "`start_server` will create one."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.strategy.Strategy`. If no "
#~ "strategy is provided, then `start_server` "
#~ "will use `flwr.server.strategy.FedAvg`."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.ClientManager`. If no "
#~ "implementation is provided, then "
#~ "`start_server` will use "
#~ "`flwr.server.client_manager.SimpleClientManager`."
#~ msgstr ""

#~ msgid ""
#~ "The maximum length of gRPC messages "
#~ "that can be exchanged with the "
#~ "Flower clients. The default should be"
#~ " sufficient for most models. Users "
#~ "who train very large models might "
#~ "need to increase this value. Note "
#~ "that the Flower clients need to be"
#~ " started with the same value (see "
#~ "`flwr.client.start_client`), otherwise clients will"
#~ " not know about the increased limit"
#~ " and block larger messages."
#~ msgstr ""

#~ msgid ""
#~ "Tuple containing root certificate, server "
#~ "certificate, and private key to start"
#~ " a secure SSL-enabled server. The "
#~ "tuple is expected to have three "
#~ "bytes elements in the following order:"
#~ "      * CA certificate.     * server "
#~ "certificate.     * server private key."
#~ msgstr ""

#~ msgid ""
#~ "Tuple containing root certificate, server "
#~ "certificate, and private key to start"
#~ " a secure SSL-enabled server. The "
#~ "tuple is expected to have three "
#~ "bytes elements in the following order:"
#~ msgstr ""

#~ msgid "CA certificate."
#~ msgstr "Certificats"

#~ msgid "server certificate."
#~ msgstr "Certificats"

#~ msgid "server private key."
#~ msgstr "stratégie.du.serveur"

#~ msgid "**hist** -- Object containing training and evaluation metrics."
#~ msgstr ""

#~ msgid "Starting an insecure server:"
#~ msgstr "Démarrer le serveur"

#~ msgid "Starting an SSL-enabled server:"
#~ msgstr "Démarrer le serveur"

#~ msgid "Contains the strategy abstraction and different implementations."
#~ msgstr ""

#~ msgid "Abstract base class for server strategy implementations."
#~ msgstr ""

#~ msgid "The current round of federated learning."
#~ msgstr "Qu'est-ce que l'apprentissage fédéré ?"

#~ msgid ""
#~ "Successful updates from the previously "
#~ "selected and configured clients. Each "
#~ "pair of `(ClientProxy, FitRes` constitutes "
#~ "a successful update from one of "
#~ "the previously selected clients. Not "
#~ "that not all previously selected clients"
#~ " are necessarily included in this "
#~ "list: a client might drop out and"
#~ " not submit a result. For each "
#~ "client that did not submit an "
#~ "update, there should be an `Exception`"
#~ " in `failures`."
#~ msgstr ""

#~ msgid ""
#~ "Exceptions that occurred while the "
#~ "server was waiting for client updates."
#~ msgstr ""

#~ msgid ""
#~ "**aggregation_result** -- The aggregated "
#~ "evaluation result. Aggregation typically uses"
#~ " some variant of a weighted average."
#~ msgstr ""

#~ msgid "Aggregate training results."
#~ msgstr "Résultats globaux de l'évaluation."

#~ msgid ""
#~ "Successful updates from the previously "
#~ "selected and configured clients. Each "
#~ "pair of `(ClientProxy, FitRes)` constitutes"
#~ " a successful update from one of "
#~ "the previously selected clients. Not "
#~ "that not all previously selected clients"
#~ " are necessarily included in this "
#~ "list: a client might drop out and"
#~ " not submit a result. For each "
#~ "client that did not submit an "
#~ "update, there should be an `Exception`"
#~ " in `failures`."
#~ msgstr ""

#~ msgid ""
#~ "**parameters** -- If parameters are "
#~ "returned, then the server will treat "
#~ "these as the new global model "
#~ "parameters (i.e., it will replace the"
#~ " previous parameters with the ones "
#~ "returned from this method). If `None`"
#~ " is returned (e.g., because there "
#~ "were only failures and no viable "
#~ "results) then the server will no "
#~ "update the previous model parameters, "
#~ "the updates received in this round "
#~ "are discarded, and the global model "
#~ "parameters remain the same."
#~ msgstr ""

#~ msgid "Configure the next round of evaluation."
#~ msgstr "Configuration de l'évaluation côté serveur"

#~ msgid "The client manager which holds all currently connected clients."
#~ msgstr ""

#~ msgid ""
#~ "**evaluate_configuration** -- A list of "
#~ "tuples. Each tuple in the list "
#~ "identifies a `ClientProxy` and the "
#~ "`EvaluateIns` for this particular "
#~ "`ClientProxy`. If a particular `ClientProxy`"
#~ " is not included in this list, "
#~ "it means that this `ClientProxy` will"
#~ " not participate in the next round"
#~ " of federated evaluation."
#~ msgstr ""

#~ msgid "Configure the next round of training."
#~ msgstr ""

#~ msgid ""
#~ "**fit_configuration** -- A list of "
#~ "tuples. Each tuple in the list "
#~ "identifies a `ClientProxy` and the "
#~ "`FitIns` for this particular `ClientProxy`."
#~ " If a particular `ClientProxy` is not"
#~ " included in this list, it means "
#~ "that this `ClientProxy` will not "
#~ "participate in the next round of "
#~ "federated learning."
#~ msgstr ""

#~ msgid "Evaluate the current model parameters."
#~ msgstr "``get_parameters`` : renvoie les paramètres du modèle local actuel"

#~ msgid ""
#~ "This function can be used to "
#~ "perform centralized (i.e., server-side) "
#~ "evaluation of model parameters."
#~ msgstr ""

#~ msgid ""
#~ "**evaluation_result** -- The evaluation "
#~ "result, usually a Tuple containing loss"
#~ " and a dictionary containing task-"
#~ "specific metrics (e.g., accuracy)."
#~ msgstr ""

#~ msgid "Initialize the (global) model parameters."
#~ msgstr "Initialise le modèle global"

#~ msgid ""
#~ "**parameters** -- If parameters are "
#~ "returned, then the server will treat "
#~ "these as the initial global model "
#~ "parameters."
#~ msgstr ""

#~ msgid "Configurable FedAvg strategy implementation."
#~ msgstr "Configuration de l'évaluation fédérée"

#~ msgid "Implementation based on https://arxiv.org/abs/1602.05629"
#~ msgstr ""

#~ msgid ""
#~ "Fraction of clients used during "
#~ "training. In case `min_fit_clients` is "
#~ "larger than `fraction_fit * "
#~ "available_clients`, `min_fit_clients` will still "
#~ "be sampled. Defaults to 1.0."
#~ msgstr ""

#~ msgid ""
#~ "Fraction of clients used during "
#~ "validation. In case `min_evaluate_clients` is"
#~ " larger than `fraction_evaluate * "
#~ "available_clients`, `min_evaluate_clients` will "
#~ "still be sampled. Defaults to 1.0."
#~ msgstr ""

#~ msgid "Minimum number of clients used during training. Defaults to 2."
#~ msgstr ""

#~ msgid "Minimum number of clients used during validation. Defaults to 2."
#~ msgstr ""

#~ msgid "Minimum number of total clients in the system. Defaults to 2."
#~ msgstr ""

#~ msgid "Optional function used for validation. Defaults to None."
#~ msgstr ""

#~ msgid "Function used to configure training. Defaults to None."
#~ msgstr ""

#~ msgid "Function used to configure validation. Defaults to None."
#~ msgstr ""

#~ msgid "Whether or not accept rounds containing failures. Defaults to True."
#~ msgstr ""

#~ msgid "Initial global model parameters."
#~ msgstr "Initialise le modèle global"

#~ msgid "Metrics aggregation function, optional."
#~ msgstr ""

#~ msgid "Aggregate evaluation losses using weighted average."
#~ msgstr "Résultats globaux de l'évaluation."

#~ msgid "Aggregate fit results using weighted average."
#~ msgstr ""

#~ msgid "Evaluate model parameters using an evaluation function."
#~ msgstr ""

#~ msgid "Initialize global model parameters."
#~ msgstr "Initialise le modèle global"

#~ msgid "Use a fraction of available clients for evaluation."
#~ msgstr ""

#~ msgid "Return the sample size and the required number of available clients."
#~ msgstr ""

#~ msgid "Configurable FedAvg with Momentum strategy implementation."
#~ msgstr ""

#~ msgid "Federated Averaging with Momentum strategy."
#~ msgstr "Stratégie de moyenne fédérée."

#~ msgid "Implementation based on https://arxiv.org/pdf/1909.06335.pdf"
#~ msgstr ""

#~ msgid "Fraction of clients used during training. Defaults to 0.1."
#~ msgstr ""

#~ msgid "Fraction of clients used during validation. Defaults to 0.1."
#~ msgstr ""

#~ msgid ""
#~ "Server-side learning rate used in "
#~ "server-side optimization. Defaults to 1.0."
#~ msgstr ""

#~ msgid "Server-side momentum factor used for FedAvgM. Defaults to 0.0."
#~ msgstr ""

#~ msgid "Configurable QFedAvg strategy implementation."
#~ msgstr ""

#~ msgid "Configurable fault-tolerant FedAvg strategy implementation."
#~ msgstr ""

#~ msgid "Configurable FedAdagrad strategy implementation."
#~ msgstr ""

#~ msgid "Federated Optim strategy interface."
#~ msgstr ""

#~ msgid "Implementation based on https://arxiv.org/abs/2003.00295v5"
#~ msgstr ""
#~ "FedYogi - Stratégie d'apprentissage fédéré "
#~ "utilisant Yogi côté serveur. Mise en "
#~ "oeuvre basée sur https://arxiv.org/abs/2003.00295"

#~ msgid "Fraction of clients used during training. Defaults to 1.0."
#~ msgstr ""

#~ msgid "Fraction of clients used during validation. Defaults to 1.0."
#~ msgstr ""

#~ msgid "Server-side learning rate. Defaults to 1e-1."
#~ msgstr ""

#~ msgid "Client-side learning rate. Defaults to 1e-1."
#~ msgstr ""

#~ msgid "Momentum parameter. Defaults to 0.0."
#~ msgstr ""

#~ msgid "Second moment parameter. Defaults to 0.0."
#~ msgstr ""

#~ msgid "Controls the algorithm's degree of adaptability. Defaults to 1e-9."
#~ msgstr ""

#~ msgid "Configurable FedProx strategy implementation."
#~ msgstr ""

#~ msgid "Federated Optimization strategy."
#~ msgstr "Stratégie de moyenne fédérée."

#~ msgid "Implementation based on https://arxiv.org/abs/1812.06127"
#~ msgstr ""

#~ msgid ""
#~ "The strategy in itself will not be"
#~ " different than FedAvg, the client "
#~ "needs to be adjusted. A proximal "
#~ "term needs to be added to the "
#~ "loss function during the training:"
#~ msgstr ""

#~ msgid ""
#~ "\\\\frac{\\\\mu}{2} || w - w^t ||^2\n"
#~ "\n"
#~ msgstr "\\\\frac{\\Nmu}{2} || w - w^t ||^2"

#~ msgid ""
#~ "Where $w^t$ are the global parameters"
#~ " and $w$ are the local weights "
#~ "the function will be optimized with."
#~ msgstr ""

#~ msgid "In PyTorch, for example, the loss would go from:"
#~ msgstr ""

#~ msgid "To:"
#~ msgstr ""

#~ msgid ""
#~ "With `global_params` being a copy of "
#~ "the parameters before the training takes"
#~ " place."
#~ msgstr ""

#~ msgid ""
#~ "The weight of the proximal term "
#~ "used in the optimization. 0.0 makes "
#~ "this strategy equivalent to FedAvg, and"
#~ " the higher the coefficient, the more"
#~ " regularization will be used (that "
#~ "is, the client parameters will need "
#~ "to be closer to the server "
#~ "parameters during training)."
#~ msgstr ""

#~ msgid "Sends the proximal factor mu to the clients"
#~ msgstr ""

#~ msgid "FedAdagrad strategy - Adaptive Federated Optimization using Adagrad."
#~ msgstr ""
#~ "Stratégie FedAdagrad - Optimisation fédérée"
#~ " adaptative à l'aide d'Adagrad."

#~ msgid "Paper: https://arxiv.org/abs/2003.00295"
#~ msgstr ""

#~ msgid "Federated learning strategy using Adagrad on server-side."
#~ msgstr ""
#~ "Construisons un système d'apprentissage fédéré"
#~ " en utilisant fastai et Flower !"

#~ msgid "FedAdam - Adaptive Federated Optimization using Adam."
#~ msgstr "FedAdam - Optimisation fédérée adaptative utilisant Adam."

#~ msgid "Momentum parameter. Defaults to 0.9."
#~ msgstr ""

#~ msgid "Second moment parameter. Defaults to 0.99."
#~ msgstr ""

#~ msgid "FedYogi [Reddi et al., 2020] strategy."
#~ msgstr "Stratégie FedYogi [Reddi et al., 2020]."

#~ msgid "Adaptive Federated Optimization using Yogi."
#~ msgstr "Optimisation fédérée adaptative à l'aide de Yogi."

#~ msgid "Federated learning strategy using Yogi on server-side."
#~ msgstr "L'apprentissage fédéré en cinq étapes"

#~ msgid "Differential Privacy Wrappers in Flower"
#~ msgstr "Les enveloppes différentielles de confidentialité dans les fleurs"

#~ msgid "Evaluation"
#~ msgstr "Solution"

#~ msgid "Code examples"
#~ msgstr "Exemple de code complet"

#~ msgid ""
#~ "Flower Quickstart (PyTorch): coming soon "
#~ "(the TensorFlow/Keras example can easily "
#~ "be changed to make it work with"
#~ " PyTorch)"
#~ msgstr ""

#~ msgid "First time contributors"
#~ msgstr "Bonnes premières contributions"

#~ msgid "First MXNet 1.6 example (MNIST)"
#~ msgstr ""

#~ msgid "ImageNet (PyTorch/TensorFlow)"
#~ msgstr ""

#~ msgid "LSTM (PyTorch/TensorFlow)"
#~ msgstr ""

#~ msgid "Transformer (PyTorch/TensorFlow)"
#~ msgstr ""

#~ msgid "BERT (PyTorch/TensorFlow)"
#~ msgstr ""

#~ msgid "Logging"
#~ msgstr "Enregistrement"

#~ msgid "|cce04c6f539b421a91f5dba40287193f|"
#~ msgstr "|cce04c6f539b421a91f5dba40287193f|"

#~ msgid "|e392aef42ba248e19e35446f95a6d1ca|"
#~ msgstr "|e392aef42ba248e19e35446f95a6d1ca|"

#~ msgid "|7e028f44defe4f31a02debc729f2010d|"
#~ msgstr "|7e028f44defe4f31a02debc729f2010d|"

#~ msgid "|b89f7b7ae05e4ecd92baa69b7a9fe1be|"
#~ msgstr "|b89f7b7ae05e4ecd92baa69b7a9fe1be|"

#~ msgid "|9c0445ce962744e1a1c0a4abc697a334|"
#~ msgstr "|9c0445ce962744e1a1c0a4abc697a334|"

#~ msgid "|a3246766a6db412888131b3bcdad0971|"
#~ msgstr "|a3246766a6db412888131b3bcdad0971|"

#~ msgid "|db6f2bee32f143b8a5085b6a8ce1acd1|"
#~ msgstr "|db6f2bee32f143b8a5085b6a8ce1acd1|"

#~ msgid "|405653bc8f874e9595fd59cc82b3d48c|"
#~ msgstr "|405653bc8f874e9595fd59cc82b3d48c|"

#~ msgid "|073a728154ed406e8fe54e1d9f18dcb9|"
#~ msgstr "|073a728154ed406e8fe54e1d9f18dcb9|"

#~ msgid "|50e80ea4f22945848b65ed7eed35e0e1|"
#~ msgstr "|50e80ea4f22945848b65ed7eed35e0e1|"

#~ msgid "|f3cf9148d85e4b68b66b6c255b25e327|"
#~ msgstr "|f3cf9148d85e4b68b66b6c255b25e327|"

#~ msgid "|1fedb4f8714947e1b13f03696180c741|"
#~ msgstr "|1fedb4f8714947e1b13f03696180c741|"

#~ msgid "|a32d4ad1ccb34461942d75c7b2b51d65|"
#~ msgstr "|a32d4ad1ccb34461942d75c7b2b51d65|"

#~ msgid "|3531696c52904cd3b9944034ab959d48|"
#~ msgstr "|3531696c52904cd3b9944034ab959d48|"

#~ msgid "An Introduction to Federated Learning"
#~ msgstr "Mise à l'échelle de l'apprentissage fédéré"

#~ msgid "Strategies in Federated Learning"
#~ msgstr "Mise à l'échelle de l'apprentissage fédéré"

#~ msgid "Building a Strategy"
#~ msgstr "Stratégies intégrées"

#~ msgid "Client and NumPyClient"
#~ msgstr "NumPyClient"

#~ msgid "Strategies"
#~ msgstr "Stratégies personnalisées"

#~ msgid "SSL-enabled Server and Client"
#~ msgstr ""

#~ msgid "About these documents"
#~ msgstr "À propos de ces documents"

#~ msgid "Index"
#~ msgstr "Index"

#~ msgid "Search"
#~ msgstr "Recherche"

#~ msgid "Copyright"
#~ msgstr "Droits d'auteur"

#~ msgid "Save Progress"
#~ msgstr ""

#~ msgid ""
#~ "The Flower server does not prescribe "
#~ "a way to persist model updates or"
#~ " evaluation results. Flower does not "
#~ "(yet) automatically save model updates "
#~ "on the server-side. It's on the"
#~ " roadmap to provide a built-in "
#~ "way of doing this."
#~ msgstr ""

#~ msgid "Release Process"
#~ msgstr "Publier Flower"

#~ msgid "Virtual Env Installation"
#~ msgstr "Virtualenv avec Anaconda"

#~ msgid "Install development versions"
#~ msgstr "Installer les versions de développement de Flower"

#~ msgid "Set up a virtual env"
#~ msgstr "Mettre en place un environment virtuel"

#~ msgid ""
#~ "Note that, in order to build the"
#~ " documentation locally (with ``poetry run"
#~ " make html``, like described below), "
#~ "`Pandoc <https://pandoc.org/installing.html>_` needs "
#~ "to be installed on the system."
#~ msgstr ""
#~ "Notez que, pour construire la "
#~ "documentation localement (avec ``poetry run"
#~ " make html``, comme décrit ci-"
#~ "dessous), ``Pandoc <https://pandoc.org/installing.html>_`"
#~ " doit être installé sur le système."

#~ msgid "Llama 2 fine-tuning, with Hugging Face Transformers and PyTorch"
#~ msgstr "Un fine-tuning de LLaMA 2 avec Hugging Face et PyTorch"

#~ msgid "XGBoost"
#~ msgstr "XGBoost"

#~ msgid "Android ONNX on-device training"
#~ msgstr ""
#~ "Utiliser Android ONNX pour faire du "
#~ "training directement sur le téléphone"

#~ msgid "Contribute on GitHub"
#~ msgstr "Contribuer sur GitHub"

#~ msgid "How to write a good PR title"
#~ msgstr "Comment rédiger un bon titre de RP"

#~ msgid ""
#~ "A well-crafted PR title helps team"
#~ " members quickly understand the purpose "
#~ "and scope of the changes being "
#~ "proposed. Here's a guide to help "
#~ "you write a good GitHub PR title:"
#~ msgstr ""
#~ "Un titre de RP bien rédigé aide"
#~ " les membres de l'équipe à comprendre"
#~ " rapidement l'objectif et la portée "
#~ "des changements proposés. Voici un guide"
#~ " pour t'aider à rédiger un bon "
#~ "titre de RP GitHub :"

#~ msgid ""
#~ "1. Be Clear and Concise: Provide a"
#~ " clear summary of the changes in "
#~ "a concise manner. 1. Use Actionable "
#~ "Verbs: Start with verbs like \"Add,\""
#~ " \"Update,\" or \"Fix\" to indicate "
#~ "the purpose. 1. Include Relevant "
#~ "Information: Mention the affected feature "
#~ "or module for context. 1. Keep it"
#~ " Short: Avoid lengthy titles for easy"
#~ " readability. 1. Use Proper Capitalization"
#~ " and Punctuation: Follow grammar rules "
#~ "for clarity."
#~ msgstr ""
#~ "1. Être clair et concis : fournir"
#~ " un résumé clair des changements de"
#~ " manière concise. 1. Utiliser des "
#~ "verbes d'action : commencer par des "
#~ "verbes comme \" Ajouter \", \" "
#~ "Mettre à jour \" ou \" Réparer "
#~ "\" pour indiquer l'objectif. 1. Inclure"
#~ " des informations pertinentes : mentionner"
#~ " la fonctionnalité ou le module "
#~ "affecté pour le contexte. 1. Faire "
#~ "court : éviter les titres trop "
#~ "longs pour faciliter la lecture. 1. "
#~ "Utiliser des majuscules et une "
#~ "ponctuation correctes : suivre les "
#~ "règles de grammaire pour plus de "
#~ "clarté."

#~ msgid ""
#~ "Let's start with a few examples "
#~ "for titles that should be avoided "
#~ "because they do not provide meaningful"
#~ " information:"
#~ msgstr ""
#~ "Commençons par quelques exemples de "
#~ "titres à éviter car ils ne "
#~ "fournissent pas d'informations significatives "
#~ ":"

#~ msgid "Implement Algorithm"
#~ msgstr "Implémenter l'algorithme"

#~ msgid "Database"
#~ msgstr "Base de données"

#~ msgid "Add my_new_file.py to codebase"
#~ msgstr "Ajoute my_new_file.py à la base de code"

#~ msgid "Improve code in module"
#~ msgstr "Améliore le code dans le module"

#~ msgid "Change SomeModule"
#~ msgstr "Change SomeModule"

#~ msgid ""
#~ "Here are a few positive examples "
#~ "which provide helpful information without "
#~ "repeating how they do it, as that"
#~ " is already visible in the \"Files"
#~ " changed\" section of the PR:"
#~ msgstr ""
#~ "Voici quelques exemples positifs qui "
#~ "fournissent des informations utiles sans "
#~ "répéter comment ils procèdent, car cela"
#~ " est déjà visible dans la section "
#~ "\"Fichiers modifiés\" du RP :"

#~ msgid "Update docs banner to mention Flower Summit 2023"
#~ msgstr ""
#~ "Mettre à jour la bannière des docs"
#~ " pour mentionner le sommet des fleurs"
#~ " 2023"

#~ msgid "Remove unnecessary XGBoost dependency"
#~ msgstr "Supprime les dépendances inutiles de XGBoost"

#~ msgid "Remove redundant attributes in strategies subclassing FedAvg"
#~ msgstr ""
#~ "Supprimer les attributs redondants dans "
#~ "les stratégies sous-classant FedAvg"

#~ msgid "Add CI job to deploy the staging system when the `main` branch changes"
#~ msgstr ""
#~ "Ajoute une tâche CI pour déployer "
#~ "le système de mise en scène "
#~ "lorsque la branche `main` change"

#~ msgid ""
#~ "Add new amazing library which will "
#~ "be used to improve the simulation "
#~ "engine"
#~ msgstr ""
#~ "Ajoute une nouvelle bibliothèque étonnante "
#~ "qui sera utilisée pour améliorer le "
#~ "moteur de simulation"

#~ msgid "Differential privacy"
#~ msgstr "Confidentialité différentielle"

#~ msgid ""
#~ "The Flower server does not prescribe "
#~ "a way to aggregate evaluation results,"
#~ " but it enables the user to "
#~ "fully customize result aggregation."
#~ msgstr ""

#~ msgid "Configure logging"
#~ msgstr "Configurer les clients"

#~ msgid ""
#~ "The Flower logger keeps track of "
#~ "all core events that take place in"
#~ " federated learning workloads. It presents"
#~ " information by default following a "
#~ "standard message format:"
#~ msgstr ""
#~ "L'enregistreur de Flower garde la trace"
#~ " de tous les événements principaux "
#~ "qui ont lieu dans les charges de"
#~ " travail de l'apprentissage fédéré. Il "
#~ "présente les informations par défaut en"
#~ " suivant un format de message "
#~ "standard :"

#~ msgid ""
#~ "containing relevant information including: log"
#~ " message level (e.g. :code:`INFO`, "
#~ ":code:`DEBUG`), a timestamp, the line "
#~ "where the logging took place from, "
#~ "as well as the log message itself."
#~ " In this way, the logger would "
#~ "typically display information on your "
#~ "terminal as follows:"
#~ msgstr ""
#~ "contenant des informations pertinentes, "
#~ "notamment : le niveau du message "
#~ "de journal (par exemple :code:`INFO`, "
#~ ":code:`DEBUG`), un horodatage, la ligne "
#~ "à partir de laquelle l'enregistrement a"
#~ " eu lieu, ainsi que le message "
#~ "de journal lui-même. De cette "
#~ "façon, le logger afficherait typiquement "
#~ "des informations sur ton terminal comme"
#~ " suit :"

#~ msgid "Saving log to file"
#~ msgstr "Enregistrement du journal dans un fichier"

#~ msgid ""
#~ "By default, the Flower log is "
#~ "outputted to the terminal where you "
#~ "launch your Federated Learning workload "
#~ "from. This applies for both gRPC-"
#~ "based federation (i.e. when you do "
#~ ":code:`fl.server.start_server`) and when using "
#~ "the :code:`VirtualClientEngine` (i.e. when you"
#~ " do :code:`fl.simulation.start_simulation`). In "
#~ "some situations you might want to "
#~ "save this log to disk. You can "
#~ "do so by calling the "
#~ "`fl.common.logger.configure() "
#~ "<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_"
#~ " function. For example:"
#~ msgstr ""
#~ "Par défaut, le journal de Flower "
#~ "est affiché dans le terminal à "
#~ "partir duquel tu as lancé ta "
#~ "charge de travail d'apprentissage fédéré. "
#~ "Cela s'applique à la fois à la "
#~ "fédération basée sur gRPC (c'est-à-dire "
#~ "lorsque tu fais :code:`fl.server.start_server`) "
#~ "et à l'utilisation du "
#~ ":code:`VirtualClientEngine` (c'est-à-dire lorsque tu"
#~ " fais :code:`fl.simulation.start_simulation`). Dans "
#~ "certaines situations, tu peux vouloir "
#~ "sauvegarder ce journal sur le disque."
#~ " Tu peux le faire en appelant "
#~ "la fonction `fl.common.logger.configure() "
#~ "<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_."
#~ " Par exemple :"

#~ msgid ""
#~ "With the above, Flower will record "
#~ "the log you see on your terminal"
#~ " to :code:`log.txt`. This file will "
#~ "be created in the same directory "
#~ "as were you are running the code"
#~ " from. If we inspect we see the"
#~ " log above is also recorded but "
#~ "prefixing with :code:`identifier` each line:"
#~ msgstr ""
#~ "Avec ce qui précède, Flower enregistrera"
#~ " le journal que tu vois sur ton"
#~ " terminal dans :code:`log.txt`. Ce fichier"
#~ " sera créé dans le même répertoire"
#~ " que celui à partir duquel tu "
#~ "exécutes le code. Si nous inspectons,"
#~ " nous voyons que le journal ci-"
#~ "dessus est également enregistré, mais en"
#~ " préfixant chaque ligne avec "
#~ ":code:`identifier` :"

#~ msgid "Log your own messages"
#~ msgstr "Enregistrer tes propres messages"

#~ msgid ""
#~ "You might expand the information shown"
#~ " by default with the Flower logger"
#~ " by adding more messages relevant to"
#~ " your application. You can achieve "
#~ "this easily as follows."
#~ msgstr ""
#~ "Tu peux élargir les informations "
#~ "affichées par défaut avec le logger "
#~ "Flower en ajoutant d'autres messages "
#~ "pertinents pour ton application. Tu peux"
#~ " y parvenir facilement en procédant "
#~ "comme suit."

#~ msgid ""
#~ "In this way your logger will show,"
#~ " in addition to the default messages,"
#~ " the ones introduced by the clients"
#~ " as specified above."
#~ msgstr ""
#~ "De cette façon, ton logger affichera,"
#~ " en plus des messages par défaut, "
#~ "ceux introduits par les clients comme"
#~ " spécifié ci-dessus."

#~ msgid "Log to a remote service"
#~ msgstr "Se connecter à un service distant"

#~ msgid ""
#~ "The :code:`fl.common.logger.configure` function, "
#~ "also allows specifying a host to "
#~ "which logs can be pushed (via "
#~ ":code:`POST`) through a native Python "
#~ ":code:`logging.handler.HTTPHandler`. This is a "
#~ "particularly useful feature in "
#~ ":code:`gRPC`-based Federated Learning workloads "
#~ "where otherwise gathering logs from all"
#~ " entities (i.e. the server and the"
#~ " clients) might be cumbersome. Note "
#~ "that in Flower simulation, the server"
#~ " automatically displays all logs. You "
#~ "can still specify a :code:`HTTPHandler` "
#~ "should you whish to backup or "
#~ "analyze the logs somewhere else."
#~ msgstr ""
#~ "La fonction :code:`fl.common.logger.configure` "
#~ "permet également de spécifier un hôte"
#~ " vers lequel les journaux peuvent "
#~ "être envoyés (via :code:`POST`) par "
#~ "l'intermédiaire d'un :code:`logging.handler.HTTPHandler`"
#~ " natif de Python. Il s'agit d'une "
#~ "fonction particulièrement utile dans les "
#~ "charges de travail d'apprentissage fédéré "
#~ "basées sur :code:`gRPC` où la collecte"
#~ " des journaux de toutes les entités"
#~ " (c'est-à-dire le serveur et les "
#~ "clients) pourrait s'avérer fastidieuse. Notez"
#~ " que dans la simulation Flower, le"
#~ " serveur affiche automatiquement tous les"
#~ " journaux. Vous pouvez toujours spécifier"
#~ " un :code:`HTTPHandler` si vous souhaitez"
#~ " sauvegarder ou analyser les journaux "
#~ "à un autre endroit."

#~ msgid "Enable SSL connections"
#~ msgstr "Collecte centralisée des données"

#~ msgid "Python version"
#~ msgstr "Version Python"

#~ msgid ""
#~ "Flower requires at least `Python 3.7 "
#~ "<https://docs.python.org/3.7/>`_, but `Python 3.8"
#~ " <https://docs.python.org/3.7/>`_ or above is "
#~ "recommended."
#~ msgstr ""
#~ "Flower nécessite `Python 3.7 "
#~ "<https://docs.python.org/3.7/>`_ ou plus, nous "
#~ "recommandons `Python 3.8 "
#~ "<https://docs.python.org/3.8/>`_."

#~ msgid "Run simulations"
#~ msgstr "Simulation de moniteur"

#~ msgid ""
#~ "Simulating Federated Learning workloads is "
#~ "useful for a multitude of use-"
#~ "cases: you might want to run your"
#~ " workload on a large cohort of "
#~ "clients but without having to source,"
#~ " configure and mange a large number"
#~ " of physical devices; you might want"
#~ " to run your FL workloads as "
#~ "fast as possible on the compute "
#~ "systems you have access to without "
#~ "having to go through a complex "
#~ "setup process; you might want to "
#~ "validate your algorithm on different "
#~ "scenarios at varying levels of data "
#~ "and system heterogeneity, client availability,"
#~ " privacy budgets, etc. These are "
#~ "among some of the use-cases where"
#~ " simulating FL workloads makes sense. "
#~ "Flower can accommodate these scenarios "
#~ "by means of its `VirtualClientEngine "
#~ "<contributor-explanation-architecture.html#virtual-"
#~ "client-engine>`_ or VCE."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`VirtualClientEngine` schedules, launches"
#~ " and manages `virtual` clients. These "
#~ "clients are identical to `non-virtual`"
#~ " clients (i.e. the ones you launch"
#~ " via the command `flwr.client.start_client"
#~ " <ref-api-flwr.html#start-client>`_)"
#~ " in the sense that they can be"
#~ " configure by creating a class "
#~ "inheriting, for example, from "
#~ "`flwr.client.NumPyClient <ref-api-"
#~ "flwr.html#flwr.client.NumPyClient>`_ and therefore "
#~ "behave in an identical way. In "
#~ "addition to that, clients managed by "
#~ "the :code:`VirtualClientEngine` are:"
#~ msgstr ""

#~ msgid ""
#~ "resource-aware: this means that each "
#~ "client gets assigned a portion of "
#~ "the compute and memory on your "
#~ "system. You as a user can control"
#~ " this at the beginning of the "
#~ "simulation and allows you to control "
#~ "the degree of parallelism of your "
#~ "Flower FL simulation. The fewer the "
#~ "resources per client, the more clients"
#~ " can run concurrently on the same "
#~ "hardware."
#~ msgstr ""

#~ msgid ""
#~ "self-managed: this means that you "
#~ "as a user do not need to "
#~ "launch clients manually, instead this "
#~ "gets delegated to :code:`VirtualClientEngine`'s "
#~ "internals."
#~ msgstr ""

#~ msgid ""
#~ "ephemeral: this means that a client "
#~ "is only materialized when it is "
#~ "required in the FL process (e.g. "
#~ "to do `fit() <ref-api-"
#~ "flwr.html#flwr.client.Client.fit>`_). The object is"
#~ " destroyed afterwards, releasing the "
#~ "resources it was assigned and allowing"
#~ " in this way other clients to "
#~ "participate."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`VirtualClientEngine` implements `virtual`"
#~ " clients using `Ray <https://www.ray.io/>`_, "
#~ "an open-source framework for scalable"
#~ " Python workloads. In particular, Flower's"
#~ " :code:`VirtualClientEngine` makes use of "
#~ "`Actors <https://docs.ray.io/en/latest/ray-"
#~ "core/actors.html>`_ to spawn `virtual` clients"
#~ " and run their workload."
#~ msgstr ""

#~ msgid "Launch your Flower simulation"
#~ msgstr ""

#~ msgid ""
#~ "Running Flower simulations still require "
#~ "you to define your client class, a"
#~ " strategy, and utility functions to "
#~ "download and load (and potentially "
#~ "partition) your dataset. With that out"
#~ " of the way, launching your "
#~ "simulation is done with `start_simulation "
#~ "<ref-api-flwr.html#flwr.simulation.start_simulation>`_ "
#~ "and a minimal example looks as "
#~ "follows:"
#~ msgstr ""

#~ msgid "VirtualClientEngine resources"
#~ msgstr "Moteur de client virtuel"

#~ msgid ""
#~ "By default the VCE has access to"
#~ " all system resources (i.e. all CPUs,"
#~ " all GPUs, etc) since that is "
#~ "also the default behavior when starting"
#~ " Ray. However, in some settings you"
#~ " might want to limit how many "
#~ "of your system resources are used "
#~ "for simulation. You can do this "
#~ "via the :code:`ray_init_args` input argument"
#~ " to :code:`start_simulation` which the VCE"
#~ " internally passes to Ray's "
#~ ":code:`ray.init` command. For a complete "
#~ "list of settings you can configure "
#~ "check the `ray.init <https://docs.ray.io/en/latest"
#~ "/ray-core/api/doc/ray.init.html#ray-init>`_ "
#~ "documentation. Do not set "
#~ ":code:`ray_init_args` if you want the "
#~ "VCE to use all your system's CPUs"
#~ " and GPUs."
#~ msgstr ""

#~ msgid "Assigning client resources"
#~ msgstr ""

#~ msgid ""
#~ "By default the :code:`VirtualClientEngine` "
#~ "assigns a single CPU core (and "
#~ "nothing else) to each virtual client."
#~ " This means that if your system "
#~ "has 10 cores, that many virtual "
#~ "clients can be concurrently running."
#~ msgstr ""

#~ msgid ""
#~ "More often than not, you would "
#~ "probably like to adjust the resources"
#~ " your clients get assigned based on"
#~ " the complexity (i.e. compute and "
#~ "memory footprint) of your FL workload."
#~ " You can do so when starting "
#~ "your simulation by setting the argument"
#~ " `client_resources` to `start_simulation <ref-"
#~ "api-flwr.html#flwr.simulation.start_simulation>`_. Two "
#~ "keys are internally used by Ray to"
#~ " schedule and spawn workloads (in our"
#~ " case Flower clients):"
#~ msgstr ""

#~ msgid ":code:`num_cpus` indicates the number of CPU cores a client would get."
#~ msgstr ""

#~ msgid ""
#~ ":code:`num_gpus` indicates the **ratio** of"
#~ " GPU memory a client gets assigned."
#~ msgstr ""

#~ msgid "Let's see a few examples:"
#~ msgstr ""

#~ msgid ""
#~ "While the :code:`client_resources` can be "
#~ "used to control the degree of "
#~ "concurrency in your FL simulation, this"
#~ " does not stop you from running "
#~ "dozens, hundreds or even thousands of"
#~ " clients in the same round and "
#~ "having orders of magnitude more "
#~ "`dormant` (i.e. not participating in a"
#~ " round) clients. Let's say you want"
#~ " to have 100 clients per round "
#~ "but your system can only accommodate "
#~ "8 clients concurrently. The "
#~ ":code:`VirtualClientEngine` will schedule 100 "
#~ "jobs to run (each simulating a "
#~ "client sampled by the strategy) and "
#~ "then will execute them in a "
#~ "resource-aware manner in batches of "
#~ "8."
#~ msgstr ""

#~ msgid ""
#~ "To understand all the intricate details"
#~ " on how resources are used to "
#~ "schedule FL clients and how to "
#~ "define custom resources, please take a"
#~ " look at the `Ray documentation "
#~ "<https://docs.ray.io/en/latest/ray-"
#~ "core/scheduling/resources.html>`_."
#~ msgstr ""

#~ msgid "Simulation examples"
#~ msgstr "Exemples de PyTorch"

#~ msgid ""
#~ "A few ready-to-run complete "
#~ "examples for Flower simulation in "
#~ "Tensorflow/Keras and PyTorch are provided "
#~ "in the `Flower repository "
#~ "<https://github.com/adap/flower>`_. You can run "
#~ "them on Google Colab too:"
#~ msgstr ""

#~ msgid ""
#~ "`Tensorflow/Keras Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_: 100 clients collaboratively "
#~ "train a MLP model on MNIST."
#~ msgstr ""
#~ "`Quickstart TensorFlow (Code) "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "tensorflow>`_"

#~ msgid ""
#~ "`PyTorch Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "pytorch>`_: 100 clients collaboratively train"
#~ " a CNN model on MNIST."
#~ msgstr ""
#~ "`Quickstart PyTorch (Code) "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "pytorch>`_"

#~ msgid ""
#~ "Flower's :code:`VirtualClientEngine` allows you "
#~ "to run FL simulations across multiple"
#~ " compute nodes. Before starting your "
#~ "multi-node simulation ensure that you:"
#~ msgstr ""

#~ msgid "Have the same Python environment in all nodes."
#~ msgstr ""

#~ msgid "Have a copy of your code (e.g. your entire repo) in all nodes."
#~ msgstr ""

#~ msgid ""
#~ "Have a copy of your dataset in "
#~ "all nodes (more about this in "
#~ ":ref:`simulation considerations <considerations-"
#~ "for-simulations>`)"
#~ msgstr ""

#~ msgid ""
#~ "Pass :code:`ray_init_args={\"address\"=\"auto\"}` to "
#~ "`start_simulation <ref-api-"
#~ "flwr.html#flwr.simulation.start_simulation>`_ so the "
#~ ":code:`VirtualClientEngine` attaches to a "
#~ "running Ray instance."
#~ msgstr ""

#~ msgid ""
#~ "Start Ray on you head node: on "
#~ "the terminal type :code:`ray start "
#~ "--head`. This command will print a "
#~ "few lines, one of which indicates "
#~ "how to attach other nodes to the"
#~ " head node."
#~ msgstr ""

#~ msgid ""
#~ "Attach other nodes to the head "
#~ "node: copy the command shown after "
#~ "starting the head and execute it "
#~ "on terminal of a new node: for "
#~ "example :code:`ray start "
#~ "--address='192.168.1.132:6379'`"
#~ msgstr ""

#~ msgid ""
#~ "With all the above done, you can"
#~ " run your code from the head "
#~ "node as you would if the "
#~ "simulation was running on a single "
#~ "node."
#~ msgstr ""

#~ msgid ""
#~ "Once your simulation is finished, if "
#~ "you'd like to dismantle your cluster "
#~ "you simply need to run the command"
#~ " :code:`ray stop` in each node's "
#~ "terminal (including the head node)."
#~ msgstr ""

#~ msgid "Multi-node simulation good-to-know"
#~ msgstr ""

#~ msgid ""
#~ "Here we list a few interesting "
#~ "functionality when running multi-node FL"
#~ " simulations:"
#~ msgstr ""

#~ msgid ""
#~ "User :code:`ray status` to check all "
#~ "nodes connected to your head node "
#~ "as well as the total resources "
#~ "available to the :code:`VirtualClientEngine`."
#~ msgstr ""

#~ msgid ""
#~ "When attaching a new node to the"
#~ " head, all its resources (i.e. all"
#~ " CPUs, all GPUs) will be visible "
#~ "by the head node. This means that"
#~ " the :code:`VirtualClientEngine` can schedule "
#~ "as many `virtual` clients as that "
#~ "node can possible run. In some "
#~ "settings you might want to exclude "
#~ "certain resources from the simulation. "
#~ "You can do this by appending "
#~ "`--num-cpus=<NUM_CPUS_FROM_NODE>` and/or `--num-"
#~ "gpus=<NUM_GPUS_FROM_NODE>` in any :code:`ray "
#~ "start` command (including when starting "
#~ "the head)"
#~ msgstr ""

#~ msgid "Considerations for simulations"
#~ msgstr "Simulation de moniteur"

#~ msgid ""
#~ "We are actively working on these "
#~ "fronts so to make it trivial to"
#~ " run any FL workload with Flower "
#~ "simulation."
#~ msgstr ""

#~ msgid ""
#~ "The current VCE allows you to run"
#~ " Federated Learning workloads in simulation"
#~ " mode whether you are prototyping "
#~ "simple scenarios on your personal laptop"
#~ " or you want to train a complex"
#~ " FL pipeline across multiple high-"
#~ "performance GPU nodes. While we add "
#~ "more capabilities to the VCE, the "
#~ "points below highlight some of the "
#~ "considerations to keep in mind when "
#~ "designing your FL pipeline with Flower."
#~ " We also highlight a couple of "
#~ "current limitations in our implementation."
#~ msgstr ""

#~ msgid "GPU resources"
#~ msgstr "Ressources"

#~ msgid ""
#~ "The VCE assigns a share of GPU "
#~ "memory to a client that specifies "
#~ "the key :code:`num_gpus` in "
#~ ":code:`client_resources`. This being said, Ray"
#~ " (used internally by the VCE) is "
#~ "by default:"
#~ msgstr ""

#~ msgid ""
#~ "not aware of the total VRAM "
#~ "available on the GPUs. This means "
#~ "that if you set :code:`num_gpus=0.5` and"
#~ " you have two GPUs in your "
#~ "system with different (e.g. 32GB and "
#~ "8GB) VRAM amounts, they both would "
#~ "run 2 clients concurrently."
#~ msgstr ""

#~ msgid ""
#~ "not aware of other unrelated (i.e. "
#~ "not created by the VCE) workloads "
#~ "are running on the GPU. Two "
#~ "takeaways from this are:"
#~ msgstr ""

#~ msgid ""
#~ "Your Flower server might need a "
#~ "GPU to evaluate the `global model` "
#~ "after aggregation (by instance when "
#~ "making use of the `evaluate method "
#~ "<how-to-implement-strategies.html#the-"
#~ "evaluate-method>`_)"
#~ msgstr ""

#~ msgid ""
#~ "If you want to run several "
#~ "independent Flower simulations on the "
#~ "same machine you need to mask-out"
#~ " your GPUs with "
#~ ":code:`CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"` when launching"
#~ " your experiment."
#~ msgstr ""

#~ msgid ""
#~ "In addition, the GPU resource limits "
#~ "passed to :code:`client_resources` are not "
#~ "`enforced` (i.e. they can be exceeded)"
#~ " which can result in the situation"
#~ " of client using more VRAM than "
#~ "the ratio specified when starting the"
#~ " simulation."
#~ msgstr ""

#~ msgid "TensorFlow with GPUs"
#~ msgstr "Exemples de TensorFlow"

#~ msgid ""
#~ "When `using a GPU with TensorFlow "
#~ "<https://www.tensorflow.org/guide/gpu>`_ nearly your "
#~ "entire GPU memory of all your GPUs"
#~ " visible to the process will be "
#~ "mapped. This is done by TensorFlow "
#~ "for optimization purposes. However, in "
#~ "settings such as FL simulations where"
#~ " we want to split the GPU into"
#~ " multiple `virtual` clients, this is "
#~ "not a desirable mechanism. Luckily we"
#~ " can disable this default behavior by"
#~ " `enabling memory growth "
#~ "<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_."
#~ msgstr ""

#~ msgid ""
#~ "This would need to be done in "
#~ "the main process (which is where "
#~ "the server would run) and in each"
#~ " Actor created by the VCE. By "
#~ "means of :code:`actor_kwargs` we can "
#~ "pass the reserved key `\"on_actor_init_fn\"`"
#~ " in order to specify a function "
#~ "to be executed upon actor "
#~ "initialization. In this case, to enable"
#~ " GPU growth for TF workloads. It "
#~ "would look as follows:"
#~ msgstr ""

#~ msgid ""
#~ "This is precisely the mechanism used "
#~ "in `Tensorflow/Keras Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_ example."
#~ msgstr ""
#~ "`Quickstart TensorFlow (Code) "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "tensorflow>`_"

#~ msgid "Multi-node setups"
#~ msgstr ""

#~ msgid ""
#~ "The VCE does not currently offer a"
#~ " way to control on which node a"
#~ " particular `virtual` client is executed."
#~ " In other words, if more than a"
#~ " single node have the resources "
#~ "needed by a client to run, then"
#~ " any of those nodes could get "
#~ "the client workload scheduled onto. "
#~ "Later in the FL process (i.e. in"
#~ " a different round) the same client"
#~ " could be executed by a different "
#~ "node. Depending on how your clients "
#~ "access their datasets, this might "
#~ "require either having a copy of "
#~ "all dataset partitions on all nodes "
#~ "or a dataset serving mechanism (e.g. "
#~ "using nfs, a database) to circumvent "
#~ "data duplication."
#~ msgstr ""

#~ msgid ""
#~ "By definition virtual clients are "
#~ "`stateless` due to their ephemeral "
#~ "nature. A client state can be "
#~ "implemented as part of the Flower "
#~ "client class but users need to "
#~ "ensure this saved to persistent storage"
#~ " (e.g. a database, disk) and that "
#~ "can be retrieve later by the same"
#~ " client regardless on which node it"
#~ " is running from. This is related "
#~ "to the point above also since, in"
#~ " some way, the client's dataset could"
#~ " be seen as a type of `state`."
#~ msgstr ""

#~ msgid "Save and load model checkpoints"
#~ msgstr "Sauvegarde et chargement des points de contrôle PyTorch"

#~ msgid ""
#~ "Flower does not automatically save model"
#~ " updates on the server-side. This "
#~ "how-to guide describes the steps "
#~ "to save (and load) model checkpoints "
#~ "in Flower."
#~ msgstr ""

#~ msgid "Legacy example guides"
#~ msgstr ""

#~ msgid "Contributor tutorials"
#~ msgstr "Configuration du contributeur"

#~ msgid "Contributor explanations"
#~ msgstr "Explications"

#~ msgid "Flower Framework Documentation"
#~ msgstr "Documentation de Flower"

#~ msgid "PyTorch"
#~ msgstr "PyTorch"

#~ msgid "TensorFlow"
#~ msgstr "TensorFlow"

#~ msgid "Flower CLI reference"
#~ msgstr "Client de Flower"

#~ msgid "flwr (Python API reference)"
#~ msgstr "flwr (paquet Python)"

#~ msgid "Unreleased"
#~ msgstr "Inédit"

#~ msgid "**Deprecate Python 3.7**"
#~ msgstr "**Deprecate Python 3.7**"

#~ msgid ""
#~ "Since Python 3.7 reached its end "
#~ "of life (EOL) on 2023-06-27, support "
#~ "for Python 3.7 is now deprecated "
#~ "and will be removed in an upcoming"
#~ " release."
#~ msgstr ""
#~ "Étant donné que Python 3.7 a "
#~ "atteint sa fin de vie (EOL) le "
#~ "2023-06-27, la prise en charge de "
#~ "Python 3.7 est désormais dépréciée et"
#~ " sera supprimée dans une prochaine "
#~ "version."

#~ msgid ""
#~ "**Add new** `FedTrimmedAvg` **strategy** "
#~ "([#1769](https://github.com/adap/flower/pull/1769), "
#~ "[#1853](https://github.com/adap/flower/pull/1853))"
#~ msgstr ""
#~ "**Ajouter un nouveau** `FedTrimmedAvg` "
#~ "**stratégie** "
#~ "([#1769](https://github.com/adap/flower/pull/1769), "
#~ "[#1853](https://github.com/adap/flower/pull/1853))"

#~ msgid ""
#~ "The new `FedTrimmedAvg` strategy implements"
#~ " Trimmed Mean by [Dong Yin, "
#~ "2018](https://arxiv.org/abs/1803.01498)"
#~ msgstr ""
#~ "La nouvelle stratégie `FedTrimmedAvg` met "
#~ "en œuvre la moyenne trimmée par "
#~ "[Dong Yin, 2018](https://arxiv.org/abs/1803.01498)"

#~ msgid ""
#~ "**Add parameter aggregation to** `mt-"
#~ "pytorch` **code example** "
#~ "([#1785](https://github.com/adap/flower/pull/1785))"
#~ msgstr ""
#~ "**Ajouter l'agrégation des paramètres à** "
#~ "`mt-pytorch` **exemple de code** "
#~ "([#1785](https://github.com/adap/flower/pull/1785))"

#~ msgid ""
#~ "The `mt-pytorch` example shows how "
#~ "to aggregate parameters when writing a"
#~ " driver script. The included `driver.py`"
#~ " and `server.py` have been aligned to"
#~ " demonstrate both the low-level way"
#~ " and the high-level way of "
#~ "building server-side logic."
#~ msgstr ""
#~ "L'exemple `mt-pytorch` montre comment "
#~ "agréger des paramètres lors de "
#~ "l'écriture d'un script de pilote. Les"
#~ " fichiers `driver.py` et `server.py` inclus"
#~ " ont été alignés pour démontrer à "
#~ "la fois la manière de bas niveau"
#~ " et la manière de haut niveau "
#~ "de construire la logique côté serveur."

#~ msgid ""
#~ "**Introduce (experimental) gRPC request-"
#~ "response API** "
#~ "([#1867](https://github.com/adap/flower/pull/1867), "
#~ "[#1901](https://github.com/adap/flower/pull/1901))"
#~ msgstr ""
#~ "**Introduire l'API demande-réponse gRPC "
#~ "(expérimentale)** "
#~ "([#1867](https://github.com/adap/flower/pull/1867), "
#~ "[#1901](https://github.com/adap/flower/pull/1901))"

#~ msgid ""
#~ "In addition to the existing gRPC "
#~ "API (based on bidirectional streaming) "
#~ "and the experimental REST API, there "
#~ "is now a new gRPC API that "
#~ "uses a request-response model to "
#~ "communicate with client nodes."
#~ msgstr ""
#~ "En plus de l'API gRPC existante "
#~ "(basée sur un flux bidirectionnel) et"
#~ " de l'API REST expérimentale, il "
#~ "existe désormais une nouvelle API gRPC"
#~ " qui utilise un modèle demande-"
#~ "réponse pour communiquer avec les nœuds"
#~ " clients."

#~ msgid ""
#~ "Please note: The gRPC request-response"
#~ " API is still experimental and will"
#~ " likely change significantly over time."
#~ msgstr ""
#~ "Remarque : l'API requête-réponse gRPC"
#~ " est encore expérimentale et est "
#~ "susceptible de changer de manière "
#~ "significative au fil du temps."

#~ msgid ""
#~ "**Replace the eperimental** "
#~ "`start_client(rest=True)` **with the new** "
#~ "`start_client(transport=\"rest\")` "
#~ "([#1880](https://github.com/adap/flower/pull/1880))"
#~ msgstr ""
#~ "**Remplacez le fichier expérimental** "
#~ "`start_client(rest=True) **par le nouveau** "
#~ "`start_client(transport=\"rest\")` "
#~ "([#1880](https://github.com/adap/flower/pull/1880))"

#~ msgid ""
#~ "The (experimental) `start_client` argument "
#~ "`rest` was deprecated in favor of "
#~ "a new argument `transport`. "
#~ "`start_client(transport=\"rest\")` will yield the"
#~ " same behaviour as `start_client(rest=True)` "
#~ "did before. All code should migrate "
#~ "to the new argument `transport`. The "
#~ "deprecated argument `rest` will be "
#~ "removed in a future release."
#~ msgstr ""

#~ msgid ""
#~ "**Migrate experimental REST API to "
#~ "Starlette** ([2171](https://github.com/adap/flower/pull/2171))"
#~ msgstr ""
#~ "**Migrer l'API REST expérimentale vers "
#~ "Starlette** ([2171](https://github.com/adap/flower/pull/2171))"

#~ msgid ""
#~ "The (experimental) REST API used to "
#~ "be implemented in "
#~ "[FastAPI](https://fastapi.tiangolo.com/), but it has"
#~ " now been migrated to use "
#~ "[Starlette](https://www.starlette.io/) directly."
#~ msgstr ""
#~ "L'API REST (expérimentale) était auparavant"
#~ " implémentée dans "
#~ "[FastAPI](https://fastapi.tiangolo.com/), mais elle "
#~ "a maintenant été migrée pour utiliser"
#~ " directement [Starlette](https://www.starlette.io/)."

#~ msgid ""
#~ "**Add a new gRPC option** "
#~ "([#2197](https://github.com/adap/flower/pull/2197))"
#~ msgstr ""
#~ "**Ajouter une nouvelle option gRPC** "
#~ "([#2197](https://github.com/adap/flower/pull/2197))"

#~ msgid ""
#~ "We now start a gRPC server with"
#~ " the `grpc.keepalive_permit_without_calls` option "
#~ "set to 0 by default. This prevents"
#~ " the clients from sending keepalive "
#~ "pings when there is no outstanding "
#~ "stream."
#~ msgstr ""
#~ "Nous démarrons maintenant un serveur "
#~ "gRPC avec l'option "
#~ "`grpc.keepalive_permit_without_calls` réglée sur 0"
#~ " par défaut, ce qui empêche les "
#~ "clients d'envoyer des pings de maintien"
#~ " lorsqu'il n'y a pas de flux en"
#~ " attente."

#~ msgid ""
#~ "**General improvements** "
#~ "([#1872](https://github.com/adap/flower/pull/1872), "
#~ "[#1866](https://github.com/adap/flower/pull/1866), "
#~ "[#1884](https://github.com/adap/flower/pull/1884))"
#~ msgstr ""
#~ "**Mettre à jour les exemples de "
#~ "code** ([#1291](https://github.com/adap/flower/pull/1291), "
#~ "[#1286](https://github.com/adap/flower/pull/1286), "
#~ "[#1282](https://github.com/adap/flower/pull/1282))"

#~ msgid "Example projects"
#~ msgstr "Exemples"

#~ msgid ""
#~ "`Flower simulation PyTorch "
#~ "<https://colab.research.google.com/github/adap/flower/blob/main/examples"
#~ "/simulation-pytorch/sim.ipynb>`_"
#~ msgstr ""
#~ "`Flower Quickstart (TensorFlow/Keras) "
#~ "<https://colab.research.google.com/github/adap/flower/blob/main/examples/simulation_tensorflow/sim.ipynb>`_"

#~ msgid ""
#~ "`Android Kotlin example "
#~ "<https://flower.dev/docs/examples/android-kotlin.html>`_"
#~ msgstr ""

#~ msgid "`Android Java example <https://flower.dev/docs/examples/android.html>`_"
#~ msgstr ""

#~ msgid "Build a strategy from scratch"
#~ msgstr "Élaborer une stratégie à partir de zéro"

#~ msgid "Customize the client"
#~ msgstr "Création du client IMDBC"

#~ msgid "Get started with Flower"
#~ msgstr ""

#~ msgid "Quickstart Android"
#~ msgstr "Démarrage rapide d'Android"

#~ msgid ""
#~ "Let's build a federated learning system"
#~ " using TFLite and Flower on Android!"
#~ msgstr ""
#~ "Construisons un système d'apprentissage fédéré"
#~ " en utilisant TFLite et Flower sur"
#~ " Android !"

#~ msgid ""
#~ "Please refer to the `full code "
#~ "example "
#~ "<https://github.com/adap/flower/tree/main/examples/android>`_ to"
#~ " learn more."
#~ msgstr ""
#~ "Réfère-toi à l'exemple de code "
#~ "complet "
#~ "<https://github.com/adap/flower/tree/main/examples/android>`_ "
#~ "pour en savoir plus."

#~ msgid "Quickstart iOS"
#~ msgstr "Démarrage rapide iOS"

#~ msgid ""
#~ "In this tutorial we will learn how"
#~ " to train a Neural Network on "
#~ "MNIST using Flower and CoreML on "
#~ "iOS devices."
#~ msgstr ""
#~ "Dans ce tutoriel, nous allons apprendre"
#~ " à former un réseau neuronal sur "
#~ "MNIST en utilisant Flower et CoreML "
#~ "sur les appareils iOS."

#~ msgid ""
#~ "First of all, for running the "
#~ "Flower Python server, it is recommended"
#~ " to create a virtual environment and"
#~ " run everything within a `virtualenv "
#~ "<https://flower.dev/docs/recommended-env-setup.html>`_."
#~ " For the Flower client implementation "
#~ "in iOS, it is recommended to use"
#~ " Xcode as our IDE."
#~ msgstr ""
#~ "Tout d'abord, pour l'exécution du "
#~ "serveur Flower Python, il est recommandé"
#~ " de créer un environnement virtuel et"
#~ " de tout exécuter au sein d'un "
#~ "`virtualenv <https://flower.dev/docs/recommended-env-"
#~ "setup.html>`_. Pour l'implémentation du client"
#~ " Flower dans iOS, il est recommandé"
#~ " d'utiliser Xcode comme notre IDE."

#~ msgid ""
#~ "Our example consists of one Python "
#~ "*server* and two iPhone *clients* that"
#~ " all have the same model."
#~ msgstr ""
#~ "Notre exemple se compose d'un *serveur*"
#~ " Python et de deux *clients* iPhone"
#~ " qui ont tous le même modèle."

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual weight updates for the model"
#~ " based on their local datasets. These"
#~ " updates are then sent to the "
#~ "*server* which will aggregate them to"
#~ " produce a better model. Finally, the"
#~ " *server* sends this improved version "
#~ "of the model back to each "
#~ "*client*. A complete cycle of weight "
#~ "updates is called a *round*."
#~ msgstr ""
#~ "*Les clients* sont chargés de générer"
#~ " des mises à jour de poids "
#~ "individuelles pour le modèle en fonction"
#~ " de leurs ensembles de données "
#~ "locaux. Ces mises à jour sont "
#~ "ensuite envoyées au *serveur* qui les"
#~ " agrège pour produire un meilleur "
#~ "modèle. Enfin, le *serveur* renvoie "
#~ "cette version améliorée du modèle à "
#~ "chaque *client*. Un cycle complet de "
#~ "mises à jour de poids s'appelle un"
#~ " *round*."

#~ msgid ""
#~ "Now that we have a rough idea "
#~ "of what is going on, let's get "
#~ "started to setup our Flower server "
#~ "environment. We first need to install"
#~ " Flower. You can do this by "
#~ "using pip:"
#~ msgstr ""
#~ "Maintenant que nous avons une idée "
#~ "approximative de ce qui se passe, "
#~ "commençons à configurer notre environnement"
#~ " de serveur Flower. Nous devons "
#~ "d'abord installer Flower, ce que tu "
#~ "peux faire à l'aide de pip :"

#~ msgid "Or Poetry:"
#~ msgstr "Ou de la poésie :"

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training using CoreML "
#~ "as our local training pipeline and "
#~ "MNIST as our dataset. For simplicity "
#~ "reasons we will use the complete "
#~ "Flower client with CoreML, that has "
#~ "been implemented and stored inside the"
#~ " Swift SDK. The client implementation "
#~ "can be seen below:"
#~ msgstr ""
#~ "Maintenant que toutes nos dépendances "
#~ "sont installées, exécutons une simple "
#~ "formation distribuée en utilisant CoreML "
#~ "comme pipeline de formation local et "
#~ "MNIST comme ensemble de données. Pour"
#~ " des raisons de simplicité, nous "
#~ "utiliserons le client Flower complet "
#~ "avec CoreML, qui a été mis en "
#~ "œuvre et stocké à l'intérieur du "
#~ "SDK Swift. La mise en œuvre du "
#~ "client peut être vue ci-dessous :"

#~ msgid ""
#~ "Let's create a new application project"
#~ " in Xcode and add :code:`flwr` as "
#~ "a dependency in your project. For "
#~ "our application, we will store the "
#~ "logic of our app in "
#~ ":code:`FLiOSModel.swift` and the UI elements"
#~ " in :code:`ContentView.swift`. We will "
#~ "focus more on :code:`FLiOSModel.swift` in "
#~ "this quickstart. Please refer to the "
#~ "`full code example "
#~ "<https://github.com/adap/flower/tree/main/examples/ios>`_ to "
#~ "learn more about the app."
#~ msgstr ""
#~ "Créons un nouveau projet d'application "
#~ "dans Xcode et ajoutons :code:`flwr` "
#~ "comme dépendance dans ton projet. Pour"
#~ " notre application, nous stockerons la "
#~ "logique de notre application dans "
#~ ":code:`FLiOSModel.swift` et les éléments de"
#~ " l'interface utilisateur dans "
#~ ":code:`ContentView.swift`.Nous nous concentrerons "
#~ "davantage sur :code:`FLiOSModel.swift` dans ce"
#~ " quickstart. N'hésite pas à te "
#~ "référer à l'`exemple de code complet "
#~ "<https://github.com/adap/flower/tree/main/examples/ios>`_ pour"
#~ " en savoir plus sur l'application."

#~ msgid "Import Flower and CoreML related packages in :code:`FLiOSModel.swift`:"
#~ msgstr ""
#~ "Importe les paquets liés à Flower "
#~ "et CoreML dans :code:`FLiOSModel.swift` :"

#~ msgid ""
#~ "Then add the mlmodel to the "
#~ "project simply by drag-and-drop, "
#~ "the mlmodel will be bundled inside "
#~ "the application during deployment to "
#~ "your iOS device. We need to pass"
#~ " the url to access mlmodel and "
#~ "run CoreML machine learning processes, "
#~ "it can be retrieved by calling the"
#~ " function :code:`Bundle.main.url`. For the "
#~ "MNIST dataset, we need to preprocess "
#~ "it into :code:`MLBatchProvider` object. The"
#~ " preprocessing is done inside "
#~ ":code:`DataLoader.swift`."
#~ msgstr ""
#~ "Ensuite, ajoute le mlmodel au projet "
#~ "simplement par glisser-déposer, le "
#~ "mlmodel sera regroupé à l'intérieur de"
#~ " l'application lors du déploiement sur "
#~ "ton appareil iOS. Nous devons passer "
#~ "l'url pour accéder au mlmodel et "
#~ "exécuter les processus d'apprentissage "
#~ "automatique CoreML, elle peut être "
#~ "récupérée en appelant la fonction "
#~ ":code:`Bundle.main.url`. Pour l'ensemble de "
#~ "données MNIST, nous devons le prétraiter"
#~ " dans l'objet :code:`MLBatchProvider`. Le "
#~ "prétraitement est effectué à l'intérieur "
#~ "de :code:`DataLoader.swift`."

#~ msgid ""
#~ "Since CoreML does not allow the "
#~ "model parameters to be seen before "
#~ "training, and accessing the model "
#~ "parameters during or after the training"
#~ " can only be done by specifying "
#~ "the layer name, we need to know"
#~ " this informations beforehand, through "
#~ "looking at the model specification, "
#~ "which are written as proto files. "
#~ "The implementation can be seen in "
#~ ":code:`MLModelInspect`."
#~ msgstr ""
#~ "Comme CoreML ne permet pas de voir"
#~ " les paramètres du modèle avant la"
#~ " formation, et que l'accès aux "
#~ "paramètres du modèle pendant ou après"
#~ " la formation ne peut se faire "
#~ "qu'en spécifiant le nom de la "
#~ "couche, nous devons connaître ces "
#~ "informations à l'avance, en regardant "
#~ "les spécifications du modèle, qui sont"
#~ " écrites sous forme de fichiers "
#~ "proto. La mise en œuvre peut être"
#~ " vue dans :code:`MLModelInspect`."

#~ msgid ""
#~ "After we have all of the necessary"
#~ " informations, let's create our Flower "
#~ "client."
#~ msgstr ""
#~ "Après avoir obtenu toutes les "
#~ "informations nécessaires, créons notre client"
#~ " Flower."

#~ msgid ""
#~ "Then start the Flower gRPC client "
#~ "and start communicating to the server"
#~ " by passing our Flower client to "
#~ "the function :code:`startFlwrGRPC`."
#~ msgstr ""
#~ "Lance ensuite le client Flower gRPC "
#~ "et commence à communiquer avec le "
#~ "serveur en passant notre client Flower"
#~ " à la fonction :code:`startFlwrGRPC`."

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ "call the provided :code:`MLFlwrClient` and "
#~ "call :code:`startFlwrGRPC()`. The attribute "
#~ ":code:`hostname` and :code:`port` tells the"
#~ " client which server to connect to."
#~ " This can be done by entering "
#~ "the hostname and port in the "
#~ "application before clicking the start "
#~ "button to start the federated learning"
#~ " process."
#~ msgstr ""
#~ "C'est tout pour le client. Il nous"
#~ " suffit d'implémenter :code:`Client` ou "
#~ "d'appeler le :code:`MLFlwrClient` fourni et"
#~ " d'appeler :code:`startFlwrGRPC()`. L'attribut "
#~ ":code:`hostname` et :code:`port` indique au"
#~ " client à quel serveur se connecter."
#~ " Pour ce faire, il suffit d'entrer"
#~ " le nom d'hôte et le port dans"
#~ " l'application avant de cliquer sur "
#~ "le bouton de démarrage pour lancer "
#~ "le processus d'apprentissage fédéré."

#~ msgid ""
#~ "Once the server is running we can"
#~ " start the clients in different "
#~ "terminals. Build and run the client "
#~ "through your Xcode, one through Xcode"
#~ " Simulator and the other by deploying"
#~ " it to your iPhone. To see more"
#~ " about how to deploy your app "
#~ "to iPhone or Simulator visit `here "
#~ "<https://developer.apple.com/documentation/xcode/running-"
#~ "your-app-in-simulator-or-on-a-device>`_."
#~ msgstr ""
#~ "Une fois que le serveur fonctionne, "
#~ "nous pouvons démarrer les clients dans"
#~ " différents terminaux. Construis et exécute"
#~ " le client grâce à ton Xcode, "
#~ "l'un via le simulateur Xcode et "
#~ "l'autre en le déployant sur ton "
#~ "iPhone. Pour en savoir plus sur la"
#~ " façon de déployer ton application "
#~ "sur l'iPhone ou le simulateur, visite"
#~ " `ici <https://developer.apple.com/documentation/xcode"
#~ "/running-your-app-in-simulator-or-"
#~ "on-a-device>`_."

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system in your ios device. The "
#~ "full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/ios>`_ for"
#~ " this example can be found in "
#~ ":code:`examples/ios`."
#~ msgstr ""
#~ "Félicitations ! Tu as réussi à "
#~ "construire et à faire fonctionner ton"
#~ " premier système d'apprentissage fédéré "
#~ "dans ton appareil ios. Le `code "
#~ "source complet "
#~ "<https://github.com/adap/flower/blob/main/examples/ios>`_ de "
#~ "cet exemple se trouve dans "
#~ ":code:`examples/ios`."

#~ msgid ""
#~ "`Star Flower on GitHub "
#~ "<https://github.com/adap/flower>`__ ⭐️ and join "
#~ "the open-source Flower community on "
#~ "Slack to connect, ask questions, and "
#~ "get help: `Join Slack <https://flower.dev"
#~ "/join-slack>`__ 🌼 We'd love to hear"
#~ " from you in the ``#introductions`` "
#~ "channel! And if anything is unclear, "
#~ "head over to the ``#questions`` channel."
#~ msgstr ""
#~ "`Star Flower on GitHub "
#~ "<https://github.com/adap/flower>`__ ⭐️ et rejoignez"
#~ " la communauté open-source Flower sur"
#~ " Slack pour vous connecter, poser des"
#~ " questions et obtenir de l'aide : "
#~ "`Join Slack <https://flower.dev/join-slack>`__ "
#~ "🌼 Nous serions ravis d'avoir de "
#~ "vos nouvelles dans le canal "
#~ "``#introductions`` ! Et si quelque chose"
#~ " n'est pas clair, dirigez-vous vers"
#~ " le canal ``#questions``."

#~ msgid "|bd48315a61c14495babefe3c7918b493|"
#~ msgstr ""

#~ msgid "|c00d9e5b0d324d96b86da8a78b05b14b|"
#~ msgstr ""

#~ msgid "|faae2ee10f4149c9907563c4f48ec6ea|"
#~ msgstr ""

#~ msgid "|13a655510351455292f145a61d6c15d6|"
#~ msgstr ""

#~ msgid "|13949884182846e3a91433190a936ba9|"
#~ msgstr ""

#~ msgid "|9bf26cc650b146e88b4745df040ece37|"
#~ msgstr ""

#~ msgid "|1590915480fc41708bd43e48af9582f9|"
#~ msgstr ""

#~ msgid "|e5ee96d702b64256b97b8ca99db10787|"
#~ msgstr ""

#~ msgid "|84840b244edd47c481278ce534c126cd|"
#~ msgstr ""

#~ msgid "|f33f5ebb3a844a2ba54bb6be3571b172|"
#~ msgstr ""

#~ msgid "|5645db4ba9c945518d51ff234f35c797|"
#~ msgstr ""

#~ msgid "|317af8d28fcc479ab981047d058c4751|"
#~ msgstr ""

#~ msgid "|8bfd0e697a494d5385662debafade6bf|"
#~ msgstr ""

#~ msgid ""
#~ "Differential privacy (DP) is often "
#~ "mentioned in the context of Federated"
#~ " Learning. It is a privacy-preserving"
#~ " method used when analyzing and "
#~ "sharing statistical data, ensuring the "
#~ "privacy of individual participants. DP "
#~ "achieves this by adding statistical "
#~ "noise to the model updates, ensuring "
#~ "any individual participants’ information "
#~ "cannot be distinguished or re-"
#~ "identified. This technique can be "
#~ "considered an optimization that provides "
#~ "a quantifiable privacy protection measure."
#~ msgstr ""
#~ "La confidentialité différentielle (DP) est "
#~ "souvent mentionnée dans le contexte de"
#~ " l'apprentissage fédéré. Il s'agit d'une"
#~ " méthode de préservation de la vie"
#~ " privée utilisée lors de l'analyse et"
#~ " du partage de données statistiques, "
#~ "garantissant la confidentialité des "
#~ "participants individuels. La DP y "
#~ "parvient en ajoutant un bruit "
#~ "statistique aux mises à jour du "
#~ "modèle, garantissant que toute information "
#~ "sur les participants individuels ne peut"
#~ " être distinguée ou réidentifiée. Cette "
#~ "technique peut être considérée comme une"
#~ " optimisation qui fournit une mesure "
#~ "quantifiable de protection de la vie "
#~ "privée."

#~ msgid "|e5dc001d27ad460caeab669e957b3c36|"
#~ msgstr ""

#~ msgid "API Reference - Flower binaries"
#~ msgstr ""

#~ msgid "API Reference - flwr"
#~ msgstr "Référence pour l'API"

#~ msgid ""
#~ "Defines whether or not the client "
#~ "is interacting with the server using "
#~ "the experimental REST API. This feature"
#~ " is experimental, it might change "
#~ "considerably in future versions of "
#~ "Flower."
#~ msgstr ""

#~ msgid "Returns a client's set of properties."
#~ msgstr ""

#~ msgid ""
#~ "Defines whether or not the client "
#~ "is interacting with the server using "
#~ "the experimental REST API. This feature"
#~ " is experimental, it might be change"
#~ " considerably in future versions of "
#~ "Flower."
#~ msgstr ""

#~ msgid ""
#~ "A function creating client instances. "
#~ "The function must take a single "
#~ "str argument called `cid`. It should "
#~ "return a single client instance of "
#~ "type ClientLike. Note that the created"
#~ " client instances are ephemeral and "
#~ "will often be destroyed after a "
#~ "single method invocation. Since client "
#~ "instances are not long-lived, they "
#~ "should not  attempt to carry state "
#~ "over method invocations. Any state "
#~ "required by the instance (model, "
#~ "dataset,hyperparameters, ...) should be "
#~ "(re-)created in either the call to "
#~ "`client_fn` or the call to any of"
#~ " the client methods (e.g., load "
#~ "evaluation data in the `evaluate` method"
#~ " itself)."
#~ msgstr ""

#~ msgid ""
#~ "A function creating client instances. "
#~ "The function must take a single "
#~ "str argument called `cid`. It should "
#~ "return a single client instance of "
#~ "type ClientLike. Note that the created"
#~ " client instances are ephemeral and "
#~ "will often be destroyed after a "
#~ "single method invocation. Since client "
#~ "instances are not long-lived, they "
#~ "should not"
#~ msgstr ""

#~ msgid "attempt to carry state over method invocations. Any state required by"
#~ msgstr ""

#~ msgid ""
#~ "the instance (model, dataset,hyperparameters, "
#~ "...) should be (re-)created in either"
#~ " the call to `client_fn` or the "
#~ "call to any of the client methods"
#~ " (e.g., load evaluation data in the"
#~ " `evaluate` method itself)."
#~ msgstr ""

#~ msgid ""
#~ "\\frac{\\mu}{2} || w - w^t ||^2\n"
#~ "\n"
#~ msgstr ""

#~ msgid ""
#~ "Adaptive Federated Optimization using Adagrad"
#~ " (FedAdagrad) [Reddi et al., 2020] "
#~ "strategy."
#~ msgstr ""

#~ msgid ""
#~ "Adaptive Federated Optimization using Adam "
#~ "(FedAdam) [Reddi et al., 2020] strategy."
#~ msgstr ""

#~ msgid ""
#~ "Adaptive Federated Optimization using Yogi "
#~ "(FedYogi) [Reddi et al., 2020] strategy."
#~ msgstr ""

#~ msgid "Contributing Baselines"
#~ msgstr "Configuration du contributeur"

#~ msgid ""
#~ "Do you have a new federated "
#~ "learning paper and want to add a"
#~ " new baseline to Flower? Or do "
#~ "you want to add an experiment to"
#~ " an existing baseline paper? Great, "
#~ "we really appreciate your contribution."
#~ msgstr ""

#~ msgid ""
#~ "The goal of Flower Baselines is to"
#~ " reproduce experiments from popular papers"
#~ " to accelerate researchers by enabling "
#~ "faster comparisons to new strategies, "
#~ "datasets, models, and federated pipelines "
#~ "in general."
#~ msgstr ""

#~ msgid ""
#~ "Before you start to work on a "
#~ "new baseline or experiment, please check"
#~ " the `Flower Issues "
#~ "<https://github.com/adap/flower/issues>`_ or `Flower "
#~ "Pull Requests <https://github.com/adap/flower/pulls>`_ "
#~ "to see if someone else is already"
#~ " working on it. Please open a "
#~ "new issue if you are planning to"
#~ " work on a new baseline or "
#~ "experiment with a short description of"
#~ " the corresponding paper and the "
#~ "experiment you want to contribute."
#~ msgstr ""

#~ msgid "TL;DR: Adding a new Flower Baseline"
#~ msgstr ""

#~ msgid ""
#~ "Let's say you want to contribute "
#~ "the code of your most recent "
#~ "Federated Learning publication, *FedAweseome*. "
#~ "There are only three steps necessary "
#~ "to create a new *FedAweseome* Flower "
#~ "Baseline:"
#~ msgstr ""

#~ msgid "**Get the Flower source code on your machine**"
#~ msgstr ""

#~ msgid ""
#~ "Fork the Flower codebase: got to "
#~ "the `Flower GitHub repo "
#~ "<https://github.com/adap/flower>`_ and fork the "
#~ "code (click the *Fork* button in "
#~ "the top-right corner and follow "
#~ "the instructions)"
#~ msgstr ""

#~ msgid ""
#~ "Clone the (forked) Flower source code:"
#~ " :code:`git clone "
#~ "git@github.com:[your_github_username]/flower.git`"
#~ msgstr ""

#~ msgid ""
#~ "Open the code in your favorite "
#~ "editor (e.g., using VSCode: ``cd flower"
#~ " ; code .``)"
#~ msgstr ""

#~ msgid "**Add the FedAwesome code**"
#~ msgstr ""

#~ msgid ""
#~ "Add your :code:`FedAwesome` code under "
#~ ":code:`baselines/flwr_baselines/publications/[fedawesome]`"
#~ msgstr ""

#~ msgid "Add a `pyproject.toml` with all necessary dependencies"
#~ msgstr ""

#~ msgid "Add a `README.md` describing how to use your baseline"
#~ msgstr ""

#~ msgid "**Open a pull request**"
#~ msgstr ""

#~ msgid "Stage your changes: :code:`git add .`"
#~ msgstr ""

#~ msgid ""
#~ "Commit & push: :code:`git commit -m "
#~ "\"Create new FedAweseome baseline\" ; "
#~ "git push`"
#~ msgstr ""

#~ msgid ""
#~ "Open a pull request: go to *your*"
#~ " fork of the Flower codebase and "
#~ "create a pull request that targets "
#~ "the Flower ``main``` branch"
#~ msgstr ""

#~ msgid "Further reading:"
#~ msgstr "Aide supplémentaire"

#~ msgid ""
#~ "`GitHub docs: About forks "
#~ "<https://docs.github.com/en/pull-requests/collaborating-"
#~ "with-pull-requests/working-with-forks/about-"
#~ "forks>`_"
#~ msgstr ""

#~ msgid ""
#~ "`GitHub docs: Creating a pull request"
#~ " <https://docs.github.com/en/pull-requests/collaborating-"
#~ "with-pull-requests/proposing-changes-to-"
#~ "your-work-with-pull-requests/creating-a-pull-"
#~ "request>`_"
#~ msgstr ""

#~ msgid ""
#~ "`GitHub docs: Creating a pull request"
#~ " from a fork <https://docs.github.com/en/pull-"
#~ "requests/collaborating-with-pull-requests"
#~ "/proposing-changes-to-your-work-with-"
#~ "pull-requests/creating-a-pull-request-from-a-fork>`_"
#~ msgstr ""

#~ msgid "Requirements"
#~ msgstr "Changements nécessaires"

#~ msgid ""
#~ "Contributing a new baseline is really"
#~ " easy. You only have to make "
#~ "sure that your federated learning "
#~ "experiments are running with Flower. As"
#~ " soon as you have created a "
#~ "Flower-based experiment, you can contribute"
#~ " it."
#~ msgstr ""

#~ msgid ""
#~ "It is recommended (but not required) "
#~ "to use `Hydra <https://hydra.cc/>`_ to "
#~ "execute the experiment."
#~ msgstr ""

#~ msgid ""
#~ "Please make sure to add your "
#~ "baseline or experiment to the "
#~ "corresponding directory as explained in "
#~ "`Executing Baseline <https://flower.dev/docs/using-"
#~ "baselines.html>`_. Give your baseline the "
#~ "unique identifier. For example, :code:`fedbn`"
#~ " refers to the paper \"FedBN: "
#~ "Federated Learning on non-IID Features"
#~ " via Local Batch Normalization\" and "
#~ "creates the corresponding directory "
#~ ":code:`flower/baselines/flwr_baselines/publications/fedbn`. Then"
#~ " you create the experiment directory "
#~ "with the experiment name. For example,"
#~ " the experiment that measures the "
#~ "convergence has the directory "
#~ ":code:`flower/baselines/flwr_baselines/publications/fedbn/convergence_rate`."
#~ " This directory contains all your "
#~ "code and a :code:`README.md` with a "
#~ "link to the paper, the paper's "
#~ "abstract, and a detailed description of"
#~ " how to execute the experiments."
#~ msgstr ""

#~ msgid ""
#~ "Please also check if :code:`pyproject.toml`"
#~ " and :code:`requirements.txt` (all in the"
#~ " directory `baselines "
#~ "<https://github.com/adap/flower/blob/main/baselines>`_ contain"
#~ " all required Python packages (libraries,"
#~ " frameworks, ...). If the required "
#~ "Python package is not yet listed, "
#~ "please add it to :code:`pyproject.toml`. "
#~ "If you need a different version of"
#~ " a package already listed, please try"
#~ " to ensure your experiment runs with"
#~ " the existing version listed in "
#~ ":code:`pyproject.toml` (or :code:`requirements.txt`). "
#~ "If that doesn't work, open a "
#~ "GitHub Issue and request the version "
#~ "change."
#~ msgstr ""

#~ msgid ""
#~ "The experiment also needs to contain "
#~ "a file with a downloader for the"
#~ " dataset - if possible automatic. "
#~ "This can be included in one of "
#~ "the files or as an extra file."
#~ msgstr ""

#~ msgid ""
#~ "Finally, please add plots for all "
#~ "experimental results your code is "
#~ "running to the :code:`experiment` directory"
#~ " and include them in :code:`README.md`. "
#~ "Doing this helps others and enables "
#~ "them to recognize your contributions "
#~ "quickly."
#~ msgstr ""

#~ msgid ""
#~ "We are aware that a few libraries"
#~ " are available only via Conda. "
#~ "However, we want to encourage you "
#~ "to ensure that your code also runs"
#~ " well outside of Conda to make "
#~ "it more accessible to the broader "
#~ "research community."
#~ msgstr ""

#~ msgid "Here is a checklist for adding a new baseline:"
#~ msgstr ""

#~ msgid ""
#~ "add required Python packages to "
#~ ":code:`pyproject.toml` or :code:`requirements.txt`"
#~ msgstr ""

#~ msgid ""
#~ "add all required code under "
#~ ":code:`baselines/flwr_baselines/publications/[new_publication]`"
#~ msgstr ""

#~ msgid "add a dataset downloader"
#~ msgstr ""

#~ msgid "add an experiment plot"
#~ msgstr ""

#~ msgid "add a :code:`README.md`"
#~ msgstr ""

#~ msgid "Usability"
#~ msgstr ""

#~ msgid ""
#~ "Flower is known and loved for its"
#~ " usability. Therefore, make sure that "
#~ "your baseline or experiment can be "
#~ "executed with a single command such "
#~ "as :code:`./run.sh` or :code:`python3 "
#~ "main.py`. How you organize the "
#~ "experiments and the related code "
#~ "structure is up to you as an "
#~ "author, but please keep in mind to"
#~ " make sure that other users can "
#~ "easily understand and execute your "
#~ "baseline."
#~ msgstr ""

#~ msgid "We look forward to your contribution!"
#~ msgstr "Exemple de première contribution"

#~ msgid "flwr"
#~ msgstr "Fleur"

#~ msgid "binaries"
#~ msgstr ""

#~ msgid "Flower Baselines"
#~ msgstr "Demande pour une nouvelle Flower Baseline"

#~ msgid ""
#~ "Flower Baselines are a collection of "
#~ "organised scripts used to reproduce "
#~ "results from well-known publications or"
#~ " benchmarks. You can check which "
#~ "baselines already exist and/or contribute "
#~ "your own baseline."
#~ msgstr ""

#~ msgid "Flower requires `Python 3.7 <https://docs.python.org/3.7/>`_ or above."
#~ msgstr "`Python 3.7 <https://docs.python.org/3.7/>`_ ou plus"

#~ msgid "|9e234df38403464899ad3aee36bf1b95|"
#~ msgstr ""

#~ msgid "|081158351506446f9f772cb45ee68523|"
#~ msgstr ""

#~ msgid "|e9325042b79c45ed96b5a8d2f6f3cdc9|"
#~ msgstr ""

#~ msgid "|11b83bb107344db78a37266e080c4a7a|"
#~ msgstr ""

#~ msgid "|cd764bcf6d174a9cb62880ace9a8a6bd|"
#~ msgstr ""

#~ msgid "|5c520984cced41e38f6bb4af416c3f84|"
#~ msgstr ""

#~ msgid "|66941b0608644cf1a2269a194d3bc0dd|"
#~ msgstr ""

#~ msgid "|4b149f3a095b402bb8890275aabc9298|"
#~ msgstr ""

#~ msgid "|675cf7d3d53a4817b5d47529c0758158|"
#~ msgstr ""

#~ msgid "|7ca594e16ae7477790c2e3cf096ec7cd|"
#~ msgstr ""

#~ msgid "|d669336577b545a081d5d74169a9bc4d|"
#~ msgstr ""

#~ msgid "|00b3d6cde1ff410ba54eff58da4e033a|"
#~ msgstr ""

#~ msgid "|29a11f5353084c1995c538f7edef71a5|"
#~ msgstr ""

#~ msgid "|d62eda312fd44726bb5db2b761fe7e0d|"
#~ msgstr ""

#~ msgid "Using Baselines"
#~ msgstr ""

#~ msgid "Structure"
#~ msgstr ""

#~ msgid ""
#~ "All baselines are available in the "
#~ "directory `baselines "
#~ "<https://github.com/adap/flower/blob/main/baselines>`_. This "
#~ "directory has two different files:"
#~ msgstr ""

#~ msgid ""
#~ "Both files contain all the information"
#~ " about required Python packages (libraries,"
#~ " frameworks, ...) and their versions. "
#~ "You can install each library separately"
#~ " by using :code: `pip install` or "
#~ "you can use Poetry and run "
#~ "code:`poetry install` in the directory "
#~ "where you find the :code:`pyproject.toml` "
#~ "file. After installing all requirements, "
#~ "you can start to run your "
#~ "baseline."
#~ msgstr ""

#~ msgid ""
#~ "Go to the baseline that you want"
#~ " to execute. The directories and "
#~ "files are structured so that you "
#~ "can first find the paper with "
#~ "their unique identifier such that, for"
#~ " example, :code:`FedProx` refers to the "
#~ "paper \"Federated Optimization in "
#~ "Heterogeneous Networks\". The :code:`fedprox` "
#~ "section contains all available experiments "
#~ "from that paper."
#~ msgstr ""

#~ msgid ""
#~ "The experiment area contains a "
#~ ":code:`README.md` covering the corresponding "
#~ "paper, its abstract, and goal as "
#~ "well as a detailed description of "
#~ "how to run the baseline. Please "
#~ "use the :code:`README.md` to see how "
#~ "to execute each individual baseline."
#~ msgstr ""

#~ msgid "Available Baselines"
#~ msgstr ""

#~ msgid ""
#~ "The following table lists all currently"
#~ " available baselines and the corresponding"
#~ " papers. If you want to add a"
#~ " new baseline or experiment, please "
#~ "check the `Contributing Baselines "
#~ "<https://flower.dev/docs/contributing-baselines.html>`_ "
#~ "section."
#~ msgstr ""

#~ msgid "Paper"
#~ msgstr ""

#~ msgid "Experiment"
#~ msgstr ""

#~ msgid "Directory"
#~ msgstr ""

#~ msgid "`FedAvg <https://arxiv.org/abs/1602.05629>`_"
#~ msgstr ""

#~ msgid "MNIST"
#~ msgstr ""

#~ msgid ":code:`flower/baselines/flwr_baselines/publications/fedavg_mnist/`"
#~ msgstr ""

#~ msgid "`FedProx <https://arxiv.org/abs/1812.06127>`_"
#~ msgstr ""

#~ msgid ":code:`flower/baselines/flwr_baselines/publications/fedprox_mnist/`"
#~ msgstr ""

#~ msgid "`FedOpt <https://arxiv.org/abs/2003.00295>`_"
#~ msgstr ""

#~ msgid "sparse gradient task"
#~ msgstr ""

#~ msgid ":code:`flower/baselines/flwr_baselines/publications/adaptive_federated_optimization`"
#~ msgstr ""

#~ msgid "`FedBN <https://arxiv.org/abs/2102.07623>`_"
#~ msgstr ""

#~ msgid "convergence rate"
#~ msgstr ""

#~ msgid ":code:`flower/baselines/flwr_baselines/publications/fedbn/convergence_rate`"
#~ msgstr ""

#~ msgid ""
#~ "Flower requires `Python 3.7 "
#~ "<https://docs.python.org/3.7/>`_ or above, we "
#~ "recommend `Python 3.8 "
#~ "<https://docs.python.org/3.8/>`_."
#~ msgstr ""
#~ "Flower nécessite `Python 3.7 "
#~ "<https://docs.python.org/3.7/>`_ ou plus, nous "
#~ "recommandons `Python 3.8 "
#~ "<https://docs.python.org/3.8/>`_."

#~ msgid "|6baade94cd14454e82ead34fcc29a182|"
#~ msgstr ""

#~ msgid "|1209ecd819104c458d396cf665c7ed4f|"
#~ msgstr ""

#~ msgid "|c088b02349304344a53f3ce1464225fb|"
#~ msgstr ""

#~ msgid "|b54d50afc82a4a57a55997a9eaeb735b|"
#~ msgstr ""

#~ msgid "|d17b57e97b714a25b43790d4b832fd87|"
#~ msgstr ""

#~ msgid "|38966d05301a4854aa73c8c5033bfaab|"
#~ msgstr ""

#~ msgid "|231d55f7926d4a5db02dcd724ec62529|"
#~ msgstr ""

#~ msgid "|fb44f2e13a1b4b69b7a72234eedd13f4|"
#~ msgstr ""

#~ msgid "|1cfc77af5d164030942e84d14268c256|"
#~ msgstr ""

#~ msgid "|0d50828231a64bc08223544a2d2fa216|"
#~ msgstr ""

#~ msgid "|904387757ceb42fbaa1875f3e8061113|"
#~ msgstr ""

#~ msgid "|68608e1b7c4842458c528b431c715f5a|"
#~ msgstr ""

#~ msgid "|2adb106bda97480bb4b33eac472e321e|"
#~ msgstr ""

#~ msgid "|025f0a6f7a6145cba4bf8fa0e2495851|"
#~ msgstr ""

